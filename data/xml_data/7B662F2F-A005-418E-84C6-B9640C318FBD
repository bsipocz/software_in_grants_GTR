<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:department>Sch of Engineering</gtr:department><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/536116AC-C155-4A24-A743-309BD68E50CE"><gtr:id>536116AC-C155-4A24-A743-309BD68E50CE</gtr:id><gtr:name>Defence Science &amp; Tech Lab DSTL</gtr:name><gtr:address><gtr:line1>Defence Science &amp; Tech Lab - MOD</gtr:line1><gtr:line2>Porton Down</gtr:line2><gtr:line4>Salisbury</gtr:line4><gtr:postCode>SP4 0JQ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/4E8EB4C1-E188-4F55-BAD5-C8CC9793F508"><gtr:id>4E8EB4C1-E188-4F55-BAD5-C8CC9793F508</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Chalmers</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/575A6F4A-0387-40D4-AE84-47959F3C1DDF"><gtr:id>575A6F4A-0387-40D4-AE84-47959F3C1DDF</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:surname>Horton</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD032148%2F2"><gtr:id>7B662F2F-A005-418E-84C6-B9640C318FBD</gtr:id><gtr:title>High Dynamic Range for High Fidelity Image Synthesis of Real Scenes</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D032148/2</gtr:grantReference><gtr:abstractText>The computer graphics industry, and in particular those involved with films, games, simulation, virtual reality and military applications, continue to demand more realistic computer-generated images, that is computed images that more accurately match the real scene they are intended to represent. This is particularly challenging when considering images of the natural world, which presents our visual system with a wide range of colours and intensities. In most real scenes, for example, looking from inside a house towards a window, the ratio between the darkest areas (e.g. inside the room) and the brightest area (outside the window), the so-called contrast ratio, could be many thousands to one. A typical computer monitor only has a contrast ratio of about 100:1 and is thus incapable of accurately displaying such scenes.A number of appearance-preserving, or tone-mapping, operators (TMOs) have been developed in order to try achieve a perceptual match between the real-world scene and what is displayed on the computer monitor. However, it has not yet been possible to validate the fidelity of these TMOs thoroughly against the real scenes they are trying to portray. The recent development of novel, high dynamic range (HDR) displays, capable of 75,000:1 contrast ratio now provide the opportunity to compute and display computer-generated images that are perceptually much closer to the real world.This research proposal will use these novel HDR displays to evaluate existing TMOs to see how well they do preserve the appearance of the real scenes, and will use the insights gained to develop new, more accurate TMOs for existing computer monitors and HDR displays. A framework will also be produced that will provide a straightforward, objective way of comparing real and synthetic images. Two applications, which are critically dependent on the realism of computed images, are virtual archaeology and military simulations. When investigating past environments on a computer, failure to produce images that accurately match what the past environment may have looked like, may in fact lead to the archaeologists misinterpreting the past. Similarly, the incorrect display of a military vehicle attempting to camouflage in a certain terrain may lead to detection of the vehicle in the real battlefield scenario. We will use specific examples from archaeology and camouflage to test the results of our research.</gtr:abstractText><gtr:fund><gtr:end>2009-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>188555</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Public engagement (IBC)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3C25D9AF-29D5-4425-A512-DCAE270F3762</gtr:id><gtr:impact>This is the largest broadcast show in Europe and attracts over 50,000 participants. I was invited to showcase my research in HDR imaging at the Emerging Technologies section of the show.

There was considerable interest - with a large number of requests for future demonstrations and for further information.</gtr:impact><gtr:outcomeId>54639481387ab2.90169829</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.ibc.org</gtr:url><gtr:year>2011,2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Filming a rocket launch (Kennedy Space Centre)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>476C39E6-E49B-4AD6-860E-58D6E02F9285</gtr:id><gtr:impact>I was invited by the Advanced Imaging Lab (AIL) at the Kennedy Space Centre to film a rocket launch with our HDR system to enable them to compare their system and current thinking with ours.

This is one of the first attempts to film a rocket launch with HDR video. The work has attracted a lot of attention and even let to the head of AIL requesting to do a PhD under my supervision at the University of Warwick.</gtr:impact><gtr:outcomeId>546395fcbda436.23845817</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public engagement (NAB 2014)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>1396D788-EA31-4BF8-ACDC-3C6F686127AC</gtr:id><gtr:impact>Invited to participate in the Future Zone of NAB 2012 and 2014 to showcase my research in HDR imaging. This is the world's largest broadcast show attracting over 92,000 participants from over 150 countries.

Large scale interest in the work presented - followed up by request to visit my lab and for further information from a number of companies. I have been invited back to exhibit at NAB 2015 in April 2015.</gtr:impact><gtr:outcomeId>54639323d78fb5.44261122</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.nabshow.com/</gtr:url><gtr:year>2012,2014</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>198187</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Royal Society Industrial Fellowship</gtr:description><gtr:end>2016-08-02</gtr:end><gtr:fundingOrg>The Royal Society</gtr:fundingOrg><gtr:fundingRef>IF120030</gtr:fundingRef><gtr:id>C7171E53-2620-403C-A4D2-608A2524C5FE</gtr:id><gtr:outcomeId>54639eee97e768.77052389</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>137357</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Bespoke high-fidelity visualsiation of tiling</gtr:description><gtr:end>2013-06-02</gtr:end><gtr:fundingOrg>Technology Strategy Board (TSB)</gtr:fundingOrg><gtr:fundingRef>101148</gtr:fundingRef><gtr:id>38468FE5-6DBC-4F2A-AA33-46E3170A8496</gtr:id><gtr:outcomeId>546397c7d620a1.47538254</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2012-06-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>A method for efficiently compressing HDR video</gtr:description><gtr:grantRef>EP/D032148/2</gtr:grantRef><gtr:id>B74BCCC9-9B68-456C-BE71-37FCB8EE7802</gtr:id><gtr:impact>The patent is licensed to the spinout company goHDR and forms the basis for their current Beta product suite.</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>m-4571198424.8563637663f2d2</gtr:outcomeId><gtr:patentId>EP2144444 B1</gtr:patentId><gtr:protection>Patent granted</gtr:protection><gtr:title>HDR Video Data Compression: Devices and methods</gtr:title><gtr:yearProtectionGranted>2009</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>goHDR Ltd</gtr:companyName><gtr:description>To provide compression/decompression solutions for HDR video</gtr:description><gtr:id>64399F87-4C5E-4A49-BF57-2FC443C91272</gtr:id><gtr:impact>Provides a world first complete HDR capture to display pipeline. Now offering Beta products for sale.</gtr:impact><gtr:outcomeId>m-1262269254.0867913308216</gtr:outcomeId><gtr:url>http://www.gohdr.com</gtr:url><gtr:yearCompanyFormed>2009</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>9A81B007-A1BF-44CE-A9CD-A5335E0EBFAC</gtr:id><gtr:title>Advanced High Dynamic Range Imaging</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f4f42d8834cca455f74c0407e7f01260"><gtr:id>f4f42d8834cca455f74c0407e7f01260</gtr:id><gtr:otherNames>Banterle F.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>54639a18274475.20075182</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4773CF0E-1B5F-4E61-9B7D-0909F1C6B67C</gtr:id><gtr:title>Enabling stereoscopic high dynamic range video</gtr:title><gtr:parentPublicationTitle>Signal Processing: Image Communication</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d01f3d1a44ee303d56685423df11ca55"><gtr:id>d01f3d1a44ee303d56685423df11ca55</gtr:id><gtr:otherNames>Selmanovic E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54639bb43c6d43.35464086</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D032148/2</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>FE0A25B4-A898-42A7-A022-0E33E99E046D</gtr:id><gtr:grantRef>EP/D032148/1</gtr:grantRef><gtr:amount>324148.88</gtr:amount><gtr:start>2006-01-01</gtr:start><gtr:end>2007-02-28</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>7B662F2F-A005-418E-84C6-B9640C318FBD</gtr:id><gtr:grantRef>EP/D032148/2</gtr:grantRef><gtr:amount>188555.86</gtr:amount><gtr:start>2007-03-01</gtr:start><gtr:end>2009-03-31</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>