<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948"><gtr:id>58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948</gtr:id><gtr:name>Xerox Corporation</gtr:name><gtr:address><gtr:line1>800 Phillips Road</gtr:line1><gtr:line2>Webster</gtr:line2><gtr:line4>New York 14580</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7"><gtr:id>88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7</gtr:id><gtr:name>University of East Anglia</gtr:name><gtr:department>Computing Sciences</gtr:department><gtr:address><gtr:line1>Earlham Road</gtr:line1><gtr:line4>Norwich</gtr:line4><gtr:line5>Norfolk</gtr:line5><gtr:postCode>NR4 7TJ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7"><gtr:id>88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7</gtr:id><gtr:name>University of East Anglia</gtr:name><gtr:address><gtr:line1>Earlham Road</gtr:line1><gtr:line4>Norwich</gtr:line4><gtr:line5>Norfolk</gtr:line5><gtr:postCode>NR4 7TJ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948"><gtr:id>58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948</gtr:id><gtr:name>Xerox Corporation</gtr:name><gtr:address><gtr:line1>800 Phillips Road</gtr:line1><gtr:line2>Webster</gtr:line2><gtr:line4>New York 14580</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2A5C593E-43C3-4E03-9530-990C61A80560"><gtr:id>2A5C593E-43C3-4E03-9530-990C61A80560</gtr:id><gtr:firstName>Graham</gtr:firstName><gtr:surname>Finlayson</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE012248%2F1"><gtr:id>C73DC3DC-65DC-4C68-BE56-7AB6CD60B630</gtr:id><gtr:title>Colour to grey scale and related transforms</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E012248/1</gtr:grantReference><gtr:abstractText>Every year, millions of poor grey scale reproductions of colour images are made. Through our research we aim to make millions more good grey scale prints.It is now increasingly common to capture images using colour digital cameras and display them on colour monitors or using colour inkjet printers. However, there are still many occasions when colour images are reproduced in greyscale. The use of black and white printers, photocopiers and fax machines is still an every day occurrence. Unfortunately, the conversion of colour images to their greyscale equivalent, either by these devices, or through other means, often results in a poor reproduction of the images. The aim of our research is to develop a method to derive the best possible greyscale reproduction of a colour image, by a careful consideration of the limitations of our own visual system, and by exploiting the underlying physics of colour image formation. Usually, the colour at a given image point is coded by three numbers, and in the greyscale transformation these three numbers are reduced to just one grey value. More generally, colour information might be coded using N (where N&amp;gt;3) numbers, and in this case it is useful to be able to derive methods to reduce these N numbers to 3, or fewer, so that the N-dimensional information recorded can be displayed on conventional imaging technology. We will extend our research to also consider such cases. Our research will lead to the improved reproduction of images on greyscale devices (e.g. improved photocopying and faxing) as well as providing us with the ability to better visualise the information contained in, for example, satellite images. We also expect that it will be possible to exploit the technology we develop to make colour images that can be viewed without error or confusion, by colour-blind observers. In addition, the work will lead to improvements in existing image processing algorithms, and to a better understanding of how our own visual system perceives colour and brightness information.</gtr:abstractText><gtr:fund><gtr:end>2010-04-03</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>332417</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Xerox Corporation</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Xerox Corporation</gtr:description><gtr:id>9149A682-F667-4DE5-96D5-B075A6BF2025</gtr:id><gtr:outcomeId>b9c135ccb9c135ea-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2006-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>63742</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>SpectralEdge Image Visualisation</gtr:description><gtr:end>2011-08-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/I028455/1</gtr:fundingRef><gtr:id>8548AB22-756E-471F-8E5A-1A70BEAE9694</gtr:id><gtr:outcomeId>5eda60125eda6026</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-12-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This grant led to the EP/IO28455 of (follow up funding) which began the commercialization of the technology developed in this grant. Briefly, our research developed methods for fusing multichannel images to make a grey-scale or colour image which naturally and without artifact portrayed all the information from all the bands. Second our research was designed to make best use of our own visual system.

Image fusion for photograph (e.g. RGB+Near Infra Red) and for visual accessibility (helping colour deficient observers see like we do) is being commercialised by Spectral Edge Ltd (spun out of Finlayson's lab)

Below, many sectors are 'ticked' as the spectral edge approach is a platform technology. Ticked are all the areas where prototype applications have been demonstrated</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>A9C74C8D-3825-4506-BBE6-12AB84960D65</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d74858573699.09418835</gtr:outcomeId><gtr:sector>Agriculture, Food and Drink,Digital/Communication/Information Technologies (including Software),Education,Environment,Healthcare,Manufacturing, including Industrial Biotechology,Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>Patent filed at national stage - publication reference: WO2011021012A1

Many techniques in image processing operate in the derivative (or detail) domain. As an example in image fusion we seek to blend the detail from many image channels (say the 200 bands in a satellite image) to make a single RGB facsimil. A key technical challenge is blending detail without hallucinating information that isn't there. This patent teaches both how to fuse without artifact and to do this quickly. Outside of image fusion, this patent has applications in image enhancement and image display (amongst others)</gtr:description><gtr:grantRef>EP/E012248/1</gtr:grantRef><gtr:id>0EF28938-0592-4383-8C15-4CE36F674B58</gtr:id><gtr:impact>This patent is a key foundation of Spectral Edge's - a UEA spin out - business. It subserves its work on image fusion and image enhancement.</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>m-7398820284.19414576672524</gtr:outcomeId><gtr:patentId>WO2011021012A1</gtr:patentId><gtr:protection>Patent application published</gtr:protection><gtr:title>Image Reconstruction Method</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Patent granted in the US (US8682093), and under prosecution in other territories.

This patent teaches how to fuse multispectral image detail in an optimal way to produce corresponding colour detail. The idea is to encode, say, a 200 channel satellite image into a 3 channel RGB image where the aim is to simultaneously give our visual system access to the higher dimensional data and maintain good colour fidelity.</gtr:description><gtr:grantRef>EP/E012248/1</gtr:grantRef><gtr:id>CACA6A2D-95A4-4A20-B54C-EC6983B4C0A5</gtr:id><gtr:impact>Spectral Edge Ltd, a spin out from the university of East Anglia, is taking this technology to market. The company is
focused on developing technology to fuse RGB+Near Infrared (or thermal) images for the photographic and surveillance industries.</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>m-367178926.586340176690c68</gtr:outcomeId><gtr:patentId>US8682093</gtr:patentId><gtr:protection>Patent granted</gtr:protection><gtr:title>Method and Apparatus for generating accented image data</gtr:title><gtr:yearProtectionGranted>2009</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:keyFindingsOutput><gtr:description>Every year, millions of poor grey scale reproductions of colour images are made. Through our research we aim to make millions more good grey scale prints.



It is now increasingly common to capture images using colour digital cameras and display them on colour monitors or using colour inkjet printers. However, there are still many occasions when colour images are reproduced in greyscale. The use of black and white printers, photocopiers and fax machines is still an every day occurrence. Unfortunately, the conversion of colour images to their greyscale equivalent, either by these devices, or through other means, often results in a poor reproduction of the images. The aim of our research is to develop a method to derive the best possible greyscale reproduction of a colour image, by a careful consideration of the limitations of our own visual system, and by exploiting the underlying physics of colour image formation. 



Usually, the colour at a given image point is coded by three numbers, and in the greyscale transformation these three numbers are reduced to just one grey value. More generally, colour information might be coded using N (where N&amp;gt;3) numbers, and in this case it is useful to be able to derive methods to reduce these N numbers to 3, or fewer, so that the N-dimensional information recorded can be displayed on conventional imaging technology. We will extend our research to also consider such cases. Our research will lead to the improved reproduction of images on greyscale devices (e.g. improved photocopying and faxing) as well as providing us with the ability to better visualise the information contained in, for example, satellite images. 



We also expect that it will be possible to exploit the technology we develop to make colour images that can be viewed without error or confusion, by colour-blind observers. In addition, the work will lead to improvements in existing image processing algorithms, and to a better understanding of how our own visual system perceives colour and brightness information.</gtr:description><gtr:id>5FDE67C0-B902-4C15-BFC3-3B1955D2ABE7</gtr:id><gtr:outcomeId>r-4789630775.1439877989e7a</gtr:outcomeId><gtr:sectors/></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>EA6E46A2-FD48-4E6B-B149-095453F3EA4F</gtr:id><gtr:title>Visual sensitivity to achromatic gradients with different luminance profiles</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0e4903963a9b06ca33d7bf0e5d5acee4"><gtr:id>0e4903963a9b06ca33d7bf0e5d5acee4</gtr:id><gtr:otherNames>L Garcia-Suarez (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_988773875213ecc9cc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6E0FEB6B-EA8C-4644-8F1F-3E3C471882EF</gtr:id><gtr:title>Consistent grey-level ordering for iso-luminant and iso-saturated colours,</gtr:title><gtr:parentPublicationTitle>Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>56c45d08edbc34.54183699</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B8B706F7-AE71-4297-B36D-3C3D8989FC98</gtr:id><gtr:title>Coding contrast as brightness to convert colour images to greyscale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a07a600b204e420e063f6d5024e9376c"><gtr:id>a07a600b204e420e063f6d5024e9376c</gtr:id><gtr:otherNames>Marina Bloj (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_560287464713efae9e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4946380E-503D-47E1-A7C6-7354EB6F9C0C</gtr:id><gtr:title>IMPROVEMENT OF COLORIZATION REALISM VIA THE STRUCTURE TENSOR</gtr:title><gtr:parentPublicationTitle>International Journal of Image and Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c88c00518f1e6da6d498cae5ccf50cd4"><gtr:id>c88c00518f1e6da6d498cae5ccf50cd4</gtr:id><gtr:otherNames>DREW M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>54634e39947a10.77837763</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4FEC8455-411E-4B5B-9F8F-ACC3122C8D1C</gtr:id><gtr:title>Path-based computations in colour image processing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7d2af2357ad530f42e006146ed02d7ce"><gtr:id>7d2af2357ad530f42e006146ed02d7ce</gtr:id><gtr:otherNames>Montagna Roberto</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>r_816915708663eaa9f4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>68C1968C-3769-47DD-91E7-CDD27D28E16D</gtr:id><gtr:title>Preferred greyscale versions of coloured images: Human vs machine</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>56c45bce8d5762.35900200</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5F295461-9E2D-4C30-BA38-8DC291EE8BF7</gtr:id><gtr:title>Histogram compression and image retrieval through Padua points interpolation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef63f66ade6b56eb02f4b56f95b51970"><gtr:id>ef63f66ade6b56eb02f4b56f95b51970</gtr:id><gtr:otherNames>Roberto Montagna (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_29482675461403cbcc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>53D382E1-9FE2-4029-96F7-299BCD14690C</gtr:id><gtr:title>Reducing Integrability Artefacts for Data Fusion through Colour Space Manipulation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>56c47d497facb0.35520204</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C05377AA-4474-404C-8DE9-9A2DC1774664</gtr:id><gtr:title>Seeing Beyond Luminance: A Psychophysical Comparison of Techniques for Converting Colour Images to Greyscale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b94c2cc34bea7d5eb433bd140e91d732"><gtr:id>b94c2cc34bea7d5eb433bd140e91d732</gtr:id><gtr:otherNames>Connah D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>56c482942a0f76.62122731</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0301FB9D-EECC-4A5C-BD5B-8557819C594D</gtr:id><gtr:title>Optimal interpolation and Lp norm minimisation in colour indexing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/94ca27c20de15a7921c37e9652ef9d5a"><gtr:id>94ca27c20de15a7921c37e9652ef9d5a</gtr:id><gtr:otherNames>Graham Finlayson (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_380968728313e1590c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9C7DC718-58F2-47C2-939E-23DD0A130846</gtr:id><gtr:title>Improved colour to greyscale via integrability correction</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2cacdc99d24acf09aef11e8bea3e98f3"><gtr:id>2cacdc99d24acf09aef11e8bea3e98f3</gtr:id><gtr:otherNames>Drew M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>56c47e41624ad4.36664867</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D127F4A0-69BE-41A5-BEDB-3C6710CAE91C</gtr:id><gtr:title>Reducing integrability error of color tensor gradients for image fusion.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_53d05e05e420a29a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D4D1D2F8-E5C0-4376-8581-E3D468EB5910</gtr:id><gtr:title>Color image compression by gray-to-color mapping</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f0c51da149e012998a6613378cf9813"><gtr:id>2f0c51da149e012998a6613378cf9813</gtr:id><gtr:otherNames>Drew MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>56c479f84eb303.30375901</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0C0E2031-247B-4BAD-90D6-2A33248115CA</gtr:id><gtr:title>Seeing Beyond Luminance: A Psychophysical Comparison of Techniques for Converting Colour Images to Greyscale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/31ab520f8c4d323fd61323c79fe26c8f"><gtr:id>31ab520f8c4d323fd61323c79fe26c8f</gtr:id><gtr:otherNames>D Connah</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_577489305113dc1f3c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6CBB8C0F-A44A-48ED-92F2-60D08630488E</gtr:id><gtr:title>Variance Maximising and Brightness preserving color to greyscale image transforms</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/81749e06cdaa7927021ffb7cbed4e8ca"><gtr:id>81749e06cdaa7927021ffb7cbed4e8ca</gtr:id><gtr:otherNames>Qiu M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>56c4811e4a40e2.65847403</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>88AFDBA2-BBAF-4CE7-AD86-2DF612DB6062</gtr:id><gtr:title>An investigation into perceptual hue-ordering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b94c2cc34bea7d5eb433bd140e91d732"><gtr:id>b94c2cc34bea7d5eb433bd140e91d732</gtr:id><gtr:otherNames>Connah D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>56c47ffbd576c8.56657723</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BF2126F3-5ACA-4AA3-8138-D36E3CDA422D</gtr:id><gtr:title>Reducing integrability artefacts for data fusion through colour space manipulation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4442-7</gtr:isbn><gtr:outcomeId>doi_53d0580586c7c582</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>93E548BA-8403-431C-B437-08A1BC8AF734</gtr:id><gtr:title>Realistic colorisation via the structure tensor</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f0c51da149e012998a6613378cf9813"><gtr:id>2f0c51da149e012998a6613378cf9813</gtr:id><gtr:otherNames>Drew MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>56c47f5fe5e9b4.23423196</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B32744F2-B2A4-47AC-B8F1-180AC28DDC0E</gtr:id><gtr:title>A novel approach to hue ordering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b94c2cc34bea7d5eb433bd140e91d732"><gtr:id>b94c2cc34bea7d5eb433bd140e91d732</gtr:id><gtr:otherNames>Connah D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>56c4820c035441.28061725</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B688B090-F985-4F57-BD87-512793EA97D9</gtr:id><gtr:title>Padua point interpolation and Lp-norm minimisation in colour-based image indexing and retrieval</gtr:title><gtr:parentPublicationTitle>IET Image Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d031031938d80d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>13897410-4885-471D-AAB7-75935ED4DCB6</gtr:id><gtr:title>A Unified Approach to Colour2Grey and Image Enhancement Through Gradient Field Integration</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/94ca27c20de15a7921c37e9652ef9d5a"><gtr:id>94ca27c20de15a7921c37e9652ef9d5a</gtr:id><gtr:otherNames>Graham Finlayson (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_705676943913e157ea</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>75E2C0C9-ACD9-4E26-95B2-FA35D10521F7</gtr:id><gtr:title>Contrast Maximizing and Brightness Preserving Color to Grayscale Image Conversion</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dfb7a67ec206fc77a45a7ff31c5a60ae"><gtr:id>dfb7a67ec206fc77a45a7ff31c5a60ae</gtr:id><gtr:otherNames>G Finlayson</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_168765565213e0000c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FF4AF798-8488-4FD3-BBC9-79AB62507B0A</gtr:id><gtr:title>A Closed form solution of colour to greyscale that maximises contrast and preserves brightness</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a93a01532ef14b3aa1a1b901c40810e"><gtr:id>6a93a01532ef14b3aa1a1b901c40810e</gtr:id><gtr:otherNames>Finlayson GD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>56c473781e5ee8.37834189</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>194CBD35-B9B3-4C0B-B4C4-EE6EDF8B68FE</gtr:id><gtr:title>Consistent grey-level ordering for iso-luminant and iso-saturated colours</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>56c480a799bd74.44427128</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>61BC5FF4-0334-4842-8189-F72848DE79D6</gtr:id><gtr:title>Constrained pseudo-Brownian motion and its application to image enhancement.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>doi_53d07e07e90b4940</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1D5A8D62-5B5B-4B31-85EF-9B08B47350EC</gtr:id><gtr:title>Coding Contrast as Brightness to Convert Colour Images to Greyscale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>56c4831732b007.35622596</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>705A8FCE-BDD3-41D0-BA13-CEA49427F35A</gtr:id><gtr:title>Human Assignment of Grey Levels Depends on Scene Complexity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/647507692b3a04f78774665548b173a0"><gtr:id>647507692b3a04f78774665548b173a0</gtr:id><gtr:otherNames>David Connah (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_621892644513dd5cbc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FAF0286E-721C-49F6-8BBD-153ECF8396B7</gtr:id><gtr:title>Lookup-table-based gradient field reconstruction.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a93a01532ef14b3aa1a1b901c40810e"><gtr:id>6a93a01532ef14b3aa1a1b901c40810e</gtr:id><gtr:otherNames>Finlayson GD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_53d05e05e3e07705</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FF67C069-26CF-4B0E-8D7A-59367341DF0B</gtr:id><gtr:title>What do we know about how humans choose grey levels for images?</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d0770773899698</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>351F2869-7721-4C3C-8E25-DD0E0262F88B</gtr:id><gtr:title>Constrained Pseudo-Brownian Motion for Image Enhancement</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef63f66ade6b56eb02f4b56f95b51970"><gtr:id>ef63f66ade6b56eb02f4b56f95b51970</gtr:id><gtr:otherNames>Roberto Montagna (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_47536652591403cb0e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1DED5D9D-CB37-4914-A9E1-F43FE1E814A4</gtr:id><gtr:title>Consistent grey-level ordering for iso-luminant and iso-saturated colours</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a07a600b204e420e063f6d5024e9376c"><gtr:id>a07a600b204e420e063f6d5024e9376c</gtr:id><gtr:otherNames>Marina Bloj (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_737331523313efad72</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AB1C7E8D-CE2D-4DCD-9BB2-D13908CF8639</gtr:id><gtr:title>Preferred Greyscale versions of coloured images: Human vs Machine</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/59f147bf6446f48ebd46b13605c6f5d6"><gtr:id>59f147bf6446f48ebd46b13605c6f5d6</gtr:id><gtr:otherNames>M Bloj</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_824150072213edd272</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0AD8A654-087C-43A7-AE6B-AE9821D3E3BE</gtr:id><gtr:title>Constrained Pseudo-Brownian Motion for Image Enhancement</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>56c47b026f22f8.96042465</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0711C063-0E5F-4F15-8CB0-73608DF99877</gtr:id><gtr:title>Human Assignment of Grey Levels Depends on Scene Complexity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b94c2cc34bea7d5eb433bd140e91d732"><gtr:id>b94c2cc34bea7d5eb433bd140e91d732</gtr:id><gtr:otherNames>Connah D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>56c4772bec1531.04877652</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D9D95760-2350-4D0B-8602-707C2335BF3C</gtr:id><gtr:title>Preferred Grayscale Images for Human Observers</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f0c51da149e012998a6613378cf9813"><gtr:id>2f0c51da149e012998a6613378cf9813</gtr:id><gtr:otherNames>Drew MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>56c47eeb085088.43730682</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5C20D63E-5D22-4733-A92E-53916BA680C1</gtr:id><gtr:title>An Investigation into Perceptual Hue Ordering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/31ab520f8c4d323fd61323c79fe26c8f"><gtr:id>31ab520f8c4d323fd61323c79fe26c8f</gtr:id><gtr:otherNames>D Connah</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_973429336613dc1e88</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4D7BCB5A-454B-43EB-97D4-2BF865C903A0</gtr:id><gtr:title>A Uni?ed Approach to Colour2Grey and Image Enhancement through Gradient Field</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a93a01532ef14b3aa1a1b901c40810e"><gtr:id>6a93a01532ef14b3aa1a1b901c40810e</gtr:id><gtr:otherNames>Finlayson GD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>56c47c7ed7f3b5.95025515</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E012248/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>