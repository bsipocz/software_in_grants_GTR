<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/AE58F21F-3622-4382-97BB-1359BD183E9F"><gtr:id>AE58F21F-3622-4382-97BB-1359BD183E9F</gtr:id><gtr:name>University of Glasgow</gtr:name><gtr:address><gtr:line1>University Avenue</gtr:line1><gtr:line4>Glasgow</gtr:line4><gtr:postCode>G12 8QQ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AE58F21F-3622-4382-97BB-1359BD183E9F"><gtr:id>AE58F21F-3622-4382-97BB-1359BD183E9F</gtr:id><gtr:name>University of Glasgow</gtr:name><gtr:address><gtr:line1>University Avenue</gtr:line1><gtr:line4>Glasgow</gtr:line4><gtr:postCode>G12 8QQ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F86362E4-3B71-440F-868F-1F91698CFE26"><gtr:id>F86362E4-3B71-440F-868F-1F91698CFE26</gtr:id><gtr:firstName>S</gtr:firstName><gtr:surname>Garrod</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MC_G1001214"><gtr:id>5C7CEC72-65D8-4DA7-8EB5-CC4E0066052A</gtr:id><gtr:title>Social interaction: A cognitive-neurosciences approach</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Intramural</gtr:grantCategory><gtr:grantReference>MC_G1001214</gtr:grantReference><gtr:abstractText>Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission, but may be because it included sensitive information such as personal details.</gtr:abstractText><gtr:technicalSummary>Social interaction is the basis of most human activities. Through social interactions people make judgments about their partners social identity, emotional state, attractiveness and trustworthiness. Psychologists convincingly argue that many of these basic social judgements are made automatically rather than as the result of conscious decision. Yet, little is known about the detailed cognitive-neural mechanisms that support the judgments. This project aims to elucidate these mechanisms using the most up-to-date experimental, computational and brain imaging techniques. The three main strands of the project will investigate in turn; (1) the immediate processing of social signals originating from the voice, face and bodily movements; (2) how such signals support the automatic interactive alignment of social behaviours (associated with pupil dilation, blinking, yawning etc.); (3) the mechanisms that underlie joint attention and action. A major goal of the three strands will be to establish the link between the processing of social signals and the formation of key social judgements relating to emotion, trust and desire to affiliate with interacting partners. To support this goal a fourth strand of the project will develop a mathematical model to capture the relationship between social signals arising from multiple sources and social judgements.</gtr:technicalSummary><gtr:fund><gtr:end>2013-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2007-04-01</gtr:start><gtr:type>EXPENDITURE_ACTUAL</gtr:type><gtr:valuePounds>789900</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B42BA34D-3C77-45D3-9DAE-12CAEE29C9F1</gtr:id><gtr:title>Speech rhythms and multiplexed oscillatory sensory coding in the human brain.</gtr:title><gtr:parentPublicationTitle>PLoS biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d34d719257bd64971a7a7dce78c0569"><gtr:id>3d34d719257bd64971a7a7dce78c0569</gtr:id><gtr:otherNames>Gross J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1544-9173</gtr:issn><gtr:outcomeId>54451c02412585.32073186</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>75B427E4-7D4B-4255-ADDD-4BC64F0916F6</gtr:id><gtr:title>Cultural confusions show that facial expressions are not universal.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/110bc41dfcffc8cb1bb088e70bfb6c28"><gtr:id>110bc41dfcffc8cb1bb088e70bfb6c28</gtr:id><gtr:otherNames>Jack RE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>pm_53cbfa7bfa7cbf42e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D91395FC-D1C8-4209-9C33-5F0DEE9EC1E1</gtr:id><gtr:title>Inverting faces elicits sensitivity to race on the N170 component: a cross-cultural study.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9e232e7135df5c0d6f9b2add623faea"><gtr:id>a9e232e7135df5c0d6f9b2add623faea</gtr:id><gtr:otherNames>Vizioli L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53cfa7fa78de6948</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>655613EF-C961-4924-8FA3-C0EA6A255EED</gtr:id><gtr:title>Looking away from faces: influence of high-level visual processes on saccade programming.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/51660b9c1ee2373142e648117f29b1d1"><gtr:id>51660b9c1ee2373142e648117f29b1d1</gtr:id><gtr:otherNames>Morand SM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53cfa7fa792550e8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5DC1807B-F183-45B4-8DC0-02AA3F18AE8D</gtr:id><gtr:title>Putting culture under the 'spotlight' reveals universal information use for face recognition.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a1de6fe1e184c4cffb2a312a5788fd32"><gtr:id>a1de6fe1e184c4cffb2a312a5788fd32</gtr:id><gtr:otherNames>Caldara R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>pm_53cbfbbbfbb99385c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E54DAFF3-5438-436E-865C-F14DE9631425</gtr:id><gtr:title>How Predictable are &amp;quot;Spontaneous Decisions&amp;quot; and &amp;quot;Hidden Intentions&amp;quot;? Comparing Classification Results Based on Previous Responses with Multivariate Pattern Analysis of fMRI BOLD Signals.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a3255ac7ed147667f82fe2bc2e4ca2e3"><gtr:id>a3255ac7ed147667f82fe2bc2e4ca2e3</gtr:id><gtr:otherNames>Lages M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>doi_53cfaefae9062efa</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>06F2DA11-42DC-4969-9216-D681FE33E9F6</gtr:id><gtr:title>Vocal attractiveness increases by averaging.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9792451d76dc7dfdf36f0d29e1c14ade"><gtr:id>9792451d76dc7dfdf36f0d29e1c14ade</gtr:id><gtr:otherNames>Bruckert L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>pm_53cbfb7bfb79da62c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B2F9212C-A3A3-4321-AA32-6CD908FB6BFA</gtr:id><gtr:title>Culture shapes eye movements for visually homogeneous objects.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/124b6e7dbc595e175d05e83c5011a479"><gtr:id>124b6e7dbc595e175d05e83c5011a479</gtr:id><gtr:otherNames>Kelly DJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>doi_53cfaefae819a452</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9D592CE8-B3E9-4419-BF52-E77FA1B9CA6E</gtr:id><gtr:title>Smile through your fear and sadness: transmitting and identifying facial expression signals over a range of viewing distances.</gtr:title><gtr:parentPublicationTitle>Psychological science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ec9069588c426eea5203eabf4ef27068"><gtr:id>ec9069588c426eea5203eabf4ef27068</gtr:id><gtr:otherNames>Smith FW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0956-7976</gtr:issn><gtr:outcomeId>pm_53cbfa8bfa861dd96</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1D91192C-DDDD-45B5-892B-2827B72609E1</gtr:id><gtr:title>The embodied nature of spatial perspective taking: embodied transformation versus sensorimotor interference.</gtr:title><gtr:parentPublicationTitle>Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76e238234f034df4737ff366aa695e59"><gtr:id>76e238234f034df4737ff366aa695e59</gtr:id><gtr:otherNames>Kessler K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0010-0277</gtr:issn><gtr:outcomeId>pm_53cbfabbfab57907a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D02713BC-0F66-4406-AE79-B42419067F88</gtr:id><gtr:title>Dynamics of trimming the content of face representations for categorization in the brain.</gtr:title><gtr:parentPublicationTitle>PLoS computational biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7dfc05fd4c2384d67efc1a9bbf6fb7ce"><gtr:id>7dfc05fd4c2384d67efc1a9bbf6fb7ce</gtr:id><gtr:otherNames>van Rijsbergen NJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1553-734X</gtr:issn><gtr:outcomeId>pm_53cbfb0bfb037c68a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A929595F-7D1E-419D-90B2-0ECDA0D8739C</gtr:id><gtr:title>Facial expressions of emotion are not culturally universal.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/110bc41dfcffc8cb1bb088e70bfb6c28"><gtr:id>110bc41dfcffc8cb1bb088e70bfb6c28</gtr:id><gtr:otherNames>Jack RE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>pm_53cc006c0064e788c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11C11C98-A83A-4729-9CD4-45EAECD8AC0D</gtr:id><gtr:title>Joint action, interactive alignment, and dialog.</gtr:title><gtr:parentPublicationTitle>Topics in cognitive science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6bc6193783dbd13cdf882af19b8ea273"><gtr:id>6bc6193783dbd13cdf882af19b8ea273</gtr:id><gtr:otherNames>Garrod S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1756-8757</gtr:issn><gtr:outcomeId>doi_53cfa5fa5c0e7f88</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>42A8F419-A7BC-4CFC-B142-DA463C845194</gtr:id><gtr:title>Expertise with multisensory events eliminates the effect of biological motion rotation on audiovisual synchrony perception.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f9645d1192df44678eccf85fe0b2a50"><gtr:id>2f9645d1192df44678eccf85fe0b2a50</gtr:id><gtr:otherNames>Petrini K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>pm_53cbfc7bfc7052627</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E3A013A2-5E1A-4F48-97D1-71DF498C00EE</gtr:id><gtr:title>The Montreal Affective Voices: A validated set of nonverbal affect bursts for research on auditory affective processing</gtr:title><gtr:parentPublicationTitle>Behavior Research Methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d2df4f5db543fcf1922201cc6658294c"><gtr:id>d2df4f5db543fcf1922201cc6658294c</gtr:id><gtr:otherNames>Belin P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53cfaefaeabb9049</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>38E9E066-9F2D-4B53-83FA-1A3653852718</gtr:id><gtr:title>Prediction and embodiment in dialogue</gtr:title><gtr:parentPublicationTitle>European Journal of Social Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/29cfe6d780576bf668b6e628e0ff936b"><gtr:id>29cfe6d780576bf668b6e628e0ff936b</gtr:id><gtr:otherNames>Pickering M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53cf8af8ae81f8c4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2B71B273-63B3-4424-B483-625C13A963E2</gtr:id><gtr:title>Characteristics of motor resonance predict the pattern of flash-lag effects for biological motion.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76e238234f034df4737ff366aa695e59"><gtr:id>76e238234f034df4737ff366aa695e59</gtr:id><gtr:otherNames>Kessler K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>pm_53cbfb5bfb52a8407</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C26C4A45-8C0A-45EB-B546-8C1C18B51029</gtr:id><gtr:title>Internal representations reveal cultural diversity in expectations of facial expressions of emotion.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. General</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/110bc41dfcffc8cb1bb088e70bfb6c28"><gtr:id>110bc41dfcffc8cb1bb088e70bfb6c28</gtr:id><gtr:otherNames>Jack RE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0022-1015</gtr:issn><gtr:outcomeId>pm_53cbfe3bfe3cececb</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>32A1AFF7-6A92-4EA4-A124-C7F9570D194F</gtr:id><gtr:title>Brain-to-brain coupling: a mechanism for creating and sharing a social world.</gtr:title><gtr:parentPublicationTitle>Trends in cognitive sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8d88132f6c5f38d9c0c9aa5fe18030c7"><gtr:id>8d88132f6c5f38d9c0c9aa5fe18030c7</gtr:id><gtr:otherNames>Hasson U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1364-6613</gtr:issn><gtr:outcomeId>pm_53cbffcbffce2fe17</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>334C0CC4-0501-491E-8B07-00EE25A07BDD</gtr:id><gtr:title>Audiovisual integration of emotional signals from music improvisation does not depend on temporal correspondence.</gtr:title><gtr:parentPublicationTitle>Brain research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f9645d1192df44678eccf85fe0b2a50"><gtr:id>2f9645d1192df44678eccf85fe0b2a50</gtr:id><gtr:otherNames>Petrini K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0006-8993</gtr:issn><gtr:outcomeId>pm_53cbfb8bfb831a7a3</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">MC_G1001214</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>3C193D18-12BD-4B15-8347-037BA623E0FF</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Mental Health</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>878A242A-6B84-462E-BEA5-346583F6CA54</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>1.2  Psychological and socioeconomic processes</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>