<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/86B4D2F1-90AE-414C-8AAF-C314956339A1"><gtr:id>86B4D2F1-90AE-414C-8AAF-C314956339A1</gtr:id><gtr:name>Barnard Microsystems Limited</gtr:name><gtr:address><gtr:line1>Brentmead House
Britannia Road</gtr:line1><gtr:city>London</gtr:city><gtr:postCode>N12 9RU</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/86B4D2F1-90AE-414C-8AAF-C314956339A1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>86B4D2F1-90AE-414C-8AAF-C314956339A1</gtr:id><gtr:name>Barnard Microsystems Limited</gtr:name><gtr:address><gtr:line1>Brentmead House
Britannia Road</gtr:line1><gtr:city>London</gtr:city><gtr:postCode>N12 9RU</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>98367.0</gtr:offerGrant><gtr:projectCost>163945.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/99771245-3199-4881-8A84-41FA4A188F70"><gtr:id>99771245-3199-4881-8A84-41FA4A188F70</gtr:id><gtr:firstName>Joseph</gtr:firstName><gtr:surname>Barnard</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=710282"><gtr:id>80B45F44-6C9E-4C52-9C46-05FFDD091CB7</gtr:id><gtr:title>AeroVision II = Enhanced Airborne Vision Sensor</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>GRD Proof of Concept</gtr:grantCategory><gtr:grantReference>710282</gtr:grantReference><gtr:abstractText>This Proof of Concept (?PoC?) project is a follow on from our Proof of Market (&amp;quot;PoM&amp;quot;)
project 700092, in which we studied and confirmed the market for this sensor. In this
technology demonstration project, we intend to prove the effectiveness of an innovative
approach to airborne object collision detection, in real time.
We are developing unmanned aircraft (&amp;quot;UA&amp;quot;) for use throughout the world in scientific (ice
thickness monitoring), commercial (oil and mineral exploration) and state (border patrol)
applications. The greatest technical challenge to the use of UA operating beyond line of sight
(&amp;quot;BLOS&amp;quot;) is the deployment of a collision detection sensor. This is an essential requirement
that has been voiced at every UA conference for the last four years. It has also been a
requirement of our potential UA customers, including Fugro Airborne Surveys and Sander
Geophysics (airborne geophysical surveys), oil and gas exploration companies, such as Statoil
and Shell and Government bodies, such as DSTL.
We propose to develop and characterise a prototype airborne collision detection sensor, based
on the use of two synchronised cameras operating as a stereo imaging pair, to mimic human
vision. We plan to introduce additional innovative enhancements to the stereo vision
technology with polarisation sensitive imagery, which has the potential to see through some
level of cloud cover. We will augment the detection capability with an acoustic detector array.
Our aim is to deploy this sensor on UA that fly BLOS, to detect airborne objects, such as
other aircraft, balloons and parachutists. Once proven, it was suggested by Cliff Whittaker at
the Civil Aviation Authority, this sensor could find wider application on light aircraft, so
contributing to the safety of air travel and enabling us to build up a world leading export
business in this area in the U.K. Another benefit will be environmental, since UA use less fuel
per km flown than their manned counterparts.</gtr:abstractText><gtr:fund><gtr:end>2014-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2013-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>98367</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">710282</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>