<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/AB307619-D4FA-427E-A042-09DBEBA84669"><gtr:id>AB307619-D4FA-427E-A042-09DBEBA84669</gtr:id><gtr:name>Swansea University</gtr:name><gtr:department>College of Science</gtr:department><gtr:address><gtr:line1>Singleton Park</gtr:line1><gtr:postCode>SA2 8PP</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AB307619-D4FA-427E-A042-09DBEBA84669"><gtr:id>AB307619-D4FA-427E-A042-09DBEBA84669</gtr:id><gtr:name>Swansea University</gtr:name><gtr:address><gtr:line1>Singleton Park</gtr:line1><gtr:postCode>SA2 8PP</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/BAD3780F-6F65-4292-A69C-923CAE91A7BB"><gtr:id>BAD3780F-6F65-4292-A69C-923CAE91A7BB</gtr:id><gtr:name>British Broadcasting Corporation - BBC</gtr:name><gtr:address><gtr:line1>British Broadcasting Corporation</gtr:line1><gtr:line2>Broadcasting House</gtr:line2><gtr:line3>Portland Place</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>W1A 1AA</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/DAEF99A9-72B9-4731-A043-5992F34C2E7A"><gtr:id>DAEF99A9-72B9-4731-A043-5992F34C2E7A</gtr:id><gtr:firstName>Sriram</gtr:firstName><gtr:surname>Subramanian</gtr:surname><gtr:orcidId>0000-0002-5266-8366</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/7A999433-6B7A-46BB-A17D-FF79D497F1A0"><gtr:id>7A999433-6B7A-46BB-A17D-FF79D497F1A0</gtr:id><gtr:firstName>Rory</gtr:firstName><gtr:surname>Wilson</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5BD0BA62-D021-431C-8FCB-FD162D298D1D"><gtr:id>5BD0BA62-D021-431C-8FCB-FD162D298D1D</gtr:id><gtr:firstName>Matt</gtr:firstName><gtr:surname>Jones</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN013948%2F1"><gtr:id>ACC07D4C-0703-421D-A83A-2C07AF3CB806</gtr:id><gtr:title>Breaking the Glass: Multimodal, Malleable Interactive Mobile surfaces for Hands-In Interactions</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N013948/1</gtr:grantReference><gtr:abstractText>Mobile phone and tablet touch screens are flat, dead surfaces. Our work seeks to explore the potential of a far more fluid, 'alive' portable display. It departs radically from existing deformable research by endeavouring to provide truly direct interaction with affordances, controls and content integrated within a visual display. We will be highly ambitious and adventurous, pushing the boundaries of technical possibility and being inspired by perspectives from deformations in the animal world through a Co-I and team from biosciences. Our work will be further grounded and informed by our end-user partner, BBC R&amp;amp;D. The outcome will be scenarios, interaction styles and a range of fully-functional prototypes that will enable us to map out a design space to drive developments in both display materials and a richer, expressive toolkit of gestures and manipulation on touch surfaces.

Consider the following scenarios that illustrate the possibilities of the new technology and user interfaces:

1. Sam is using the new paint application on her tablet. At the top of the screen is a row of paint pots that dynamically recess into the display. Each contains a colour, and the deeper she dips her paintbrush into the pot, the deeper and thicker she is able to paint onto the remaining screen surface, just as in the real world of watercolour sets.

2. Rosie is watching a BBC nature programme on her very large screen HD television set. In her hands she holds a tablet which can display companion content for the programme. While the large screen shows a butterfly dancing around a garden, her tablet screen deforms to provide a sensation of the flapping wings, indicating to Rosie that there is further content on the second screen. However, she is immersed with the main screen display and briskly pushes the deformation away to the right of the mobile. The force of her interaction is used by the system as a gauge to her interruptibility as additional second screen content becomes available.

3. Si&amp;acirc;n is producing a live music event for broadcast over iPlayer. She needs to keep her eyes and ears alive to the pace and spectacle of the band whilst catching the individual performances of each of its members. Normally a sea of controls from an array of mixing desks would surround her, rigged to control every potential shot from the camera crew on and off stage. The new flat panel touch screen mixers enable Si&amp;acirc;n to customise the controls, reducing the kit required, but without tactile feedback her attention is diverted from the action to the control surface. These micro moments of distraction can be critical and the continual switching of attention increases the stress of the job. The new deformable displays give her best of both worlds: a smaller, responsive mixing desk with tactile feedback that keeps her eyes on the performance she is broadcasting.

We propose a number of transformative benefits of the novel surfaces and architectures we will construct:

- The three dimensional and multimodal nature of the elements can be used to communicate features of an information space in more efficient and satisfying ways;
- The surface can provide sophisticated and nuanced controls with, for instance, the extent to which the user pokes her finger or stylus into the surface adjusting the degree of system response; and,
- The tangibility of the elements can enable eyes-free operation, allowing the user to combine their handheld interaction with other objects in their environment in order to deal with a complex content space. The platform can then provide physical affordances and controls, in a dynamic way, as the user interacts with the Internet of Things around them.

The team combines world leading researchers with expertise in: user experience, hardware and materials innovation, electronics, design space analysis and biosciences.</gtr:abstractText><gtr:potentialImpactText>The market for new display forms and the experiences and services they can afford is vast. Already, there are over two billion owners of smartphones, with analysts expecting this to increase dramatically over the next 5-10 years, and existing users upgrading. Our work will be the very start of a highly novel surface that could revolutionise this market in the longer term, with the successors of the materials and interaction styles we investigate finding their way onto devices everyone in the world owns. We would expect companies, including start-ups and spin-outs, to exploit this work with direct benefit to the health of the UK economy and employment. We are keen to see this project lead to such tangible outcomes, and have previously had success with transferring advanced output technologies to spin-outs (e.g., see ultrahaptics.com).

The improved ways a user can interact with ICT (from a better understanding of big data sets to eyes-free control of objects connected to the 'Internet of Things' (IoT)) will have significant impacts on the perceived quality of life of populations. For specific application areas there could be even greater benefits: for example, consider a surgeon manipulating a keyhole surgery tool during an operation where the tool is controlled by a mobile surface. As she focuses on a tumour in the patient's colon, the deformable surface generates an appropriately shaped tweezer element, the size and form adapted dynamically to the tumour's characteristics. Or, consider a partially sighted user who can read enlarged text on a mobile but has great difficulty presently in operating sliders, selectors or switches on the UI, for instance. The hands-in surface enhances the communication channel by providing a range of non-visual cues including, for example, tangible size and shape of controls.

While we expect the full and sustained impacts of our work to be in the long term (i.e., 10 years out and beyond), we expect many of our discoveries to be applied quickly via existing platforms and new devices in the short to medium terms. For example, the work that will look at providing direct manipulation of IoT-connected objects will inform implementations possible today: e.g., pointing a mobile at an overhead projector might generate a photorealistic rendering of the focusing knob on a conventional touch screen that the user can manipulate (as opposed to the tangible, deformed control possible in the advanced displays envisaged here). Alternatively, a malleable surface peripheral could be produced and connected to a conventional mobile to provide additional hands-in interactions without integration into the smartphone itself. We see, then, many varied possibilities of such products and services, and impacts on the economy within a short timeframe.

We also anticipate significant impacts on the UK's capability to lead in this emerging field of innovation. There are relatively few groups in the UK focusing on advances in materials to extend user experience and interaction (with Co-I Subramanian's being one of these). Our work will enhance the profile and standing of this important set of activities in the UK, developing people with skills and outlooks that can shape and take the opportunities that these new platforms will enable.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-03-31</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>822222</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>BBC Research &amp; Development</gtr:department><gtr:description>BBC UXRP</gtr:description><gtr:id>BD623EFB-C2C6-4595-B794-F0E0370688DD</gtr:id><gtr:impact>All PhD academic papers and awards noted have been from directly working with the BBC. 

I have worked with my supervisor, Dr. Michael Evans, and (to a lesser extent) various content designers at the BBC to inform my research.</gtr:impact><gtr:outcomeId>56d5d9cb575bf3.82706357-1</gtr:outcomeId><gtr:partnerContribution>Dr. Michael Evans is my joint academic supervisor.</gtr:partnerContribution><gtr:piContribution>Worked extensively with the BBC on informing the design of attention for multi-device platforms.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Project featured on Reuters Technology</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>649AFDF3-7396-464A-B765-9751B580E850</gtr:id><gtr:impact>The project was featured on Reuters Technology - &amp;quot;Scientists working on 'morphing' smart phone screens&amp;quot;. This involved a video interview with the PI about the project, who outlined our vision.</gtr:impact><gtr:outcomeId>58c7c7e69d9723.73189588</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://reut.rs/2dmihV2</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>NESTA Digital Innovation and the Arts in Wales, invited talk: The future of the digital economy</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>560BA6D3-D9B2-4818-A352-D50BC73944AA</gtr:id><gtr:impact>An invited talk about the project, discussing the project and its aims at The Digital Innovation Fund for the Arts in Wales.</gtr:impact><gtr:outcomeId>58c7d12d3cad44.02941914</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Policymakers/politicians</gtr:primaryAudience><gtr:url>http://www.nesta.org.uk/project/digital-innovation-fund-arts-wales</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Touching the Future talk at British Science Festival</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>72004D9F-7EDF-4C26-8B9D-4ED2E00FC4A9</gtr:id><gtr:impact>Prof. Matt Jones, accompanied by Simon Robinson, Timothy Neate, Cameron Steer and Jen Pearson gave a talk at the British Science Festival (https://www.britishsciencefestival.org/)

The talk was given to a lecture hall of the general public at Swansea University and talked about our past work and our vision for this project. 

The event was covered on the BBC's Science Cafe, BBC Click, and by the South Wales Evening Post.</gtr:impact><gtr:outcomeId>58c7c6011d6ac9.17290799</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b07tmbk2#playt=1m11s</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings have been presented at the British Science Festival and also covered by BBC and Reuters.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>F4775621-C58A-463B-AA5D-50F5D5BC7FF2</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58c97b4b0cb442.48310975</gtr:outcomeId><gtr:sector>Creative Economy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have developed a proof of concept of a deformable screen that allows users to touch and use dials and sliders that emerge from the surface of a mobile.</gtr:description><gtr:exploitationPathways>We are in process of creating a toolkit of examples that others can appropriate.</gtr:exploitationPathways><gtr:id>DDE0F33F-CEA7-4BAF-AEDA-C0D3894513BF</gtr:id><gtr:outcomeId>58c97af8cf7a95.63664893</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors><gtr:url>http://cs.swan.ac.uk/breaking-the-glass/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B0EAF658-EE5C-4DD0-9B9F-18E322354A96</gtr:id><gtr:title>JDLED</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6aaa3f5b947d65d0df099340f47cc3a1"><gtr:id>6aaa3f5b947d65d0df099340f47cc3a1</gtr:id><gtr:otherNames>Sahoo D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a86bd6ee8d827.58014185</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N013948/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>772CD758-53CD-407F-9B2C-F2B861E86155</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Mechanical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>3DA0C45A-BB41-4C35-A977-05FCC6966C8C</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Materials testing &amp; eng.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>