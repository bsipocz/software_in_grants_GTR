<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/BA2685AB-275C-4612-8454-D90790672A46"><gtr:id>BA2685AB-275C-4612-8454-D90790672A46</gtr:id><gtr:name>York University Canada</gtr:name><gtr:address><gtr:line1>4700 Keele Street</gtr:line1><gtr:line4>Toronto</gtr:line4><gtr:line5>Ontario M3J 1P3</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/AF3A7A6E-F17B-4E1E-9717-2752658C8E09"><gtr:id>AF3A7A6E-F17B-4E1E-9717-2752658C8E09</gtr:id><gtr:firstName>Ross</gtr:firstName><gtr:surname>Goutcher</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FG004803%2F1"><gtr:id>8B7DA485-9BF6-4991-8686-14DB2410C09B</gtr:id><gtr:title>Functional role of second-order processing in binocular vision</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/G004803/1</gtr:grantReference><gtr:abstractText>The human brain uses small differences between the images reaching our two eyes to perceive the three-dimensional shape of the world around us. In order to detect these differences, known as binocular disparities, the brain must find points in one eye's image that match to points in the other eye's image. However, for any single point in an image, the brain is often forced to choose between multiple matches. The problem of finding the correct match from amongst these alternatives is known as the correspondence problem. This problem can be simplified by making assumptions about the typical shape of objects in the world, and by finding matches between different kinds of basic tokens. For example, the number of alternative solutions to the correspondence problem will be far greater if the brain uses single points of light as a basic token for matching, compared to a case where a more complex token, such as a shape or texture, is used. Furthermore, these complex tokens can be based on different kinds of information. The research proposed here examines how matching tokens based on different forms of information can be used by the brain to solve the correspondence problem. Specifically, we shall examine how the brain may solve the correspondence problem using tokens derived from mechanisms sensitive to changes in light and dark (i.e. changes in luminance), and mechanisms sensitive to changes in texture. We shall develop computer simulations of the processes used by the brain to solve the correspondence problem and measure disparity. These simulations will show how the use of different basic information for matching (i.e. changes in luminance and changes in texture) can change the nature of the correspondence problem. We shall discover whether the combined use of texture- and luminance-based matching tokens can help to reduce noise in disparity measurement and whether the use of texture-based matching can reduce the number of available solutions to the correspondence problem. Following this, we shall examine whether the brain actually makes use of the combined information available from texture and luminance. By presenting human participants with images containing disparities defined by both texture and luminance, we shall establish whether the human brain actually uses these different types of information to reduce noise, or improve its ability to solve the correspondence problem. In addition to examining whether using luminance and texture information to measure disparity helps the brain to reduce noise and simplify the correspondence problem, we shall also examine whether sensitivity to these different types of image information can help the brain to detect discontinuities in depth. Depth discontinuities arise when depth changes sharply across a small area, such as when an observer's view of one object is partially obscured by another object in front of it. The processing of texture-based disparities may help in the detection of depth discontinuities since different objects often differ in texture. We shall establish whether information of this kind may actually be useful in the detection of depth discontinuities, and whether human observers actually use this information.</gtr:abstractText><gtr:technicalSummary>Small differences between the images falling onto the retinas of our two eyes are detected by the human visual system and used to recover information about the three-dimensional structure of the environment. If these differences, known as binocular disparities, are to be properly encoded, the visual system must first find matching points between the two images. Through a combination of computational analysis and psychophysical experimentation, the proposed research will investigate the mechanisms used by the human visual system to find matching points and accurately encode the structure of the environment. Specifically, the proposed research will examine the visual system's use of second-order information for the encoding of binocular disparity. By analysing the second-order content of binocular natural images, we will establish ways in which such information may prove helpful in solving the correspondence problem. A series of psychophysical experiments shall establish whether potentially helpful second-order information is used by the visual system to solve the correspondence problem. Further analyses of natural image data will establish whether second-order image content can provide useful information about the spatial locations of discontinuities in depth. Psychophysical experiments will further establish whether any potential usefulness of second-order information is actually exploited by the visual system for the purpose of discontinuity detection.</gtr:technicalSummary><gtr:fund><gtr:end>2011-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2009-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>272247</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This research has examined the processes that allow humans to perceive depth using the information available with two eyes. This information, known as binocular disparity, can be used to perceive depth even when three-dimensional (3D) structure cannot be seen with only one eye. This is known as cyclopean perception. To perceive cyclopean structure the brain must overcome two problems. First, it must measure the disparities in the image. Second, it must group together those disparity measurements into descriptions of 3D properties. Our research addresses both these issues.



To examine the measurement problem, we have conducted an analysis of the disparity information available in binocular natural images. Model disparity sensitive cells, similar to those found in the macaque brain, were used to process such images. Model cell responses were then analysed in order to quantify the complexity of the measurement problem in natural scenes. Our results suggest that the measurement problem can be reduced through a combination of multiple types of disparity sensitive cells, including cells that are sensitive to variations in image contrast. 



In a further examination of disparity measurement, we have looked at how human observers perform in tasks requiring the perception of cyclopean structure, in the presence of measurement noise. Measurement noise was added by randomly replacing parts of the image, by randomly moving image parts away from the cyclopean surface, by reducing contrast (the difference between light and dark), and by varying the orientation of lines used to depict cyclopean surfaces. Our results suggest that different forms of noise affect different processing levels and that combinations of noise types severely disrupt disparity measurement. 



In examining the problem of cyclopean grouping, we have looked at how the addition of image elements with random locations in depth affects the visual system's ability to recover cyclopean structure. The observed reduction in performance is consistent with a model that groups pairs of image features over a local area, and provides further processing stages with a description of the relations between those pairs. Such a model will be of use in the production of general descriptions of cyclopean structure, that allow for comparisons of performance to be made across different tasks and stimuli. Importantly, our results cannot be accounted for by models that make no attempt to group together multiple disparity signals over space.



In further examinations of the problem of cyclopean grouping, we have looked at the visual system's understanding of clouds of random dots in depth. This investigation has revealed that that we have little sensitivity to the shape of such clouds and rely only on estimates of their extent in depth. We have also looked at the role of disparity in grouping image elements into contours. Our results show that similarity of disparity plays a role in contour detection, but that its importance is outweighed by other factors such as contour linearity and element orientation.</gtr:description><gtr:exploitationPathways>Our findings on the importance of grouping processes in the perception of cyclopean form demonstrate the need for models of disparity processing that go far beyond simple disparity measurement. Currently, our model may only be applied to a limited subset of (random-dot) stimuli, and may only be used to measure a limited set of cyclopean properties. Further extensions of this model will allow for a far fuller description of cyclopean form. Such a model may be applied to coupled camera-computer systems to allow for 3D image analysis, addressing problems beyond the production of 3D maps. Thus the models we are developing may be of use in robot navigation and 3D imaging applications.



Finally, our findings on the perception of stereoscopic volumes (clouds in depth), provide significant limitations on the use of stereoscopic displays for 3D data visualisation. If observers possess only a limited description of the shape of a cloud in depth, then stereoscopic visualisation technologies must provide additional signals to aid users. These results also hold similar implications for designers of 3D virtual environments. 
 The research conducted on this grant offers several potential strands for exploitation. First, the results of our image analysis demonstrate the importance of applying multiple disparity sensor types in order to solve the measurement problem. We have highlighted several potential sensor types, and show that the measurement problem is distinct in each. Our image analysis code may be made available to the scientific community in order to aid further development of models of disparity measurement.



Second, our models of cyclopean grouping offer significant opportunities for exploitation. Currently, however, they offer only limited use. Further development of these models would allow for greater applicability. Collaboration with the computer vision community would offer the possibility to fully develop the concepts used in our grouping model.</gtr:exploitationPathways><gtr:id>B969827F-0AD9-4278-BC00-2836C258D9F7</gtr:id><gtr:outcomeId>r-3988456776.3548875774884da</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>1DF5070E-0776-47B4-AD0F-2CF1C45079CB</gtr:id><gtr:title>Representation of Stereoscopic Volumes</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>546371ad041dd7.86092912</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CF0DC808-D780-478C-949D-D957541963E5</gtr:id><gtr:title>Effects of inter-ocular contrast difference and decorrelation noise on disparity discrimination</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>5463752506a5a2.67054346</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5C401E74-BF3D-4EB0-937A-5C1E0F904F85</gtr:id><gtr:title>Mechanisms for similarity matching in disparity measurement.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>5441216a5d5b17.84152428</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B42348A1-88ED-4B90-B0D1-A4B7998AFEF0</gtr:id><gtr:title>Representation and measurement of stereoscopic volumes.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5a35f7a85b4d34.62808591</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>108809E5-27F5-45CD-A270-C55E0E103F38</gtr:id><gtr:title>Remote interactions in contour detection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3455cee0c423d16b1c93457f9a8ea1db"><gtr:id>3455cee0c423d16b1c93457f9a8ea1db</gtr:id><gtr:otherNames>O'Kane L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>m_2409223743140d9634</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>84582E7B-9596-4C11-8642-A04E6454362B</gtr:id><gtr:title>Tuned Inhibitory Responses in Binocular Natural Images</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>544122813f4087.73898967</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>35F662AF-823E-457C-954E-2E64D3CD913E</gtr:id><gtr:title>What does a decorrelated stereogram look like?</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6614cf1b81d78c6df678272d5d207077"><gtr:id>6614cf1b81d78c6df678272d5d207077</gtr:id><gtr:otherNames>Goutcher R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>5463763b9cd633.43073029</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C7FE17C1-CDAE-4864-ADC0-8EB0EA542DCC</gtr:id><gtr:title>Encoding and estimation of first- and second-order binocular disparity in natural images.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a663d40f64953891ab494a253453d12c"><gtr:id>a663d40f64953891ab494a253453d12c</gtr:id><gtr:otherNames>Hibbard PB</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>56d6e51409f3b7.24089719</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>45C59EFF-FFFA-406D-8F55-7A2158797667</gtr:id><gtr:title>Effects of orientation and noise on the detection of cyclopean form</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3455cee0c423d16b1c93457f9a8ea1db"><gtr:id>3455cee0c423d16b1c93457f9a8ea1db</gtr:id><gtr:otherNames>O'Kane L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>5463749e1eea28.06713558</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/G004803/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>