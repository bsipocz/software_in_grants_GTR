<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24"><gtr:id>89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24</gtr:id><gtr:name>Open University</gtr:name><gtr:address><gtr:line1>Walton Hall</gtr:line1><gtr:line2>Walton</gtr:line2><gtr:line4>Milton Keynes</gtr:line4><gtr:line5>Buckinghamshire</gtr:line5><gtr:postCode>MK7 6AA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:department>Dept of Computing</gtr:department><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24"><gtr:id>89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24</gtr:id><gtr:name>Open University</gtr:name><gtr:address><gtr:line1>Walton Hall</gtr:line1><gtr:line2>Walton</gtr:line2><gtr:line4>Milton Keynes</gtr:line4><gtr:line5>Buckinghamshire</gtr:line5><gtr:postCode>MK7 6AA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F0F4BD12-F24A-4617-9BE9-615A9EE3AC1F"><gtr:id>F0F4BD12-F24A-4617-9BE9-615A9EE3AC1F</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:surname>Colton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FF067127%2F1"><gtr:id>5743EE80-5F81-4536-87B2-3605CCFE81C7</gtr:id><gtr:title>Enhancing Objet Trouve Methods in Graphic Design (A Feasibility Study)</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F067127/1</gtr:grantReference><gtr:abstractText>Software products such as Adobe Photoshop have revolutionised graphic design in the past decade, by enabling designers to be more creative and more efficient. Whenever a designer uses such software - whether it is for something simple like finding a suitable image, or something more complex, like making a piece of art or putting together an entire design - they will be making aesthetic judgements about the images/artworks/designs (which we call artefacts) that they are presented with. They will choose one image, but reject another; they will play around with image manipulation tools, rejecting many possibilities and developing others until they are happy with the end result; they will attempt a design then scrap it in favour of another.In theory, the aesthetic choices made by a designer could be analysed by the software they are using, and this information could be used to make the software better. This improvement could be in the form of greater efficiency, so that the designer can expect to finish their project quicker, or it could be in the form of improved creativity, so that the designer can expect to be able to try out more possibilities in the time they have available. While there have been a number of studies in this area, in general, graphics software does not utilise any aesthetic information from the user, and there is a great opportunity to bring in Artificial Intelligence techniques for this purpose.If we were to sit down and ask a designer to describe why certain artefacts are good or bad, and try and write down a method for approximating their choices, we would end up using mathematical concepts such as choosing the largest of two values, or taking averages, or composing two ideas together, etc. In effect, we would be mathematically modeling their aesthetic preferences. The purpose of this project is to test the feasibility of using our HR automated mathematical theory formation software for this modeling process. HR has had much success with the invention of mathematical concepts, and the discovery of theorems of genuine interest to mathematicians in number theory, graph theory and various algebraic domains. Moreover, it has recently been used to invent mathematical concepts which approximate the value of scenes for a computer art application. This small case study has highlighted the potential benefits of using HR in graphic design applications.We are proposing a two stage approach to integrating HR with graphic design software so that the user employs the software, oblivious to HR running in the background. We assume that the user starts the session with only a vague idea of what artefact they would like to produce, and are happy to work in an objet trouve (found art) manner. That is, they will look for artefacts within those presented to them for inspiration, and then pursue any ideas they have vigorously. In the first stage, we will replace the usual ad-hoc browsing of possibilities with a themed approach, where we will use HR to invent methods (fitness functions) for evaluating artefacts and then present the user with artefacts which score well within each theme. In the second stage, we will use closed-loop learning to mathematically model an approximation of the user's aesthetic. When the model is sufficiently good, it will be used to guide the user more quickly to a final artefact.We will test this approach in three application domains, namely evolutionary art, image retrieval and city design for video games. We have assembled a team of project partners with great experience in these areas, and we have software available with which to integrate HR. We plan to pay subjects to perform experiments, and we will test whether they are more efficient and/or more creative with the enhanced application software. This is a risky project, but if it is successful, it may lead to a radical change in the way designers take advantage of intelligent software in the creative process.</gtr:abstractText><gtr:fund><gtr:end>2009-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>95571</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Open University</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Open University</gtr:description><gtr:id>0D19C309-20CF-48DF-8047-9B7EE660F5C5</gtr:id><gtr:outcomeId>b9cebfeeb9cec002-1</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>2E3F00A6-CFD4-436F-8B3F-857125486874</gtr:id><gtr:title>Experiments in Objet Trouve Browsing.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5e819b212b53b6af52591f46e23cda36"><gtr:id>5e819b212b53b6af52591f46e23cda36</gtr:id><gtr:otherNames>Colton. S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>54632e91937d85.13041178</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEC79A7B-670D-4BED-8DFC-CFD3AB2D2241</gtr:id><gtr:title>Computers and Creativity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dfb3539ddc79baa25031032f45c73d7a"><gtr:id>dfb3539ddc79baa25031032f45c73d7a</gtr:id><gtr:otherNames>Colton S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-3-642-31726-2</gtr:isbn><gtr:outcomeId>56e15abb8fc643.54610616</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D6A700F4-34BE-44E8-A569-4035F56E0FA7</gtr:id><gtr:title>Automatic Invention of Fitness Functions, with application to Scene Generation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5e819b212b53b6af52591f46e23cda36"><gtr:id>5e819b212b53b6af52591f46e23cda36</gtr:id><gtr:otherNames>Colton. S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>546340780165c4.37075928</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A7B17BF7-DCCD-474E-B93B-757EA67B0668</gtr:id><gtr:title>Emotionally Aware Automated Portrait Painting</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/df7d3a20d02df5ba9e2f806711d56211"><gtr:id>df7d3a20d02df5ba9e2f806711d56211</gtr:id><gtr:otherNames>Colton.S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>54632cc2c70863.39254022</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>70726EFE-38EF-46E2-81EE-071C8B224F88</gtr:id><gtr:title>Evolving Simple Art-based Games</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/700b784f13c8e71dc3a5e516346325e2"><gtr:id>700b784f13c8e71dc3a5e516346325e2</gtr:id><gtr:otherNames>S Colton</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_860795174263dbcc18</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E9DC16BE-86DE-4D63-84C3-787B7DEBB0D5</gtr:id><gtr:title>Experiments in Example based Image Filter Retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7b31d371dae3f0ed1191b29716b8480e"><gtr:id>7b31d371dae3f0ed1191b29716b8480e</gtr:id><gtr:otherNames>P Torres</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_395941676963d0f310</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEB96501-6B73-476B-A1D4-20E7C95CE4D9</gtr:id><gtr:title>Stroke Matching for Paint Dances</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5e819b212b53b6af52591f46e23cda36"><gtr:id>5e819b212b53b6af52591f46e23cda36</gtr:id><gtr:otherNames>Colton. S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>5463301ec3d4d3.68636947</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>961C9D06-EF22-43F3-925F-69197276FA08</gtr:id><gtr:title>Experiments in Constraint Based Automated Scene Generation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5e819b212b53b6af52591f46e23cda36"><gtr:id>5e819b212b53b6af52591f46e23cda36</gtr:id><gtr:otherNames>Colton. S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>546340ceb088d3.01041411</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>66D95547-D401-4D8D-8A51-41BDC1A298C3</gtr:id><gtr:title>Experiments in Example based Image Filter Retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6000f7f229b42a7decbe739339ce700e"><gtr:id>6000f7f229b42a7decbe739339ce700e</gtr:id><gtr:otherNames>Torres. P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>54634230068ac7.01822641</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11E2F995-328A-4BE2-90B1-38782B54A7D3</gtr:id><gtr:title>Automated Meta-Theory Induction in Pure Mathematics</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6000f7f229b42a7decbe739339ce700e"><gtr:id>6000f7f229b42a7decbe739339ce700e</gtr:id><gtr:otherNames>Torres. P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>546341e580dbc5.20434406</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3382FB51-6801-4C6A-B287-D078719FD6E4</gtr:id><gtr:title>Automated Collage Generation - With Intent.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2789043cc07b6199c970d235908ff16e"><gtr:id>2789043cc07b6199c970d235908ff16e</gtr:id><gtr:otherNames>Krzeczkowska.A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>54632e425a51f0.93654031</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>298303E7-CE6B-47E8-9606-51480230D629</gtr:id><gtr:title>Evolving Approximate Image Filters</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/700b784f13c8e71dc3a5e516346325e2"><gtr:id>700b784f13c8e71dc3a5e516346325e2</gtr:id><gtr:otherNames>S Colton</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_952258952463dbcaf6</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F067127/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>608431EA-925E-44D8-A1E2-8C24B4768085</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Design</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>55</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>4A856E02-8C94-4981-B572-E381EEB60DD2</gtr:id><gtr:percentage>5</gtr:percentage><gtr:text>Media</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>9E4BDAC2-CD51-4625-BCC1-5F768EE168D0</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Design HTP</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>82C70E72-2209-4A44-A192-A9AACE9E06C2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Design Processes</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>56E563D3-2614-496C-AD1F-9841F4388401</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Digital Art &amp; Design</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0F8B7B13-F2F5-42B3-95C6-EF12D7877319</gtr:id><gtr:percentage>5</gtr:percentage><gtr:text>Multimedia</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>C597DCEC-497B-45A1-8662-9C7AFF112DDE</gtr:id><gtr:percentage>5</gtr:percentage><gtr:text>Publishing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>