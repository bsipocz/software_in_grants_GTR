<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Informatics</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/268676F3-8E18-4E32-95B0-9952D98BEC0C"><gtr:id>268676F3-8E18-4E32-95B0-9952D98BEC0C</gtr:id><gtr:firstName>Oliver</gtr:firstName><gtr:surname>Lemon</gtr:surname><gtr:orcidId>0000-0001-9497-4743</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/BC768B4F-1979-44A7-8527-4740ED86498F"><gtr:id>BC768B4F-1979-44A7-8527-4740ED86498F</gtr:id><gtr:firstName>James</gtr:firstName><gtr:otherNames>Brinton</gtr:otherNames><gtr:surname>Henderson</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE019501%2F1"><gtr:id>818FB156-CBCE-42F5-9E9D-7EFF7FD8FF94</gtr:id><gtr:title>End-to-end integrated Statistical processing for Context-aware dialogue systems</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E019501/1</gtr:grantReference><gtr:abstractText>This project targets a new processing paradigm for the development andoptimization of spoken dialogue systems (SDS) that are context-aware,efficient, and most importantly robust to the uncertainty thatpervades natural language. We will develop tractable and effectivetechniques for the integrated end-to-end treatment of uncertainty incontext-aware SDS, using learning algorithms combinedwith Partially Observable Markov Decision Processes (POMDPs). Thisrequires us to develop effective methods for training and testing suchsystems. We will also determine, through system tests withreal users, whether the end-to-end statistical treatment ofuncertainty improves SDS for users, in comparison to rulebased and standard MDP-based techniques.No current SDS treats dialogue processing as an end-to-endintegrated statistical system, constrained by context, whereuncertainty in one process feeds into other processes, whereuncertainty in one dialogue state feeds into the nextdialogue state, and where this whole system is constrained viacontextual feedback. It is still standard practice to ignore theuncertainty in the output of a lower-level process by passing only asingle best analysis to higher-level processes, with the sideeffect that lower-level processes do not take into account importanthigh-level constraints. For example, contextual features ofdialogues such as user goals or previous speech acts are notsystematically exploited in speech recognition or utteranceinterpretation. This is a serious shortcoming for current SDS, given that uncertainty pervades and proliferates throughevery level of dialogue processing, from speech recognition errorsthrough interpretation ambiguities, to uncertain dialogue states andcompeting strategies. These problems lead to the currentsituation where SDS are not robust or efficient enoughfor any but very simple tasks.We will build and evaluate SDS which usestatistical processing end-to-end, and which use contextrepresentations to constrain the uncertainty inherent in dialogue. Wewill build on exisiting knowledge and techniques developed in the TALKproject, and well as recent corpora (COMMUNICATOR, TALK, AMI). TheSDS development tools, components, and environments usedand developed at Edinburgh's HCRC (e.g. DIPPER, HTK, Festival) alsoprovide a number of exisiting dialogue systems (FLIGHTS, TALK, WITAS), forming a platform to be extended usingthe new methods developed in the project. These systems can then beused for testing, evaluation, and further data collection.The proposal thus aims to improve dialogue system robustness andefficiency, and allow SDS to be developed and optimized usingdata-driven approaches. There is much user frustration with currently deployed SDS, so there is much to be gained from improved robustness andefficiency. Data-driven optimization will also lead to decreaseddeployment and development costs for industry. Thus the beneficiaries ofthis research will potentially be all futureusers of IT (including the illiterate andIT-illiterate, also in the developing world). In the short tomedium term, commercial applications include: interactive SDS, dialogue and meeting summarisation, interactiveentertainment, intelligent tutoring systems, intelligent personalassistants, and dialogue supported question-answering and search.With recent advances in speech recognition, parsing, context-sensitivestatistical dialogue management, the theory of learning with PartiallyObservable states, the availability of new,large, and richly annotated dialogue corpora, we are now in a position to treat dialogueprocessing as an end-to-end context-aware statistical system. Webelieve this model will lead to a breakthough in robust, efficient, and natural human-computer SDS, andhas the potential to radically improve the state-of-the-art indialogue management.</gtr:abstractText><gtr:fund><gtr:end>2009-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>266906</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>3209918</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>EC FP7 ICT project: JAMES: Joint Action for Multimodal Embodied Social Systems</gtr:description><gtr:end>2014-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>270435</gtr:fundingRef><gtr:id>251EE05A-A206-4BEE-8B5E-0E7F37F0C27A</gtr:id><gtr:outcomeId>5ec59a745ec59a88</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-02-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>645000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>EC FP7 ICT grant: SpaceBook</gtr:description><gtr:end>2014-02-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>270019</gtr:fundingRef><gtr:id>0F1D62F3-E4A9-4EF5-B213-F5E980F49072</gtr:id><gtr:outcomeId>5ec595ec5ec59600</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-03-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Applications of the this work include: interactive spoken dialogue systems, dialogue and meeting summarisation, interactive entertainment, intelligent tutoring systems, intelligent personal assistants, and dialogue supported question-answering and search on mobile devices -- such as Apple's Siri, Microsoft's Cortana, and Google Now. Our findings form some of the fundamental technological approaches for such systems.</gtr:description><gtr:firstYearOfImpact>2008</gtr:firstYearOfImpact><gtr:id>16BE9ABA-C402-4C92-930B-21ACCA6A4DB2</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>54467cc9c98317.06137079</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This project targeted a new processing paradigm for the development and optimization of spoken dialogue systems (SDS) that are context-aware, efficient, and most importantly robust to the uncertainty that pervades natural language. We published 5 journal papers, 8 conference papers, and 5 workshop papers on these issues (all peer reviewed). We also gave several invited talks on this research (e.g. Oxford University 2008, King's College London 2008, International Conference on Human-Computer Conversation 2008). 

We developed tractable and effective techniques for the integrated end-to-end treatment of uncertainty in context-aware SDS, using learning algorithms combined with Partially Observable Markov Decision Processes (POMDPs). This required us to develop effective methods for training and testing such systems. We also investigated, through system tests in more than 400 test dialogues, whether this end-to-end statistical treatment of uncertainty improves SDS for end users. We have shown that our proposed model has specific benefits: for example a 5% reduction in Word Error Rates using a memory-based learning context-sensitive speech recognition method (Lemon &amp;amp; Konstas EACL 2009). This is an example of reducing uncertainty in the output of a lower-level process by taking into account high-level contextual constraints in an end-to-end statistical model.

The project achieved its planned milestones (M1 - M4). The first end-to-end statistical system was built by month 10 (the &amp;quot;Q-MDP system&amp;quot;: M1). This system was evaluated in simulation and with real users at the start of year 2 (M3), and year 2 then focussed on the creation of a POMDP SDS within this framework (M2). This system was completed towards the end of 2008, and refined and evaluated (in simulation and with real users: M4) in early 2009.

In summary, we built and evaluated one of the first SDS which used statistical processing end-to-end, and which used context representations to constrain the uncertainty inherent in dialogue. We have shown that this model produces more robust and efficient SDS, especially as noise increases.

We have therefore shown how to improve dialogue system robustness and efficiency, and developed a methodology allowing SDS to be developed and optimized using data-driven approaches. 

We have shown that such an approach can ultimately lead to a breakthrough in robust, efficient, and natural human-computer SDS, and has the potential to improve the state-of-the-art in dialogue management.</gtr:description><gtr:exploitationPathways>Applications of the this work include: interactive spoken dialogue systems, dialogue and meeting summarisation, interactive entertainment, intelligent tutoring systems, intelligent personal assistants, and dialogue supported question-answering and search on mobile devices -- such as Apple's Siri.</gtr:exploitationPathways><gtr:id>03004A6B-EDDD-4C83-89A7-0C27F7E4FB57</gtr:id><gtr:outcomeId>54467c56eed987.07597957</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors><gtr:url>https://sites.google.com/site/epsrcstatdial/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>Collection of algorithms for end-to-end statistical processing in automated spoken dialogue systems. See project publications for details</gtr:description><gtr:id>7DE28E0B-FBCA-487B-B6B6-BB8C49C6AD3A</gtr:id><gtr:impact>Use in future EC FP7 projects such as SpaceBook, JAMES, PARLANCE.</gtr:impact><gtr:outcomeId>545a0a932d5002.79867306</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>End-to-End statistical dialogue management algorithms</gtr:title><gtr:type>Computer model/algorithm</gtr:type><gtr:yearFirstProvided>2010</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>Spoken dialogue data collected in the evaluation of the end-to-end statistical systems</gtr:description><gtr:id>065BF880-D69E-4ACF-B194-08FA00FB9A82</gtr:id><gtr:impact>Data used in follow-up EPSRC project and also EC FP7 projects such as SpaceBook and PARLANCE</gtr:impact><gtr:outcomeId>545a093f77e360.42059468</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Spoken dialogue data -- end-to-end</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Working automated spoken dialogue system used in project demonstrations (see publications) and for system evaluations with real users, in telephone-based interactions.</gtr:description><gtr:id>9A749077-ED46-420E-AC2E-F866845939A0</gtr:id><gtr:impact>Platform used in further research in EC FP7 projects such as PARLANCE and SpaceBook.</gtr:impact><gtr:outcomeId>545a0bb4d4da29.73978982</gtr:outcomeId><gtr:title>ABC demonstration / evaluation automated spoken dialogue system (telephone-based)</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:url>https://sites.google.com/site/abcpomdp/home</gtr:url><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>0A2A6BF1-1990-4725-B959-64FE568E05D0</gtr:id><gtr:title>Machine Learning for Spoken Dialogue Systems</gtr:title><gtr:parentPublicationTitle>Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7d97a15016c9bed29e7058769098809"><gtr:id>e7d97a15016c9bed29e7058769098809</gtr:id><gtr:otherNames>O Lemon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>5464c6fd973336.54202799</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F8A26D03-3779-46BF-88AF-06B59D9FBB39</gtr:id><gtr:title>Learning human multimodal dialogue strategies</gtr:title><gtr:parentPublicationTitle>Natural Language Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a8dbf688af21c4560a689c0b305c91c8"><gtr:id>a8dbf688af21c4560a689c0b305c91c8</gtr:id><gtr:otherNames>RIESER V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d0130136fccfd4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>80FA1091-5EA5-416F-A8C3-6E1B03C4997C</gtr:id><gtr:title>Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</gtr:title><gtr:parentPublicationTitle>Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/32fe4ceebc1ed31dd64b02d54fe50612"><gtr:id>32fe4ceebc1ed31dd64b02d54fe50612</gtr:id><gtr:otherNames>Henderson J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_55f95195105a4357</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ECEC32B9-9B71-42DE-A96D-8B7D869A9380</gtr:id><gtr:title>User Simulations for Context-sensitive Speech Recognition in Spoken Dialogue Systems</gtr:title><gtr:parentPublicationTitle>EACL</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/222d88b0fc82ec1e915ffd88817fa8eb"><gtr:id>222d88b0fc82ec1e915ffd88817fa8eb</gtr:id><gtr:otherNames> O Lemon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_523548927713f4ceb0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CD9259A3-4C73-42AB-9DF4-BAF89AD41AA1</gtr:id><gtr:title>Learning Effective Multimodal Dialogue Strategies from Wizard-of-Oz data: Bootstrapping and Evaluation</gtr:title><gtr:parentPublicationTitle>ACL</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/239fb76a36412c94319cb28d27ff9e0d"><gtr:id>239fb76a36412c94319cb28d27ff9e0d</gtr:id><gtr:otherNames>V Rieser</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>5464ced14f9d17.14229709</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>74A7BE65-1EDD-448F-8ADB-C4DFA66064C5</gtr:id><gtr:title>Learning human multimodal dialogue strategies</gtr:title><gtr:parentPublicationTitle>Natural Language Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a8dbf688af21c4560a689c0b305c91c8"><gtr:id>a8dbf688af21c4560a689c0b305c91c8</gtr:id><gtr:otherNames>RIESER V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_55f951951048c84d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B2FE3368-B51A-4FBB-8B0A-39C785C0ECCE</gtr:id><gtr:title>Spoken Language Understanding in dialogue systems, using a 2-layer Markov Logic Network: improving semantic accuracy</gtr:title><gtr:parentPublicationTitle>Workshop on the Semantics and Pragmatics of Dialogue</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4d2b40f17657721402d83ffe12f1f212"><gtr:id>4d2b40f17657721402d83ffe12f1f212</gtr:id><gtr:otherNames>I Meza-Ruiz</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>5464c24ad19698.92851779</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EA8998D4-F4A1-4810-94F1-635FC0EBFD97</gtr:id><gtr:title>Accurate Probability Estimation of Hypothesised User Acts for POMDP Approaches to Dialogue Management</gtr:title><gtr:parentPublicationTitle>Proceedings of the 12th Annual Research Colloquium of the Special-interest group for Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/60391d59e2ae131685c541abf01e0fa0"><gtr:id>60391d59e2ae131685c541abf01e0fa0</gtr:id><gtr:otherNames> P Crook</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_373791649763db26b4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>68C092CB-8E6A-4196-8086-86D641EE53E1</gtr:id><gtr:title>Automatic annotation of context and speech acts for dialogue corpora</gtr:title><gtr:parentPublicationTitle>Natural Language Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d2a080afcbd4614de3db7127e20ecce"><gtr:id>3d2a080afcbd4614de3db7127e20ecce</gtr:id><gtr:otherNames>GEORGILA K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d01301370558e7</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5A3358E4-A875-4C9B-A5B4-5B4BDFA18887</gtr:id><gtr:title>A Wizard-of-Oz environment to study Referring Expression Generation in a Situated Spoken Dialogue Task</gtr:title><gtr:parentPublicationTitle>European Workshop on Natural Language Generation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7579968450c90ee925415ab06e84b63f"><gtr:id>7579968450c90ee925415ab06e84b63f</gtr:id><gtr:otherNames>S Janarthanam</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>5464c666abe5f4.49513209</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FE03DF78-BBF0-47E8-8E13-ED306C10EFD8</gtr:id><gtr:title>Dialogue Policy Learning for combinations of Noise and User Simulation:transfer results</gtr:title><gtr:parentPublicationTitle>SIGDIAL</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7d97a15016c9bed29e7058769098809"><gtr:id>e7d97a15016c9bed29e7058769098809</gtr:id><gtr:otherNames>O Lemon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>5464c7941f6fb1.96269990</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DF400346-A2BF-4CC7-9657-A96165755BA9</gtr:id><gtr:title>Does this list contain what you were searching for? Learning adaptive dialogue strategies for interactive question answering</gtr:title><gtr:parentPublicationTitle>Natural Language Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a8dbf688af21c4560a689c0b305c91c8"><gtr:id>a8dbf688af21c4560a689c0b305c91c8</gtr:id><gtr:otherNames>RIESER V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_55f95195103ee2f2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CB96C1F6-1F26-4126-86A6-168AFA77367B</gtr:id><gtr:title>Learning what to say and how to say it: Joint optimisation of spoken dialogue management and natural language generation</gtr:title><gtr:parentPublicationTitle>Computer Speech &amp; Language</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0d9ae1a40c18c69d3c9eac73b6e925f6"><gtr:id>0d9ae1a40c18c69d3c9eac73b6e925f6</gtr:id><gtr:otherNames>Lemon O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>5464cdb4ea75f6.31304076</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5E8068A1-B855-4ABF-BABE-09BA7F1B683A</gtr:id><gtr:title>Reinforcement Learning for Adaptive Dialogue Systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6ed8915c4f7fbd63030ebe07f5e97060"><gtr:id>6ed8915c4f7fbd63030ebe07f5e97060</gtr:id><gtr:otherNames>Rieser V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>54579f9253cd76.29024192</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>48051E4D-32BF-49F6-AE6D-D72A2C828BC6</gtr:id><gtr:title>Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</gtr:title><gtr:parentPublicationTitle>Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/32fe4ceebc1ed31dd64b02d54fe50612"><gtr:id>32fe4ceebc1ed31dd64b02d54fe50612</gtr:id><gtr:otherNames>Henderson J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53d076076cc5156e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4DE40DF5-AB5A-454A-B5E7-B4998150280B</gtr:id><gtr:title>Fast and Robust Multilingual Dependency Parsing with a Generative Latent Variable Model</gtr:title><gtr:parentPublicationTitle>EMNLP-CoNLL</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e9aa7c3dc2ca2260666681f49e476a49"><gtr:id>e9aa7c3dc2ca2260666681f49e476a49</gtr:id><gtr:otherNames>I Titov</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>5464c82a038f08.45584831</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>18D1533B-E32D-40D1-A1A1-86CA3238650B</gtr:id><gtr:title>Automatic annotation of context and speech acts for dialogue corpora</gtr:title><gtr:parentPublicationTitle>Natural Language Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d2a080afcbd4614de3db7127e20ecce"><gtr:id>3d2a080afcbd4614de3db7127e20ecce</gtr:id><gtr:otherNames>GEORGILA K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_55f9519510518151</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B2923E3-EBEA-43B3-B2E9-ACC5AE76E41F</gtr:id><gtr:title>Constituent Parsing with Incremental Sigmoid Belief Networks</gtr:title><gtr:parentPublicationTitle>Association for Computational Lingusitics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e9aa7c3dc2ca2260666681f49e476a49"><gtr:id>e9aa7c3dc2ca2260666681f49e476a49</gtr:id><gtr:otherNames>I Titov</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>5464c389294cc3.51552167</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FBF791E1-8B11-4C02-9780-5C29CD320940</gtr:id><gtr:title>Adaptive Natural Language Generation in Dialogue using Reinforcement Learning</gtr:title><gtr:parentPublicationTitle>SEMDIAL</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7d97a15016c9bed29e7058769098809"><gtr:id>e7d97a15016c9bed29e7058769098809</gtr:id><gtr:otherNames>O Lemon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>5464c98307bf93.70083323</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E019501/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>