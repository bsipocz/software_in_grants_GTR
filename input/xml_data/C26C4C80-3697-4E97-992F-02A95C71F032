<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/1358BB49-2007-4151-9442-5672E8E5816B"><gtr:id>1358BB49-2007-4151-9442-5672E8E5816B</gtr:id><gtr:firstName>Stephen</gtr:firstName><gtr:otherNames>Richard</gtr:otherNames><gtr:surname>Langton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/B01BF354-7AC7-47C5-A1C9-62C10636DAA0"><gtr:id>B01BF354-7AC7-47C5-A1C9-62C10636DAA0</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:surname>Hancock</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FI034803%2F1"><gtr:id>C26C4C80-3697-4E97-992F-02A95C71F032</gtr:id><gtr:title>Orienting of visual attention in response to naturalistic, dynamic shifts of another's gaze</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/I034803/1</gtr:grantReference><gtr:abstractText>&lt;p>Anecdotally, people seem to have a strong tendency to follow one another's eye gaze and experimental research seems to support this observation. During a normal conversation, however, speakers often avert their gazes from listeners' faces. They may do this to avoid distraction, to signal that their conversational turns are ongoing, to maintain an appropriate level of intimacy, or perhaps to fixate on something they have noticed in the environment. Following a speaker's eye-gaze in all but the last case will be of little use to a listener, and yet the existing research suggests that all such shifts of gaze will trigger reflexive shifts of attention.&lt;/p>

&lt;p>In our research we ask whether listeners can distinguish different types of gaze behaviour, and if so, how? Pairs of people will be asked to engage in a task that will elicit normal, conversational gazes on the part of speakers (eg glances away while they are thinking), but which will also elicit deliberate, object-directed gazes at designated targets, and reflexive gazes toward the source of an unexpected loud noise. Using eye-tracking equipment, we will examine whether listeners are more likely to follow the deliberate and reflexive object-directed gazes of speakers than their conversational gazes. &lt;/p></gtr:abstractText><gtr:fund><gtr:end>2014-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2011-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>271398</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Invited lecture</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0D32645C-13EF-4B9A-8249-684F77017D7D</gtr:id><gtr:impact>Invited lecture to undergraduate students at Queens University, Kington, Ontario. This was attended by over 100 students, mainly from Canada.</gtr:impact><gtr:outcomeId>56d97715603c61.49034468</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>To date we have no evidence of any impact of our work beyond academia. One reason may be that, because of technical difficulties we experienced building the equipment we used for our experiments (see the Key Findings report), we have only recently begun dissemination of our main findings. Two papers have recently been submitted for publication (see publications), and some of the work has been presented in invited talks given at Queens University, Ontario, Canada; El Bosque University, Bogota, Colombia; and the University of Stirling. We also plan to engage users beyond academia by presenting our work at the International Symposium on Robot and Human Interactive Communication in New York, August 2016. A paper has recently been submitted to this conference (see publications).</gtr:description><gtr:id>ECBDE966-615C-49B5-A841-CDF639014629</gtr:id><gtr:impactTypes/><gtr:outcomeId>56349c1d2ff8f7.13001905</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Lab studies have shown that observers experience rapid and automatic shifts of attention in the direction in which they have just seen someone else shift their gaze - an effect know as gaze cued orienting of attention. This effect occurs when observers are sitting in front of a computer screen and they are shown a series of brief, isolated clips of a face whose eyes shift to the left or right in each of a number of trials. Our research investigated the extent to which this orienting response occurs in more natural situations in which observers are actually interacting with other individuals. We were interested in comparing gaze following in response to gazes in natural interactions, with gaze-cued orienting in response to the same gazes presented in isolation, as in the normal lab-based experiments. 

First we discovered that overt gaze following is very rare in the natural interactions we studied. Even though we took care to mimic as far as possible the conditions in which gaze cued orienting has been observed in the lab (e.g., faces were seen against a black background, the objects toward which gazes were directed were not always visible to observers, the deliberate target-directed gazes involved gaze shifts of similar angles as typically seen in the lab studies), only 6.8% of all gazes were followed in the studies we conducted. When observers did follow gaze, however, it was relatively more likely to be in response to deliberate target-directed gazes, 10% of which were followed, than conversational gazes (e.g., glances away from the observer's face while thinking), of which just 4% were followed. 

Second, we found that although gaze following is rare when gazes are in the context of an ongoing interaction, the same gazes when shown in isolation do seem to trigger gaze-cued attention shifts. Clearly, the context of a natural interaction serves to reduce gaze-cued orienting of attention, which may therefore be under a good deal more cognitive control than is often assumed from the basic lab studies. Consistent with this, in another set of experiments, we found evidence that high level cognitive control processes are involved in basic gaze-cued orienting, which is contrary to the idea that the response is like a reflex.

Third, we examined the physical properties that might discriminate between gazes that might be worth following (i.e., target-directed gazes) and those that might not be (i.e., conversational gazes). In terms of their physical properties, target-directed gazes tended to be of longer duration and were more likely to contain a head turn than conversational gazes. However, of these two cues, only gaze duration was reliably related to gaze following, and then only for target directed gazes. In marked contrast to these findings with naturally occurring gazes, gaze-cued orienting with isolated gazes was insensitive to speed of gaze shifting, fixation duration or the presence of motion cues per se.

Finally, and surprisingly, we found that the amount of gaze following in natural situations did not increase when both parties in the interaction could see the objects toward which deliberate gazes were directed. What did increase when target context was shared, however, was the reliance on gaze duration as a cue to gaze following: when observers could see the objects toward which their interacting partners were occasionally directing their gazes, longer gazes were relatively more likely to trigger gaze following responses.</gtr:description><gtr:exploitationPathways>Our research suggests that the automatic gaze-cued orienting found in lab-based studies may not be something that occurs when ecological validity is improved. However, it seems likely that there are ecologically valid situations in which the effect does occur, and future research could explore what factors are important. Moreover, we only studied gaze following in a certain type of face-to-face interaction, in an environment with few distracting objects, and where target-directed gazes were oriented towards objects that were irrelevant to the ongoing interaction. Future studies might test whether gaze following is increased in more complex environments with objects which are potentially relevant. 

Beyond the academic community, there are others who might make use of our findings. For example, designers are currently interested in using eye gaze as a component of animated displays the purposes of which are to direct people's attention to important locations during tasks such as buying groceries from self-service checkouts, or withdrawing money from ATMs, or in giving directions to people in airports and hospitals, and so on. Our research suggests that, to be effective, relevant gazes should not be embedded in a sequence containing natural conversational gazes that are not intended to direct another's attention.

Designers of home help robots may also be interested in our findings. An effective robot would need to be able to &amp;quot;read&amp;quot; and respond appropriately to its owner's gazes; our data suggest that gaze duration is an important variable in predicting when a gaze might be followed. Furthermore, if the robot itself were to be fitted with human-like eyes, our data might inform designers of acceptable durations of &amp;quot;natural&amp;quot; averted gazes, and of gazes intended to direct the owner's attention to some location.</gtr:exploitationPathways><gtr:id>1EDF3490-77AE-4D5F-B17F-285B270E297F</gtr:id><gtr:outcomeId>54db7e33ab3559.15644041</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>60102FB7-FA0D-4DF7-AD0B-6763CB44BD71</gtr:id><gtr:title>Saccades and smooth pursuit eye movements trigger equivalent gaze-cued orienting effects.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1b0d05bc5c214754a419d6fc71e1016d"><gtr:id>1b0d05bc5c214754a419d6fc71e1016d</gtr:id><gtr:otherNames>Langton SRH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>5aa26353036562.40993639</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7EA400AF-6E69-4748-9244-D03F83DEB77E</gtr:id><gtr:title>Motion signals do not influence gaze-cued orienting of attention</gtr:title><gtr:parentPublicationTitle>Visual Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/91505be856a88c2ddbc76a9d389c69ed"><gtr:id>91505be856a88c2ddbc76a9d389c69ed</gtr:id><gtr:otherNames>Langton S. R. H</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>58c6b8d9dd1870.60947750</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>526F09CC-C20B-4AA8-8DFE-CB3B48D7FA2A</gtr:id><gtr:title>Working memory load disrupts gaze-cued orienting of attention.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4673d6c89cf44146364c96ec0f0e1bfb"><gtr:id>4673d6c89cf44146364c96ec0f0e1bfb</gtr:id><gtr:otherNames>Bobak AK</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>546323931dd3a1.12219435</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>768261FF-64C9-456B-8F69-68540AD5F851</gtr:id><gtr:title>Saccades and smooth pursuit eye movements trigger equivalent gaze cued orienting of attention</gtr:title><gtr:parentPublicationTitle>Quarterly Journal of Experimental Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b54d4e9459792e7d41d095d0b997328"><gtr:id>3b54d4e9459792e7d41d095d0b997328</gtr:id><gtr:otherNames>Langton S. R. H.</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>562899b8dc08a6.11198276</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B34B4D7-580D-4ED1-A5AB-73EFDA3FB936</gtr:id><gtr:title>Human gaze following in response to naturalistic, dynamic social gazes: A challenge for the design of social robots</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f2a743f5b787e9dc644cdd2c8ba3e8a7"><gtr:id>f2a743f5b787e9dc644cdd2c8ba3e8a7</gtr:id><gtr:otherNames>Langton, S. R. H.</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>56d97368a2c804.97138040</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B44763D6-477C-4971-A746-42E6213ED4FB</gtr:id><gtr:title>Covert and overt orienting of attention in response to naturalistic, dynamic shifts of another's social gaze</gtr:title><gtr:parentPublicationTitle>Cognitive Research: Principles and Implications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b54d4e9459792e7d41d095d0b997328"><gtr:id>3b54d4e9459792e7d41d095d0b997328</gtr:id><gtr:otherNames>Langton S. R. H.</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>562898e6dcea74.13858809</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9AF0651A-24E3-42AE-8F07-B9936D9CF276</gtr:id><gtr:title>Looking back at the stare-in-the-crowd effect: staring eyes do not capture attention in visual search.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f6b7634c5e5338cc29abbbb95726b483"><gtr:id>f6b7634c5e5338cc29abbbb95726b483</gtr:id><gtr:otherNames>Cooper RM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>pm_53cc022c022deae36</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>227EFEDE-A4C3-496F-B1F5-3983BCD229F5</gtr:id><gtr:title>I Don't See It Your Way: The Dot Perspective Task Does Not Gauge Spontaneous Perspective Taking</gtr:title><gtr:parentPublicationTitle>Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/257a64070f5859026830c8786b424bd0"><gtr:id>257a64070f5859026830c8786b424bd0</gtr:id><gtr:otherNames>Langton S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa2631cc317a5.00004430</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RES">RES-062-23-3211</gtr:identifier><gtr:identifier type="RCUK">ES/I034803/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>