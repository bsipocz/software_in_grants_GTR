<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Engineering Science</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/04B6A2AB-0C99-425B-98F3-5F2CDFF2D434"><gtr:id>04B6A2AB-0C99-425B-98F3-5F2CDFF2D434</gtr:id><gtr:firstName>Alison</gtr:firstName><gtr:surname>Noble</gtr:surname><gtr:orcidId>0000-0002-3060-3772</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9E6C09E6-578C-4956-96C8-335B7AD5ECFC"><gtr:id>9E6C09E6-578C-4956-96C8-335B7AD5ECFC</gtr:id><gtr:firstName>Julia</gtr:firstName><gtr:otherNames>Anne</gtr:otherNames><gtr:surname>Schnabel</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/AECB89A1-215A-45FF-9BC9-FD65453C24E6"><gtr:id>AECB89A1-215A-45FF-9BC9-FD65453C24E6</gtr:id><gtr:firstName>Alejandro</gtr:firstName><gtr:otherNames>Federico</gtr:otherNames><gtr:surname>Frangi</gtr:surname><gtr:orcidId>0000-0002-2675-528X</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/E7410EF7-9051-4F95-8981-1D02ED062618"><gtr:id>E7410EF7-9051-4F95-8981-1D02ED062618</gtr:id><gtr:firstName>Ben</gtr:firstName><gtr:surname>Glocker</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8EB2DEAC-68D4-44F8-BE0A-36CE64BFC01E"><gtr:id>8EB2DEAC-68D4-44F8-BE0A-36CE64BFC01E</gtr:id><gtr:firstName>Tom</gtr:firstName><gtr:otherNames>Kamiel</gtr:otherNames><gtr:surname>Vercauteren</gtr:surname><gtr:orcidId>0000-0003-1794-0456</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN026993%2F1"><gtr:id>6FEAFD26-B2A4-4FBF-8048-D5C63D64726F</gtr:id><gtr:title>EPSRC-NIHR HTC Partnership Award 'Plus': Medical Image Analysis Network (MedIAN)</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N026993/1</gtr:grantReference><gtr:abstractText>The EPSRC-NIHR Healthcare Technology Co-operatives Partnership Network in Medical Image Analysis seeks to bring leading UK researchers in medical image analysis together to identify new opportunities for medical image analysis methodology research within the clinical areas of high morbidity/unmet need of the NIHR Cardiovascular HTC and HTC in Colorectal Therapies.

The HTCs are working with patient groups and clinicians on identifying unmet clinical needs in these areas. An aim of the Medical Image Analysis Network (MedIAN) is to bring together imaging scientists with different skills sets and experiences to consider how technological advances in how images are acquired and images (and associated information) are analysed can be applied to solve some of these problems. 

The primary purpose of the Network is to encourage new collaborations to be set up between academic healthcare technologists, clinicians and industry partners to develop and evaluate new solutions. Network members are jointly tasked to work on some of the hardest medical image analysis problems there are today. The hope is that the resulting research will lead to new image-based biomarkers and quantification methods which will allow earlier detection of disease, and better stratification of disease so that the most appropriate therapy can be selected for a patient, and new image-based quantitative tools will lead to increases success of interventions and therapies and improve the
overall well-being of patients with these conditions.

How is MedIAN aiming achieve this goal? MedIAN is encouraging the development of new collaborations through scientific meetings with other networks/organisations, Clinical Readiness events which allow clinicians to evaluate current methods, and Challenge competitions which allow the international medical image analysis community to benchmark method on given clinical problems. 

This new award will augment the existing one by enabling a number of new activities to be run: People and Knowledge Exchanges between UK research groups for early career researchers, Medical Image Analysis hackathons, Scoping Workshops to help work-up grant proposals and the facilitation of two national meetings for early career researchers (ECRs) working in medical image analysis which will be run by ECRs for ECRs. The new award will also enable a new internet resource to be set up which aims to be a focal information portal for UK medical image analysis researchers and those who wish to work with them.</gtr:abstractText><gtr:potentialImpactText>The main non-academic beneficiaries of MedIAN activities are patients, clinicians, establishments where treatment happens, and companies that make healthcare products.

Clinical Impact:
The HTC partners will take the lead on this. The HTCs will use their knowledge gleaned from interactions with NHS Patient &amp;amp; Public Involvement groups, and clinicians linked to their HTC to pose new challenges to MedIAN members that may lead to technical solutions to some of the most challenging problems in diagnosis and treatment of patients with high morbidity conditions. Clinical impact at network award end will be measured in terms of the degree of active engagement of clinicians in the network and as partners on feasibility studies and grant submissions.

Commercial Impact:
The technology area of interest of this Network is likely to be of great interest to industry (imaging companies, medtech companies who use imaging for guidance, and medical diagnostic companies). The timeline from concept to product is typically of the order of 5-7 years in this area, so it unlikely that there will commercial success stories to report by award end. Commercial impact at network award end may be measured in terms of the degree of active engagement and support of industry in the network and as partners on
grant submissions. Intellectual Property may also be generated in feasibility projects and protection will be managed following the standard practices of the institutions involved.

Societal Impact:
The Network aims to make its own unique contribution to improving healthcare products and services, and through this, improve the quality of life of patients with high morbidity conditions. Direct benefits of network outputs are likely to be realised in the medium term. However, the network aims to contribute to societal needs for better solutions for rapid and early detection of conditions, and personalised surgery to improve patient outcome, as well as to reduce the cost of healthcare by developing healthcare technology solutions that will encourage clinical adoption of lower-cost imaging technology.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>507583</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>69CD7F3B-A134-4EA4-B9E4-208E7734A8E2</gtr:id><gtr:title>Precision Imaging: more descriptive, predictive and integrative imaging.</gtr:title><gtr:parentPublicationTitle>Medical image analysis</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1a8e73dae65dfa1d72fec62415814c9e"><gtr:id>1a8e73dae65dfa1d72fec62415814c9e</gtr:id><gtr:otherNames>Frangi AF</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1361-8415</gtr:issn><gtr:outcomeId>5a2fe6a118c419.47358651</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N026993/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A759BB04-AFFE-4780-BD31-9A2707BC44BA</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Medical Imaging</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>