<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Engineering Science</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A824CAC0-4FA7-428C-A470-C909FCCE874B"><gtr:id>A824CAC0-4FA7-428C-A470-C909FCCE874B</gtr:id><gtr:name>Network Rail Ltd</gtr:name><gtr:address><gtr:line1>Kings Place</gtr:line1><gtr:line2>90 York Way</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>N1 9AG</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/72F3F851-5EAD-4880-9F6C-D8C603B68B27"><gtr:id>72F3F851-5EAD-4880-9F6C-D8C603B68B27</gtr:id><gtr:name>Amey Plc</gtr:name><gtr:address><gtr:line1>The Sherard Building</gtr:line1><gtr:line2>Edmund Halley Road</gtr:line2><gtr:postCode>OX4 4DQ</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D9111769-DF66-4DB1-8D4A-842FEB13D7ED"><gtr:id>D9111769-DF66-4DB1-8D4A-842FEB13D7ED</gtr:id><gtr:name>Department for Transport</gtr:name><gtr:address><gtr:line1>Gt Minster House</gtr:line1><gtr:line2>76 Marsham Street</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW1P 4DR</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DE30AE2F-B9A4-405B-8439-49F05CA4E033"><gtr:id>DE30AE2F-B9A4-405B-8439-49F05CA4E033</gtr:id><gtr:name>CHESS Center,UC Berkeley</gtr:name><gtr:address><gtr:line1>EECS Department</gtr:line1><gtr:line2>UC Berkeley</gtr:line2><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C2F49FCD-4AAB-432C-AD31-B2274868B038"><gtr:id>C2F49FCD-4AAB-432C-AD31-B2274868B038</gtr:id><gtr:name>CGG Services SA</gtr:name><gtr:address><gtr:line1>27, Ave Carnot</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1C0C0EC8-3AEE-4671-A717-FC834D00338C"><gtr:id>1C0C0EC8-3AEE-4671-A717-FC834D00338C</gtr:id><gtr:name>Nissan Motor Company</gtr:name><gtr:address><gtr:line1>1-1 Morinosatoaoyama, Atsugi-shi</gtr:line1><gtr:postCode>243-0123</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Japan</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F83C387C-9289-4DC5-AE30-6F66CB36080C"><gtr:id>F83C387C-9289-4DC5-AE30-6F66CB36080C</gtr:id><gtr:name>MIRA Ltd</gtr:name><gtr:address><gtr:line1>Advanced Engineering Electrical Group</gtr:line1><gtr:line2>Watling Street</gtr:line2><gtr:line4>Nuneaton</gtr:line4><gtr:line5>Warwickshire</gtr:line5><gtr:postCode>CV10 0TU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F15CC95E-2AC8-45D6-A4B6-8507124470D3"><gtr:id>F15CC95E-2AC8-45D6-A4B6-8507124470D3</gtr:id><gtr:name>Fraunhofer</gtr:name><gtr:address><gtr:line1>Postfach 20 07 33</gtr:line1><gtr:line4>Munich</gtr:line4><gtr:line5>80007</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Germany</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/273F7312-D608-4BF1-917F-0E2FFE42E1D0"><gtr:id>273F7312-D608-4BF1-917F-0E2FFE42E1D0</gtr:id><gtr:name>Guidance Navigation Ltd.</gtr:name><gtr:address><gtr:line1>4 Dominus Way</gtr:line1><gtr:line2>Meridian Business Park</gtr:line2><gtr:postCode>LE19 1RR</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/847DAE6D-B1E4-4DDB-8269-0D060B0763A6"><gtr:id>847DAE6D-B1E4-4DDB-8269-0D060B0763A6</gtr:id><gtr:name>Automotive Council UK</gtr:name><gtr:address><gtr:line1>71 Great Peter Street</gtr:line1><gtr:postCode>SW1P 2BN</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5F600791-9929-4BAE-9186-DB9F207BD7C1"><gtr:id>5F600791-9929-4BAE-9186-DB9F207BD7C1</gtr:id><gtr:name>McGill University</gtr:name><gtr:address><gtr:line1>845 Sherbrooke Street W</gtr:line1><gtr:line4>Montreal</gtr:line4><gtr:line5>Quebec, H3A 2T5</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/05CF356C-765C-4254-8B98-803128F2A792"><gtr:id>05CF356C-765C-4254-8B98-803128F2A792</gtr:id><gtr:name>SciSys Ltd</gtr:name><gtr:address><gtr:line1>Clothier Road</gtr:line1><gtr:line2>Brislington</gtr:line2><gtr:line4>BRISTOL</gtr:line4><gtr:postCode>BS4 5SS</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/828C6345-D68E-4CCA-9B22-5DE0025D35DE"><gtr:id>828C6345-D68E-4CCA-9B22-5DE0025D35DE</gtr:id><gtr:name>BP Global</gtr:name><gtr:address><gtr:line1>501 Westlake Park Boulevard</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CBE67477-F5D1-4C99-A693-63D2874DE108"><gtr:id>CBE67477-F5D1-4C99-A693-63D2874DE108</gtr:id><gtr:name>OC Robotics</gtr:name><gtr:address><gtr:line1>Unit 5, Abbey Wood Busnss Pk</gtr:line1><gtr:line2>Emma-Chris Way</gtr:line2><gtr:line3>Filton</gtr:line3><gtr:postCode>BS34 7JU</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DC2E9FE0-77C5-4D65-8327-E8D9FD0180C4"><gtr:id>DC2E9FE0-77C5-4D65-8327-E8D9FD0180C4</gtr:id><gtr:name>UK Space Agency</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:line4>Swindon</gtr:line4><gtr:line5>Wiltshire</gtr:line5><gtr:postCode>SN2 1SZ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3B1E5961-8677-4A32-B15C-12FB968FA163"><gtr:id>3B1E5961-8677-4A32-B15C-12FB968FA163</gtr:id><gtr:name>University of Pennsylvania</gtr:name><gtr:address><gtr:line1>3451 Walnut Street,</gtr:line1><gtr:line2>Suite P-221</gtr:line2><gtr:line3>Franklin Building</gtr:line3><gtr:line4>Philadelphia</gtr:line4><gtr:postCode>PA 19104</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D535F886-24F2-4E8C-BB78-369651E9530F"><gtr:id>D535F886-24F2-4E8C-BB78-369651E9530F</gtr:id><gtr:name>Navtech Radar Limited</gtr:name><gtr:address><gtr:line1>16 Home Farm</gtr:line1><gtr:line2>Ardington</gtr:line2><gtr:line4>Wantage</gtr:line4><gtr:line5>Oxfordshire</gtr:line5><gtr:postCode>OX12 8PD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C573436E-8DCA-4CA2-9B5D-31C6D7F66F6A"><gtr:id>C573436E-8DCA-4CA2-9B5D-31C6D7F66F6A</gtr:id><gtr:name>Gompels HealthCare Ltd</gtr:name><gtr:address><gtr:line1>No.1 Swift Way</gtr:line1><gtr:line2>Bowerhill Industrial Estate</gtr:line2><gtr:postCode>SN12 6GX</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F23C0CBC-4BD2-4571-AC66-98D623CF1D02"><gtr:id>F23C0CBC-4BD2-4571-AC66-98D623CF1D02</gtr:id><gtr:name>ARC Centre of Excellence for Robotic Vis</gtr:name><gtr:address><gtr:line1>Level 11, S Block</gtr:line1><gtr:line2>Gardens Point Campus</gtr:line2><gtr:line3>QUT, 2 George Street</gtr:line3><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1F0A0B4A-2EA7-430C-B704-D7CB74F7B211"><gtr:id>1F0A0B4A-2EA7-430C-B704-D7CB74F7B211</gtr:id><gtr:name>Eidgenossiche Technical College</gtr:name><gtr:address><gtr:line1>Eidgenossiche Technische Hochschule</gtr:line1><gtr:postCode>CH-8092</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CC787094-5DAF-465E-BEC7-F1AD5CE7B383"><gtr:id>CC787094-5DAF-465E-BEC7-F1AD5CE7B383</gtr:id><gtr:name>Tracetronic</gtr:name><gtr:address><gtr:line1>Heidelberger</gtr:line1><gtr:line2>Strasse 24</gtr:line2><gtr:postCode>01189</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Germany</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5A38ADCD-C654-4D5F-A34E-8B4FA5850DC2"><gtr:id>5A38ADCD-C654-4D5F-A34E-8B4FA5850DC2</gtr:id><gtr:name>EURATOM/CCFE</gtr:name><gtr:address><gtr:line1>Culham Science Centre</gtr:line1><gtr:line4>Abingdon</gtr:line4><gtr:line5>Oxfordshire</gtr:line5><gtr:postCode>OX14 3DB</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5624A530-E796-4C66-B878-D1991105BCCD"><gtr:id>5624A530-E796-4C66-B878-D1991105BCCD</gtr:id><gtr:firstName>Niki</gtr:firstName><gtr:surname>Trigoni</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/4D83C9E4-588F-445A-91F8-0702B22B950C"><gtr:id>4D83C9E4-588F-445A-91F8-0702B22B950C</gtr:id><gtr:firstName>Ingmar</gtr:firstName><gtr:surname>Posner</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/C74C9612-26CA-4D91-B65F-260FD21EB7A4"><gtr:id>C74C9612-26CA-4D91-B65F-260FD21EB7A4</gtr:id><gtr:firstName>Paul</gtr:firstName><gtr:otherNames>Michael</gtr:otherNames><gtr:surname>Newman</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/3E5903CB-C904-4B16-8532-D43FF1E88751"><gtr:id>3E5903CB-C904-4B16-8532-D43FF1E88751</gtr:id><gtr:firstName>Marta</gtr:firstName><gtr:otherNames>Zofia</gtr:otherNames><gtr:surname>Kwiatkowska</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM019918%2F1"><gtr:id>C492A5EF-0142-40B3-8914-04A56084F92A</gtr:id><gtr:title>Mobile Robotics: Enabling a Pervasive Technology of the Future</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M019918/1</gtr:grantReference><gtr:abstractText>VISION: To create, run and exploit the world's leading research programme in mobile autonomy addressing fundamental technical issues which impede large scale commercial and societal adoption of mobile robotics.

AMBITION: We need to build better robots - we need them to be cheap, work synergistically with people in large, complex and time-changing environments and do so for long periods of time. Moreover, it is essential that they are safe and trusted. We are compelled as researchers to produce the foundational technologies that will see robots work in economically and socially important domains. These motivations drive the science in this proposal. 

STRATEGY: Robotics is fast advancing to a point where autonomous systems can add real value to the public domain. The potential reach of mobile robotics in particular is vast, covering sectors as diverse as transport, logistics, space, defence, agriculture and infrastructure management. In order to realise this potential we need our robots to be cheap, work synergistically with people in large, complex and time-changing environments and do so robustly for long periods of time. Our aim, therefore, is to create a lasting, catalysing impact on UKPLC by growing a sustainable centre of excellence in mobile autonomy. A central tenet to this research is that the capability gap between the state of the art and what is needed is addressed by designing algorithms that leverage experiences gained through real and continued world use. Our machines will operate in support of humans and seamlessly integrate into complex cyber-physical systems with a variety of physical and computational elements. We must, therefore, be able to guarantee, and even certify, that the software that controls the robots is safe and trustworthy by design. We will engage in this via a range of flagship technology demonstrators in different domains (transport, logistics, space, etc.), which will mesh the research together, giving at once context, grounding, validation and impact.</gtr:abstractText><gtr:potentialImpactText>Mobile autonomy is a pivotal precursor to a large number of industrial sectors in the global economy with an ability to reach a truly vast audience. To realise this potential, it is imperative to combine academic excellence with an appropriate grounding of the research in industrial need. We run a &amp;quot;petal&amp;quot; impact model. At the heart of the endeavour is research staff (the focus of this proposal). The research team are surrounded by an expert engineering support. Within this team are knowledge exchange engineers and an impact coordinator who are charged with managing the flow of knowledge between industrial parties and the group. We offer membership to the group on a sector by sector basis to industrial parties. 

Here our proposal will create a lasting, catalysing impact on UKPLC. 

Industrial Impact - the true impact, reach, ambition and industrial richness of this proposal is best illustrated by some of our research flagships - domain-specific, physical instantiations of integrated competencies developed across the consortium - which act as showcases to existing and potential industrial partners and therefore serve to catalyse impact. Examples include the development of the UK's first self-driving car (in collaboration with Nissan, automotive council, transport catapult, MIRA), the development of ultra low-cost warehousing solutions for stock management and asset tracking (in collaboration with Gompells Ltd, Guidance Navigation Ltd) and the development of robotics technology to help understand the condition of our national transport infrastructure -- particularly rail and road (in collaboration with AMEY, Highways Agency, Network Rail). Our long term plan is to act as a hub for enterprise networking and support and will serve as a catalyst to enable investors, existing businesses, and new enterprises to shape the service and autonomous robotics industries of tomorrow. 

Academic Impact - the award of a Programme Grant will stimulate the transition of robotics technology from an academic pedigree to real-world applications of industrial significance. As such, it will inspire a novel research paradigm driven by need. It will foster innovation to overcome real-world challenges in realising sustainable and affordable autonomy. This, we expect, will consolidate and strengthen the UK research base across disciplines (such as the currently disjoint fields of robotics and verification) and open up new vistas of research such as safe-by-design autonomous systems.

Societal Impact - we aspire for robots to assist people in various aspects of everyday life, from driverless cars to assisted living. However, while the scientific boundaries are receding issues surrounding trust and acceptance of this technology into society become ever more apparent. Immediately then questions of Responsible Innovation must be asked. The AREA (Anticipate-Reflect-Engage-Act) paradigm is of course apt here as set out by EPSRC. The Programme Grant will: Anticipate results of related research on the impact of automation on employment; Reflect on and promote ethical thinking around intelligent machines and the social benefits of micro-interactions between robots and people; Engage with stakeholders at TSB and BIS, and the general public to provide us with feedback surrounding the effects of our innovation; and Act to test exemplars of human-robot interaction and embed safety in the DNA of machines that people interact with.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-02-29</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>4991610</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Training graduate students in the AIMS CDT</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>8E4BBDAE-B83D-4253-975A-638D786B1E6B</gtr:id><gtr:impact>Impact via CDTs
Training graduate students in the AIMS CDT
15th and 19th February 2016 - Ingmar Posner and Lina Paz will present projects to CDT
CDT week 7-11 March 2016: PMN, HIP and 2nd Year PhD's, selected PDRA's and Engineers will contribute by running workshops, training and evaluation exercises.
Marta taught on AIMS CDT (Quantitative Verification), 26-27 Jan 2016, and offered projects to AIMS students 
Twice yearly seminar / workshop given by RA's and open to all UK CDT Students
no action on this yet. NT considering</gtr:impact><gtr:outcomeId>56e00edc144b84.18501186</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Paul Newman gave Keynote at Autonomous Vehicles Test &amp; Development Symposium in Stuttgart</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>ABC11382-FF30-48C3-8322-E5005415C23D</gtr:id><gtr:impact>PMN gave keynote at Autonomous Vehicles Test &amp;amp; Development Symposium in Stuttgart: 30th,31st May 2016 and in 2017

Autonomous Vehicle Test &amp;amp; Development Symposium 2017 will bring together the world's leading engineers in the field of autonomous vehicle research, testing, validation and development. The conference will be held in Stuttgart alongside Automotive Testing Expo 2017, the world's largest exhibition dedicated to new vehicle development and testing, and in conjunction with Traffic Technology International magazine, the world's leading magazine for advanced highway and traffic management technologies. It will boast over 60 of the world's leading experts in driverless vehicle testing.</gtr:impact><gtr:outcomeId>58c179bd520979.52567356</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.autonomousvehiclesymposium.com/</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Data and Software Sharing</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>3592AE2E-157C-4FBE-979C-54044EB249CB</gtr:id><gtr:impact>Data and Software Sharing
Data gathered from flagships will be made available to third parties on a project website
We have purchased a new suite of hardware to achieve this mission
We have now collected over 0.6PB of data to release
We are creating a web interface to access the data in different forms
We expect roll out in June 2016

Software tools that we develop can be licensed
please add evidence of this impact below
Software tool PRISM-games developed in Marta's group and used for autonomous driving case study released open source, with tool paper at TACAS 2016 conference (http://www.veriware.org/bibitem.php?key=KPW16)</gtr:impact><gtr:outcomeId>56e00fa7034170.73809931</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.veriware.org/bibitem.php?key=KPW16</gtr:url><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Impact to UK Academia</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>3FD9BE05-52E5-44FB-BA71-52ECBA4D3F84</gtr:id><gtr:impact>Organise a yearly annual summit on Mobile Autonomy
We hosted the UK -RAS network here in Feb 2016. 
We will be hosting a series of deep dives this year in which we invite a broad spectrum of industry to a technical exposition of what we can do already and what we are working on. 
 Organise two international meetings 
Marta and PG postdocs submitted proposal to RSS 2016 for Workshop on Social Trust in Autonomous Robots, expect to hear 18th Feb. We intend to build an international meeting around that event in Michigan.</gtr:impact><gtr:outcomeId>56e010d4248534.59351832</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>International Impact</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FD502FFC-5332-412A-8AE3-81553BD23AE0</gtr:id><gtr:impact>International
Formal Academic Visitor Scheme linkage (secondments for internationally recognised experts 1 - 6 months) with:
Australia's Robotic Vision
Peter Corke visited from 6th July to 4th December 2015 and is a Fellow of the PG
Paul Newman reciprocating and visiting the ARC in April.

USA's CHESS
They use tools developed in Marta's group (notably Prism) for driver modelling and control improvisation
Marta gave lecture at Berkeley in March 2015
 Marta will visit Berkeley for the month of October
PRECISE
They used tools developed in Marta's group for UAV operator modelling http://www.veriware.org/bibitem.php?key=FWHT15
Marta invited to Workshop on the integration of control theory, formal methods, learning and human factors for autonomous systems at Texas Austin, organised by ex-PRESCISE member Ufuk Topcu and US Airforce Laura Humphreys
ETHZ
that group is currently unstable because of apple and google. No contact yet
Other
Robotics and Biology Laboratory, TU Berlin
Ingmar Posner visited RBo from 15 Novemeber 2015 - 15 February 2016; dissemination of results and discussion of ongoing research questions</gtr:impact><gtr:outcomeId>56e01375ce7f16.12133330</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Paul Newman gave Keynote at INC 2016 in Glasgow. 9th November 2016</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>725E5FE5-C730-4EA1-8621-6D311745DE9A</gtr:id><gtr:impact>When the RIN promises a cutting-edge international conference, what you get is a cutting-edge
international conference, with researchers from some of the world's most renowned institutions.</gtr:impact><gtr:outcomeId>58c17ecfb5d645.65375250</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.internationalnavigationconference.org.uk/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>EPSRC Robotics, Automation &amp; Artificial Intelligence (RAAI) Theme Day</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>530C84F3-556D-4714-8D56-258B724987F8</gtr:id><gtr:impact>EPSRC are undertaking a review of our robotics, automation and artificial intelligence portfolios of relevance to Robotics and Autonomous Systems (RAS) in order to evaluate the quality and importance of EPSRC's portfolio of research and training in the area. To facilitate this we are hosting a Theme Day on the 31st January 2017 in Central London.
 
The Theme Day will involve poster presentations from holders of current and recent related grants from across the EPSRC portfolio. A panel of internationally leading experts chaired by Prof David Hogg will use the posters and discussions with attendees to draw conclusions about the portfolio as a whole. The outcomes of the review will be used to inform future strategy in the area of RAAI and will not impact on future funding decisions at a PI level. 
 
The Theme day will be an opportunity for PIs to present their research to the review panel. The day will also give attendees an opportunity to view work of relevance to RAAI from across the EPSRC portfolio and to network with leaders in the area from across the UK.
 
As a holder of such a related grant(s) (details below) we would like to invite you to attend the event.
 
Related Grant(s): EP/I005021/1, EP/J012017/1, EP/M019918/1</gtr:impact><gtr:outcomeId>58ca64c4053467.40485308</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Supporters</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>RSS 2015</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>F1239939-4300-4982-BABC-1BA341A77EC4</gtr:id><gtr:impact>Submission of papers to RSS 2015 - listed in publications</gtr:impact><gtr:outcomeId>56e016c05f54d2.23145652</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2014,2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Responsible Innovation</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1DACB67F-1BB4-4D12-B1D8-C0AFD8F44E6F</gtr:id><gtr:impact>UK Government Agency Engagement
23rd July 2015: PMN Spoke at DfT &amp;quot;Robotics and Autonomous Systems Teaching Session with Paul Newman&amp;quot; - attended by Philip Rutnam and Michael Hurwitz
24th September 2015: PMN Presented at RAS and AI Roundtable
19th October 2015: Ministerial CAV Expert meeting - chaired by Mark walport. Cabinet office - Oliver Letwin and Philip Rutnam - spearheads Civil Services interest in RAS. PMN to gave tutorials to ministers.
20th October 2015: Paul on panel at Treasury. Launch pad re: Disruptive data - harnessing the power of data-led innovation 
21st October 2015: Gave talk at Ordnance Survey - &amp;quot;Low-cost infrastructure-free mapping and understanding&amp;quot;
10th November: CCAV team visited MRG. PMN gave tour of workshop and presented on Flagships and key technology.
13th November 2015: PMN, Peter Corke and Nick Roy present at RAS Event at The Royal Society.
14th December 2015: PMN spoke at &amp;quot;The Event&amp;quot; DfT Internal Seminars aimed at teach DfT staff on new tech. Initialed by Michael Hurwitz, attended by Philip Rutnam.
22nd February 2016: CCAV - set up in Gov. Proposing to run with GCHQ a gig about cyber security (Katherine Fletcher workshop) hits responsible innovation requirement.
7th March 2016: PMN to present at a RAS workshop, initiated by Mark Walport
15th March 2016: PMN will talk at RAS Seminar, directed at Perm Secs and CSAG
DfT SAC
13th April 2016: PMN to present to Sec of State, at DfT
28th April: PMN to attend working SAC Working dinner with Perm Sec</gtr:impact><gtr:outcomeId>56e01078ee2464.98462664</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Policymakers/politicians</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Press releases for LUTZ Public demonstration</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A2D58346-7A66-41A7-A976-6DB578CBB3FF</gtr:id><gtr:impact>Driverless vehicle to be tested on UK streets for the first time
Reuters (US), 10/10/2016,
A driverless vehicle carrying passengers will take to Britain's public roads for the first time on Tuesday, as part of trials aimed at paving the way for autonomous cars to hit the highways by the end of the decade. The system was developed by Oxford University spin-out Oxbotica, with software developed by the University's Oxford Robotics Institute.
A pod - like a small two-seater car - developed by Oxbotica will be tested in Milton Keynes today, with organisers hoping the trials will provide vital information about how the vehicle interacts with pedestrians and other road-users. The pod will operate fully without human control, using data from cameras and radars to move around pedestrianised areas.
The government is encouraging technology companies, carmakers and start-ups to develop and test their autonomous driving technologies in Britain, aiming to build an industry to serve a worldwide market which it forecasts could be worth around &amp;pound;900 billion pounds by 2025. Earlier this year, it launched a consultation on changes to insurance rules and motoring regulations to allow driverless cars to be used by 2020 and said it would allow such vehicles to be tested on motorways from next year.
&amp;quot;Today's first public trials of driverless vehicles in our towns is a ground-breaking moment,&amp;quot; business minister Greg Clark said.
www.reuters.com/article/us-britain-autos-driverless-idUSKCN12A2KX
 
Also:
Radio: LBC 97.3, Nick Abbot
11/10/2016
The first 'driverless' cars will be tested in the UK in an area of Milton Keynes today. Professor Paul Newman of Oxford University is interviewed about the technology used in the vehicles.
Radio: LBC 97.3, Steve Allen
11/10/2016
The first 'driverless' cars will be tested in the UK in an area of Milton Keynes today. Professor Paul Newman of Oxford University is interviewed about the technology used in the vehicles.
Road to the future
The Sun, 11/10/2016, Costas Pitas
https://www.thesun.co.uk/news/1951858/driverless-cars-hit-the-streets-of-britain-for-the-first-time/
Public trial for driverless cars beginning in Milton Keynes
Sky News, 11/10/2016, Tom Cheshire
http://news.sky.com/story/public-trial-for-driverless-cars-beginning-in-milton-keynes-10613089
Driverless cars to be tested on UK streets for the first time
Mail Online, 11/10/2016, Abigail Beall
http://www.dailymail.co.uk/sciencetech/article-3831600/Driverless-vehicle-tested-UK-streets-time.html
Driverless cars have officially hit the UK's roads for the first time
City AM, 11/10/2016, Lynsey Barber
http://www.cityam.com/251157/driverless-cars-have-officially-hit-uks-roads-first-time
Driverless vehicle to be tested on UK streets for the first time
Metro (US), 10/10/2016, via Reuters
http://www.metro.us/news/driverless-vehicle-to-be-tested-on-uk-streets-for-the-first-time/DBVpjj---ekq12nEu8BMRUbs8Y8eu6A/
 
 
TV: Sky News, Sky News with Colin Brazier and Jayne Secker
11/10/2016, 13:18
A driverless vehicle carrying passengers took to Britain's public roads for the first time yesterday in Milton Keynes as part of trials aimed at paving the way for autonomous cars to hit the highways by the end of the decade.
Professor Paul Newman from Oxford University, who has been leading the development of the software installed in the vehicle, said: 'Technology like this is going to have a big part to play in our lives, and it's going to roll out over time. I see it as more than just driverless cars, though. Think about all the things that move: ports, warehouse, farming, agriculture, mining - it's the software that makes these things extraordinary. It's not so much the hardware, it's the information engineering, it's programmes that can take data from cameras and lasers and turn that into an understanding for the machine of what's going on, and from that it can figure out what it should do. So we have three questions: where am I? What's around me? What should I do? And the software answers that question really fast all the time.'
 
Also:
TV: ITV 1, ITV Lunchtime News
11/10/2016
Professor Paul Newman is interviewed and reporter Alok Jha goes for a drive in the autonomous vehicle.
TV: Five, 5 News at 5
11/10/2016
Professor Paul Newman is interviewed.
TV: BBC One, South Today
11/10/2016
http://www.bbc.co.uk/iplayer/episode/b07xpsys/south-today-oxford-evening-news-11102016 &amp;amp; http://www.bbc.co.uk/iplayer/episode/b07xpsyx/south-today-oxford-late-news-11102016
Sky's Tom Parmenter drives hands-free in Milton Keynes
Sky News online, 11/10/2016
Sky's reporter Tom Parmenter goes for a drive in the autonomous vehicle.
http://news.sky.com/video/taking-a-ride-in-a-driverless-car-10613503
Self-driving car tested for first time in UK in Milton Keynes
The Guardian online, 11/10/2016, Rob Davies
https://www.theguardian.com/technology/2016/oct/11/self-driving-car-first-uk-test-milton-keynes-driverless-lutz-pathfinder
Driverless car tested in public in UK
BBC News online, 11/10/2016
http://www.bbc.co.uk/news/technology-37618574
Driverless cars given first public runabout
Daily Express, 12/10/2016, p.27, Robert Kellaway
http://www.express.co.uk/news/uk/719942/Driverless-cars-UK-First-Britain-arrive-ground-breaking-Milton-Keynes
Pokemon Go test pass for driverless car
Daily Mirror, 12/10/2016, p.16, Sam Blewett
http://www.mirror.co.uk/news/uk-news/driverless-cars-go-trial-uk-9022534#ICID=nsm
Driverless cars hit British roads for the first time
City AM, 12/10/2016, p.9, Lynsey Barber
University of Oxford scientists help launch first driverless car
ITV News online.com, 11/10/2016
http://www.itv.com/news/meridian/update/2016-10-11/university-of-oxford-scientists-help-launch-first-driverless-car/
Driverless Vehicle to Be Tested on UK Streets for the First Time
New York Times online (USA), 11/10/2016, Costas Pitas, via Reuters
http://www.nytimes.com/reuters/2016/10/10/technology/10reuters-britain-autos-driverless.html?_r=0
Driverless car makes debut on UK streets
Reuters, 11/10/2016
Video feature.
http://www.reuters.tv/v/2jy/2016/10/11/driverless-car-makes-debut-on-uk-streets
Britain tests self-driving vehicles in public space
Xinhua News Agency (China), 11/10/2016
http://news.xinhuanet.com/english/2016-10/11/c_135746615.htm
Britain tests self-driving vehicles in public space
Global Times (China), 12/10/2016, via Xinhua
http://www.globaltimes.cn/content/1010860.shtml
Driverless cars hit British streets in landmark trial
Business Standard India, 11/10/2016, via AFP
http://www.business-standard.com/article/pti-stories/driverless-cars-hit-british-streets-in-landmark-trial-116101100649_1.html
Driverless cars hit Britain's streets in landmark trial
Indian Express, 11/10/2016, via AFP
http://indianexpress.com/article/technology/tech-news-technology/driverless-cars-hit-britains-streets-in-landmark-trial-3077365/
Driverless cars hit British streets in landmark trial
Deccan Chronicle (India), 11/10/2016, via AFP
http://www.deccanchronicle.com/technology/in-other-news/111016/driverless-cars-hit-british-streets-in-landmark-trial.html
Driverless vehicle to be tested on UK streets for the first time
Financial Express (India), 11/10/2016, via Reuters
http://www.financialexpress.com/industry/tech/driverless-vehicle-to-be-tested-on-uk-streets-for-the-first-time/413758/
Driverless cars have taken to the road
Oxford Mail, 12/10/2016, p.5
http://www.oxfordmail.co.uk/news/14795078.Driverless_car_developed_in_Oxford_tested_for_the_first_time_on_UK_roads/
Radio: BBC Radio Wales, Good Evening Wales
11/10/2016,
Professor Paul Newman is interviewed.
http://www.bbc.co.uk/programmes/b07xj516 (55:04 on clock)
Radio: BBC Radio Oxford, Kat Orman
11/10/2016,
Professor Paul Newman is interviewed.
Radio: BBC Radio Oxford, David Prever
11/10/2016
 
 
Milton Keynes now has self-driving cars (sort of)
Wired UK online, 12/10/2016, Matt Burgess
Milton Keynes now has autonomous cars. The LUTZ Pathfinder autonomous car, built by the Transport Systems Catapult (TSC), has been tested for the first time on UK streets. Using virtual maps, the two-seater car has driven on pathways around the city in its full autonomous mode. The software in the cars has been developed by academics at the University of Oxford. A 25-person company called Oxbotica is using computer vision and cloud-based services to help the cars communicate with others in a future fleet.
http://www.wired.co.uk/article/milton-keynes-self-driving-car-test
Also:
Driverless car gets road tested with passengers in UK
ABC Online Australia online, 12/10/2016, Unattributed
Oxford University's Paul Newman, the engineer who built one of the UK's first self-driving cars watched with amazement today as it hit the road about an hour out of London for the first time - with passengers. Professor Newman is interviewed for the PM programme.
http://www.abc.net.au/pm/content/2016/s4555276.htm
Watch | Driverless cars hit Britain's roads
Hindustan Times online, 12/10/2016, Unattributed
http://www.hindustantimes.com/videos/world-news/watch-driverless-cars-hit-britain-s-roads/video-whlxAVf3rkXmryZvyL0uvM.html
University's driverless car takes to the 'road'
Oxford Times, 13/10/2016, p.3
http://www.oxfordtimes.co.uk/news/14795078.Driverless_car_developed_in_Oxford_tested_for_the_first_time_on_UK_roads/


Also:
New Scientist
https://www.newscientist.com/article/2108977-first-uk-trial-of-driverless-pods-paves-way-for-autonomous-taxis/
MK Citizen
http://www.miltonkeynes.co.uk/news/uk-s-first-driverless-car-trial-kicks-off-in-milton-keynes-1-7623400
Digit
http://www.digit.in/car-tech/self-driven-car-goes-through-first-ever-public-road-trial-in-uk-32042.html</gtr:impact><gtr:outcomeId>58c17c4779abc9.70161556</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://news.sky.com/story/public-trial-for-driverless-cars-beginning-in-milton-keynes-10613089</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>CDT Workshop</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>5D2D0282-CFC3-4F33-BFEE-B7CE6A175689</gtr:id><gtr:impact>&amp;quot;The machines are coming and it's going to be good. We won't have to drive oursleves when tired, schlep stuff around warehouses, be bored on tractors, choke in mines, freeze on mars or miss broken pipes in nuclear inspection. If we choose to, the coming years will see machines doing more for us and doing it better. In this talk I pull apart some of the competencies needed to build &amp;quot;intelligent&amp;quot; self driving vehicles. I'll explain what makes it hard, what makes it exciting and how it all comes together in a glorious bit of robotics science.&amp;quot; Prof. Paul Newman, Oxford Robotics Institute.

CDT students from all the sciences at Oxford University Join us for a day of exploring Information Engineering and Computer Science, with some of Oxford's leading and most exciting academics.</gtr:impact><gtr:outcomeId>58c178b09623d6.46601627</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Shell Eco-Marathon June / July 2016</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6E7433AF-3DD5-4ACE-8DFC-779B0C058315</gtr:id><gtr:impact>Shell Eco-marathon challenges student teams around the world to design, build, test and drive ultra-energy-efficient vehicles.</gtr:impact><gtr:outcomeId>58c17cf1b3a989.81038712</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.youtube.com/watch?v=kU7OYLgnlkM</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Visiting Lecture at Robotic Vision Summer School (Queensland University of Technology )</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>AC635C92-080A-4C1F-9EAA-AD28C615285F</gtr:id><gtr:impact>The Australian Centre for Robotic Vision presents Robotic Vision Summer School (RVSS) in Kioloa, Australia.
The ability to see is the remaining technological roadblock to the ubiquitous deployment of robots into society. The Robotic Vision Summer School (RVSS) provides a premium venue for graduate students and industry researchers to learn about fundamental and advanced topics in robotic vision. The technical program is presented by world's leading experts from the Australian Centre for Robotic Vision and international guests. The summer school offers participants:
In-depth tutorial material on fundamentals of computer vision and robotics.
State-of-the-art presentations on the latest developments in robotic vision.
Introduction to application domains and applied robotic vision technologies.
A unique opportunity to experiment with computer vision algorithms on actual robotic hardware.
Chance to meet and network with present day and the next generation of robotic vision experts.
The summer school is held annually at the Kioloa campus, Australian National University on the NSW south coast, Australia. This is an international summer school targeting Masters (later-year)/PhD students, academics, and industrial researchers.</gtr:impact><gtr:outcomeId>58c16fdf20c427.69410384</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>http://roboticvision.org/events/rvss-summer-school/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BBC Radio 4 Interview - The Today Programme</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>6C878C02-D6EE-4511-B0D0-9431EA729B0C</gtr:id><gtr:impact>Go to 1:34:14 for Paul's interview on the Today Programme:</gtr:impact><gtr:outcomeId>58ca652ea5ea72.19685209</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b08hl5rt</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Paul Newman spoke at New Scientist Live 22nd September 2016</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>4249732A-DCAA-4AA5-AC07-86A7CFB24B6F</gtr:id><gtr:impact>New Scientist Live is a festival of ideas and discovery, taking place at ExCeL London. Rooted in the biggest, best and most provocative science, New Scientist Live will touch on all areas of human life. The show will feature four immersive zones covering Humans, Technology, Engineering, Earth and Cosmos. For four days this Autumn, New Scientist Live will be like no other place on Earth.</gtr:impact><gtr:outcomeId>58c17aec06a632.02155515</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://live.newscientist.com/</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Impact to UK Society</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>D5B91049-1C9E-4799-AFC7-72FE987C9E4F</gtr:id><gtr:impact>Engagement with the public via press and public events
6th July 2015: PMN Radio 4 Interview - Feature about the testing of 'driverless' vehicles and 'pods.
21st July 2015: PMN attended TSC Lutz Stakeholder Engagement Event
Marta provided input to feature in New Scientist, 2 Dec 2015, &amp;quot;Bugged out&amp;quot; Want a computer that never crashes? Don't let bugs freak it out
Marta: Currently producing an article about verification in Polish technology press http://naukawpolsce.pap.pl/aktualnosci/news,405530,aby-urzadzenia-nie-mylily-sie-w-obliczeniach.html
11th February 2016: PMN to speak at The British Computer Society
22nd February 2015: CCAV - set up in Gov. Proposing to run with GCHQ a gig about cyber security (Katherine Fletcher workshop) hits responsible innovation requirement.

Leverage open days and outreach events by AIMS CDT
15th and 19th February 2016 - Ingmar Posner and Lina Paz will present projects to CDT
CDT week 7-11 March 2016: PMN, HIP and 2nd Year PhD's, selected PDRA's and Engineers will contribute by running workshops, training and evaluation exercises.
School pupils, emergency services, transport, crime, law enforcement... 
9th June 2015: PMN gave Keynote Regus Inaugural and Autonomous Systems Showcase, at Southampton University. 
27th January: PMN gave a talk to 6th form students at Oxford Hight School titled &amp;quot;From Mars to Self Drive Cars&amp;quot;
11th February: PMN to talk at British Computer Society Oxfordshire (Oxford e-Research Centre). 
Nominet, Smart City, (community consultations, infrastructure planning, business and economic plans)
16th February: PMN to talk at TSU Annual Seminars on Urban Mobilities in the Smart City &amp;quot;Urban Mobility&amp;quot; at School of Geography and the Environment.</gtr:impact><gtr:outcomeId>56e01013be1879.00782329</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>CDT week</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>5261280D-503F-43A4-82FD-E2151AF403A8</gtr:id><gtr:impact>CDT week is a concentrated programme of study in Robotics, at the Robotics Institute, for AIMS CDT students. 

The Oxford robotics Institute provide teams with a working robot (a Husky or Kuku Youbot) and some key software and hardware components for example a visual odometry system, a low level controller, a communications manager and a visualisation tool kit, a dense stereo library and a location sensing device.

Exercises
The course is built around a single extensive practical (long days of great enjoyment). Students are split into two teams, each given a mobile robot (100kg) and at the end of the week compete in a mobile robot challenge (for example finding an object in the University Parks).

Assessment Mode
Students give a presentation of results and critique of their system to the Oxford Robotics Institute on the final day of the program. Each team member will be asked to write a 3 page report on their contribution and evaluate the overall performance of their implementation.b</gtr:impact><gtr:outcomeId>58c1782fde5e22.00029537</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>http://aims.robots.ox.ac.uk/course/mobile-robots/</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Michael Tanner (PhD student) judged the &quot;regionals&quot; of Vex Robotics competition (primarily a STEM-outreach program) hosted at Stowe School</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>8D7B5665-3EB2-4F39-9335-65E6096A2415</gtr:id><gtr:impact>From: Michael Tanner 
Subject: Vex Robotics Competition
Date: 6 February 2017 at 12:59:07 GMT
To: Paul Newman , Ingmar Posner 

[This is purely an FYI/feel-good email. No action required.]

Paul/Ingmar,

Last week I took a day off to judge the &amp;quot;regionals&amp;quot; of Vex Robotics competition (primarily a STEM-outreach program) hosted at Stowe School
 http://www.vexrobotics.com/vexedr/competition/

I thoroughly enjoyed the event and was fascinated at the creative designs students developed for this year's challenge. Here is a YouTube video showing the types of robots students develop:
 https://www.youtube.com/watch?v=FCck9_vk8H4

The students were quite diverse (boys/girls, 10 - 17 years old, hail from UK/US/China, etc.), but they all shared a deep passion regarding their respective robot designs. The level of knowledge some of the students demonstrated was impressive (e.g., describing the chemical/material property trade-offs between various plastics included in their designs). Once the students learned I was studying robotics at Oxford, I was inuidated with questions.

I went home and immeditally ordered one of Vex Robotics' cheaper toy robotics kits (http://www.vexrobotics.com/vexiq) for my daughters to play with at home.

--
Michael Tanner
Oxford Robotics Institute
Department of Engineering Science
University of Oxford
Comm +44 7514 119187</gtr:impact><gtr:outcomeId>58ca6708922090.94266661</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.vexrobotics.com/vexedr/competition/</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>ICRA 2015</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A33866A6-47C4-41BB-AF29-0130A2D3EF6D</gtr:id><gtr:impact>Submission of papers to ICRA 2015 - listed in publications</gtr:impact><gtr:outcomeId>56e016762d4489.81352038</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2014,2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Paulo Newman spoke at IET for UK Robotics week: 1st July 2016</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>C8A808B1-25B7-4CCE-AFDB-7887544552EF</gtr:id><gtr:impact>UK Robotics Week is an annual event, which aims to act as a forum to showcase the latest innovations, in Robotics and Autonomous Systems (RAS), through a number of academic and industrial challenges and events. This year we have challenges in Surgical, Extreme Environments, Infrastructure and Social Care Robots. We are also engaging with local schools through our School Robot Challenge. Detailed information can be found here. 

The pinnacle event of the UK Robotics Week is the Robotics Showcase Event on Friday 30th June 2017. This finale includes sponsor exhibitions alongside demonstrations and presentations from the finalists of the Robot Challenges as well as keynote lectures, network forum and an award ceremony for the winners.</gtr:impact><gtr:outcomeId>58c17a7e789a77.69666393</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://hamlyn.doc.ic.ac.uk/roboticsweek2017/</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>EPSRC Funded initiatives</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>D6540CE1-7133-40D8-9A38-03F04993C7F7</gtr:id><gtr:impact>UK-RAS Network - we will use this to communicate, share linking and promote this work
MRG will host UK RAS Network on Friday 5th February 2016
Marta participates in EPSRC UK Network on the Verification and Validation of Autonomous Systems (VandV)
group attended VandV Verification of Mobile and Autonomous Robots - Winter School and Workshop, 1-4 Dec 2015, York https://www.cs.york.ac.uk/circus/RoboCalc-event/</gtr:impact><gtr:outcomeId>56e00f51d6a823.66925287</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://www.cs.york.ac.uk/circus/RoboCalc-event/</gtr:url><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>LUTZ Public Demonstration 10-15 October 2016</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>1FB71D2E-D521-4A1A-BA61-163F99EF5558</gtr:id><gtr:impact>This flagship has its genesis in the LUTZ project which is a collaboration between RDM, Oxford and the Transport Systems Catapult. RDM are making the vehicle hardware, we are supplying the autonomy software and sensor systems and the Transport Systems Catapult are overseeing the project and coordinating trials with Milton Keynes Council.

Beyond demonstrating autonomous vehicles, the project will address the wider key challenge of how to increase mobility by demonstrating and analysing the potential for effective and cost-efficient movement of people in a city.

The LUTZ project will see Pods deployed in the streets of Milton Keynes in 2016 running the complete autonomy system we refer to as &amp;quot;Selenium.&amp;quot; Selenium draws on competencies from across our technology portfolio but some of the videos below give a sense of its deployment on Light Urban Vehicles.</gtr:impact><gtr:outcomeId>58c17b9f4ae096.39050427</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://mrg.robots.ox.ac.uk/projects/lutz-self-driving-pods/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk at AHRC Research Network Workshop</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>7F98633E-B60E-484A-AB93-34A36CF96F5A</gtr:id><gtr:impact>The action-based alternative to 3D coordinate-frame representation was the main topic of our video meetings throughout 2016, and of our workshop at St John's College, Oxford, in January 2017. This workshop brought together experts from diverse disciplines for a focussed multidisciplinary discussion across three days, testing the action-based hypothesis by assessing its philosophical, computational and neuroscientific consequences. You can see the final discussion of the workshop here. As well as discussions led by Andrew and me, the workshop featured talks by:</gtr:impact><gtr:outcomeId>58ca641fd18677.08782749</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://jamesstazicker.com/research/the-action-based-brain/</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This grant is just two years old. But already we have 10 pieces of Intellectual Property in place, 20 papers, and two awards. Just like the leadership fellowship EP/I005021/1 this is a transformational affair. Industrial Impact - the true impact, reach, ambition and industrial richness of this grant is best illustrated by some of our research flagships - domain-specific, physical instantiations of integrated competencies developed across the consortium - which act as showcases to existing and potential industrial partners and therefore serve to catalyse impact. Examples include the development of the UK's first self-driving car (in collaboration with Nissan, automotive council, transport catapult, MIRA), the development of ultra low-cost warehousing solutions for stock management and asset tracking (in collaboration with Gompells Ltd, Guidance Navigation Ltd) and the development of robotics technology to help understand the condition of our national transport infrastructure -- particularly rail and road (in collaboration with AMEY, Highways Agency, Network Rail). Our long term plan is to act as a hub for enterprise networking and support and will serve as a catalyst to enable investors, existing businesses, and new enterprises to shape the service and autonomous robotics industries of tomorrow. Academic Impact - The Programme Grant will stimulate the transition of robotics technology from an academic pedigree to real-world applications of industrial significance. As such, it will inspire a novel research paradigm driven by need. It will foster innovation to overcome real-world challenges in realising sustainable and affordable autonomy. This, we expect, will consolidate and strengthen the UK research base across disciplines (such as the currently disjoint fields of robotics and verification) and open up new vistas of research such as safe-by-design autonomous systems. Societal Impact - we aspire for robots to assist people in various aspects of everyday life, from driverless cars to assisted living. However, while the scientific boundaries are receding issues surrounding trust and acceptance of this technology into society become ever more apparent. Immediately then questions of Responsible Innovation must be asked. The AREA (Anticipate-Reflect-Engage-Act) paradigm is of course apt here as set out by EPSRC. The Programme Grant will: Anticipate results of related research on the impact of automation on employment; Reflect on and promote ethical thinking around intelligent machines and the social benefits of micro-interactions between robots and people; Engage with stakeholders at InnovateUK and BIS, and the general public to provide us with feedback surrounding the effects of our innovation; and Act to test exemplars of human-robot interaction and embed safety in the DNA of machines that people interact with.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>119199D5-0E1D-41BA-AFEB-5C05B85E289A</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Economic,Policy &amp; public services</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d9b68b7d4198.89949699</gtr:outcomeId><gtr:sector>Construction,Digital/Communication/Information Technologies (including Software),Government, Democracy and Justice,Transport</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>Chris Prahacs and Paul Newman &amp;quot;NABU4 Design&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>5C49A7B1-B116-4F80-B93F-E3E90ABB293F</gtr:id><gtr:impact>Chris Prahacs and Paul Newman &amp;quot;NABU4 Design&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044a39d7453.39566715</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;NABU4 Design&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Parsing Traffic Lights Version 2</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>91C117EB-1C09-4B72-B132-08BD849E5C22</gtr:id><gtr:impact>Parsing Traffic Lights Version 2</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94b6b8b3017.90684867</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Parsing Traffic Lights Version 2</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Akshay Morye, Dominic Wang, Chi Tong and Ingmar Posner &amp;quot;TrackLib 1.0&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>08F268A3-7CE3-4BF2-A9A1-5430C7E8994E</gtr:id><gtr:impact>Akshay Morye, Dominic Wang, Chi Tong and Ingmar Posner &amp;quot;TrackLib 1.0&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e0450667b2b6.94176013</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;TrackLib 1.0&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Daniel Wilde and Ingmar Posner &amp;quot;3D to 2D label projection&amp;quot; Not registered yet. Not licensed yet</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>5E081C18-AACB-4730-A03C-E0CA4DFEA88E</gtr:id><gtr:impact>Daniel Wilde and Ingmar Posner &amp;quot;3D to 2D label projection&amp;quot; Not registered yet. Not licensed yet</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044caacaaa3.59618833</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>3D to 2D label projection</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Real-time Remote State Visualisation</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>A78B78F3-79FF-49BF-BA89-4DD21A079527</gtr:id><gtr:impact>Real-time Remote State Visualisation</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94b92bde466.03711918</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Real-time Remote State Visualisation</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Semantic Label Projection v2</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>F9B0C34E-711D-4220-AFA6-FEEADE934D1A</gtr:id><gtr:impact>Semantic Label Projection v2</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94b4cb389b8.20775088</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Semantic Label Projection v2</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Path Discovery using Random Forests and Dense Stereo</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>0A045436-781D-4E81-A6D9-F154628505BF</gtr:id><gtr:impact>Path Discovery using Random Forests and Dense Stereo</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94bfe5cfb06.20667223</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Path Discovery using Random Forests and Dense Stereo</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Pedro Pinies, Lina Paz and Paul Newman &amp;quot;Dense disparity estimation using laser and stereo vision&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>7B91DA27-3964-48A9-93A9-8D02A229B4BA</gtr:id><gtr:impact>Pedro Pinies, Lina Paz and Paul Newman &amp;quot;Dense disparity estimation using laser and stereo vision&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e043a76c4957.32939680</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Dense disparity estimation using laser and stereo vision&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Geoff Hester, Ingmar Posner and Paul Newman &amp;quot;Planning in the Presence of Dynamic Obstacles&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>1803EB12-11E5-4E21-8F3D-524EBFC67091</gtr:id><gtr:impact>Geoff Hester, Ingmar Posner and Paul Newman &amp;quot;Planning in the Presence of Dynamic Obstacles&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e04525a6dc85.21010055</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Planning in the Presence of Dynamic Obstacles&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Akshay Morye, Dominic Wang, Chi Tong and Ingmar Posner &amp;quot;TrackLib 1.0&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>7D61F382-B7C8-4F7B-9C63-88A4329EF232</gtr:id><gtr:impact>Akshay Morye, Dominic Wang, Chi Tong and Ingmar Posner &amp;quot;TrackLib 1.0&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e0450a9756a7.97655082</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;TrackLib 1.0&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Deep Image-based Detection</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>35B56206-369E-43B9-858C-31A35BB744E1</gtr:id><gtr:impact>Deep Image-based Detection</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94bd8136c90.22556150</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Deep Image-based Detection</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Vote3Deep</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>0A4C3E51-899F-4584-BF5D-8FE134CB4A6A</gtr:id><gtr:impact>Vote3Deep</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94c603df216.11371563</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Vote3Deep</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>William Maddern and Paul Newman &amp;quot;Dense Stereo&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>84B02190-278A-4466-A54A-6FAB9B640956</gtr:id><gtr:impact>William Maddern and Paul Newman &amp;quot;Dense Stereo&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044818eb924.09868530</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Dense Stereo&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Daniel Wilde and Ingmar Posner &amp;quot;Laser Simulation in virtual environments&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>1B79FFFD-41F4-4CFB-912E-58007A68F13F</gtr:id><gtr:impact>Daniel Wilde and Ingmar Posner &amp;quot;Laser Simulation in virtual environments&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044e8c80601.49295155</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Laser Simulation in virtual environments&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Dominic Wang, Ingmar Posner and Paul Newman &amp;quot;Vote 3D 2.0&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>791EF942-9B4E-45B3-89EC-9D75D07B9A59</gtr:id><gtr:impact>Dominic Wang, Ingmar Posner and Paul Newman &amp;quot;Vote 3D 2.0&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e0458b0a6d22.19115369</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Vote 3D 2.0&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Chris Linegar and Paul Newman &amp;quot;Patch-based localisation technique using camera images&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>9946E380-5525-4A9D-9317-C41866C1B3EC</gtr:id><gtr:impact>Chris Linegar and Paul Newman &amp;quot;Patch-based localisation technique using camera images&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044052de4e4.84062739</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Patch-based localisation technique using camera images&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Semi-supervised Training for deep semantic Segmentation</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>F7582697-EFD8-410C-AFD5-130A686F637C</gtr:id><gtr:impact>Semi-supervised Training for deep semantic Segmentation</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94e02b23909.78604174</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Semi-supervised Training for deep semantic Segmentation</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Jonathan Attias and Paul Newman &amp;quot;Scenario Planner - a software tool for creating simulation scenarios for robot environments&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>93707DB0-8C28-4B84-9C03-D9861D13C19B</gtr:id><gtr:impact>Jonathan Attias and Paul Newman &amp;quot;Scenario Planner - a software tool for creating simulation scenarios for robot environments&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e044374ab846.37031858</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Scenario Planner - a software tool for creating simulation scenarios for robot environments&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Dan Barnes, William Maddern and Ingmar Posner &amp;quot;Label Projection from Semantic Map Priors&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>DEBB7760-736C-4DEB-B838-F6D0012BBCC2</gtr:id><gtr:impact>Dan Barnes, William Maddern and Ingmar Posner &amp;quot;Label Projection from Semantic Map Priors&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e0456dcc9782.71654251</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Label Projection from Semantic Map Priors&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Dan Barnes, William Maddern and Ingmar Posner &amp;quot;Parsing Traffic Lights&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>986465FB-671B-4411-B781-AB6FD417F2CC</gtr:id><gtr:impact>Dan Barnes, William Maddern and Ingmar Posner &amp;quot;Parsing Traffic Lights&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e045495ad654.07916299</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Parsing Traffic Lights&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Winston Churchill and Paul Newman &amp;quot;Visual Inertial Odometry&amp;quot; (an upgrade package to oVo) Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>BEC10577-6DE4-425E-BFDB-0EF7C90C59F8</gtr:id><gtr:impact>Winston Churchill and Paul Newman &amp;quot;Visual Inertial Odometry&amp;quot; (an upgrade package to oVo) Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e04460d30fa4.27688159</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Visual Inertial Odometry&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Dense Laser Stereo</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>1188AF99-8CB2-4C7A-8258-552694DC2FC1</gtr:id><gtr:impact>Dense Laser Stereo</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94b19c27ec0.43526342</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Dense Laser Stereo</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Lina Paz, Pedro Pinies, and Paul Newman &amp;quot;Route segmentation and Tracking with Cameras&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>8AB77074-30CC-4AAB-8DFF-DF2287A7BEA9</gtr:id><gtr:impact>Lina Paz, Pedro Pinies, and Paul Newman &amp;quot;Route segmentation and Tracking with Cameras&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>56e043d96147b5.65466088</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Route segmentation and Tracking with Cameras&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Scene Prior Builder v2</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>6C9D66F4-F8E6-4C39-AD2F-F39145CBAB62</gtr:id><gtr:impact>Scene Prior Builder v2</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94c41090493.08958717</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Scene Prior Builder v2</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Pedro Pinies, Lina Paz and Paul Newman &amp;quot;Dense disparity estimation for stereo vision&amp;quot; Not registered yet. Not licensed yet.</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>09B439B3-CF32-4240-80EC-2287242A6767</gtr:id><gtr:impact>Pedro Pinies, Lina Paz and Paul Newman &amp;quot;Dense disparity estimation for stereo vision&amp;quot; Not registered yet. Not licensed yet.</gtr:impact><gtr:licensed>No</gtr:licensed><gtr:outcomeId>56e043714b0655.29883523</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>&amp;quot;Dense disparity estimation for stereo vision&amp;quot;</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>Dub4</gtr:description><gtr:grantRef>EP/M019918/1</gtr:grantRef><gtr:id>F0F60AC4-CFAF-4ED2-82BD-78E81EB5F3B0</gtr:id><gtr:impact>Dub4</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c94c1d4f2973.63240372</gtr:outcomeId><gtr:protection>Copyrighted (e.g. software)</gtr:protection><gtr:title>Dub4</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:keyFindingsOutput><gtr:description>Overall the grant is proceeding exactly as we had hoped. We are making steady and exciting progress through the science case and producing a stream of prize winning publications. 

We are breaking into new technical ground (dense reconstruction, verification, trust)

We are starting to see ways in which the verification ideas in CS can be applied to vital parts of the robotics endeavour for example in the algorithms at the heart of Ingmar's 3D perception system &amp;amp; Vote3D.

The PG has enticed JLR to join as an MRG member and on the back of that will soon be taking delivery of a new vehicle for us to autonomise. We hope to be on the road by the summer of 2016.

We have recruited 5 new postdocs despite the recruitment concern below.

We are more enthused than ever about the efficacy of flagships as a spectacular way to force the integration of research outcomes. Indeed at the end of this summer we should see the PG outputs operating a self-driving Pod around MiltonKeynes.

We have had two international visits Peter Corke and Hadas Kress-Gazit and the latter in particular looks like catalysing new work with both CS and MRG.

We are looking to move into new spaces and just recently started a thread on looking at how our perception and localisation could help with the management of Ash die back - we see forestry as an important global concern.</gtr:description><gtr:exploitationPathways>The MRG's work has been commercialised into a company,
PlinkArt, which was purchased by Google in 2010
- its first UK acquisition. MRG's laser based navigation
work has been licensed to Guidance Navigation Ltd, a
major robot navigation company and sponsor. Newman's
navigation software was used in curtailing the 2010 Gulf
oil leak. Newman is the author of the MOOS software
package used in marine autonomy projects around the
world (for example DARPA DASH program which will run
on a US submarines next year). In Summer 2014, after
a year-long selection process and independent verification,
MRG's visual navigation package &amp;quot;oVo&amp;quot; was chosen
(and licensed) for the upcoming ESA ExoMars project. In
Sept 2014, a university spin out &amp;quot;Oxbotica&amp;quot; will be started
(founded by Newman and Posner) to handle the commercialisation of Oxford's robotics I.P portfolio.</gtr:exploitationPathways><gtr:id>369CEAB8-4368-4614-AC2F-24A4B9DE0DDF</gtr:id><gtr:outcomeId>56d9b89767c737.39684944</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Government, Democracy and Justice,Transport</gtr:sector></gtr:sectors><gtr:url>http://mrg.robots.ox.ac.uk/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Driverless Cars</gtr:description><gtr:geographicReach>National</gtr:geographicReach><gtr:id>BC6A77E0-613D-4D7E-8B5D-EEBB7B8475AF</gtr:id><gtr:outcomeId>5464cfbfd88fd0.06559828</gtr:outcomeId><gtr:type>Gave evidence to a government review</gtr:type><gtr:url>http://www.policyexchange.org.uk/publications/category/item/eight-great-technologies</gtr:url></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>Oxbotica</gtr:companyName><gtr:description>Oxbotica is a spin-out from Oxford University's internationally acclaimed Mobile Robotics Group. We specialise in mobile autonomy, navigation and perception, and draw on our heritage of world leading research into autonomous robotics. Our solutions allow robots, vehicles, machinery and people to precisely map, navigate and actively interact with their surroundings, delivering new capability and precision to a wide range of applications. Our 3D imaging and localisation solutions operate indoors and outdoors and are suitable for use in applications ranging from hand held survey devices to autonomous vehicles.

Oxbotica was founded by Prof. Ingmar Posner and Prof. Paul Newman - leaders of Oxford University's Mobile Robotics Group (MRG). MRG has an outstanding reputation for innovation and industrial collaborations (mrg.robots.ox.ac.uk). It has licensed navigation software for use on Mars rovers, developed the UK's first self-driving car, and has been a key and influential innovator in the area of Robotics and Autonomous Systems.</gtr:description><gtr:id>F8858132-0997-4097-BB24-93E51D421508</gtr:id><gtr:impact>Oxbotica will leverage the innovative and world leading outputs of the UK's premier mobile robotics group, enabling rapid commercialisation with our industry partners and further application of spin-off technologies.</gtr:impact><gtr:outcomeId>5463530f914259.91764147</gtr:outcomeId><gtr:url>http://www.oxbotica.com/</gtr:url><gtr:yearCompanyFormed>2014</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>33B61BEA-1E89-4BD3-ADDB-39A70EA7DAAC</gtr:id><gtr:title>Find Your Own Way: Weakly-Supervised Segmentation of Path Proposals for Urban Autonomy</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3bb3b922bbd0e8c01d824fa210e4c7c2"><gtr:id>3bb3b922bbd0e8c01d824fa210e4c7c2</gtr:id><gtr:otherNames>Daniel Barnes</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2810b4c37b4.43438985</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DF7C3973-2E59-4F20-A054-7D407A9F7BBD</gtr:id><gtr:title>Quantitative verification and strategy synthesis for stochastic games</gtr:title><gtr:parentPublicationTitle>European Journal of Control</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3cf859719493e85aff8066eb17e1539f"><gtr:id>3cf859719493e85aff8066eb17e1539f</gtr:id><gtr:otherNames>Svorenov? M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2dc06d55a2.30718363</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1C3ADF3C-C306-4545-AF24-AF246ED75223</gtr:id><gtr:title>Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks</gtr:title><gtr:parentPublicationTitle>ArXiv e-prints</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/858607509b0af8142ab224d6a827b769"><gtr:id>858607509b0af8142ab224d6a827b769</gtr:id><gtr:otherNames>Martin Engelcke</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2804b41ecb7.44614093</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E37753EC-5BA2-4D34-BA0E-BF10DBD16CB2</gtr:id><gtr:title>Large-scale cost function learning for path planning using deep inverse reinforcement learning</gtr:title><gtr:parentPublicationTitle>The International Journal of Robotics Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/644e92ffe4453bc79f6ee65cf3ce993e"><gtr:id>644e92ffe4453bc79f6ee65cf3ce993e</gtr:id><gtr:otherNames>Wulfmeier M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e76e996e0.90617355</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FB4D1424-2908-4101-9424-ABED004D1B32</gtr:id><gtr:title>Direct Visual Localisation and Calibration for Road Vehicles in Changing City Environments</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e01a290a4bdc93ddd06e50485738cc55"><gtr:id>e01a290a4bdc93ddd06e50485738cc55</gtr:id><gtr:otherNames>G.Pascoe</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cef83d458312.17903598</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B01A3D48-0082-4DA3-A27E-7E468E2D523D</gtr:id><gtr:title>DeepVO: Towards End-to-End Visual Odometry with Deep Recurrent Convolutional Neural Networks</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58c9656a503ee7.53514127</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F85E072D-C2C9-4964-84BF-2B7EEC18F9AB</gtr:id><gtr:title>A unified representation for application of architectural constraints in large-scale mapping</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1458d2bde2c4212347e1b4315698023b"><gtr:id>1458d2bde2c4212347e1b4315698023b</gtr:id><gtr:otherNames>Amayo P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c29abc0599d1.33042406</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D7815262-1392-4115-92E3-96C73610CA12</gtr:id><gtr:title>Keyframe Based Large-Scale Indoor Localisation Using Geomagnetic Field and Motion Pattern</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c966d70aaaa2.66856903</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3BF9E9B0-68C2-403D-BDDB-8477590B16A6</gtr:id><gtr:title>Off the beaten track: Predicting localisation performance in visual teach and repeat</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bc724fef42194883dee1fe02f782ea49"><gtr:id>bc724fef42194883dee1fe02f782ea49</gtr:id><gtr:otherNames>Dequaire J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c29a5a1a37a6.43003280</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BCB91EB5-B35E-4D79-A18E-A9B0FF2FAFEE</gtr:id><gtr:title>Iterative Temporal Planning in Uncertain Environments With Partial Satisfaction Guarantees</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Robotics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1f97ce6767ecc00a75b418d44ac85b67"><gtr:id>1f97ce6767ecc00a75b418d44ac85b67</gtr:id><gtr:otherNames>Lahijanian M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2d8b2ccc59.68057314</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EB3B27D7-2D13-4028-9BE3-C0EA997BA94D</gtr:id><gtr:title>Checkout my map: Version control for fleetwide visual localisation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5beb69924584b6a1ae2a929ac7e7c45c"><gtr:id>5beb69924584b6a1ae2a929ac7e7c45c</gtr:id><gtr:otherNames>Gadd M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2898e823299.22326472</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>368D5C68-099C-4A7E-BE0C-19F167DC007A</gtr:id><gtr:title>Deep tracking in the wild: End-to-end tracking using recurrent neural networks</gtr:title><gtr:parentPublicationTitle>The International Journal of Robotics Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bc724fef42194883dee1fe02f782ea49"><gtr:id>bc724fef42194883dee1fe02f782ea49</gtr:id><gtr:otherNames>Dequaire J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e948aa564.36964837</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>24ACA10A-B51D-4CC6-A8BC-E78AA6CFFFFE</gtr:id><gtr:title>Find your own way: Weakly-supervised segmentation of path proposals for urban autonomy</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/111ba2944f322745faf204c4cdf4a961"><gtr:id>111ba2944f322745faf204c4cdf4a961</gtr:id><gtr:otherNames>Barnes D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e1ccd58e5.21608784</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>61583977-90EC-47FD-BDAD-E27D710E3004</gtr:id><gtr:title>Learn from experience: probabilistic prediction of perception performance to avoid failure</gtr:title><gtr:parentPublicationTitle>The International Journal of Robotics Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/18d7ac69d992ed0186fb7aeccb924208"><gtr:id>18d7ac69d992ed0186fb7aeccb924208</gtr:id><gtr:otherNames>Gurau C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e204e0387.64877465</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>60797AB1-A787-46D4-A0E9-F2EB3D55C091</gtr:id><gtr:title>Advances and challenges of quantitative verification and synthesis for cyber-physical systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/74520a7ae7c30a41b48e87669d300016"><gtr:id>74520a7ae7c30a41b48e87669d300016</gtr:id><gtr:otherNames>Kwiatkowska M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2e3874bc77.95993484</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ADB84807-2AAA-4DD7-BC3F-0EC0A089FDAF</gtr:id><gtr:title>Watch this: Scalable cost-function learning for path planning in urban environments</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/644e92ffe4453bc79f6ee65cf3ce993e"><gtr:id>644e92ffe4453bc79f6ee65cf3ce993e</gtr:id><gtr:otherNames>Wulfmeier M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c286bd5a4569.46385168</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>595BDC1D-8A3E-4BF4-9FC5-8ECE3A81474D</gtr:id><gtr:title>1 year, 1000 km: The Oxford RobotCar dataset</gtr:title><gtr:parentPublicationTitle>The International Journal of Robotics Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d81eaa1265fa908e57800b54c76f2ed"><gtr:id>5d81eaa1265fa908e57800b54c76f2ed</gtr:id><gtr:otherNames>Maddern W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c27cc5d504d7.24907285</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7118A8ED-7738-4598-ACFD-27DBA58DAC7C</gtr:id><gtr:title>The Path Less Taken: A Fast Variational Approach for Scene Segmentation Used For Closed Loop Control</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/41cebbadd3846527c7ff8217f5c4e4d5"><gtr:id>41cebbadd3846527c7ff8217f5c4e4d5</gtr:id><gtr:otherNames>Tarlan Suleymanov</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c288fb0e5113.63657276</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C8088878-3E4B-4BFA-A8F1-C888053716C3</gtr:id><gtr:title>A Variational Approach to Online Road and Path Segmentation with Monocular Vision</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/823ff5e2dae7641249bdc8d9ed39795a"><gtr:id>823ff5e2dae7641249bdc8d9ed39795a</gtr:id><gtr:otherNames>L.M.Paz</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf0d4798b694.60591386</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>830594BC-6D68-46A0-ACB9-9058463BDB53</gtr:id><gtr:title>Exploiting 3D semantic scene priors for online traffic light interpretation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/111ba2944f322745faf204c4cdf4a961"><gtr:id>111ba2944f322745faf204c4cdf4a961</gtr:id><gtr:otherNames>Barnes D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5a6f2e37eed620.28526231</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>72644BDA-762E-4BB4-BBB0-7D1B09464AAC</gtr:id><gtr:title>Leveraging the urban soundscape: Auditory perception for smart vehicles</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a028963d24624c1ae88f450d2e85356b"><gtr:id>a028963d24624c1ae88f450d2e85356b</gtr:id><gtr:otherNames>Marchegiani L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e75bbb371.15125086</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FE35B8F8-9802-45DB-9A16-4DBBEF0C6D22</gtr:id><gtr:title>Incorporating Human Domain Knowledge into Large Scale Cost Function Learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9417e66100ae5e7589057337ba2a165f"><gtr:id>9417e66100ae5e7589057337ba2a165f</gtr:id><gtr:otherNames>Markus Wulfmeier</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c27e05779636.54920805</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F772167C-EB4D-4C2F-8AF1-F3D5C7D1E0D2</gtr:id><gtr:title>Deep Tracking on the Move: Learning to Track the World from a Moving Vehicle using Recurrent Neural Networks</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5017e1b5a9c14ca2881c62a510ed25a4"><gtr:id>5017e1b5a9c14ca2881c62a510ed25a4</gtr:id><gtr:otherNames>Julie Dequarie</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c27ef15df4a4.92698864</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F2847EB8-ED49-40C6-91F3-BBAF25B8C473</gtr:id><gtr:title>Automated valet parking and charging for e-mobility</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/940de71efd256e96924b4e68a35b89e8"><gtr:id>940de71efd256e96924b4e68a35b89e8</gtr:id><gtr:otherNames>Schwesinger U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2d893385c0.16873324</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>09026DD8-F1CD-439D-86A1-9637329C815F</gtr:id><gtr:title>Specification revision for Markov decision processes with optimal trade-off</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1f97ce6767ecc00a75b418d44ac85b67"><gtr:id>1f97ce6767ecc00a75b418d44ac85b67</gtr:id><gtr:otherNames>Lahijanian M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2e9497e6e1.09352028</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4875F110-8063-4658-96D2-5CD8F546F692</gtr:id><gtr:title>Vote3Deep: Fast object detection in 3D point clouds using efficient convolutional neural networks</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecafc209d67be05dcc2e840e73d8c9ac"><gtr:id>ecafc209d67be05dcc2e840e73d8c9ac</gtr:id><gtr:otherNames>Engelcke M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2de619fae3.29069112</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>68732294-C8F8-47E5-889B-0A6B13BE3A40</gtr:id><gtr:title>PRISM-games: verification and strategy synthesis for stochastic multi-player games with multiple objectives</gtr:title><gtr:parentPublicationTitle>International Journal on Software Tools for Technology Transfer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/74520a7ae7c30a41b48e87669d300016"><gtr:id>74520a7ae7c30a41b48e87669d300016</gtr:id><gtr:otherNames>Kwiatkowska M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e77883d97.45070015</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CA0FB262-7F30-401B-8144-F2BE3D8375EA</gtr:id><gtr:title>Too Much TV is Bad: Dense Reconstruction from Sparse Laser with Non-convex Regularisation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ccae6aef918f3fbe42a6fe9bac41466"><gtr:id>1ccae6aef918f3fbe42a6fe9bac41466</gtr:id><gtr:otherNames>P.Pinies</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf0ca3555342.40993481</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>013DC870-1E56-43D3-AB08-4DDD98207F00</gtr:id><gtr:title>Exploiting Known Unknowns: Scene Induced Cross-Calibration of Lidar-Stereo Systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8f3456fc10bc8df3b9ce8a64a7238a3b"><gtr:id>8f3456fc10bc8df3b9ce8a64a7238a3b</gtr:id><gtr:otherNames>T. Scott</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56dda316724ff6.04289633</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1C4B249E-22B5-4204-B359-C106166627FE</gtr:id><gtr:title>Building, Curating, and Querying Large-scale Data Repositories for Field Robotics Applications</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d563bbae934438a053c13740cde2a48f"><gtr:id>d563bbae934438a053c13740cde2a48f</gtr:id><gtr:otherNames>P.Nelson</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf0af7336a88.81127116</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>29B7F697-BCE7-4211-A860-3A0A00FDC0DB</gtr:id><gtr:title>Deep Inverse Reinforcement Learning</gtr:title><gtr:parentPublicationTitle>CoRR</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/544eef76938ab37f85455abac04d123c"><gtr:id>544eef76938ab37f85455abac04d123c</gtr:id><gtr:otherNames>M. Wulfmeier</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56dda28cdfb4c6.58512682</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BD298ED3-E4BE-48B5-9E21-A831481887AC</gtr:id><gtr:title>End-to-End Tracking and Semantic Segmentation Using Recurrent Neural Networks (Best Paper in Workshop)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0cfcb9ce8c360ad04900d964d2f175f9"><gtr:id>0cfcb9ce8c360ad04900d964d2f175f9</gtr:id><gtr:otherNames>Peter Ondruska</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c295895eddc7.85272794</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8A7E75B8-EC6C-46D0-87D3-B89EA9F205B7</gtr:id><gtr:title>VINet: Visual Inertial Odometry as a Sequence to Sequence Learning Problem</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ad56dd744e720c3bb05e1d22df493d95"><gtr:id>ad56dd744e720c3bb05e1d22df493d95</gtr:id><gtr:otherNames>Clark R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58c96628ba9170.35519511</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4C625769-9576-4279-AA64-D7495B5EB0E1</gtr:id><gtr:title>Reading the Road: Road Marking Classification and Interpretation</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Intelligent Transportation Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c383bcdbcc9faa1eb7bf2af1eaae0cf0"><gtr:id>c383bcdbcc9faa1eb7bf2af1eaae0cf0</gtr:id><gtr:otherNames>Mathibela B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5a6f2da99251c1.12846376</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1D0C6EAC-1949-43AB-9CFA-02BA1D73A47D</gtr:id><gtr:title>Dense Mono Reconstruction: Living with the Pain of the Plain Plane</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ccae6aef918f3fbe42a6fe9bac41466"><gtr:id>1ccae6aef918f3fbe42a6fe9bac41466</gtr:id><gtr:otherNames>P.Pinies</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf0be8b5d624.08406568</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7FD2CB37-39ED-48CA-8A6D-7FE15BB5BD5E</gtr:id><gtr:title>Compositional strategy synthesis for stochastic games with multiple objectives</gtr:title><gtr:parentPublicationTitle>Information and Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6dfd8d6bf5a03420ab32383660475514"><gtr:id>6dfd8d6bf5a03420ab32383660475514</gtr:id><gtr:otherNames>Basset N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2e1983cd31.30844117</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>44C96195-3D6E-4A8F-B682-0B0ED269226C</gtr:id><gtr:title>Temporal logic control for stochastic linear systems using abstraction refinement of probabilistic games</gtr:title><gtr:parentPublicationTitle>Nonlinear Analysis: Hybrid Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3cf859719493e85aff8066eb17e1539f"><gtr:id>3cf859719493e85aff8066eb17e1539f</gtr:id><gtr:otherNames>Svorenov? M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2dc096e6d3.89867127</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9A1802A4-9E2C-4389-B626-93ABEE3848EF</gtr:id><gtr:title>BOR2G: Building Optimal Regularised Reconstructions with GPUs (in cubes)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0962d14abe4c885b67a53082e6636714"><gtr:id>0962d14abe4c885b67a53082e6636714</gtr:id><gtr:otherNames>M.Tanner</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf0a6b3e23f2.72542211</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A348F835-AFA4-4FDE-A4DD-39F0E06AB491</gtr:id><gtr:title>Introspective classification for robot perception</gtr:title><gtr:parentPublicationTitle>The International Journal of Robotics Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/38888467eee7d5e3ccaa70308f092111"><gtr:id>38888467eee7d5e3ccaa70308f092111</gtr:id><gtr:otherNames>Grimmett H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5a6f2e7b017c68.95918663</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F26FC2A5-170E-4440-A76E-C22938F1EA51</gtr:id><gtr:title>Choosing a time and place for calibration of lidar-camera systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f15c492bda7ffabf37da386aa31532fd"><gtr:id>f15c492bda7ffabf37da386aa31532fd</gtr:id><gtr:otherNames>Scott T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c29b25c22740.50863645</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>44589E93-F5DF-41F5-8756-83DEDEF8F17B</gtr:id><gtr:title>Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9e9d23c70859d5402aef2c0214fc5e64"><gtr:id>9e9d23c70859d5402aef2c0214fc5e64</gtr:id><gtr:otherNames>P. Ondruska</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56ddaa08672ba3.24802808</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4B8E4B6C-D941-4253-A1E6-3A0AD10CE2E3</gtr:id><gtr:title>NID-SLAM: Robust Monocular SLAM Using Normalised Information Distance</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7f24b66af805ab428ca4fb43d327a823"><gtr:id>7f24b66af805ab428ca4fb43d327a823</gtr:id><gtr:otherNames>Pascoe G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708d376b1e51.41871349</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AD452F97-839F-470C-B3BE-98858041E0AB</gtr:id><gtr:title>Symbolic optimal expected time reachability computation and controller synthesis for probabilistic timed automata</gtr:title><gtr:parentPublicationTitle>Theoretical Computer Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cc4cf1e7d99d9cd51c5e6c26710258c9"><gtr:id>cc4cf1e7d99d9cd51c5e6c26710258c9</gtr:id><gtr:otherNames>Jovanovic A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5964b980a0f1a0.77035713</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>087EE6ED-4C1A-4318-B6AF-65FC360872D2</gtr:id><gtr:title>Keep Geometry in Context: Using Contextual Priors for Very-Large-Scale 3D Dense Reconstructions</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f934aaa600d9e1b0587cd5e493ae50a9"><gtr:id>f934aaa600d9e1b0587cd5e493ae50a9</gtr:id><gtr:otherNames>Michael Tanner</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2962a1fa668.27393519</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>308549E1-9C2B-41C2-969B-67721E64CB39</gtr:id><gtr:title>End-to-End Tracking and Semantic Segmentation Using Recurrent Neural Networks</gtr:title><gtr:parentPublicationTitle>ArXiv e-prints, 2016.</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0cfcb9ce8c360ad04900d964d2f175f9"><gtr:id>0cfcb9ce8c360ad04900d964d2f175f9</gtr:id><gtr:otherNames>Peter Ondruska</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2996a093d52.30834001</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B444EB62-2DBF-4440-B45F-14E14FBD9835</gtr:id><gtr:title>Enabling Intelligent Energy Management for Robots using Publicly Available Maps</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fc88a0eea3d9a881e11df373b95df36a"><gtr:id>fc88a0eea3d9a881e11df373b95df36a</gtr:id><gtr:otherNames>Oliver Bartlett</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c281fce836c1.18583924</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>034C88E3-D0CC-4344-A45E-61006E72B59F</gtr:id><gtr:title>Enabling intelligent energy management for robots using publicly available maps</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ca7e6bbe3035841fa023c57e50c79a10"><gtr:id>ca7e6bbe3035841fa023c57e50c79a10</gtr:id><gtr:otherNames>Bartlett O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a6f2e8f0a7915.04496382</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8F0CB417-0C97-45FD-9994-02C77B9E1DDC</gtr:id><gtr:title>On-line Scene Understanding for Closed Loop Control</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/00a4ad0d860328c530aef886f82f585f"><gtr:id>00a4ad0d860328c530aef886f82f585f</gtr:id><gtr:otherNames>Lina Maria Paz</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c28a7c5e8911.54516927</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M019918/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>772CD758-53CD-407F-9B2C-F2B861E86155</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Mechanical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>