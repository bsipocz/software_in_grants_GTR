<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/ED6A6B32-663C-4A62-A33B-2C6A68E2E102"><gtr:id>ED6A6B32-663C-4A62-A33B-2C6A68E2E102</gtr:id><gtr:name>University of Essex</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Wivenhoe Park</gtr:line1><gtr:line4>Colchester</gtr:line4><gtr:line5>Essex</gtr:line5><gtr:postCode>CO4 3SQ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/ED6A6B32-663C-4A62-A33B-2C6A68E2E102"><gtr:id>ED6A6B32-663C-4A62-A33B-2C6A68E2E102</gtr:id><gtr:name>University of Essex</gtr:name><gtr:address><gtr:line1>Wivenhoe Park</gtr:line1><gtr:line4>Colchester</gtr:line4><gtr:line5>Essex</gtr:line5><gtr:postCode>CO4 3SQ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5195F775-F0E4-443A-AE02-3E6B51BB33A7"><gtr:id>5195F775-F0E4-443A-AE02-3E6B51BB33A7</gtr:id><gtr:name>Phonak Hearing Systems</gtr:name><gtr:address><gtr:line1>Laubisrutistrasse 28</gtr:line1><gtr:line4>8712 Stafa</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>Switzerland</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6865C66E-3181-4456-98D4-B188E971EE4A"><gtr:id>6865C66E-3181-4456-98D4-B188E971EE4A</gtr:id><gtr:firstName>Ray</gtr:firstName><gtr:surname>Meddis</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE064590%2F1"><gtr:id>E557D032-DC4C-4B2E-80F2-8B825963B10D</gtr:id><gtr:title>Hearing dummy</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E064590/1</gtr:grantReference><gtr:abstractText>The dispensing of hearing aids has not kept pace with the dramatic increase in technological sophistication of the aids themselves. Current diagnostic tests are simple, the principles for choosing a particular aid are rudimentary, the evaluation of hearing after dispensing is inadequate and, not surprisingly, levels of patient satisfaction are much lower than for, for example, spectacles.This project will develop a new approach to the problem by adapting a computer model of hearing to represent the particular deficit of an individual patient. The model (or 'hearing dummy'') can then be used to evaluate objectively, the potential benefit of different hearing aid designs and indicate a 'best-buy' prescription.The aim is to produce a comprehensive system from assessment through to dispensing advice that is viable in a clinical context given the normal constraints of audiological practice. Within this general aim, a particular effort is required in three areas, patient assessment, adapting the computer model to represent the hearing of the patient and using the model to generate dispensing advice. Patient assessment requires a range of auditory tests that can be conducted quickly which cover a range of different auditory functions. The test battery will build on recently-developed assessment protocols and will cover functions not normally assessed in audiology clinics at present but are necessary to define the underlying pathology. They will include the measurement of filter bandwidths, compression, temporal integration, distortion-product oto-acoustic emissions and averaged brain response in addition to absolute thresholds. These tests will need to be faster and easier to administer than existing laboratory techniques. In this respect we will benefit from the support of the local audiology clinic and a private dispensing agency where the practicalities of assessment with patients are their primary concern.An existing computer model of normal peripheral hearing will be used in this project. It will be adapted using data collected in the assessment stage to represent the hearing of that individual patient. The accuracy of the 'hearing dummy' model will be assessed by testing it using the same audiometric procedures used with the patient. The model must give the same outcome as the patient tests to be regarded as accurate. While this may appear to be a tall order, the results of 20 years of research and development of this particular model offer reassurance that it is achievable on a routine clinical basis.A hearing aid transforms the ambient acoustic signal into a form thought to be more useful to the patient. Some transforms will be more successful than others in restoring the response of the auditory periphery to a more normal pattern. The project will measure the response of the model to different signal transforms representing different hearing aid designs. These outputs will be compared to the response of a model of a healthy ear to the original sound. The best aid is forecast as the one that restores the output to a pattern closest to normal.A good hearing aid is one that helps the patient function normally in everyday situations. The greatest challenge is to hear speech details against a confusing acoustic background. The project will focus on this as the ultimate test of a beneficial aid. In this we shall benefit from a parallel collaborative project with Sheffield University that is using our auditory computer model to develop and evaluate automatic recognition of speech sounds in noisy backgrounds.</gtr:abstractText><gtr:fund><gtr:end>2011-02-16</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-09-17</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>363889</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>4EEC1538-752C-4BB1-BAFD-692901A981C5</gtr:id><gtr:title>Tinnitus and patterns of hearing loss.</gtr:title><gtr:parentPublicationTitle>Journal of the Association for Research in Otolaryngology : JARO</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1a4abe7535f6885ec270b582c281ffc3"><gtr:id>1a4abe7535f6885ec270b582c281ffc3</gtr:id><gtr:otherNames>Tan CM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1438-7573</gtr:issn><gtr:outcomeId>doi_53cfd8fd83e4c4a6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D4CCC8A4-061F-41BB-B650-20DF158C6112</gtr:id><gtr:title>Convergence and parameter choice for Monte-Carlo simulations of diffusion MRI.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on medical imaging</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/78f23454964737814b06e3dba545233f"><gtr:id>78f23454964737814b06e3dba545233f</gtr:id><gtr:otherNames>Hall MG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0278-0062</gtr:issn><gtr:outcomeId>doi_55f95195185ec2f4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5C86A21F-94AE-4B26-95C0-DA5803187A67</gtr:id><gtr:title>A simple single-interval adaptive procedure for estimating thresholds in normal and impaired listeners.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f00a1903f8a22f7541874e72c685b977"><gtr:id>f00a1903f8a22f7541874e72c685b977</gtr:id><gtr:otherNames>Lecluyse W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>doi_53d06e06e844d0cd</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8B2B98EB-6622-4026-B1F9-28B23395115A</gtr:id><gtr:title>The psychophysics of absolute threshold and signal duration: a probabilistic approach.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fe9278d09d52ae37972ac42e173454b7"><gtr:id>fe9278d09d52ae37972ac42e173454b7</gtr:id><gtr:otherNames>Meddis R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>doi_53d06e06ea35a43c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A4CB7FAD-3B65-46B0-AEF2-2CC3E55B1315</gtr:id><gtr:title>A computer model of auditory efferent suppression: implications for the recognition of speech in noise.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/927de28339d4fea28f000fb150e2a503"><gtr:id>927de28339d4fea28f000fb150e2a503</gtr:id><gtr:otherNames>Brown GJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>doi_53d06e06e88d3536</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E064590/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>