<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/46B41008-0EB4-4E28-BBFB-E98366999EC5"><gtr:id>46B41008-0EB4-4E28-BBFB-E98366999EC5</gtr:id><gtr:name>Durham University</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Old Shire Hall</gtr:line1><gtr:line2>Old Elvet</gtr:line2><gtr:line4>Durham</gtr:line4><gtr:line5>County Durham</gtr:line5><gtr:postCode>DH1 3HP</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/46B41008-0EB4-4E28-BBFB-E98366999EC5"><gtr:id>46B41008-0EB4-4E28-BBFB-E98366999EC5</gtr:id><gtr:name>Durham University</gtr:name><gtr:address><gtr:line1>Old Shire Hall</gtr:line1><gtr:line2>Old Elvet</gtr:line2><gtr:line4>Durham</gtr:line4><gtr:line5>County Durham</gtr:line5><gtr:postCode>DH1 3HP</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/A846C577-F6C7-4DEC-999D-49A86F5B900B"><gtr:id>A846C577-F6C7-4DEC-999D-49A86F5B900B</gtr:id><gtr:firstName>Lore</gtr:firstName><gtr:surname>Thaler</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/283AFED7-243E-4B2A-B990-EAB92738C45B"><gtr:id>283AFED7-243E-4B2A-B990-EAB92738C45B</gtr:id><gtr:firstName>James</gtr:firstName><gtr:otherNames>Earl</gtr:otherNames><gtr:surname>Negen</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/28330861-3887-4BBB-9884-24357E7185AE"><gtr:id>28330861-3887-4BBB-9884-24357E7185AE</gtr:id><gtr:firstName>Marko</gtr:firstName><gtr:surname>Nardini</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FN01846X%2F1"><gtr:id>C6A4DED5-D755-4A84-B37E-4ED1910BB4B5</gtr:id><gtr:title>Learning Cue Combination</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/N01846X/1</gtr:grantReference><gtr:abstractText>People often have to deal with multiple streams of information at once. For example, imagine you are on a walk out in the woods trying to find a kind of rare bird. You hear a bird call (audio information) and turn towards it. You can see some leaves moving around in a tree (visual information). Neither stream of information is perfectly reliable -- you will tend to make some error one way or another when you try to pinpoint the sound location, and you don't know exactly which leaf the bird was behind -- but both are useful pieces of information. What we see in the lab when we give these kinds of tasks to adults is called 'optimal cue combination'. Adults tend to combine all the different 'cues' available in an 'optimal' way that gets them as close as possible to the right location. To do this, they have to take into account how reliable each cue is, weight each cue by its reliability, and then take a weighted average. Developmental Psychologists have found that children don't begin doing this until they are about 10 or 11 years old; before that, they seem to just ignore one cue or the other (e.g. Nardini, Bedford &amp;amp; Mareschal, 2010). This is surprising because in these studies, children have all the information they need to make more accurate judgments. They are just failing to combine the information in the right way. We want to know why. What is changing at 10-11 years old that allows them to start doing optimal cue combination?

We are going to examine two big ideas that might provide good answers to this puzzle. First, children at 10-11 might gain a new ability. They might first develop the ability to learn how to put cues together at this age. The second idea is that it might come down to the quality of the individual cues that children are trying to average together. It's generally a bad idea to do 'optimal cue combination' with a cue that is strongly biased (systematically incorrect) -- in that case, it makes more sense to ignore the biased cue. Even if a cue is not strictly-speaking biased, it might also be so noisy that it is hard to learn how it works. It could be that children under 10-11 years don't show optimal cue combination because the individual cues that they have available are all too biased or noisy. To test these ideas, we will test several predictions that they make. For example, we should be able to train children at 7-9 years as much as we want and they should never learn cue combination; we should be able to prevent adults from learning cue combination with a new cue by inducing child-like biases. It is possible that both of these big ideas might be correct -- it could be that children need a new ability and that the individual cues also have to improve.

This work will be made possible by a combination of methods newly developed in our lab especially for this project, including testing and training children's abilities to combine the senses, and to learn a completely &amp;quot;new&amp;quot; sense, in immersive virtual reality. The work will be interesting to cognitive scientists, especially those interested in development and education. It will help us design better future interventions to teach additional senses to children with sensory loss. It will give us a better understanding of how the use of multiple cues responds to training in childhood, which is of interest to safety-oriented organizations since so many behaviours like safe road crossing can rely on multiple senses (seeing and hearing traffic). It will also be of interest to people who design educational tests since we will continue to develop our new test of a major sensory milestone and show people how similar efficient tests can be designed in other areas of education.</gtr:abstractText><gtr:potentialImpactText>Our impact will have 3 aims: (1) understanding how and when we can improve sensory learning in non-clinical populations in late childhood so that we can strengthen ties and develop strategies for future research into direct applications to clinical populations, particularly vision loss, (2) improve our understanding of the multisensory aspect of basic safety during tasks like road crossing in early childhood and communicate both the current state of the art and our new findings to councils, (3) create a specific worked example of a new individual-level Bayesian psychological test that will be shared via our ties to the educational evaluation and monitoring community at Durham University and online.

(1) Syndromes like retinitis pigmentosa can affect young children by causing gradual permanent loss of vision and even eventual blindness. Echolocation and other supplementary sensory strategies could potentially help affected patients, but current research suggests that a major roadblock exists: children under 10 years old have not been found to use multiple sensory cues simultaneously to improve on the precision they exhibit with just one cue. If this is true then teaching a young child with some remaining vision to echolocate may be less effective than hoped for, as they may fail to supplement their failing vision with echolocation and instead switch between using one sense and the other. This initial training still has the potential to be useful, but to optimise these kinds of interventions we require a better understanding of exactly what is blocking a typical younger person from combining multiple cues. This will allow us to design future applied research with clinical populations to potentially overcome those specific obstacles. We are starting with non-clinical populations in this project but can use results to guide specific research questions in future with smaller, potentially more vulnerable clinical populations. 

Objective 1.1: International workshop held at 33-36 months where we communicate findings to the vision loss/sensory substitution community and receive feedback from them about the kind of applied research that they would like to follow; 1.2: online publication of materials. 


(2) Many basic safety behaviours require integrating multiple sensory cues in order to be as accurate and safe as possible e.g. crossing the road can require a child to combine cues like peripheral vision and localised sound. Councils should be aware of the danger of assuming that a young person would be able to fall back on secondary cues in an adult-like way and will want to know what kind of training (if any) can improve this. 

Objective 2.1: Meeting with Durham and Stockton councils in months 18-21 where we explain the current state of the art and also the results of Studies 1.1-1.3, which all deal with training at different ages; 2.2: online publication of materials.


(3) Educational evaluation and monitoring experts are always facing a crucial tradeoff between the time taken to perform an evaluation and the accuracy of that evaluation. The new analysis introduced in this project shows how Bayesian model-based comparison can allow a specific stage of development to be assessed efficiently within a single child's dataset. The impact here is potentially both specific, in that it assesses a major milestone in sensory development, and general, in that the analysis logic could be used as a template in other assessment settings. 

Objective 3.1: On-campus workshop to show educational testers our experimental task, explain the logic of the data analysis (compared with previous approaches) and explore other applications, in months 18-21; 3.2: online publication of materials.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-07-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2016-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>445916</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>092213BA-5BAE-4AF1-BDBE-0C564A53493F</gtr:id><gtr:title>Is a newly learnt sense immediately combined with vision?</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aef0fdc2261fd0d5c78b5baef0bc6a0b"><gtr:id>aef0fdc2261fd0d5c78b5baef0bc6a0b</gtr:id><gtr:otherNames>Nardini M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5aa698475b8db9.18498383</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F1D3667F-AEFA-4BB8-9FF8-B191C1396451</gtr:id><gtr:title>Young Children Can Combine Audio-Visual Cues Near-Optimally After Training</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e96878a999d814de605da998dccb0b4a"><gtr:id>e96878a999d814de605da998dccb0b4a</gtr:id><gtr:otherNames>Negen J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5aa6984727c439.41540585</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/N01846X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>9A6079E0-357B-44DA-80F9-C5953586BD0C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Developmental psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>51E91F17-25CD-4FBD-917E-1BD82B72BDB9</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Mathematical &amp; Statistic Psych</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>