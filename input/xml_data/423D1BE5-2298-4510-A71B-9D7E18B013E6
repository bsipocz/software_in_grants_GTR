<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8"><gtr:id>3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8</gtr:id><gtr:name>Stanford University</gtr:name><gtr:address><gtr:line1>450 Serra Mall</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C0E4FAD2-3C8B-410A-B6DF-3B9B9E433060"><gtr:id>C0E4FAD2-3C8B-410A-B6DF-3B9B9E433060</gtr:id><gtr:name>University of St Andrews</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>College Gate</gtr:line1><gtr:line4>St. Andrews</gtr:line4><gtr:line5>Fife</gtr:line5><gtr:postCode>KY16 9AJ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C0E4FAD2-3C8B-410A-B6DF-3B9B9E433060"><gtr:id>C0E4FAD2-3C8B-410A-B6DF-3B9B9E433060</gtr:id><gtr:name>University of St Andrews</gtr:name><gtr:address><gtr:line1>College Gate</gtr:line1><gtr:line4>St. Andrews</gtr:line4><gtr:line5>Fife</gtr:line5><gtr:postCode>KY16 9AJ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8"><gtr:id>3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8</gtr:id><gtr:name>Stanford University</gtr:name><gtr:address><gtr:line1>450 Serra Mall</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5F812F7E-6C9C-4BB8-8BAD-DD2ED86AF76B"><gtr:id>5F812F7E-6C9C-4BB8-8BAD-DD2ED86AF76B</gtr:id><gtr:firstName>Julie</gtr:firstName><gtr:surname>Harris</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM001660%2F1"><gtr:id>423D1BE5-2298-4510-A71B-9D7E18B013E6</gtr:id><gtr:title>Neural pathways underlying human 3D motion perception</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M001660/1</gtr:grantReference><gtr:abstractText>We use our eyes and brain to move confidently within our surroundings without bumping into things, identifying objects as dangerous or attractive and parsing subtle changes in facial expression. Vision is a hugely complex process that uses much of the brain's resources and involves a constant trade-off between energetic efficiency, speed and accuracy. How is this achieved? 

Clues to answer this question come from fundamental biology. Anatomically, it is striking that there are multiple pathways in the visual system and neurons in different visual areas and pathways appear differentially sensitive to certain types of visual information, such as colour or motion. 

It is clear that some visual brain areas and pathways have evolved at different times and for different functions. Dedicating different pathways to different functions can be a way of reducing the complexity of the processing problem - allowing the brain to compute independent properties in parallel. Here, we are interested in a specific set of pathways that seem to show strong independence of this type: those involved in the perception of motion in three dimensional space.

Whilst motion is known to be critical for the 'where' functions of the dorsal pathway, very little attention has been placed on how binocular information for motion is processed, nor what pathways carry out that processing. In this project we explore how binocular visual information about motion-in-depth (MID) is processed and carried by several different visual pathways. 

Two computational processes have been proposed for using binocular information for MID, and there is evidence for each of them being useful for human vision. Are these signals processed along different fundamental pathways in the brain? Why is it interesting to ask this question? (1) Because neither pathway is fully understood: the sites and natures of the computations involved in processing MID in two ways have not been identified. Even more intriguingly, while one pathway, has been much studied, the other is barely explored, very poorly understood and potentially ancient, in an evolutionary sense. (2) The two pathways might perform different functions, and we propose a series of studies to specifically explore what those functions might be.

Our project has very broad scope, we explore the nature of the putative pathways at the anatomical level, using functional magnetic resonance imaging (fMRI) to localize function, and source-imaged electroencephalography (EEG), which can be used to understand the temporal dynamics of visual processing. We will use psychophysical behavioural studies to study what computational processes take place during MID perception, using both a normal population to explore normal function, and a clinical group of subjects (strabismic amblyopes) that we know have compromised MID processing using one specific pathway. Additionally using Transcranial Magnetic Stimulation (TMS) to degrade information in a particular visual area we will test the causal relevance of MID-responsive regions identified with fMRI and EEG. Finally, we will also employ eye-tracking methods to understand what specific sources of MID information are useful for. Using all these techniques will allow us to get a full picture of the processes underlying MID. To achieve this we require the expertise of three institutions, and we will need to host two RA's, one with visual behavioural and eye tracking skills, the other with imaging credentials.

The work proposed in this project is primarily core visual neuroscience. However, it has implications for human health. One of our techniques will exploit the fact that a person with a squint (strabismic amblyopes) is unable to use a core source of MID information, namely binocular disparity. There are hints that this group may be able to use other sources of MID. Our group will be the first to explore this issue comprehensively.</gtr:abstractText><gtr:technicalSummary>Anatomically, it is striking that there are multiple pathways in the visual system. Physiologically, neurons in different visual areas appear specifically sensitive to different visual information, like colour, motion or objects. Why? Dedicating different pathways to different functions can be a way of reducing the complexity of the processing problem. Here, we are interested in a specific set of pathways, those involved in the perception of motion in three dimensions.

Whilst motion is known to be critical for the 'where' functions of the dorsal pathway, very little attention has been placed on how binocular information for motion is processed, nor what pathways carry out that processing. In this project we explore how specifically binocular visual information about motion-in-depth (MID) is potentially processed and carried by several different visual pathways. 

Two computational processes have been proposed for using binocular information for MID, and there is evidence for each of them being useful for human vision. One is the rate of change of binocular disparity over time (changing disparity, CD), the other is the binocular combination of monocular motion signals (inter-ocular velocity difference, IOVD). Both are known to be used in human vision. Our aim here is to determine if these signals processed along different fundamental pathways in the brain. We target the magnocellular (magno), parvocellular (parvo) and koniocellular (konio) pathways. The former two are well studied; disparity is carried by both pathways, motion predominantly by the magno. Of particular interest, is the fact that the konio pathway projects to extra-striate cortex without passing through V1, thus providing an alterative pathway to higher visual areas. We will use brain imaging (fMRI, EEG) and visual psychophysics, to explore where, how and why MID information may be separated across different pathways.</gtr:technicalSummary><gtr:potentialImpactText>Specific Users / Stakeholders
Our proposal is for core human neuroscience research with no immediate application to UK-plc. However, we have identified two groups of possible indirect stakeholders, and two groups of direct stakeholders:
(1) Technologists and display developers, using stereoscopic displays and stereoscopic content producers.
(2) Medical professions involved in diagnosing and understanding binocular vision deficits.
(3) The general public: both consumers and producers of new stereoscopic content.
(4) Project researchers, who will be trained in interdisciplinary skills and exchange subject-specific knowledge.

Plans for engagement

(1) Technologists developing 3D material
Whilst the basic neuroscientific knowledge we generate will not be of direct interest to this group, they should be interested in the our characterisation of the utility of CD and IOVD information, in other words, how important these two sources of information are for 3D display. Harris or RA1 will attend the international conference &amp;quot;Stereoscopic Displays and Applications&amp;quot;, set up by IEEE, towards the end of the project to disseminate our results in the appropriate way for this audience.

(2) Medical professionals
Our work should be of relevance to medical professionals interested in amblyopia and strabismus, conditions that are linked and thought to be due to deficits in the development of binocular vision. One of our experiments will test a population of strabismic observers. For our purposes, we use that population's differently developed vision to test hypotheses, however, our experimental results will have relevance to the understanding of the conditions, and for their potential treatment. Towards the end of the project, we plan to invite our clinical contacts to a workshop session organised under the auspices of the Bradford Institute for Health Research to discuss the clinical implications of our work.

(3) The general public
We intend to make full use of the Press Relations Offices at each of the Institutions involved to maximise our outreach. To this end both RA's will attend the BBSRC Media Training Course. 
Wade hosts public engagement websites to teach the public about colour vision, http://www.vischeck.com/ and infant visual development http://www.tinyeyes.com/ . We will build on this experience to develop a website to demonstrate the two forms of binocular motion in depth systems that can be isolated both and allow users to generate stimuli that contain mixtures of each cue for educational purposes. 
Binocular vision is also a very popular topic with the general public of all ages, due in part to the recent resurgence of 3D film. This therefore provides an excellent opportunity for public engagement, to involve people in understanding how the brain is needed for sight and how 3D technology works. We have experience and equipment to deliver public displays at Science Fairs on how the psychology and neuroscience of binocular vision link to optics and ophthalmology. We plan to attend opens days and science fairs in Scotland and Yorkshire.

(4) Project researchers
The proposal is an interdisciplinary collaboration. We will appoint experienced postdoctoral researchers in St. Andrews and York. Each individual will experience training and will be exposed to research across disciplines, allowing us to deliver genuine inter-disciplinary scientists to the UK research community, at the end of the project. This aim will be achieved via our regular (12 in total) face to face meetings between all members of the project group.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-04-08</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2015-01-09</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>307582</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Birmingham</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>School of Psychology Birmingham</gtr:department><gtr:description>ViiHM network: Visual image interpretation in humans and machines</gtr:description><gtr:id>44A55429-7A86-4E85-9E0C-2B9206185E10</gtr:id><gtr:impact>None yet</gtr:impact><gtr:outcomeId>545a5843b231a6.96846138-1</gtr:outcomeId><gtr:partnerContribution>A network funded by EPSRC -- Schofield at Birmingham is the PI</gtr:partnerContribution><gtr:piContribution>EPSRC funded network, I am a member.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Stanford University</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:department>Center for Population Health Sciences</gtr:department><gtr:description>Harris collaboration with Norcia, Stanford University</gtr:description><gtr:id>B595E956-716E-4CEB-86C4-8A29030E71C5</gtr:id><gtr:impact>Presentation to appear at Vision Sciences Society, 2017.</gtr:impact><gtr:outcomeId>58c169c4601220.75532815-1</gtr:outcomeId><gtr:partnerContribution>We are working on a joint project with Tony Norcia and his Stanford Vision and Neurodevelopment Lab. Experiments on eye movements and motion in depth are being carried out in both locations, on related problems in how visual motion in depth drives eye movements.</gtr:partnerContribution><gtr:piContribution>We are working on a joint project with Tony Norcia and his Stanford Vision and Neurodevelopment Lab. Experiments on eye movements and motion in depth are being carried out in both locations, on related problems in how visual motion in depth drives eye movements.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Quiz a whiz interviews, Julie Harris, with Royal Society of Edinburgh</gtr:description><gtr:form>Engagement focused website, blog or social media channel</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>5059A82B-F75D-463E-9476-CBE696DBC7FE</gtr:id><gtr:impact>As part of the Royal Society of Edinburgh's Schools program, they deliver interviews with academics, based on questions from school children on the topic of interest. these are broadcast on their own web channel and on their youtube channel.</gtr:impact><gtr:outcomeId>58c161097ae301.41976911</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>https://www.rse.org.uk/schools/students/watch/</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Maloney 2015 YNiC talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>34C74233-DDD0-4A6E-910C-CF318A8AF3AF</gtr:id><gtr:impact>Talk at the York Neuroimaging Centre Science Day on eye of origin information and neural pathways in motion in depth</gtr:impact><gtr:outcomeId>56cd96752e9798.65234974</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Harris St Andrews Open Assoc 2015</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>F8E8554F-969D-4FDA-9764-8D43748E84B6</gtr:id><gtr:impact>Talk on vision as part of the St. Andrews University Open Association lecture series, aimed at the general public from Fife and the surrounding area. There was an extended question session, where there were many questions, linked in particular to visual deficits and disorders and how our science informs these areas.</gtr:impact><gtr:outcomeId>56c6e4a00728c9.08974938</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Explorathon 2016:  Harris lab exhibit at this European Researchers night event, highlighting research activity on vision.</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>84A23AED-8A0B-4BB0-BACF-147A8E52B6A0</gtr:id><gtr:impact>Part of a European Researchers Night event, showing academic research taking place at the University of St. Andrews</gtr:impact><gtr:outcomeId>58b5c1f8a36360.39512347</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Harris Sutton Trust Lectures</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>7E618BEB-17DC-4012-952A-ABE3EB70D2EC</gtr:id><gtr:impact>The talk was on vision, part of a Summer School for disadvantaged teenagers, organised by the Sutton Trust charity. Participants were surprised that vision and perception are part of the psychology and neuroscience curricula but were interested and engaged in the topics.</gtr:impact><gtr:outcomeId>56c6f01ceb4f74.73756357</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2007,2009,2011,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Harris lab vision exhibit, Fife Science Festival: St. Andrews Open Day</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>DEB1B6D5-247F-4C0E-B49D-D233ECEAEEA0</gtr:id><gtr:impact>Demos and hands-on lab activities from the Harris lab including 3D vision and motion perception, vision and driving, visual camouflage. The activities were popular with all age-groups, from small children, to parents, and older adults.

Several people commented that they didn't know vision was linked to neuroscience and psychology, as well as optometry and physics.</gtr:impact><gtr:outcomeId>545cee0f752321.47394181</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2010,2011,2012,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Harris talk at Cafe Scientifique, Dunkeld and Pitlochry , Scotland</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>73C92A80-18E4-4331-8651-62EBD58E9349</gtr:id><gtr:impact>Harris talk at Cafe Scientifique, Dunkeld and Pitlochry , Scotland. Talk was primarily on basic 3D vision, but included discussion of how camouflage and animal patterning affects predation.</gtr:impact><gtr:outcomeId>58c165dc443904.21526614</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>90000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Eastbio PhD program</gtr:description><gtr:end>2019-09-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:id>87344277-9F8E-4D8F-B63D-95CF4F01FE13</gtr:id><gtr:outcomeId>58c16a507bc8a8.02218067</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The primary goals of the research comprised core human neuroscience research, but the results have scientific impacts beyond the specific outcomes detailed elsewhere. The project itself explores the basic visual pathways that analyse motion, a core feature of the perceptual system for a mobile animal, such as ourselves.

We outlined 4 groups of user and stakeholders in our Pathways to Impact document, technologists, medical professional, general public and project researchers. At this, point, one year into the project we have contributed to impact deliverables for the latter 3 of these.

(a) Engagement with medical professionals. We have engaged with Dr. Alison Bruce, Head Orthoptist at Bradford Teaching Hospitals NHS Foundation Trust/ NIHR Post Doctoral Research Fellow at the Bradford Institute for Health Research (BIHR). We are collaborating with her to deliver part of the project using participants with amblyopia and she will help establish a Yorkshire-based (University of York/ University of Bradford) pool of suitable study participants and at the end of the project she will help us organise a clinical workshop session, under the auspices of the BIHR http://www.bradfordresearch.nhs.uk/ to discuss and disseminate the clinical implications of our work. 

(b) Public engagement. The Harris lab have developed displays for public science festival events, so far taking part in the St. Andrews University Science Open Day, 2015. Harris has given two talks in 2015, to young adults in 6th form, as part of a Sutton Trust Summer School, and for the St. Andrews Open Association lectures. Harris's lab have taken part in European Researcher's Night in 2016 (University of St Andrews) and Harris has talked at Cafe Scientifique (Dunkeld and Pitlochry) in 2016 and has deliver two Quiz a Whiz interviews for the Royal Society of Edinburgh.
 
 (c) RA's Giesel and Maloney are to complete the BBSRC media training course in 2016 and 17. The whole group, including 3 PhD students working in similar areas, meet 4 times a year for project meetings. These give the RA's the opportunity to interact with scientists trained in other areas and to learn to collaborate in an interdisciplinary fashion.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>872D7585-A530-46C1-AC2E-37FF5A68C0B2</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d55aa0a96099.24507106</gtr:outcomeId><gtr:sector>Education,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We are making progress on both of our original aims:

Aim 1
A paper on the chromatic tuning of motion in depth mechanisms is under review.
fMRI data for two experiments is well underway: Expt 1 examines the coding of eye-specific information within the visual cortex and asks, in addition, if regions that are not directly driven by a monocular stimulus nevertheless contain information about it's eye of origin. Expt 1 asks which regions are involved in coding the two types of motion in depth information critical to this grant. Elegant stimuli are used to ensure that both stimulus types are independent and, again, both directly driven and 'surround' regions are interrogated. Chromatic calibration for a third experiment examining the interaction between MID and colour in cortex is complete and these experiments will begin in mid April.


Aim 2
Psychophysical experiments on the nature of the IOVD cue to 3D motion. We have shown so far IOVD information can likely only be totally isolated using de-correlated rather than anti-correlated motion. The well known increase in duration thresholds with stimulus size for lateral motion is not present for motion in depth. Thus there appears to be a fundamental difference between motion in depth and lateral motion information. this work has been presented at the Applied Vision Association and European Conference on Visual Perception.
We are conducting eye movement experiments, in collaboration with Tony Norcia's lab (Stanford University), to explore how different sources of visual information about motion in depth drive vergence eye movements. A first study is near to completion, showing that IOVD information is not a good driver of vergence. The work will be presented at Vision Sciences Society, 2017.</gtr:description><gtr:exploitationPathways>Findings will be taken to national and international conferences over 2016-17 and published in top journals.

See also some details of our engagement activities under &amp;quot;Narrative Impact&amp;quot;</gtr:exploitationPathways><gtr:id>25077EF3-8322-4084-A6D4-5B9CC04EA46C</gtr:id><gtr:outcomeId>56d55b58c5dfe3.38519607</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>83EE25ED-DEA4-40E2-9774-63133BA396E6</gtr:id><gtr:title>Comparing perception of motion-in-depth for anti- and de-correlated random dot stimuli.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6cf179af0a022f13d437265177155285"><gtr:id>6cf179af0a022f13d437265177155285</gtr:id><gtr:otherNames>Giesel, M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56cc8960760189.55958627</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M001660/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>