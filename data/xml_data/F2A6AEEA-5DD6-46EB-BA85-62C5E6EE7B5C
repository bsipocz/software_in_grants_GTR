<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Electrical and Electronic Engineering</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/ED82DD59-59D7-4BB0-98E3-3F0855524F98"><gtr:id>ED82DD59-59D7-4BB0-98E3-3F0855524F98</gtr:id><gtr:firstName>Melvyn</gtr:firstName><gtr:surname>Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/A14DCB1A-2638-4A03-98EF-AEE39C08C14C"><gtr:id>A14DCB1A-2638-4A03-98EF-AEE39C08C14C</gtr:id><gtr:firstName>Bruce</gtr:firstName><gtr:otherNames>Donaldson</gtr:otherNames><gtr:surname>Grieve</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FN02107X%2F1"><gtr:id>F2A6AEEA-5DD6-46EB-BA85-62C5E6EE7B5C</gtr:id><gtr:title>4D-HSI-4-Free: Integrating Sensors &amp;amp; Vision Process Engineering to Deliver a Tool for revealing 3D Hyperspectral Agri-data from 2D Images</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/N02107X/1</gtr:grantReference><gtr:abstractText>Hyperspectral and multispectral imaging for crop phenotyping and stress analysis has seen significant growth in recent years for wide area scanning, notably from satellites and aircraft. This has been principally based on variants of the Normalised Difference Vegetation Index, 'red edge', ratios and / or chlorophyll fluorescence bands. Though more subtle agri-analysis is being introduced within these remote monitoring technologies, notably with the launch of the ESA Sentinel family of satellites, the reliance on sunlit imaging and the physical engineering limits on resolving power of the optics, alongside atmospheric variations in absorbance and refraction, set hard boundaries on the spatial and spectral sensitivity.

In more recent years Close-Proximity Hyperspectral Imaging (CP-HSI) has been progressed by a number of research groups, in order to ground-truth remotely collected images as well as to gain data with greater subtlety and differentiating power than can be obtained from the remote platforms, due to the physical constraints described. Additionally, CP-HSI offers the potential for greater data availability by avoiding the issues of cloud-cover, and other obstructions, as well as the lack of access to images whilst satellites are orbiting. These CP-HSI studies have tended to adopt the same high-cost passive HSI instruments, as used by the geospatial imaging sector, and then take advantage of the variations in plant and soil data arising intra- and inter-crop canopy to identify the new agri-features.

The e-Agri research team at the University of Manchester have worked over recent years on translating the above concepts into lower-cost and miniaturised engineered systems through replacing the passive HSI instrumentation with active systems, based on broadband proprietary silicon imaging detectors coupled with narrowband LED sources. The resulting Active Close-Proximity (ACP) HSI systems are not only several orders of magnitude cheaper and higher spatial resolution, than their remote passive equivalents, they also offer spectral signal-to-noise that can far exceed what is possible from the passive instruments.

Encouraging as this is, there are engineering challenges associated with active CP-HSI, not least the need to compensate for the orientation affects from position of the biological specimen with respect to the sensor system as well prevent corruption of the spectral data by variations in the lighting location and optical power of the LEDs. These are reconcilable through integrating the optical engineering of multiple sources alongside Photometric Stereo (PS) image reconstruction. The PS technique has arisen as an alternate technique to structured-light for delivering surface normals and texture information at unprecedented spatial resolution, while using inherently low-cost equipment. PS involves capturing a number of images (3+) of an object under varying but known lighting, with each image providing a constraint on the orientation at each pixel. Work pioneered by the CMV has allowed the PS technique to move beyond a laboratory setting towards real-word applications, by relaxing prior assumptions, such as Lambertian surface reflection, collimated illumination and by extending the technique to moving applications.

The team will deliver a new class of 4-Dimensional imaging within an accessible tool which will only marginally increases the component cost versus the 2D hyperspectral precursor. The project is achievable as it will be accelerated via the e-Agri UoM team partnering with the Centre for Machine Vision, at the Bristol Robotics Laboratory, to translate their PS algorithms so that they may be integrated within the ACP-HSI sensors research. The merger of these capabilities will prove the viability of a miniaturised 4D imaging system and deliver a proof-of-principal prototype system for characterisation against plant, animal and aquatic samples.</gtr:abstractText><gtr:technicalSummary>Hyperspectral and multispectral imaging for crop phenotyping and stress analysis has seen significant growth in recent years for wide area scanning, notably from satellites and aircraft. This has been principally based on variants of the Normalised Difference Vegetation Index, 'red edge', ratios and / or chlorophyll fluorescence bands. Though more subtle agri-analysis is being introduced within these remote monitoring technologies, notably with the launch of the ESA Sentinel family of satellites, the reliance on sunlit imaging and the physical engineering limits on resolving power of the optics, alongside atmospheric variations in absorbance and refraction, set hard boundaries on the spatial and spectral sensitivity.

In more recent years Close-Proximity Hyperspectral Imaging (CP-HSI) has been progressed by a number of research groups, in order to ground-truth remotely collected images as well as to gain data with greater subtlety and differentiating power than can be obtained from the remote platforms, due to the physical constraints described. Additionally, CP-HSI offers the potential for greater data availability by avoiding the issues of cloud-cover, and other obstructions, as well as the lack of access to images whilst satellites are orbiting.

The team will deliver a new class of 4-Dimensional imaging within an accessible tool which will only marginally increases the component cost versus the 2D hyperspectral precursor. The project is achievable as it will be accelerated via the e-Agri UoM team partnering with the Centre for Machine Vision, at the Bristol Robotics Laboratory, to translate their PS algorithms so that they may be integrated within the ACP-HSI sensors research. The merger of these capabilities will prove the viability of a miniaturised 4D imaging system and deliver a proof-of-principal prototype system for characterisation against plant, animal and aquatic samples.</gtr:technicalSummary><gtr:potentialImpactText>The potential duties, that are actively being pursued by the Manchester team currently fall into four areas. The first is the early detection of fungal disease symptoms on leaf. The initial work in this area was in partnership with the plant scientist at the University of Bonn, and demonstrated that the ACP-HSI approach could be delivered in a package costing euro 100s as opposed to euro 100,000s. This then led on to a small proof of concept project, to show how such a package could exploited alongside a Smartphone handset to enable in-field plant diagnostics and autonomous advice services to be made available in an appropriately costed package for mass deployment to even the poorest smallholder farmers, to enhance their yields through more informed decision making. Incorporating the PS technique in this 'handset package' would add marginal cost but would enable plant scientists access to texture information as well as quantifiable HSI images from what could be 10,000s and then 1Ms of new data-points arising from farmers around the globe, in even the remotest areas. The potential to use 'Big Data' mining approaches on this more rich dataset, by virtue of the PS technique, are significant and have obvious implications on yield forecasting and crop stress mapping that impact on governmental decision making all the way through to mitigating insurance risks.

The second area of activity is in precision intra-row weed detection and eradication. This is due to both the growing resistance, by weeds, to such treatments or the lack of suitable products in the first place (e.g. ryegrass in cereals globally and Amaranthus spp and Conyza spp. in US maize), as well as the removal of older chemistries in a number of regions, notably the EU (ref. directive EU91-414), due to health concerns. The PS approach will become a key element of this autonomous weed identification technique for precision farming as the orientation information it offers will open up the most subtle of classification challenges, such as Blackgrass in post-emergence cereal crops, as the leaf-angle to the sensor will be effectively random.

The third area of ongoing research, that this PS approach will impact, is protein prediction in pre-harvest crops, notably winter wheat. Unlike previous work on late-stage growth or protein measurement in post-harvest grain, the ACP-HSI approach exploit the image data and not the composite NIR spectra. This potentially enables protein development to be tracked at much earlier stages in the growth cycle with corresponding smaller and more precise control of nutrient additions to gain acceptable post-harvest protein content, with the corresponding reduction in farm input costs and carbon-footprint. The PS technique offers the potential to take this tool from a manual technique, where wheat-ear samples are clamped and scanned by a handheld device whilst field-walking, to one that would be applicable to robotic autonomous scanning as it would reduce the impact of ear topology on the HSI data.

The fourth area is in partnership with the Natural Resources Institute (University of Greenwich) the ACP-HSI approach is being investigated to detect insect disease vectors, notably white fly for mosaic virus in cassava. Without PS the technique may be able to detect and, most importantly, speciate the adults (1-2mm) and possibly the nymphs (0.1-1mm), between potential disease carriers and benign insects. However, PS integrated to ACP-HSI offers the potential to reveal the eggs which are hidden within a leaf structure and so determine the full viral infection probability within a crop, and so prevent contamination of the future seasons seed-bank.

Additional applications for the PS technique are also potentially viable within: fish parasite detection, post-harvest produce quality traits in pack-houses (e.g. texture analysis of bagged salads) or soil organic carbon monitoring, amongst other duties.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2016-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>149646</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Linked to supporting the weed control project with Syngenta PLC</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>65FE6162-16A6-41C1-AF5A-3DE3E8A529AF</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58af151803f6d5.47392449</gtr:outcomeId><gtr:sector>Agriculture, Food and Drink</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>New method for detecting meristems in plants</gtr:description><gtr:exploitationPathways>For use in the non-chemical management of weed infestation by the farming sector</gtr:exploitationPathways><gtr:id>5D8D90E8-D5A0-4F7F-862C-CED25FA1E93E</gtr:id><gtr:outcomeId>58af14b4c24133.61042993</gtr:outcomeId><gtr:sectors><gtr:sector>Agriculture, Food and Drink</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>4BC8B92B-7ED9-4146-B25D-88884654A3EB</gtr:id><gtr:title>Photometric stereo for three-dimensional leaf venation extraction</gtr:title><gtr:parentPublicationTitle>Computers in Industry</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33b3a33f2507beb150e78e1e5a17353e"><gtr:id>33b3a33f2507beb150e78e1e5a17353e</gtr:id><gtr:otherNames>Zhang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa7b6177e40c3.40055990</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E5E2E900-2A2F-476F-B7CE-14A5638C6B54</gtr:id><gtr:title>BRDF of human skin in the visible spectrum</gtr:title><gtr:parentPublicationTitle>Sensor Review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f5cb9a29dbca049607c2d02d8fab7729"><gtr:id>f5cb9a29dbca049607c2d02d8fab7729</gtr:id><gtr:otherNames>Sohaib A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa7bf1cb63721.18105915</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/N02107X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5B25B6A3-B218-4F11-8A9D-661236DF455C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Agri-environmental science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>C5107770-461D-42E3-B991-48AE97DF206F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Crop science</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>