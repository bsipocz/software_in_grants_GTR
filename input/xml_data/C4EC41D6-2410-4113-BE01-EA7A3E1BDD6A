<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:department>Dept of Bioengineering</gtr:department><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/D0910B51-8D07-4A7B-A5D1-CB191B9690F8"><gtr:id>D0910B51-8D07-4A7B-A5D1-CB191B9690F8</gtr:id><gtr:firstName>Andriy</gtr:firstName><gtr:surname>Kozlov</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FN008731%2F1"><gtr:id>C4EC41D6-2410-4113-BE01-EA7A3E1BDD6A</gtr:id><gtr:title>How do auditory cortical neurons represent ethologically relevant natural stimuli? Characterizing stimulus feature selectivity and invariance</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/N008731/1</gtr:grantReference><gtr:abstractText>How sensory systems represent natural signals is a long-standing classical problem in neuroscience. Using stimuli that are relevant to the animal produced the clearest descriptions of how sensory neurons work in &amp;quot;specialized animals&amp;quot;, such as bats, the electric fish, and the barn owl. In each of these examples, the stimuli were both natural and simple, which was key to understanding their representations. Most of the sensory cortex in other animals and humans, however, deals with real-life stimuli that are statistically complex. Our progress in understanding how cortical circuits represent complex stimuli, such as speech and music, has been limited because standard statistical methods do not work well with complex stimuli. But today the situation has changed. Cutting-edge methods of receptive-field analysis that work well with any kind of natural stimuli and can discover complete representations have been recently developed, and I have tested them successfully in the auditory system of songbirds. We can at last investigate encoding in cortical neurons with stimuli that matter to animals, which will be decisive for understanding how the brain represents complex natural sounds.

In this project, I propose to investigate at the single-neuron resolution the principles that govern these representations by neural circuits in auditory cortex. We will use mice, because unlike songbirds, they have auditory cortex. Like songbirds, mice sing to each other melodic songs (at frequencies that are too high for humans to hear). These ultrasonic vocalizations (USVs) form a part of flexible social communication in mice, and neurons in the mouse auditory cortex respond to them.

We will address the following questions. 1) Does an individual neuron respond to several (many) different features of natural stimuli, or only to a single one? In other words, what is a neuron's receptive field? Computational models indicate that neuronal ensembles composed of diverse, mosaic receptive fields, are superior for encoding complex stimuli compared to populations in which each neuron responds only to a single stimulus feature. 2) What are the rules that govern how features are combined within a receptive field to achieve robust representations resistant to noise?

To answer these questions, we will record responses of excitatory and inhibitory neurons to behaviourally relevant USVs in different layers of the auditory cortex sensitive to vocalizations. For comparison, we will also record responses to unfamiliar, behaviourally irrelevant birdsongs. We will then use the new statistical methods to compute the neurons' receptive fields.

Next, we will take advantage of the latest advances in the field of machine learning and train state-of-the-art unsupervised neural networks to discover statistically optimal representations of these complex sounds. We will then compare these representations to those found in vivo. I expect that the artificial and natural representations of USVs (but not birdsongs) will involve the same or similar features, indicating that the brain represents vocalizations in a statistically optimal way.

Finally, having identified features that drive individual cortical neurons, we will characterize whether they are combined within a receptive field in a way that helps to achieve representations that are resistant to acoustical noise-a fundamental property of animal and human hearing.

The proposed work will advance our understanding of how the brain encodes natural sounds. The availability of the new statistical methods means that we can solve this long-standing problem now. Because USV communication is impaired in murine models of brain disorders accompanied by perturbed central auditory processing, such as autism spectrum disorders, understanding neuronal and computational mechanisms of central auditory processing in the mouse will help us understand both normal hearing and auditory and communication deficits in humans.</gtr:abstractText><gtr:technicalSummary>A central question in sensory neuroscience is how neurons represent multidimensional natural stimuli. This process involves extracting features, and then more abstract features of features, to obtain a condensed categorical representation useful for classification and behaviour.

To understand better the principles underlying this process in the central auditory system, we will record neuronal responses (spikes) from auditory cortical neurons in awake mice, and characterise their receptive fields with natural stimuli. We will use mouse ultrasonic vocalisations and pitch-shifted birdsongs (as a natural but ethologically irrelevant control stimulus), and employ statistical methods that work well with complex natural stimuli and can identify any number of receptive-field features.

We will then take advantage of the recent developments in the field of unsupervised neural networks-implicitly or explicitly based on cortical hierarchies-which can learn statistically optimal feature representations. We will train deep belief nets and other classes of unsupervised neural networks on vocalisations to discover statistically optimal representations of these stimuli. We will then compare the biological and artificial representations using appropriate statistical measures. These experiments will characterize auditory cortical neurons' selectivity.

To characterize invariance in representation of natural communication sounds, we will test whether the MAX (or softmax) feature recombination function makes neuronal responses in auditory cortex resistant (invariant) to added noise. This class of OR-like operations has been used to achieve invariance in models of visual object recognition, but these model predictions have not been verified experimentally in any biological sensory system.

By characterizing response selectivity and invariance in auditory cortical circuits, this interdisciplinary project will advance our knowledge of sound processing by the brain.</gtr:technicalSummary><gtr:potentialImpactText>Who will benefit from this research, when and how?

Researchers working in the field of auditory neuroscience will certainly benefit from the results of this research, even before they are published in peer-reviewed journals. This close circle of colleagues will benefit through informal and formal interactions (lab visits, seminars, collaborations). Researchers working in several related fields, such as natural and computer vision and pattern recognition, cognitive sciences, other areas of sensory neuroscience and biophysics, both in academia and in industry, will also benefit from the results of the proposed research. I am the Imperial College's &amp;quot;local group representative&amp;quot; for the British Neuroscience Association and I plan to organize at least one meeting during the course of the project to bring researchers (both from the UK and from other countries) who work in these loosely related fields to exchange ideas and foster collaborations. This will benefit the UK science.

Students and postdocs taking part in this interdisciplinary research will benefit directly because of the opportunities they will have to broaden and deepen their knowledge and skills. They will be able to apply these skills later in their life, whether they remain in academia or work in the private sector. Some of my former colleagues are applying such skills at Google now.

Anyone who is curious about how we can talk to a fiend over the phone in a noisy pub on a Friday night (and hear the friend respond), or how penguins can find their chicks by listening to their squeaks in the deafening cacophony of the colony, or about how hearing works in general, can benefit from this research when its results are published in an open-access journal or in a magazine.

Children may benefit from this research. I have just initiated a pilot program with a school in Wimbledon to give lectures on topics related to bioengineering, including on how the brain and computers represent the world. If the effort proves successful, I will expand it (together with the Department's Outreach and Public Engagement Manager) to other schools in London.

All the named groups of people are likely to benefit from this research in the short term (within the course of the project).

Other benefits may occur in a longer term. In particular, inasmuch as the proposed research seeks to understand the computational &amp;quot;building blocks&amp;quot; that auditory cortex uses to represent natural sounds, it will form a foundation for the future research into the computational pathophysiology of canonical cortical circuits (auditory and other) which will in turn be relevant to clinicians focused on auditory processing disorders.

Industry may also benefit from the outcomes of the proposed research. For instance, developing neural networks that can learn and classify features of animal (and human) vocalizations has attracted a lot of interest recently. There is potentially a big market for this kind of applications.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2016-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>338064</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>78F45113-E0B4-4994-9FDD-718BBEA4879A</gtr:id><gtr:title>Comparative Aspects of Hearing in Vertebrates and Insects with Antennal Ears.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/abec4480c7087e349f7c845bf620f678"><gtr:id>abec4480c7087e349f7c845bf620f678</gtr:id><gtr:otherNames>Albert JT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>588b5872336710.19005572</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/N008731/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>4A2A69ED-37ED-4980-91A7-E54B4F6A9BC6</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal organisms</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>