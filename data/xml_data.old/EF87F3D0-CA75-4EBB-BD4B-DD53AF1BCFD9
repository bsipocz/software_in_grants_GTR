<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/264D3335-602A-42E2-8BFD-CC8B5B564070"><gtr:id>264D3335-602A-42E2-8BFD-CC8B5B564070</gtr:id><gtr:firstName>Gavin</gtr:firstName><gtr:surname>Brown</gtr:surname><gtr:orcidId>0000-0003-2261-9018</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FF023855%2F1"><gtr:id>EF87F3D0-CA75-4EBB-BD4B-DD53AF1BCFD9</gtr:id><gtr:title>ADEPT: Adaptive Dynamic Ensemble Prediction Techniques</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F023855/1</gtr:grantReference><gtr:abstractText>Predicting unknown quantities is a fundamental part of science andengineering. For example, in medicine one might wish to predict whether aperson has a cancerous tumour or not based on a scan; or in manufacturing, whether an industrial machine is producing faulty devices or not. The field of Artificial Intelligence has studied many techniques to produce good predictors. The last decade of research has seen the development of population-based techniques. Instead of using a single predictor, these build teams of predictors and combine the decisionsof the individuals through a voting or averaging process. Both theory andexperiments show this reliably improves upon using a single predictor --as they say two heads are better than one. A nice feature is that thesemethods are predictor-independent, meaning they can combine any kind ofpredictors (e.g. neural networks, decisions trees) into a team.This project aims to unify two sub-fields of Artificial Intelligence thatdeal with these population-based predictor-independent techniques:Ensemble Methods and Learning Classifier Systems.Ensemble Methods have produced some of the most powerful predictors ofthe last decade; the most well-known is called AdaBoost , and has beendubbed the best off-the-shelf predictor in the world (Professor LeoBreiman, University of California at Berkeley). These methods have beenwidely applied in many areas; however, one important area not yetinvestigated is multi-step problems. These are problems where decisionsin thepast and present can affect what the best decisions in the future willbe---for example choosing to play a certain opening strategy in chessmeans certain moves are less favourable later on in the game. Our mostdifficult multi-step problem will be optimising elevator scheduling tominimise the amount of time between pressing an elevator call button andthe arrival of the elevator. It is surprisingly difficult to optimise themovement of elevators in a large building. For one thing, a building with5 elevators and 30 floors has more possible configurations than thereare grains of sand on all the beaches in the world. Most ensemble methodscannot be directly applied to this kind of problem.Learning Classifier Systems are a class of nature-inspired algorithms, thatcan dynamically generate and adjust sets of predictors, and are capableof tackling these multi-step problems. Traditional ensemble methodshave not considered the multi-step domain, but have strong theoreticalfoundations to build upon. Learning Classifier Systems do not have sucha strong theory base, but have been intensely studied on multi-step problems.This project will create hybrid methods using theory and practice fromthese two quite disparate fields. We will advance the state-of-the-artin both fields and increase research capacity for tackling several problemclasses, focusing in particular on multi-step problems.</gtr:abstractText><gtr:fund><gtr:end>2012-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>347176</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The main results have been implemented in a publicly available data mining framework called SPARK, and are being used by Oracle Research Labs, USA in a product.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>FEB94D09-710F-46A1-BF23-55F0ED1A2B56</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>546249a57d1e18.19905660</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>ADEPT (Adaptive Dynamic Ensemble Prediction Techniques) aimed to capitalize on the synergy between three seemingly diverse fields: evolutionary computation, ensemble learning, and probabilistic modelling. We developed a number of results which could never have been possible without all three influences. The result was a number of entirely new formalised models of learning, enabling new directions for the research community.

In more technical terms, the project's primary goal was to take a heuristic technique from the Evolutionary Computation literature - Learning Classifier Systems - and translate it into an ensemble-based probabilistic model. The probabilistic model we developed can precisely reproduce the capabilities of the LCS - an online supervised learning system, continuously adaptive, maintaining a parsimonious set of human-interpretable rules. However, the new model stands apart from the parameter-laden heuristic nature of LCS, having the advantages of a statistical underpinning: flexibility and a solid probabilistic foundation.</gtr:description><gtr:exploitationPathways>The primary impact was on the research community - the results have been taken forward in other projects housed at Manchester and Bristol.</gtr:exploitationPathways><gtr:id>0434358F-E954-411F-9012-C7107FB16A8E</gtr:id><gtr:outcomeId>546248f7466015.04791471</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors><gtr:url>http://www.cs.man.ac.uk/~gbrown/adept/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>FEAST provides efficient implementations of &amp;quot;feature selection&amp;quot; algorithms, as developed during the project. These algorithms are widely seen as the first step in any &amp;quot;big data&amp;quot; analysis, hence are very widely used.</gtr:description><gtr:id>B8F06014-CFD4-4E17-9D51-7374BC65D489</gtr:id><gtr:impact>Oracle Research Labs have adopted many of the techniques internally for their big data applications.</gtr:impact><gtr:outcomeId>54635348740b05.00900240</gtr:outcomeId><gtr:title>FEAST</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://mloss.org/software/view/386/</gtr:url><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>46711778-D43B-4621-AB9E-3C3FE8DB9AF4</gtr:id><gtr:title>A New Perspective for Information Theoretic Feature Selection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/26abd53b6933c80866a7eb492ea6efa6"><gtr:id>26abd53b6933c80866a7eb492ea6efa6</gtr:id><gtr:otherNames>Brown G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>54623b582199e5.67891021</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E3587D49-3233-4A00-93C6-19E8FBC0C4A3</gtr:id><gtr:title>Boosting as a Product of Experts</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d342c5f12e3242d80cf80cafb531e155"><gtr:id>d342c5f12e3242d80cf80cafb531e155</gtr:id><gtr:otherNames>Edakunni N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>m_898455660213f3f436</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B6B71F5B-85E3-4CEB-B004-EE417501A432</gtr:id><gtr:title>Cost-sensitive boosting algorithms: Do we really need them?</gtr:title><gtr:parentPublicationTitle>Machine Learning</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c4489957db55612c58cbcd10da04871"><gtr:id>2c4489957db55612c58cbcd10da04871</gtr:id><gtr:otherNames>Nikolaou N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58beb9b96c5598.83517438</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>122092E6-83D1-46FC-BE09-F635B3365A60</gtr:id><gtr:title>Modelling UCS as a Mixture of Experts</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d342c5f12e3242d80cf80cafb531e155"><gtr:id>d342c5f12e3242d80cf80cafb531e155</gtr:id><gtr:otherNames>Edakunni N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_930980875913f3f558</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6C00C9BB-04FC-47D2-B29B-3181FEB948D3</gtr:id><gtr:title>Individual Confidence-Weighting and Group Decision-Making.</gtr:title><gtr:parentPublicationTitle>Trends in ecology &amp; evolution</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a51bb954f975f451ecf6678909155f46"><gtr:id>a51bb954f975f451ecf6678909155f46</gtr:id><gtr:otherNames>Marshall JAR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0169-5347</gtr:issn><gtr:outcomeId>5a351c67d24572.62743165</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9C0D1814-481E-4238-9377-476178BDFD28</gtr:id><gtr:title>Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/26abd53b6933c80866a7eb492ea6efa6"><gtr:id>26abd53b6933c80866a7eb492ea6efa6</gtr:id><gtr:otherNames>Brown G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_676673450313842d9a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9C9BF947-BD84-4BA3-95FE-97C94B588E72</gtr:id><gtr:title>Theoretical and empirical analysis of diversity in non-stationary learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d899519c767871b31135afb6e5ad56b5"><gtr:id>d899519c767871b31135afb6e5ad56b5</gtr:id><gtr:otherNames>Stapenhurst R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4244-9930-4</gtr:isbn><gtr:outcomeId>54623c1d652ab3.80646601</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F613F905-1949-4958-933C-4364FDDFDA94</gtr:id><gtr:title>Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications</gtr:title><gtr:parentPublicationTitle>JOURNAL OF MACHINE LEARNING RESEARCH</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8b1b690ed2ea9b82d693b43e323acc56"><gtr:id>8b1b690ed2ea9b82d693b43e323acc56</gtr:id><gtr:otherNames>Zhao Ming-Jie</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1532-4435</gtr:issn><gtr:outcomeId>5a351b8bc3d2a2.41843528</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F023855/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>