<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/16C42590-30C0-4CCE-894F-C4189A4DE800"><gtr:id>16C42590-30C0-4CCE-894F-C4189A4DE800</gtr:id><gtr:name>University of Bordeaux I</gtr:name><gtr:address><gtr:line1>351 Cours de la Liberation</gtr:line1><gtr:postCode>F-33405</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D691EFF1-B8D2-4403-AFCD-44A25175D830"><gtr:id>D691EFF1-B8D2-4403-AFCD-44A25175D830</gtr:id><gtr:name>NOTAM - Norsk senter for teknologi i musikk og kunst</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/7801F008-7C77-45E7-90E9-4345B47D138E"><gtr:id>7801F008-7C77-45E7-90E9-4345B47D138E</gtr:id><gtr:name>University of Plymouth</gtr:name><gtr:department>Sch of Humanities &amp; Performing Arts</gtr:department><gtr:address><gtr:line1>Drake Circus</gtr:line1><gtr:line4>Plymouth</gtr:line4><gtr:line5>Devon</gtr:line5><gtr:postCode>PL4 8AA</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7801F008-7C77-45E7-90E9-4345B47D138E"><gtr:id>7801F008-7C77-45E7-90E9-4345B47D138E</gtr:id><gtr:name>University of Plymouth</gtr:name><gtr:address><gtr:line1>Drake Circus</gtr:line1><gtr:line4>Plymouth</gtr:line4><gtr:line5>Devon</gtr:line5><gtr:postCode>PL4 8AA</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/16C42590-30C0-4CCE-894F-C4189A4DE800"><gtr:id>16C42590-30C0-4CCE-894F-C4189A4DE800</gtr:id><gtr:name>University of Bordeaux I</gtr:name><gtr:address><gtr:line1>351 Cours de la Liberation</gtr:line1><gtr:postCode>F-33405</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D691EFF1-B8D2-4403-AFCD-44A25175D830"><gtr:id>D691EFF1-B8D2-4403-AFCD-44A25175D830</gtr:id><gtr:name>NOTAM - Norsk senter for teknologi i musikk og kunst</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/FEB08E8B-17C7-4368-B709-5F74C7D9DBF5"><gtr:id>FEB08E8B-17C7-4368-B709-5F74C7D9DBF5</gtr:id><gtr:firstName>Eduardo</gtr:firstName><gtr:surname>Miranda</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ002135%2F1"><gtr:id>C47A2E1E-FFC7-403E-84BA-2EC4E2D19769</gtr:id><gtr:title>Brain-Computer Interface for Monitoring and Inducing Affective States</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J002135/1</gtr:grantReference><gtr:abstractText>Brain Computer Interfaces (BCI) allow for modification of subject's environment or control of external devices by the power of thought alone. They achieve this by analysis of small electrical potentials generated by the subject's brain while its owner is thinking. Emotions involve specific mental states hence also involve particular patterns of brains electrical activity. The proposed research will build innovative intelligent BCI systems that can monitor our emotions, and modify them automatically and adaptively via controlled computer music generation system. Creation of such systems would advance our understanding of fundamental relationships between the subjective emotions, corresponding brain states and characteristics of music that can induce very vivid and powerful emotions in humans. Such systems can be used for treatment of emotional/mood disorders such as depression so are of direct benefit to society and NHS. In addition, they are of interest for healthy subjects as means of relaxation or perhaps by enhancement of gaming experience. Thus the proposed project could also lead to interesting developments in the entertainment industries such as the gaming industry.</gtr:abstractText><gtr:fund><gtr:end>2017-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>367101</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>The BCMI Concert was held on the opening night of the 11th international Symposium on Computer Music Multidisciplinary Research: Music, Mind &amp;amp; Embodiment, following the satellite workshops on Brain-Computer Interfacing. The concert featured works and performances by project PI, Prof Eduardo Miranda, as well as american pioneer Prof David Rosenboom, from CalArts.</gtr:description><gtr:id>E96FC435-150D-45F5-B3E3-762F35A4C8D9</gtr:id><gtr:impact>The concert was public at a theatre conveniently located in the city centre. The event reached an audience beyond the delegates of the conference and was reported in the local media (The Herald newspaper); this contributed to inform and raise the local population's awareness of the project and its significance. A German journalist, from magazine Zeit Wissen came specially to this workshop and concert to write an article, which was published in the Aug/Sep 2015 issue.</gtr:impact><gtr:outcomeId>56b9d111d6c554.47377137</gtr:outcomeId><gtr:title>BCMI Concert</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://cmr.soc.plymouth.ac.uk/cmmr2015/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Activating Memory is a composition for 8 participants: a string quartet and BCMI quartet. BCMI stands for Brain Computer Music Interface.
The BCMI quartet involves four persons wearing a brain cap furnished with electrodes to read information from the brain of 4 persons. I teamed up with g.tec, a manufacturer of biomedical technology, and Joel Eaton at ICCMR, to design an extraordinary machine that converts brain information into musical scores.

During the performance, the BCMI quartet generates musical scores to be performed by the string quartet in real-time: each member of the BCMI quartet generates an individual part for a musician of the string quartet.

The first public experimental performance of Activating Memory took place on 09 February 2014 at Peninsula Arts Contemporary Music Festival, Plymouth, UK, by the Bergersen String Quartet.</gtr:description><gtr:id>24EC392F-2A09-429D-BECC-7ACAA3F8D41F</gtr:id><gtr:impact>This was featured in BBC Click, BBC News World service and subsequently the story re-appeared in news worldwide, in various European countries, Africa and South America. This composition raised awareness and public understanding of the research we are developing and demonstrated how the technology might be used in real-world applications.</gtr:impact><gtr:outcomeId>5450bc418e7242.00489499</gtr:outcomeId><gtr:title>Activating Memory</gtr:title><gtr:type>Composition/Score</gtr:type><gtr:url>https://vimeo.com/88151780</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Performance in USA of the composition Activating Memory, a string quartet controlled by 4 persons wearing our new brain-computer music interface. The performance, which was accompanied by a lecture delivered by the PI, Prof Eduardo Miranda, took place at Scripps Research Institute in San Diego, during the prestigious Mainly Mozart Festival.</gtr:description><gtr:id>74681B6D-8996-4F14-8B37-CB0BEB0018D6</gtr:id><gtr:impact>The work was widely reported in California, notably on a very popular news programme in FOX 5 TV and in the newspaper San Diego Union-Tribune.</gtr:impact><gtr:outcomeId>56b9c9fdcd8458.28800037</gtr:outcomeId><gtr:title>Learn about your brain with music</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://fox5sandiego.com/2015/09/22/learn-about-your-brain-with-music/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>This is a performance that took place at the Royal Hospital for Neuro-disability in Putney, London, where we tried for the first time our Brain-Computer Music Interfacing technology with a group of severely motor-impaired patients to make music.</gtr:description><gtr:id>A149CE0C-DAD2-4A3E-9A34-2503DDBA1A1F</gtr:id><gtr:impact>This is the first time even that a group of severely-motor impaired patients were able to make music together, collaboratively, using brain-computer interfacing technology. This event made the news headlines worldwide (a selection of which is reported under Engagement Activities).

The work we developed with the patients made a tremendous impact on the patient's well-being, including a lady who was a professional violinist before she suffered an accident that left her paralized. She was able to make music again after 27 years (as reported in The Sunday Telegraph on 09 Feb 2016): &amp;quot;Brain-damaged violinist makes music for first time in 27 years with mind-reading technology&amp;quot;.</gtr:impact><gtr:outcomeId>56b9cc7a3f57b5.46766950</gtr:outcomeId><gtr:title>Paramusical Ensemble</gtr:title><gtr:type>Artistic/Creative Exhibition</gtr:type><gtr:url>http://www.rhn.org.uk/news-and-media/press-releases/paraensemble.htm</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Performance by PhD student associated to the project (match-funded by the University) Joel Eaton with brain-computer interface controlled sound synthesisers at FACT, in Liverpool, in an event called Syndrome, exploring new technologies for control of music.</gtr:description><gtr:id>D0D15DC1-15CA-4C5A-9B30-3D24201F8935</gtr:id><gtr:impact>This performance contributed to raise the awareness of artists, practitioners of digital arts and audience of the research are are developing. A accompanying talk explained the system/technology to the public.</gtr:impact><gtr:outcomeId>5450bfb5007043.18802901</gtr:outcomeId><gtr:title>Flex</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://joeleaton.co.uk/project/flex/</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>This film is a documentary about the work we developed with patients at the Royal Hospital for Neuro-disability, Putney, London, which lead to a public performance. The focus of the film is on taking research out of the lab and bringing it into the real-world of the beneficiaries.</gtr:description><gtr:id>6CB9EC6F-6469-4CFE-8E1D-E385813678C8</gtr:id><gtr:impact>The documentary was made for the Internet/social media and is aimed at raising the awareness of the research and clarify and demystify what the technology can and cannot do, nowadays and in the future. The film shows how the outcomes of the research has the potential to transform lives and improve the well-being of severely motor-impaired patients (e.g., sufferers of Locked-in syndrome).</gtr:impact><gtr:outcomeId>56b9d3754728d3.67370992</gtr:outcomeId><gtr:title>Paramusical Ensemble Documentary</gtr:title><gtr:type>Film/Video/Animation</gtr:type><gtr:url>https://vimeo.com/143363985</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>The composition Activating Memory, for 4 brain-computer music interfaces and a string quartet was featured prominently at Music Tech Fest, as St Luke's, London, in Sep. 2014.</gtr:description><gtr:id>1404B2D5-7579-4673-8AD0-4456DC489834</gtr:id><gtr:impact>This innovative composition was presented at this fairly large international Music Technology event for the industry and practitioners. BBC Click's LJ Rich tried the system and reported her experience on the TV show. It is estimated that over 2 million people viewed the story live on TV and website. This development contributed to raising the public awareness of the potential of brain-computer interfacing technology for musical applications and serves to clarify misconceptions about what is possible and what is not possible with this technology.</gtr:impact><gtr:outcomeId>5450be17cde8f8.97943553</gtr:outcomeId><gtr:title>Music Tech Fest</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://www.bbc.co.uk/news/technology-29333741</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Bordeaux</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>University of Bordeaux (France)</gtr:description><gtr:id>2B4F84AE-5070-4B47-9A61-5E7A60978127</gtr:id><gtr:impact>This collaboration is multi-disciplinary, combining Artificial Intelligence, Music Technology and Biomedical Engineering. Considerable time was needed to gain a deeper understanding of the respective research projects and technologies developed by the partners. One of the concrete outcomes is the integration of Plymouth and Bordeaux systems, in the sense that both systems talk to each other. A proof-of-concert system is in implementation process and a join paper is in sight.</gtr:impact><gtr:outcomeId>58c674a08fe782.40759868-1</gtr:outcomeId><gtr:partnerContribution>University of Bordeaux's LaBRI (Laboratoire Bordelais de Recherche en Informatique) has developed a formalism for managing computational tasks where time control is critical, such as music. They've implemented a system called 'i-score', which embodies this formalism in the domain of music. It allows for the specification of temporal relations between interactive triggering and releasing of abstract events or processes occurring during a musical performance. Temporal durations are specified between parts or notes of a written piece. Then, the system develops a statistical analysis of the piece in order to produce an execution of the piece according to temporal relations. Bordeaux contributed (and is contributing) ways in which i-score might be able to process EEG signals and signature of emotions in time for BCI control. Since their system was originally designed for music, i-score's technology is an ideal candidate for our ambitious aim of controlling music with EEG signatures of emotions with efficient timing/sequencing management of both EEG signals, signatures of emotion (affective signatures) and musical sequences.</gtr:partnerContribution><gtr:piContribution>Plymouth contributed methods for designing BCI systems for musical applications, focusing on the SSVEP technique. Prof Miranda demonstrated how Plymouth's SSVEP system works and presented the methods that we have been developing within the BMCI MIdAS project to harness signatures of emotion in the EEG signal. At present we are looking into ways to integrate Bordeaux's time-management formalism and system (see below for musical sequences into a BCI system.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>NOTAM - Norsk senter for teknologi i musikk og kunst</gtr:collaboratingOrganisation><gtr:country>Norway, Kingdom of</gtr:country><gtr:description>NOTAM - Oslo Collaboration</gtr:description><gtr:id>1D452069-CB08-4FDE-AD9E-7DDEA639DE5C</gtr:id><gtr:impact>1) A piece of music 
2) A jointly authored book chapter:
Miranda, E. R. and Vinjar, A. (2016). &amp;quot;Recomposing Beethoven with Music Neurotechnology&amp;quot;. In J. Bresson et al. (Eds.) OM Composer's Book 3. Paris: Ircam.</gtr:impact><gtr:outcomeId>56bf59bbc01961.43758015-1</gtr:outcomeId><gtr:partnerContribution>Contributed design and programming of a generative computer music system, which combines brain signals with analysis of musical information. Contributed a visual video artist to realise an artistic visual interpretation of brain scans and facilitated the composition of a piece of music, which we have been using to promote public understanding of your project.</gtr:partnerContribution><gtr:piContribution>Shared results of research into using EEG as control signal for musical applications. Share know-how on how to built practical systems for using EEG and other brain signals in musical performance and composition.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>CogTalk: Art, music, memory &amp; emotion</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>0D010355-28B6-4170-85C7-CCEC1FAE6726</gtr:id><gtr:impact>CogTalk special event held to coincide with the exhibition &amp;quot;Peter Randall-Page: New Sculpture and Works on Paper&amp;quot;. Artist Peter Randall-Page was in discussion with Dr Michael Verde and Dr Duncan Williams to discuss how our emotions are both affected by and have a profound effect upon our experiences of art, music and memory.

Peter Randall-Page creates sculptures, drawings and prints, which are inspired and informed by natural phenomena and their subjective impact on emotions. Dr Michael Verde is a lecturer in Psychology at Plymouth University with an interest in, amongst other things, memory and emotion, false memories and illusions, distinctiveness and decision-making. Dr Duncan Williams is a Research Fellow at the Interdisciplinary Centre for Computer Music Research, Plymouth University, and has composed a unique piece of computer generated music, based on Peter-Randall Page's sculptures, which will be performed on the 7th February as part of the Peninsula Arts Contemporary Music Festival 2014
The exhibition (Peter Randall-Page: New Sculpture and Works on Paper) is running from 1st February to 29th March in the Peninsula Arts gallery.</gtr:impact><gtr:outcomeId>58c69e8ac86be1.91668998</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://www.youtube.com/watch?v=KBHn8UJmoPI</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Social media exposure for over 130,000 viewers</gtr:description><gtr:form>Engagement focused website, blog or social media channel</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E19F6FD2-06B2-4717-9EA4-AA2CA1B02605</gtr:id><gtr:impact>Short social media movie story published by Collective Evolution FaceBook which attracted over 130,000 viewers and 100 comments and over 1,500 shares.</gtr:impact><gtr:outcomeId>58c688d66ad279.42073336</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>https://www.facebook.com/CollectiveEvolutionPage/videos/10154712506763908/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Plymouth University to develop computer that composes mood-driven music</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D851F78C-9B92-40A3-A536-9820487147C1</gtr:id><gtr:impact>News story in Wired.

Link to article online:

http://www.wired.co.uk/news/archive/2012-09/23/music-writing-computer

A number of readers made enquiries about the project. It generated considerable activity in the social media (Twitter and Facebook).</gtr:impact><gtr:outcomeId>r-9343122150.1372030cb8f0b6</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.wired.co.uk/news/archive/2012-09/23/music-writing-computer</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk at University of the Basque Country</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C186F6DB-438C-4DE3-BA06-19480AE645CE</gtr:id><gtr:impact>Invited to give a talk in a lecture series entitled &amp;quot;Jornadas Interdisciplinares Espacio de Conexiones&amp;quot; on the topic of developing multi-disciplinary research combining bioengineering and the arts. The talked followed with a discussion with the audience. The organisers informally reported that the talk sparked interest in the matters introduced by the talk.</gtr:impact><gtr:outcomeId>58c685275ecfc5.15613142</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>News in Radio France</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0D6DBC5D-5F87-45B1-80D3-220814075E46</gtr:id><gtr:impact>Article in France Musique news website about the project. Features the Activating Memory composition/demo.

We received enquires from France and invitations to showcase the research in Paris.</gtr:impact><gtr:outcomeId>5450e35ec7a018.96116349</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.francemusique.fr/actu-musicale/composer-de-la-musique-avec-ses-ondes-cerebrales-19790</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Music of the Future - Interview</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>83AF2F64-928F-4C7F-A6C3-DDBDFF401105</gtr:id><gtr:impact>Interview published in online magazine with substantial readership numbers.

Interview on new technologies for the future of music, focusing on the research developed for this project as one of such technologies with potential for shift of paradigm.</gtr:impact><gtr:outcomeId>5450e43c457a38.41383657</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.imperica.com/en/in-conversation-with/music-of-the-future</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Many Worlds on BBC Click</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3B0A53FC-295A-4F44-9B52-A03FCA5DE8BF</gtr:id><gtr:impact>A feature on the film &amp;quot;Many Worlds&amp;quot; which explore potential uses of the technology being developed through this project.

BBC Click A comprehensive guide to all the latest gadgets, websites, games and computer industry news. Subconscious cinema - film endings changed by your mood Link to the feature:

https://www.youtube.com/watch?v=kx-n7dS_4Zo




High volume of traffic in social media. Invitation to present the work abroad (e.g., Israel, USA).</gtr:impact><gtr:outcomeId>r-9994859769.9355890cb90fc4</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.youtube.com/watch?v=N6WpH6IU3DM</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Playing music with your brain</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E3FF13DE-69B8-46A8-9E0A-9790179DAFFA</gtr:id><gtr:impact>News feature on BBC Click, reporting on a demonstration we gave in a public event which took place at LSO St Luke's in London. This news video is estimated to have bee watched by over 5 million people worldwide.</gtr:impact><gtr:outcomeId>56c0be1c84d529.44773517</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/news/technology-29333741</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk at IRCAM - Paris</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C0965601-E4C8-4999-BBBD-54AA0947976C</gtr:id><gtr:impact>Talk entitled Blurring the line between Musical Creativity and Scientific Development with Music Neurotechnology, advocated that Truly interdisciplinary research involving the arts and the sciences should ideally bring benefits to both. This talk will illustrate the influential role of the emerging field of Music Neurotechnology in the development of musical research that is equally relevant to musical creativity and scientific development.

The talk paved the way for future collaboration with IRCAM in the field of music technology.</gtr:impact><gtr:outcomeId>5450d59f5599e4.47571788</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://forumnet.ircam.fr/espresso_event/research-and-creativity-seminar/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research visit (University of Music and Performing Arts Vienna)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0EAE2467-010F-476F-9C9E-F952A22C3689</gtr:id><gtr:impact>Visit at invitation of University of Music and Performing Arts Vienna's music department to give a research talk and discuss future collaborations. An application for joint research funding was discussed.</gtr:impact><gtr:outcomeId>58c67ef4178412.68065233</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Is this the code to joy?</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6D58CDE1-D4AC-41B7-AFEA-5CFA679F96DA</gtr:id><gtr:impact>News story in The Independent on Sunday, 19 May 2013.

Link to article:

http://www.thesundaytimes.co.uk/sto/culture/music/pop_and_rock/article1259505.ece

Received a great number of enquires about the project and invitations to give talks at 3 universities in Edinburgh, York and London.</gtr:impact><gtr:outcomeId>r-7724194152.0238250cb8ef4e</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.thesundaytimes.co.uk/sto/culture/music/pop_and_rock/article1259505.ece</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Learn about your brain with music</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E178E3E9-886A-4892-8816-A12318D5A1DC</gtr:id><gtr:impact>Interview on premium time broadcast morning news on Fox TV 5 in San Diego, USA. Our project was one of the flagship features of a major classi music festival in California (Mainly Mozart), which in 2015 was on the theme of music &amp;amp; brain.</gtr:impact><gtr:outcomeId>56c0bc0de50dd7.03130808</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://fox5sandiego.com/2015/09/22/learn-about-your-brain-with-music/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Classical music's 'all in the mind'</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>09AE7E36-7BF4-4E91-AFDE-F6E846D6843E</gtr:id><gtr:impact>The World at One programme's reporter Neil Bowdler went to meet Eduardo Miranda, professor in computer music at the University of Plymouth, to find out how people have very different reactions to classical music.

This BBC World Service programme is estimated to have reached an audience over 10 million people worldwide.</gtr:impact><gtr:outcomeId>r-9988182540.9719562b83571e</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/news/uk-20799961</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Article in Der Spiegel</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>225D6945-3289-44BC-BF44-92A4F0A60DE0</gtr:id><gtr:impact>Article on the German magazine Der Spiegel on the theme of music and emotions, where our research project features as an example of cutting edge international research in the field.

This is important communication outreach and demonstrates that our project enjoys good esteem and visibility internationally.</gtr:impact><gtr:outcomeId>5450e20765a474.00250717</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://magazin.spiegel.de/EpubDelivery/spiegel/pdf/127307938</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Many Worlds at Print Screen Festival</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>70EA1245-1A4E-4BA9-A168-FE1F98B82616</gtr:id><gtr:impact>ICCMR Research Fellow Dr Alexis Kirke was an invited speaker at the opening of Print Screen Festival in Tel Aviv, Israel, which also screened the short film 'many worlds' as part of the festival. The visit was covered by the Jerusalem Post, Tel Aviv Channel 10 TV, and Ha-aretz.

This is a high-profile festival in Israel, which served to disseminate the research and raise the awareness of the public of the potential applications of our research beyond the real of music; e.g., cinema.</gtr:impact><gtr:outcomeId>5450cbf55b82b1.78905602</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://69.195.124.60/~alexiski/manyworlds/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Residency at Harvard University</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>510B99B3-D564-4968-811F-B844F5841724</gtr:id><gtr:impact>Develop collaborative work with Harvard University Studio for Electroacoustic Music (HUSEAC) on musical composition with new technologies. A talk was delivered on the interface between music and biology (focusing on human voice) and discussions were held with partners in the music department on how this project's outcomes may benefit the music community.</gtr:impact><gtr:outcomeId>58c67de40b3c37.79940505</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>EAR: Environments for Alzheimer's friendly Radio</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>F578B4CE-3357-4E21-9902-D4515E711B5B</gtr:id><gtr:impact>Interview with Dr Alexis Kirke to BBC Radio Devon about our initiative to draw from the experience we have been gaining from this research project to develop a radio programme suitable for people suffering from Alzheimer, in collaboration with BBC.

This initiative attracted the attention of the Alzheimer Society, which is interested in collaborating with the research. This activity is important because it opens opportunities to apply the knowledge generated by the research in real-world scenarios, out of the lab.</gtr:impact><gtr:outcomeId>5450c640788cd6.94248170</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://soundcloud.com/alexiskirke/bbc-interview-on-project-ear-environments-for-alzheimers-friendly-radio</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Social media exposure with over 970,000 views</gtr:description><gtr:form>Engagement focused website, blog or social media channel</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>37BFF370-C322-46D4-B98E-0DFCE26A7885</gtr:id><gtr:impact>Social media story published by Rockets Are Cool FaceBook, which attracted nearly 1 million viewers, over 10 comments and 2,300 shares.</gtr:impact><gtr:outcomeId>58c689e3757ea7.30383299</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>https://www.facebook.com/RocketsAreCool/videos/1009792159150315/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Remixing Beethoven with brain data</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>2124B66E-6353-44C1-8C80-5F4128052980</gtr:id><gtr:impact>Talk at Research Seminar at NOTAM (Norwegian Center for Technology in Music and the Arts) in Oslo, on developing algorithms to compose music with brain data.

Talk that sparked discussion about the use of brain scanning data in musical composition and wider implications of this practice to the music industry.</gtr:impact><gtr:outcomeId>5450cd50123e93.18574941</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.notam02.no/web/2014/05/talk-med-eduardo-miranda/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Brain damaged violinist makes music for first time in 27 years with mind-reading technology</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>828FC293-A124-4AFD-A76E-25805A98A7BB</gtr:id><gtr:impact>Excellent news story in The Sunday Telegraph about the groundbreaking achievement of this research. This news story was replicated by a great number of online news outlets (over 50) and uncountable social media (blogs, Twitters, Facebook, etc.) worldwide, reaching an estimated 50 million people all over the world.</gtr:impact><gtr:outcomeId>56c0baca8b8ef9.21202308</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.telegraph.co.uk/good-news/2016/02/11/brain-damaged-violinist-makes-music-for-first-time-in-27-years-w/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>In Tune - David Christophersen, Jian Wang, Eduardo Reck Miranda</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>142B7635-CE24-4E2A-BD69-5E402088A56C</gtr:id><gtr:impact>Sean Rafferty presents, with live music from cellist Jian Wang, straight from rehearsals with the BBC Symphony Orchestra ahead of their Barbican concert. Pianist David Christophersen plays music by Kabalevsky and Granados live in the studio and we talk to composer Eduardo Reck Miranda about his new work 'Symphony of Minds Listening'.

This is a very popular BBC Radio 3 programme, which generated a number of enquiries about the project and expression of interest in keeping informed of similar initiatives.</gtr:impact><gtr:outcomeId>r-4697010037.2070542b835e58</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b01qqsf1</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description> 1st International Workshop on Brain-Computer Music Interfacing</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>78B5784D-1BB4-4160-9AB9-050385194135</gtr:id><gtr:impact>1st International Workshop on Brain-Computer Music Interfacing organised as part of a major international conference on music technology (11th International Symposium on Computer Music Multidisciplinary Research). This first workshop was aimed at raising the awareness of researchers and post-graduates students of trends in the field of this research project and encourage young researchers to engage with the field.</gtr:impact><gtr:outcomeId>56c0c763ae6f25.35966939</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://cmr.soc.plymouth.ac.uk/bcmi2015/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Music, information and symmetry</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>4CCAD4DF-297E-43FC-8051-6714A1F7FC24</gtr:id><gtr:impact>Invited keynote given to &amp;quot;Music, information and symmetry&amp;quot;, event organised by Moscow P. I. Tchaikovsky Conservatory, held in Vienna, on 4 June, 2015. Talk on music &amp;amp; brain and Music Neurotechnology developed during the project, to an audience of non-experts in the field of research. The talk fostered debate and interest on the topic of the research.</gtr:impact><gtr:outcomeId>56c0c66b96d499.60689315</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>http://summit.is4is.org/calls/call-for-papers/music-information-and-symmetry</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Apr?s 26 ans de silence, une violoniste joue avec son cerveau</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>53643DE4-DD44-42AB-ADC2-F8575B2BFA89</gtr:id><gtr:impact>The achievements of our research project was news in France Musique's magazine, which generated a great amount on traffic in the social media in France and other French-speaking countries, contributing to raising the awareness of the significance of our research.</gtr:impact><gtr:outcomeId>56c0b762da7795.68459184</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.francemusique.fr/actu-musicale/apres-26-ans-de-silence-une-violoniste-joue-avec-son-cerveau-122023</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Symphony of Minds Listening</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>73DDCDA1-10FE-4497-8984-720913800D0E</gtr:id><gtr:impact>Keynote: Symphony of Minds Listening (2013 - 2014) is a new orchestral composition in 3 movements, based on the fMRI scans taken from 3 people while they listened to the second movement of Beethoven's 7th Symphony: a ballerina, a philosopher and myself. The instrumentation is the same as for Beethoven's original instrumentation and the duration is approximately 25 minutes in total. I deconstructed Beethoven's movement to its essential elements with the aid of bespoke Artificial Intelligence (AI) software developed in my lab and stored them together with statistical information about Beethoven's compositional decisions. Then I re-assembled these elements following a method of my own, which uses fMRI information to guide the process. The original material was remixed and modified according to a number of musical operations guided by the brain scans. The brain activity of 3 different minds listening to Beethoven's music yielded 3 different movements of the composition, some bearing more resemblance to the Beethoven movement than others. The respective brain scans were rendered into movies showing the brain activity of the three persons, which are screened during the concert. I did to the Beethoven score what our hearing system does when we listen to music: sounds are deconstructed as soon as they enter the ear and are relayed through various pathways towards cortical structures, where the data are reconstructed into what is perceived as music.
.

Stimulated thinking and discussion about musical composition using brain-data.</gtr:impact><gtr:outcomeId>r-1225822466.63591120cb7da3c</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://cmr.soc.plymouth.ac.uk/pacmf-programme.html#saturday</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Disabled violinist plays for first time in 27 years with mind-reading technology</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>D76E00E9-95E4-476F-93D7-D2F45E1C9604</gtr:id><gtr:impact>News about unprecedented opportunity that our research project offered to a disabled musician to play music again using our technology.</gtr:impact><gtr:outcomeId>56c0b4f2a442b4.81207868</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://metro.co.uk/2016/02/09/disabled-violinist-plays-for-first-time-in-27-years-with-mind-reading-technology-5671013/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>LASER: Talks on the intersection of art, science and technology</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>9722BCCA-A955-4F3F-95FD-5D1BC90C4660</gtr:id><gtr:impact>Invited to give a talk and participate in a discussion panel exploring issues connected with interspecies communication, co-creation and collaboration. Discussion included considerations of working creatively with living matter, the implications of shared authorship, notions of nonhuman subjectivity, and issues of care and control.</gtr:impact><gtr:outcomeId>58c68714782036.50362798</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.londonlaser.net/london-laser-19-programme-announced/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Story in The Guardian</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>63B59A91-3FD7-4F67-8741-9403FAEFCD9E</gtr:id><gtr:impact>Story about the research project in The Guardian newspaper.</gtr:impact><gtr:outcomeId>58c68b9b1e6589.84960678</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>https://www.theguardian.com/lifeandstyle/2016/sep/12/mind-blowing-music-tinie-tempahs-brain-scan</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Disabled musicians create music from brainwaves</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>46062791-6C41-4F7B-B873-C1EED2B46AA5</gtr:id><gtr:impact>Report on BBC News, Science &amp;amp; Environment, first screened on BBC Breakfast Show, about how our research is transforming the lives of people with physical motor-impairment. The impact of the research has been demonstrated to an estimated 10 million viewers worldwide.</gtr:impact><gtr:outcomeId>56c0bf8d718ca2.40880217</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/news/science-environment-35557908</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>This Is Your Brain on Music! Offers Interactive Installations at UC San Diego</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FE566663-63EE-4C82-9D9C-01F498CC3EC2</gtr:id><gtr:impact>Keynote given at Mozart &amp;amp; the Mind event held at The Qualcomm Institute in San Diego. The talk reported on the outcomes of this research project and how it is leading to new approaches to computer-aided creativity with music technology. Prof Miranda also performed his composition &amp;quot;Mozart Reloaded,&amp;quot; for which Mozart piano sonatas were algorithmically processed into new compositions. The audience engaged in a debate with the speaker during a Q&amp;amp;A session after the talk.</gtr:impact><gtr:outcomeId>56c0c9a3961730.49163525</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.calit2.net/newsroom/release.php?id=2583</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk at MIT MediaLab</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>31A4764D-10B8-4D8D-96A7-606D7103DF00</gtr:id><gtr:impact>Invited talk at MIT MediaLab in Cambridge (MA), on the future of Artificial Intelligence-mediated music technology, with focus on new interfaces and Brain-Computer Music Interfaces.</gtr:impact><gtr:outcomeId>58c67c5e346769.77739335</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Mind-reading software allows brain-damaged Welsh violinist to compose music</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C7123B40-CDF8-4E97-8359-AAFE9CADEF99</gtr:id><gtr:impact>News story about the groundbreaking research achievement of our project published in Australia, which raised the awareness of our research work in Australia through a number of re-postings in the social media.</gtr:impact><gtr:outcomeId>56c0b85bebefe1.57203380</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.ibtimes.com.au/mind-reading-software-allows-brain-damaged-welsh-violinist-compose-music-27-years-after-car-crash</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Dara O'Briain Science Club Ep 6 - Music &amp; Science</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>DFB891D5-1113-4812-A959-F5563E87AA1D</gtr:id><gtr:impact>Alexis Kirke explains to Dara O'Briain how artificial agents can evolve music.

Exposure on very well-known BBC program, with an audience estimated at 5 million.</gtr:impact><gtr:outcomeId>r-8257816497.4766012b83548a</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://vimeo.com/56950291</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Key note speaker at SMC2016 - Hamburg</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>986A3152-BB81-4480-B026-7220324AC64B</gtr:id><gtr:impact>Invited keynote at Sound and Music Computing Conference, which sparked debate amongst the delegated on the future of computing technology for music.</gtr:impact><gtr:outcomeId>58c681cba2fb49.17731217</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://smc2016.hfmt-hamburg.de/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>NeurotecX - A sceptical look into neurotech</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>916CF7A4-D56F-405E-9F28-DFA569D80B97</gtr:id><gtr:impact>Invited to be member of a debating panel on neurotechnology. The interest in neuroscience and neurotech has grown significantly during the last years. This increased exposure has also contributed to a lot of hype, misinformation and unrealistically high expectations about what this growing field could deliver. This event initiated an important dialogue in order to better understand the limits of the field, while highlighting the incredible achievements and potential that applied neuroscience could bring to the general public in the next years.</gtr:impact><gtr:outcomeId>58c682da3c2a99.83127457</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.meetup.com/NeuroTechLDN/events/233910615/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The research is still ongoing but we can already report the impact of our experiments with motor-impaired patients at Royal Hospital for Neuro-disability, which has enabled them to play music in a public concert and on a movie/documentary, which is publicly accessible/available on Vimeo. The research has also attracted the attention of the media world-wide for its potential to transform the lives of such patients.

As a follow up from the above, we developed an unprecedented public music concert at the Royal Hospital for Neuro-disability in July 2015, whereby we enabled 4 severely motor-impaired patients to team up with a professional string quartet to form the Paramusical Ensemble. Patients and the quartet had the opportunity to make music together performing a bespoke composition by Prof E Miranda entitled &amp;quot;Activating Memory&amp;quot;. Please refer to a short documentary publicly available on Vimeo, which has been watched over 78,000 times in 20 months): https://vimeo.com/143363985</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>A141C1F2-E7CA-47FB-87AE-66721B6D976B</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>54526f3aad0c73.44670109</gtr:outcomeId><gtr:sector>Communities and Social Services/Policy,Creative Economy,Education,Healthcare,Leisure Activities, including Sports, Recreation and Tourism</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The findings to date are partial, because the research is still ongoing. However, we confirm that we are on track to meet the research objectives as stated on the project proposal.</gtr:description><gtr:exploitationPathways>The project is still ongoing. This information will be compiled when the project is competed.</gtr:exploitationPathways><gtr:id>E0F350ED-89DD-45C9-BFFE-79177DC08135</gtr:id><gtr:outcomeId>54526f063ab1a8.77377676</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Healthcare</gtr:sector></gtr:sectors><gtr:url>http://cmr.soc.plymouth.ac.uk/bcmi/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Environments for Alzheimer's-friendly Radio</gtr:description><gtr:geographicReach>National</gtr:geographicReach><gtr:id>78E9E8F2-DF16-45DE-8761-A396CC831746</gtr:id><gtr:impact>The ICCMR team advises the BBC on the project EAR (Environments for Alzheimer's-friendly Radio), which is developed with BBC Radio Devon, aimed at producing Alzheimer's-friendly radio programmes. This resulted in an one hour-long experimental radio programme aimed at listeners suffering from Alzheimer's disease, which was broadcast by BBC Radio Devon in 2015. Dr Alexis Kirke presented guidelines for production of such programmes at BBC's Broadcasting House in the invite-only BBC Sound Now and Next Conference.</gtr:impact><gtr:outcomeId>56ba1a701857b9.50246971</gtr:outcomeId><gtr:type>Membership of a guideline committee</gtr:type></gtr:policyInfluenceOutput><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Prime Minister's Task and Finish Group for Rural Dementia</gtr:description><gtr:geographicReach>National</gtr:geographicReach><gtr:id>FD3C0AA5-0467-4ADC-8710-97C38C111F1D</gtr:id><gtr:impact>Dr Alexis Kirke is member of Prime Minister's Task and Finish Group for Rural Dementia, which is a group that meets regularly in the House of Commons, Palace of Westminster and in other venues outside of London to discuss strategies and recommend policies for dealing with the increasing problem of dementia in rural parts of the UK.</gtr:impact><gtr:outcomeId>56ba1808cf5006.32215340</gtr:outcomeId><gtr:type>Membership of a guideline committee</gtr:type></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>18E3A79F-FF5A-4F8B-9EE5-370CC2FAB114</gtr:id><gtr:title>Artificial Intelligence in Organised Sound</gtr:title><gtr:parentPublicationTitle>Organised Sound</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1355-7718</gtr:issn><gtr:outcomeId>56bf4c62511483.66483770</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9EBA7A58-ADDD-4C3E-B848-8EE4036DE94A</gtr:id><gtr:title>Investigating affect in algorithmic composition systems</gtr:title><gtr:parentPublicationTitle>Psychology of Music</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5448f815e57ba1.53398756</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B03A8AF4-3FEC-4FA8-9B9F-6B40BF919B0A</gtr:id><gtr:title>Towards Affective Algorithmic Composition</gtr:title><gtr:parentPublicationTitle>Proceedings of the 3rd International Conference on Music and Emotion - ICME3</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/48338986ac1da5654bb94ca0ca001e58"><gtr:id>48338986ac1da5654bb94ca0ca001e58</gtr:id><gtr:otherNames> Duncan Williams (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_268639815913de3164</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A7F8464E-7A23-4D8A-9980-A22CE0980547</gtr:id><gtr:title>Towards Human-Computer Music Interaction: Evaluation of an Affectively-Driven Music Generator Via Galvanic Skin Response Measures</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/daae3998c9c7407251714d5447ea76b7"><gtr:id>daae3998c9c7407251714d5447ea76b7</gtr:id><gtr:otherNames>Daly, I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf522ae76db7.10786582</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>81D1949A-DBDC-4D55-B3A0-557E22C89409</gtr:id><gtr:title>Brain-computer music interfacing for continuous control of musical tempo</gtr:title><gtr:parentPublicationTitle>Proceedings of the 6th International Brain-Computer Interface Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a65e87037ecafdc18e2e023b94ff93ae"><gtr:id>a65e87037ecafdc18e2e023b94ff93ae</gtr:id><gtr:otherNames>Daly, I. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5449173f500d26.52867011</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4F9A42B0-BE96-4C20-B08F-62EA6444CB7F</gtr:id><gtr:title>Guide to Brain-Computer Music Interfacing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4471-6583-5</gtr:isbn><gtr:outcomeId>5448f6a3ce1944.82233757</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DDC31FE7-E855-4910-BB1A-6D9A302C39FD</gtr:id><gtr:title>An affective brain-computer music interface</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b94f13248df4.14712126</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E258BD81-F6B5-49FC-B58A-F23D1441F351</gtr:id><gtr:title>Towards Harmonic Extensions of Pulsed Melodic Affective Processing - Further Musical Structures for Increasing Transparency in Emotional Computation</gtr:title><gtr:parentPublicationTitle>International Journal of Unconventional Computing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/63da815cafb24aec18faf4d1896ba690"><gtr:id>63da815cafb24aec18faf4d1896ba690</gtr:id><gtr:otherNames>Kirke, A. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>544915b3e041c3.49625616</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A68F68E4-0D7A-4092-9CE6-37222CF45314</gtr:id><gtr:title>Affective Jukebox: A Confirmatory Study of EEG Emotional Correlates in Response to Musical Stimuli</gtr:title><gtr:parentPublicationTitle>Proceedings of Joint ICMC | SMC 2014 | 11th Sound and Music Conference |14th International Computer Music Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b6bc8f8cc8e89d56d5bc554c739a2d6f"><gtr:id>b6bc8f8cc8e89d56d5bc554c739a2d6f</gtr:id><gtr:otherNames>Eaton, J. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5448f5985b86e4.28840714</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>541C5707-225C-4F51-9FCD-DBF0E7BB43E2</gtr:id><gtr:title>Ashgate Research Companion to Electronic Music</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>58b95862917223.07283813</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DFC18185-1D13-4963-82E6-36DC452FDA8D</gtr:id><gtr:title>Personalised, Multi-modal, Affective State Detection for Hybrid Brain-Computer Music Interfacing</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Affective Computing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a9959be9dc0a6.66319778</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EE12BB4F-42A4-468F-9B40-10526E543FE5</gtr:id><gtr:title>Guide to Brain-Computer Music Interfacing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1631fa3b6a8793e5ed92feb90627bb99"><gtr:id>1631fa3b6a8793e5ed92feb90627bb99</gtr:id><gtr:otherNames>Eaton J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4471-6583-5</gtr:isbn><gtr:outcomeId>5448f47d0056d2.60979863</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CCD884FD-C11F-4F29-9B35-8E10261D7AEF</gtr:id><gtr:title>Light, Image, Imagination</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f965b52cc74e38f3fc65f32a16b30b73"><gtr:id>f965b52cc74e38f3fc65f32a16b30b73</gtr:id><gtr:otherNames>Eduardo R. Miranda</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:isbn>978-9-08964-384-1</gtr:isbn><gtr:outcomeId>r_258152895691e60d08</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EFFF873E-50DD-48D9-B0CD-CC8B3FF611F9</gtr:id><gtr:title>A new hybrid BCI paradigm based on P300 and SSVEP.</gtr:title><gtr:parentPublicationTitle>Journal of neuroscience methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/737ffe0e530a693d7c0da01892f1528d"><gtr:id>737ffe0e530a693d7c0da01892f1528d</gtr:id><gtr:otherNames>Wang M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0165-0270</gtr:issn><gtr:outcomeId>58b965b5b36800.84296875</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AE7006C5-9BD0-40F9-BFF1-093D06DB756D</gtr:id><gtr:title>Towards a Timbral Classification System for Musical Excerpts</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a481247dbad66e68ad5cfa573920197c"><gtr:id>a481247dbad66e68ad5cfa573920197c</gtr:id><gtr:otherNames>Antoine A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b96669ec4a60.61825737</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>89DDB2DA-93F2-419F-94A8-3D090ABAF022</gtr:id><gtr:title>Real-Time Hallucination Simulation and Sonification through User-Led Development of an iPad Augmented Reality Performance</gtr:title><gtr:parentPublicationTitle>Leonardo</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0d95f3c47db9d1742eb5f682e3937d14"><gtr:id>0d95f3c47db9d1742eb5f682e3937d14</gtr:id><gtr:otherNames>Kirke A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0024-094X</gtr:issn><gtr:outcomeId>56b9d7e36ea957.50931656</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2A09DC1C-AA9F-4557-B0BF-F5F1128E0A36</gtr:id><gtr:title>Real-Time Brainwave Control for Live Performance</gtr:title><gtr:parentPublicationTitle>Proceedings of 10th International Symposium on Computer Music Multidisciplinary Research - CMMR 2014</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f36a042ada8d7514c541b5c7e37ec0a3"><gtr:id>f36a042ada8d7514c541b5c7e37ec0a3</gtr:id><gtr:otherNames> Joel Eaton (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_623737893813e577b2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>196CE4E4-AAEE-443E-8747-817BC81EFF49</gtr:id><gtr:title>Affective brain-computer music interfacing.</gtr:title><gtr:parentPublicationTitle>Journal of neural engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1741-2552</gtr:issn><gtr:outcomeId>585d5026b62378.27810382</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3A6BB1CB-0392-43AE-8BA9-29085FADF783</gtr:id><gtr:title>Toward Emotionally-Congruent Dynamic Soundtrack Generation</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b95a14d6e1c5.93572414</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>14CBEE73-5BDA-4864-96E9-24E45E69586E</gtr:id><gtr:title>: Evaluating a multi-user affective brain-computer music interface</gtr:title><gtr:parentPublicationTitle>Brain-Computer Interfaces</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1631fa3b6a8793e5ed92feb90627bb99"><gtr:id>1631fa3b6a8793e5ed92feb90627bb99</gtr:id><gtr:otherNames>Eaton J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf4c04a55e11.55858461</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4713DF76-C764-4BBD-8DFF-565B10DA01C9</gtr:id><gtr:title>Artificial Affective Listening Towards a Machine Learning Tool for Sound-based Emotion Therapy and Control</gtr:title><gtr:parentPublicationTitle>Proceedings of the Sound and Music Computing Conference - SMC 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/570d62c74f25e50f3050aa39fa805b66"><gtr:id>570d62c74f25e50f3050aa39fa805b66</gtr:id><gtr:otherNames> Alexis Kirke (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_590863641513d7390e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>98F3E286-39F1-4C33-8930-35A162A8ADF9</gtr:id><gtr:title>Affective calibration of a computer aided composition system by listener evaluation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93cd2ca6651198abea632bf1fabf3474"><gtr:id>93cd2ca6651198abea632bf1fabf3474</gtr:id><gtr:otherNames>Williams, D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf50b49f8750.28909743</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7AFF54A9-11D6-4B90-B138-6B05498BF499</gtr:id><gtr:title>Pulsed Melodic Affective Processing: Musical structures for increasing transparency in emotional computation</gtr:title><gtr:parentPublicationTitle>SIMULATION</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0d95f3c47db9d1742eb5f682e3937d14"><gtr:id>0d95f3c47db9d1742eb5f682e3937d14</gtr:id><gtr:otherNames>Kirke A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5449154aaac1d0.07485446</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C8B23481-694C-4ECF-843E-E80DB9CA790A</gtr:id><gtr:title>An investigation into the use of six facially encoded emotions in brain-computer interfacing</gtr:title><gtr:parentPublicationTitle>Brain-Computer Interfaces</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b9632ba91127.89603263</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F02E1DFD-FBDA-4309-9E0B-C7005392D7E8</gtr:id><gtr:title>Real-time notation using brainwave control</gtr:title><gtr:parentPublicationTitle>Sound and Music Computing Conference - SMC 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f36a042ada8d7514c541b5c7e37ec0a3"><gtr:id>f36a042ada8d7514c541b5c7e37ec0a3</gtr:id><gtr:otherNames> Joel Eaton (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_746647826613e57866</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E7EE202F-45AB-4A14-BF53-D54629CF2FBE</gtr:id><gtr:title>Enhancing the Social Impact of Contemporary Music with Neurotechnology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf5333917ef7.79644017</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E1395322-DCC7-468A-AFD5-EBC8736009E6</gtr:id><gtr:title>An exploration of spatial auditory BCI paradigms with different sounds: music notes versus beeps.</gtr:title><gtr:parentPublicationTitle>Cognitive neurodynamics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4ab051e465eab0e967de131aa216bdc5"><gtr:id>4ab051e465eab0e967de131aa216bdc5</gtr:id><gtr:otherNames>Huang M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1871-4080</gtr:issn><gtr:outcomeId>58b962d3a40ca3.64778238</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>843E31AC-7277-43EA-8D3D-B63560D8B334</gtr:id><gtr:title>Guide to Brain-Computer Music Interfacing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4471-6583-5</gtr:isbn><gtr:outcomeId>5448f4fab10c67.55105435</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B676DF09-4F38-4D74-9BD0-AF484BD12BA0</gtr:id><gtr:title>Automated identification of neural correlates of continuous variables.</gtr:title><gtr:parentPublicationTitle>Journal of neuroscience methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0165-0270</gtr:issn><gtr:outcomeId>doi_55f9749746125ded</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CAC3AC24-03BA-4460-9D88-07F728074BBC</gtr:id><gtr:title>Investigating Perceived Emotional Correlates of Rhythmic Density in Algorithmic Music Composition</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Applied Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58b955942b25b5.75422695</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C1F03169-2A03-4CB4-9572-ACD752CF4F0D</gtr:id><gtr:title>Music Neurotechnology: From Music of the Spheres to Music of the Hemispheres</gtr:title><gtr:parentPublicationTitle>Symmetry: Culture and Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/04a81850bb12acc1443d1e58b32db622"><gtr:id>04a81850bb12acc1443d1e58b32db622</gtr:id><gtr:otherNames>Miranda, E. R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56b9eb00463c90.72569708</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>099EF924-A478-47C3-904C-924EF4507460</gtr:id><gtr:title>Identifying music-induced emotions from EEG for use in brain-computer music interfacing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf4f9a67dc19.99830062</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9A2F84EE-D8B2-4247-8DB7-B2E903DABAFF</gtr:id><gtr:title>Neural correlates of emotional responses to music: an EEG study.</gtr:title><gtr:parentPublicationTitle>Neuroscience letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0304-3940</gtr:issn><gtr:outcomeId>544914dcd8b068.02721492</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>196D6102-37D9-4C9B-B088-4C38D20FA6FA</gtr:id><gtr:title>Towards Harmonic Extensions of Pulsed Melodic Affective Processing - Further Musical Structures for Increasing Transparency in Emotional Computation</gtr:title><gtr:parentPublicationTitle>International Journal of Unconventional Computing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/570d62c74f25e50f3050aa39fa805b66"><gtr:id>570d62c74f25e50f3050aa39fa805b66</gtr:id><gtr:otherNames> Alexis Kirke (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>m_505545330713d739c2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>20F667EF-56AA-4C68-BBE0-41F3936D2030</gtr:id><gtr:title>The Space Between Us. A live performance with musical score generated via emotional levels measured in EEG of one performer and an audience member</gtr:title><gtr:parentPublicationTitle>Proceedings of New Interfaces for Musical Expression - NIME 2014</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b6bc8f8cc8e89d56d5bc554c739a2d6f"><gtr:id>b6bc8f8cc8e89d56d5bc554c739a2d6f</gtr:id><gtr:otherNames>Eaton, J. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5448f63960e966.84151697</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1CF4381F-373A-499A-85CA-394F7B7F011E</gtr:id><gtr:title>Evaluating a system for autonomous collaborative performance of affective algorithmic composition</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Multimedia Computing Communications and Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58b951bae6ab46.03902832</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4380A84A-84B0-4251-B47A-35E413ACE899</gtr:id><gtr:title>Evaluating perceptual separation in a pilot system for affective composition</gtr:title><gtr:parentPublicationTitle>Proceedings of the Joint 40th International Computer Music Conference / 13th Sound and Music Computing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b7a1e1cab7a2caca8f57c6efac75a9eb"><gtr:id>b7a1e1cab7a2caca8f57c6efac75a9eb</gtr:id><gtr:otherNames>Williams, D. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>544913f74137b7.28639114</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AAEC07D0-3FD6-44EB-93F9-5BA07217FDEF</gtr:id><gtr:title>A perceptual and affective evaluation of an affectively-driven engine for video game soundtracking</gtr:title><gtr:parentPublicationTitle>ACM Computers in Entertainment (CIE) - Special Issue on Musical Metacreation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b94e1d73abd5.59099760</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DD976E44-F2D7-453F-8E30-D9D378B8CA28</gtr:id><gtr:title>The OM Composer's Book 3</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef6499f68ace8d7e6a2eeae99a83daf6"><gtr:id>ef6499f68ace8d7e6a2eeae99a83daf6</gtr:id><gtr:otherNames>Miranda E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:isbn>978-2-7521-0283-6</gtr:isbn><gtr:outcomeId>58b9596d8276d6.99121502</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>73B1F2C7-257D-4124-B897-6DDC731DAFBA</gtr:id><gtr:title>Music-induced emotions can be predicted from a combination of brain activity and acoustic features.</gtr:title><gtr:parentPublicationTitle>Brain and cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76c6242cb5a578b95426f037da1f4a08"><gtr:id>76c6242cb5a578b95426f037da1f4a08</gtr:id><gtr:otherNames>Daly I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0278-2626</gtr:issn><gtr:outcomeId>56b9ea4651b1f8.62377018</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9756AC04-0755-4F8C-B947-AE59224FCE71</gtr:id><gtr:title>Changes in music tempo entrain movement related brain activity</gtr:title><gtr:parentPublicationTitle>Proceedings of the 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a65e87037ecafdc18e2e023b94ff93ae"><gtr:id>a65e87037ecafdc18e2e023b94ff93ae</gtr:id><gtr:otherNames>Daly, I. (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>544916669172d6.04764831</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7CDC127D-28D0-4856-A9A1-A6DA331F591F</gtr:id><gtr:title>Dynamic Game Soundtrack Generation in Response to a Continuously Varying Emotional Trajectory</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93cd2ca6651198abea632bf1fabf3474"><gtr:id>93cd2ca6651198abea632bf1fabf3474</gtr:id><gtr:otherNames>Williams, D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf55280b0769.37959018</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D41BE057-2A31-4725-BC26-9E3A715D7600</gtr:id><gtr:title>Affective Calibration of Musical Feature Sets in an Emotionally Intelligent Music Composition System</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Applied Perception (TAP)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d3cf5cd802f563f9377bacca8a23898a"><gtr:id>d3cf5cd802f563f9377bacca8a23898a</gtr:id><gtr:otherNames>Williams D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58b95088bac7b2.65852702</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J002135/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>