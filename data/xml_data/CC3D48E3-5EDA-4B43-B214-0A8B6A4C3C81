<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/C6E66080-879D-4C24-9063-88E56AF55614"><gtr:id>C6E66080-879D-4C24-9063-88E56AF55614</gtr:id><gtr:name>Sony Broadcast and Professional Europe</gtr:name><gtr:address><gtr:line1>The Heights</gtr:line1><gtr:line2>Brooklands</gtr:line2><gtr:postCode>KT13 0XW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/FDE2FB5E-C474-426E-A7E3-F32FA7BCE366"><gtr:id>FDE2FB5E-C474-426E-A7E3-F32FA7BCE366</gtr:id><gtr:name>Body Metrics</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D6480614-BFEA-4BE8-BF95-0DA9AED70BA3"><gtr:id>D6480614-BFEA-4BE8-BF95-0DA9AED70BA3</gtr:id><gtr:name>Numerion Software Limited</gtr:name><gtr:address><gtr:line1>Mark Beech Rake Lane
Milford</gtr:line1><gtr:city>Godalming</gtr:city><gtr:postCode>GU8 5AB</gtr:postCode><gtr:region>South East</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:department>Vision Speech and Signal Proc CVSSP</gtr:department><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C6E66080-879D-4C24-9063-88E56AF55614"><gtr:id>C6E66080-879D-4C24-9063-88E56AF55614</gtr:id><gtr:name>Sony Broadcast and Professional Europe</gtr:name><gtr:address><gtr:line1>The Heights</gtr:line1><gtr:line2>Brooklands</gtr:line2><gtr:postCode>KT13 0XW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FDE2FB5E-C474-426E-A7E3-F32FA7BCE366"><gtr:id>FDE2FB5E-C474-426E-A7E3-F32FA7BCE366</gtr:id><gtr:name>Body Metrics</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D6480614-BFEA-4BE8-BF95-0DA9AED70BA3"><gtr:id>D6480614-BFEA-4BE8-BF95-0DA9AED70BA3</gtr:id><gtr:name>Numerion Software Limited</gtr:name><gtr:address><gtr:line1>Mark Beech Rake Lane
Milford</gtr:line1><gtr:city>Godalming</gtr:city><gtr:postCode>GU8 5AB</gtr:postCode><gtr:region>South East</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FBFB4615-9E00-440D-944E-B80CDDA11131"><gtr:id>FBFB4615-9E00-440D-944E-B80CDDA11131</gtr:id><gtr:name>Bodymetrics Limited</gtr:name><gtr:address><gtr:line1>The Deco Partnership Archer House Britland Estate Northbourne Road Eastbourne
East Sussex</gtr:line1><gtr:city>Sussex</gtr:city><gtr:postCode>BN22 8PW</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0D1B6198-1936-4309-89B9-49F659607603"><gtr:id>0D1B6198-1936-4309-89B9-49F659607603</gtr:id><gtr:name>Guided Collective</gtr:name><gtr:address><gtr:line1>Guided Ltd</gtr:line1><gtr:line2>Unit 1.1</gtr:line2><gtr:line3>11-19 Fashion Street</gtr:line3><gtr:postCode>E1 6PX</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2D0F82D5-F19E-4EA8-A0C7-C7F120102A69"><gtr:id>2D0F82D5-F19E-4EA8-A0C7-C7F120102A69</gtr:id><gtr:firstName>Adrian</gtr:firstName><gtr:surname>Hilton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FI031936%2F1"><gtr:id>CC3D48E3-5EDA-4B43-B214-0A8B6A4C3C81</gtr:id><gtr:title>Body Shape Recognition for Online Fashion</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/I031936/1</gtr:grantReference><gtr:abstractText>We are proposing to develop an online tool that will give potential benefit to many, allowing an untrained user to realise their body size and shape, from their own home, using a standard digital camera/webcam. At present, the majority of body scanning technologies deployed in retail environments are expensive and require dedicated technical support, confining their use to high-end department stores and specialist sports retailers. The fashion, social and economic benefits that body scanning offers are therefore inaccessible to the majority of the general public. This project aims to exploit low cost webcam/cameras to reformat this technology into a service that isn't reliant upon specialist hardware, and to reprogram the experience out from the controlled retail environment and into the home.There are both technical and cultural challenges to be addressed before we can achieve our goal and we have created a collaborative partnership to deal with them. Our proposed scanning technology is based upon photogrammetry, a branch of Computer Science that aims to extract 3D information from one or more 2D images. The images are usually taken from known locations with calibrated cameras, however these are two dependencies that we plan to remove from this technology from the outset. If enough prior knowledge about standard body shape, structure and posture is known, both physiological and fashion insights included, a tool can be designed to be more intelligent and less reliant upon resolution or use of multiple views. Through a double-pronged approach that uses innovative Computer Vision techniques to construct an initial model, to refinement by the application of style ontologies and retailer metadata, we aim to create a tool that will offer benefits to consumer, retailer and manufacturer alike. We will work closely with our industry partner to help us define the base requirements of our data capture tool. This will include online clothing brands that also have production interests and are working with Bodymetrics@Selfridges to develop custom fit clothing. The potential for this home sizing tool to enable a wider infrastructure of rapid manufacturing and leaner distribution networks has led us to approach a particular type of retailer that would benefit greatly from a reduction in purchase returns and greater market insights. We plan to develop a prototype for integration within our industry partner's website, we will link to its stock database and our initial trial will aim to size a user group, and recommend them items from the partner's stock. Results will be judged upon the user group's feedback, and the webcam-based tool will be re-specified as new knowledge is gained. Qualitative research will also be undertaken on the user experience arising from using a webcam and solutions will be developed to encourage the user, with possible amendments made to account for cultural differences and perceptions on trust and security. The research offers the potential for the project team to research the user experience, which is a significant contributor to the slow take up to date of scanning technology. The project will help to catalyse the uptake of mass-customisation of garments, which is fundamentally a new business model. In this paradigm, garments are produced 'on-demand' for a particular customer's fit and style preferences. This allows the retailer to obtain monies from customers before the products are produced; a 'reverse' of the standard cash-flow dynamics of retail and establishing a very attractive business model for clothing retailers.The project can also develop the efficiencies of the current business models practised by on-line retailers by helping to 'lower the cost of information'. The method that the project is aiming to pioneer can be seen as an efficient way to 'search for clothes' on-line as it helps to match an individual's body with garments that fit that person.</gtr:abstractText><gtr:fund><gtr:end>2013-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2011-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>148660</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Sony Broadcast and Professional Europe</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Sony Broadcast and Professional Europe</gtr:description><gtr:id>A2BF5667-F39F-4409-A66B-EA0DC6B0D88B</gtr:id><gtr:outcomeId>b9973088b997309c-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2004-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Numerion Software Limited</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Numerion</gtr:description><gtr:id>D58831BE-0F95-43B7-83BF-87816ED0F59A</gtr:id><gtr:impact>Physically validated cloth simulation tools</gtr:impact><gtr:outcomeId>58c2c7a539a504.05405285-1</gtr:outcomeId><gtr:partnerContribution>Physics based cloth simulation expertise</gtr:partnerContribution><gtr:piContribution>Validation of physics based cloth simulation against real cloth measurements</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Body Metrics</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>BodyMetrics</gtr:description><gtr:id>375C76DA-A01C-4E81-A219-92A96E34B9D6</gtr:id><gtr:impact>research publications and tools</gtr:impact><gtr:outcomeId>58c2c862648960.26633212-1</gtr:outcomeId><gtr:partnerContribution>Access to data of body scans</gtr:partnerContribution><gtr:piContribution>Methods for body shape measurement from images</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This project introduced methods for body shape measurement from a single image. This method was used to develop a mobile app for clothing recommendation for use in online retail.</gtr:description><gtr:firstYearOfImpact>2013</gtr:firstYearOfImpact><gtr:id>52EB7CD9-EF4F-47C9-AA26-4291954E0434</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545cfb95c48b56.89188915</gtr:outcomeId><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Retail</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The primary advance achieved in this project is the introduction of a method to measure and classify human body shape from a single image capture on a mobile device.

This technology has been deployed and evaluated as a mobile app to allow clothing recommendation for online retail. 



Key contributions of the research include:

(1) Novel learnt representations of human body shape and pose variation from a database of 3D body scans.

(2) Robust reconstruction of human shape from a single image with unknown camera calibration.

(3) Statistical model based human segmentation from images of people in natural scenes.

(4) Classification of human body shape using image-based reconstruction.

(5) Measurement of human shape dimensions from a single image for clothing size recommendation.

(6) Development of a mobile app allowing body shape classification and measurement from a single image captured on a mobile device.

(7) A low-cost system for human body scanning using multiple Kinect RGBD sensors to capture a database of 3D body shape.



The application for human body shape classification and measurement has been integrated with an online system for clothing recommendation developed by the London College of Fashion as part of the project.

This system has been evaluated for in-store and online clothing recommendation with high-street retailers.</gtr:description><gtr:exploitationPathways>Primary application: Online clothing retail.



Secondary applications: Body shape measurement for health and fitness applications. 

Technology for estimation and classification of human body shape from a single image has attract considerable interest for commercialisation from online and high-street retailers internationally. The mobile app is currently under discussion for licensing. This research is also the focus of further development and technology transfer.</gtr:exploitationPathways><gtr:id>8E4E9D0C-FF63-41BB-85CB-FAA21C521C85</gtr:id><gtr:outcomeId>r-3569645260.99119877927856</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Retail,Security and Diplomacy</gtr:sector></gtr:sectors><gtr:url>http://cvssp.org/Personal/AdrianHilton</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>Multiple view video datasets and reconstructed 4D models</gtr:description><gtr:id>B42B42CF-E3D9-460C-9C24-B3706E4179BC</gtr:id><gtr:impact>Data available is used by over 300 research groups worldwide. It is considered the benchmark dataset for research in this field.</gtr:impact><gtr:outcomeId>56e13d3a66d971.88681288</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Multiview and 4D Video</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://cvssp.org/data/cvssp3d/</gtr:url></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C3183F8B-23C3-47DB-8106-107DE15B2D5F</gtr:id><gtr:title>Shape Mate: A Virtual Tape Measure</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/960f1928541d8a372e5403f5082cfec4"><gtr:id>960f1928541d8a372e5403f5082cfec4</gtr:id><gtr:otherNames>Alexandros Neophytou (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_148520398813d735f8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>66AE743D-E0CF-4DF5-A1B6-7B345BB5ED48</gtr:id><gtr:title>3D Human Body Shape Estimation and Classification for Online Fashion</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/960f1928541d8a372e5403f5082cfec4"><gtr:id>960f1928541d8a372e5403f5082cfec4</gtr:id><gtr:otherNames>Alexandros Neophytou (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_785718677613d73544</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C9399E67-9F41-4950-AECC-D184A0622395</gtr:id><gtr:title>Shape and Pose Space Deformation for Subject Specific Animation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/17927ebcf630994340aee4eee61401d1"><gtr:id>17927ebcf630994340aee4eee61401d1</gtr:id><gtr:otherNames>Neophytou A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53d056056214646e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D9737080-6FCD-4E0A-B081-9DF5C2F7D455</gtr:id><gtr:title>A Layered Model of Human Body and Garment Deformation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/17927ebcf630994340aee4eee61401d1"><gtr:id>17927ebcf630994340aee4eee61401d1</gtr:id><gtr:otherNames>Neophytou A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56e0b3bfce6fc1.17096940</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>21925EDE-60D6-4BB4-909E-F6E28FA650E5</gtr:id><gtr:title>3D Scanning with Multiple Depth Sensors</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7b680c09db100d051f6da36dcb09b88e"><gtr:id>7b680c09db100d051f6da36dcb09b88e</gtr:id><gtr:otherNames>Joe Kilner (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_483669880413e573f2</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/I031936/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>608431EA-925E-44D8-A1E2-8C24B4768085</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Design</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>7A6348FE-CF33-4F09-B4DA-BA731821F803</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Product Design</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>