<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/9DE31489-7E3B-4E34-BA75-DD367FF833FB"><gtr:id>9DE31489-7E3B-4E34-BA75-DD367FF833FB</gtr:id><gtr:name>The Foundry Visionmongers Ltd</gtr:name><gtr:address><gtr:line1>The Foundry</gtr:line1><gtr:line2>5 Golden Square</gtr:line2><gtr:postCode>W1F 9HT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/04DA7C22-39FD-419C-858C-6C49364C0D54"><gtr:id>04DA7C22-39FD-419C-858C-6C49364C0D54</gtr:id><gtr:name>Gobo Games</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/456959E8-6263-4AD9-913A-4D8FD0F9985E"><gtr:id>456959E8-6263-4AD9-913A-4D8FD0F9985E</gtr:id><gtr:name>Double Negative</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9DE31489-7E3B-4E34-BA75-DD367FF833FB"><gtr:id>9DE31489-7E3B-4E34-BA75-DD367FF833FB</gtr:id><gtr:name>The Foundry Visionmongers Ltd</gtr:name><gtr:address><gtr:line1>The Foundry</gtr:line1><gtr:line2>5 Golden Square</gtr:line2><gtr:postCode>W1F 9HT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/04DA7C22-39FD-419C-858C-6C49364C0D54"><gtr:id>04DA7C22-39FD-419C-858C-6C49364C0D54</gtr:id><gtr:name>Gobo Games</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/456959E8-6263-4AD9-913A-4D8FD0F9985E"><gtr:id>456959E8-6263-4AD9-913A-4D8FD0F9985E</gtr:id><gtr:name>Double Negative</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A5AB67B6-BFE6-4C91-9391-5DC826CAC682"><gtr:id>A5AB67B6-BFE6-4C91-9391-5DC826CAC682</gtr:id><gtr:name>The Walt Disney Company</gtr:name><gtr:address><gtr:line1>500 S. Buena Vista Street</gtr:line1><gtr:line2>Hammersmith</gtr:line2><gtr:line4>Burbank</gtr:line4><gtr:line5>CA 91521</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0879843D-CC22-4CA2-8EE9-3415649FCD30"><gtr:id>0879843D-CC22-4CA2-8EE9-3415649FCD30</gtr:id><gtr:name>Gobo Games Limited</gtr:name><gtr:address><gtr:line1>Unit 8, Hove Business Centre</gtr:line1><gtr:line2>Fonthill Road</gtr:line2><gtr:postCode>BN3 6HA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CF3A2998-3D4E-4019-9694-5D3E5238AE62"><gtr:id>CF3A2998-3D4E-4019-9694-5D3E5238AE62</gtr:id><gtr:name>Crytek Ltd</gtr:name><gtr:address><gtr:line1>122 Canal Street</gtr:line1><gtr:line2>Nottingham</gtr:line2><gtr:postCode>NG1 7HG</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0954F2A0-CC4B-4798-9401-D96389885987"><gtr:id>0954F2A0-CC4B-4798-9401-D96389885987</gtr:id><gtr:name>Double Negative Ltd</gtr:name><gtr:address><gtr:line1>Double Negative Ltd</gtr:line1><gtr:line2>77 Shaftesbury Avenue</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W1D 5DU</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/BAD3780F-6F65-4292-A69C-923CAE91A7BB"><gtr:id>BAD3780F-6F65-4292-A69C-923CAE91A7BB</gtr:id><gtr:name>British Broadcasting Corporation - BBC</gtr:name><gtr:address><gtr:line1>British Broadcasting Corporation</gtr:line1><gtr:line2>Broadcasting House</gtr:line2><gtr:line3>Portland Place</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>W1A 1AA</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/7B3C0C16-DEA3-4C5B-8405-10907BB3B6C8"><gtr:id>7B3C0C16-DEA3-4C5B-8405-10907BB3B6C8</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:otherNames>Maxwell</gtr:otherNames><gtr:surname>Hall</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5EFEEA9A-A081-437B-A0C8-951478FB34F7"><gtr:id>5EFEEA9A-A081-437B-A0C8-951478FB34F7</gtr:id><gtr:firstName>Darren</gtr:firstName><gtr:otherNames>Peter</gtr:otherNames><gtr:surname>Cosker</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/ACF7E721-2E00-4CDF-966F-06AAA770B4F3"><gtr:id>ACF7E721-2E00-4CDF-966F-06AAA770B4F3</gtr:id><gtr:firstName>Yongliang</gtr:firstName><gtr:surname>Yang</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/05DCE62C-C1BC-4909-A0F4-ABE2936C062B"><gtr:id>05DCE62C-C1BC-4909-A0F4-ABE2936C062B</gtr:id><gtr:firstName>Neill</gtr:firstName><gtr:otherNames>Duncan</gtr:otherNames><gtr:surname>Campbell</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FK02339X%2F1"><gtr:id>E95752C0-B160-49FA-99F3-AD3BDAA626E2</gtr:id><gtr:title>Acquiring Complete and Editable Outdoor Models from Video and Images</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K02339X/1</gtr:grantReference><gtr:abstractText>Imagine being able to take a camera out of doors and use it to capture 3D models of the world around you. The landscape at large, including valleys and hills replete with trees, rivers, waterfalls, fields of grass, clouds; seasides with waves rolling onto shore here and crashing onto rocks over there; urban environments complete with incidentals such as lamposts, balconies, and the detritus of modern life. Imagine models that look and move like the real thing. Models that you can use with to make up new scenes of your own, which you can control as you please, and render in how you like. You can zoom into to see details, and out to get a wide impression.

This is an impressive vision, and one that is well beyond current know-how. Our plan is to take a major step towards meeting this vision. We will enable users to use video and images to capture large scale scenes of selected types and populate them with models trees, fountains, street furniture and such like, again carefully selecting the types of objects. We will provide software that recognises the sort of environment the camera is in, and objects in that environment, so that 3D moving models can be automatically created.

This will prove very useful to our intended user group, which is the creative industries in the UK: films, games, broadcast. Modelling outdoor scenes is expensive and time consuming, and the industry recognises that video and images are excellent sources for making models they can use. To help them further we will develop software that makes use of their current practice of acquiring survey shots of scenes, so that all data is used at many levels of detail. Finally we will wrap all of our developments into a single system that shows the acquisition, editing and control of complete outdoor environments is one step closer.</gtr:abstractText><gtr:potentialImpactText>The impact of our work is likely to be significant both academically and industrially. Indeed, we hope to place UK PLC in a world
leading position with respect to model acquisition in outdoor environments.

TO make academic impact we will publish in high quality forums (eg. ICCV, SIGGRAPH) we will organise workshops, two domestically and one internationally. One domestic workshop will be run with the help of the British Machine Vision Association as part of their one-day seminar series, the other via the London Graphics Seminar series which is well attended by both academia and the creative industries. Internationally, we will organise a workshop at a major conference such as Eurographics or ICCV.

Our industrial and communication impact plan has three main parts:
(1) Engage in research of the highest academic quality, yet ensure output are useful to industry; we have convened an
 Industrial Advisory Panel (IAP) for this.
(2) Transfer this research into the industry, via the Engineering Doctoral (Eng.D.) centres.
(3) Disseminate our work to the general public as widely as possible.

The IAP keeps our research industrially relevant, without compromising academic integrity. One role of the IAP is to suggest classes of landscape, phenomena of interest and such like, which helps us in selecting which scenes and scene elements to target for model acquisition. A second role is to advise us on industry practice regarding current acquisition via cameras, and modelling needs in terms of editing requirements etc. A third role is to keep us abreast of innovations in industry. The IAP comprises BBC, Disney, Crytec, Gobo Games, EA, Double Negative, and The Foundry, which represents a cross section of the UK's world-class creative sector.

Each academic partner has direct access to an Eng.D. centre: the Centre for Digital Entertainment and Bath, and the Virtual Environments, Imaging and Visualization centre at UCL. Both Eng.D. centres are focussed upon placing doctoral level students into the creative industries, jointly supervised by an academic and an industrial researcher. This makes them the ideal vehicle by which to transfer our IP. We already have working relationships will all IAP members through these Eng.D. centres.

Dissemination to the wider public is important. It helps science in general, and the EPSRC in particular, maintain a relationship with the tax payer. We are luck in that our work is visual in nature and therefore easily accessible at a consumer level - indeed our previous work has enjoyed media reportage on a world wide basis on websites, newpapers, radio and TV. This has resulted in many enquiries from industry and from fellow academics. We will continue to produce show-reels, maintain web-sites and make press releases. In addition we will speak about our work at public meeting, such as Bath Camp.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-04-21</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-10-23</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>959780</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>BBC Research &amp; Development</gtr:department><gtr:description>Industrial Advisory Panel (BBC, Gobo, DNeg, Foundry)</gtr:description><gtr:id>1E3A693D-E45B-4EAB-A0DC-44746C6CF6DF</gtr:id><gtr:impact>We are actively engaged with partners to transfer our research IP into their hands. Bath's doctoral training centre, the EPSRC funded Centre for Digital Entertainment is a viable option.</gtr:impact><gtr:outcomeId>56c2fc40b0b0c7.90907078-2</gtr:outcomeId><gtr:partnerContribution>Partners provide problem directions, and avenue for industrial impact.</gtr:partnerContribution><gtr:piContribution>We provide core research capability and academic impacy.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Gobo Games</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Industrial Advisory Panel (BBC, Gobo, DNeg, Foundry)</gtr:description><gtr:id>201E9761-0BE3-40C2-A51B-A31165C14E55</gtr:id><gtr:impact>We are actively engaged with partners to transfer our research IP into their hands. Bath's doctoral training centre, the EPSRC funded Centre for Digital Entertainment is a viable option.</gtr:impact><gtr:outcomeId>56c2fc40b0b0c7.90907078-1</gtr:outcomeId><gtr:partnerContribution>Partners provide problem directions, and avenue for industrial impact.</gtr:partnerContribution><gtr:piContribution>We provide core research capability and academic impacy.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>The Foundry Visionmongers Ltd</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Industrial Advisory Panel (BBC, Gobo, DNeg, Foundry)</gtr:description><gtr:id>0763893A-7959-43FB-B423-FBE43BAB2817</gtr:id><gtr:impact>We are actively engaged with partners to transfer our research IP into their hands. Bath's doctoral training centre, the EPSRC funded Centre for Digital Entertainment is a viable option.</gtr:impact><gtr:outcomeId>56c2fc40b0b0c7.90907078-4</gtr:outcomeId><gtr:partnerContribution>Partners provide problem directions, and avenue for industrial impact.</gtr:partnerContribution><gtr:piContribution>We provide core research capability and academic impacy.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Double Negative</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Industrial Advisory Panel (BBC, Gobo, DNeg, Foundry)</gtr:description><gtr:id>A550DE7F-2D20-4722-8CBB-B386D872CCA2</gtr:id><gtr:impact>We are actively engaged with partners to transfer our research IP into their hands. Bath's doctoral training centre, the EPSRC funded Centre for Digital Entertainment is a viable option.</gtr:impact><gtr:outcomeId>56c2fc40b0b0c7.90907078-3</gtr:outcomeId><gtr:partnerContribution>Partners provide problem directions, and avenue for industrial impact.</gtr:partnerContribution><gtr:piContribution>We provide core research capability and academic impacy.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University College London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Computer Science</gtr:department><gtr:description>UCL academic partners</gtr:description><gtr:id>87BA31F2-2CEB-43A3-B722-22D72E326A6A</gtr:id><gtr:impact>We have held several meetings, including with the IAP.
We have identified further leads, such as the British Library.</gtr:impact><gtr:outcomeId>56df059e9c7e86.37638619-1</gtr:outcomeId><gtr:partnerContribution>We collaborate on research, each way. This include UCL staff visiting Bath.</gtr:partnerContribution><gtr:piContribution>We collaborate on research, each way. This includes Bath staff visiting UCL.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Playfair Capital 2015 AI Summitt</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>26E344C6-FE69-4FFF-BE98-6A198D9CF0A1</gtr:id><gtr:impact>Probably about 300 people attended this event organized to showcase how AI and Machine Learning progress could potentially be explored by and for private industry. G. Brostow was an invited speaker for the panel, and the event was held at Bloomberg News headquarters in London.</gtr:impact><gtr:outcomeId>56da075f62fbd7.88906851</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Conference Organisation</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D3F747F5-72D1-42D2-9953-A6918541AEB9</gtr:id><gtr:impact>We ran (as paper chair in 2013, and 2015, general chair in 2014, and in 2016) the Computational Visual Media Production conference, aimed at bringing together academics and industry in the creative sector. It therefore fits with our aims for pathways to impact, enabling OAK researchers to engage directly with industry.</gtr:impact><gtr:outcomeId>56df06f93734e8.69297626</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www.cvmp-conference.org/2014-Papers</gtr:url><gtr:year>2013,2014,2015,2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We are actively engaged with companies to transfer our IP to them. This includes pathways via the Center for Digital Entertainment DTC at Bath / Bournemouth.

We have engaged with the public, in particular A-level students as part of a wider dissemination brief.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>40289FDC-BC19-441F-8A9F-970154F7E14D</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56dfedd2d355f5.49019542</gtr:outcomeId><gtr:sector>Creative Economy,Education</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>(i) Spatio-temporal features, that we call HOMES, can be used to segment complex moving objects from a background to state of the art levels.

(ii) We can now recover models of fire, and control them to create new output. This is being put into the hands of industry.

(iii) Solid mathematical approaches to data filtering with a little interaction yields excellent results in terms of building architectural models of existing buildings.</gtr:description><gtr:exploitationPathways>The creative sector have expressed a strong interest in the work to date.</gtr:exploitationPathways><gtr:id>3A39AC0E-CFB7-4AAA-9C48-715E1BB0C9E7</gtr:id><gtr:outcomeId>56c300b46adbd3.50684014</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>03699A8A-E3EF-4216-B442-268DA1C3F443</gtr:id><gtr:title>Learning similarity metrics for dynamic scene segmentation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b14079442045b791ed7c6c7985dfb2c9"><gtr:id>b14079442045b791ed7c6c7985dfb2c9</gtr:id><gtr:otherNames>Teney D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56baff0b094746.73430328</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>285B9E1C-669C-4CB0-8AA9-E6FDF47BF891</gtr:id><gtr:title>Scalable inside-out image-based rendering</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f08b99c04b6a7da6f02ff2f1e2a9fb80"><gtr:id>f08b99c04b6a7da6f02ff2f1e2a9fb80</gtr:id><gtr:otherNames>Hedman P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0730-0301</gtr:issn><gtr:outcomeId>58c7bbd0cfddb3.55474623</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F2A1C24F-0980-451E-A4A3-015D34B061B8</gtr:id><gtr:title>Computational network design from functional specifications</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d68a56ff134fbcc40a5fbe7eb869b5f0"><gtr:id>d68a56ff134fbcc40a5fbe7eb869b5f0</gtr:id><gtr:otherNames>Peng C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58aea334c0a285.19841648</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>589556AF-D902-4799-9872-F43B260C9F68</gtr:id><gtr:title>Comprehensive Use of Curvature for Robust and Accurate Online Surface Reconstruction.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/13d2cad01e814b9ebf63dc102c627d06"><gtr:id>13d2cad01e814b9ebf63dc102c627d06</gtr:id><gtr:otherNames>Lefloch D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>58c7bee22a79f6.55379863</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A85452FB-6114-4606-81E2-33B792C3D2EC</gtr:id><gtr:title>Roto++</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce73e661495882f5061c864c6e2c1985"><gtr:id>ce73e661495882f5061c864c6e2c1985</gtr:id><gtr:otherNames>Li W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0730-0301</gtr:issn><gtr:outcomeId>58c7c63fd087c2.77077523</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5AABD8AC-2C34-4DA3-9166-B0DF71AC7AC4</gtr:id><gtr:title>Segmentation of dynamic scenes with distributions of spatiotemporally oriented energies</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8addf917c3c23f433a04254e450b229a"><gtr:id>8addf917c3c23f433a04254e450b229a</gtr:id><gtr:otherNames>Teney D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56dddb2b708be3.66023527</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8EDF5075-22D3-4BFE-8841-24781B89DE29</gtr:id><gtr:title>Learn to model blurry motion via directional similarity and filtering</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce73e661495882f5061c864c6e2c1985"><gtr:id>ce73e661495882f5061c864c6e2c1985</gtr:id><gtr:otherNames>Li W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a2fefcccb8742.03147728</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3236B128-9074-4212-9636-2BC5FD08C516</gtr:id><gtr:title>Blur robust optical flow using motion channel</gtr:title><gtr:parentPublicationTitle>Neurocomputing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce73e661495882f5061c864c6e2c1985"><gtr:id>ce73e661495882f5061c864c6e2c1985</gtr:id><gtr:otherNames>Li W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>585d6c6d397a23.67510110</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6F758564-6700-45ED-8E61-DCF1CBB0CC4F</gtr:id><gtr:title>Fitting quadrics with a Bayesian prior</gtr:title><gtr:parentPublicationTitle>Computational Visual Media</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8f36e2018940c5129e922d981cb01776"><gtr:id>8f36e2018940c5129e922d981cb01776</gtr:id><gtr:otherNames>Beale D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56c2f069dcbba7.82325862</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FDFABE38-A811-4207-81BA-982941C31ABB</gtr:id><gtr:title>My Text in Your Handwriting</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9c492bb39ff2308f7f364eb19212b22b"><gtr:id>9c492bb39ff2308f7f364eb19212b22b</gtr:id><gtr:otherNames>Haines T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56d9c9938ffb47.51602429</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E84E5E23-34A0-465A-BB3B-6238D808AAE7</gtr:id><gtr:title>Feature-Aware Pixel Art Animation</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ced921809b4f77bcb6c6a186fb7e48f3"><gtr:id>ced921809b4f77bcb6c6a186fb7e48f3</gtr:id><gtr:otherNames>Kuo M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58aea334e98c18.05254345</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A3DDD9A4-4614-496A-893D-8048CF0D01BE</gtr:id><gtr:title>Video interpolation using optical flow and Laplacian smoothness</gtr:title><gtr:parentPublicationTitle>Neurocomputing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce73e661495882f5061c864c6e2c1985"><gtr:id>ce73e661495882f5061c864c6e2c1985</gtr:id><gtr:otherNames>Li W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>585d6c7285d997.33775188</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K02339X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>