<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/468F2797-5295-4912-BDED-8F3402CE246A"><gtr:id>468F2797-5295-4912-BDED-8F3402CE246A</gtr:id><gtr:name>New York University</gtr:name><gtr:address><gtr:line1>7 East 12th Street</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/465A95CE-B9CC-4267-AA3E-CB35040AFDDD"><gtr:id>465A95CE-B9CC-4267-AA3E-CB35040AFDDD</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:otherNames>Eric</gtr:otherNames><gtr:surname>Turner</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG050821%2F1"><gtr:id>BD8300EB-CBAF-44F8-B4FE-B708851CA51E</gtr:id><gtr:title>Probabilistic Auditory Scene Analysis</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>EP/G050821/1</gtr:grantReference><gtr:abstractText>Auditory environments are typically very complicated. For example, thecocktail party comprises many sources; the chinking of glasses; thechattering of the many guests; the sound of backgroundmusic. Nevertheless, our auditory system can make sense of such ascene; it can work out how many acoustic sources there are anddetermine the individual contributions to the scene fromeach. Remarkably, it can do this using the information from a singlemicrophone. A major goal of auditory neuroscience is to understandhow the auditory system achieves this feat.Broadly speaking, it is thought that there are three stages toauditory scene analysis. The first stage is well understoodphysiologically and that is to convert the incoming sound into atime-frequency representation. This reveals the local energy in afrequency band at a particular time. In the second stage,psychophysical evidence suggests that primitive grouping principlesare used to group local regions of spectral-temporal energy arisingfrom a common source. By using simple stimuli - like tones and noise -a long list of primitive grouping principles have been elucidated. Forexample, the principle of good continuation identifies smoothlyvarying features with a single source and abrupt changes as asignature of separate sources. In the final stage of auditory sceneanalysis, called schema-based grouping, higher level knowledge, likethe structure of music or speech, is used to bind the groups ofspectral-temporal energy into streams so that there is one stream foreach source.There are many outstanding questions with this framework. Oneimportant open question is the role that auditory cortex plays inauditory scene analysis as it is not well established. Anotherconcerns the generality and completeness of the established list ofprimitive grouping rules. For although the principles successfullycharacterise perception of simple sounds it is unclear how successfuland relevant the description is for natural sounds. This project aims to resolve these questions though modelling work,psychophysics experiments and neural recording experiments. The newidea is to view the primitive grouping principles as arising frominference in a latent variable model of auditory scenes. A latentvariable model is a description of how an auditory scene, like thatencountered at a coctail party, is composed of latent auditorysources, like the chinking glasses and chattering guests. It alsoincludes a description of the statistics of these sources, like thefact that the chinking glasses tend to be isolated, high frequencyevents whist the chattering rather more constant and lower infrequency. The idea is that the brain is trying to infer these latentsources using prior knowledge of their statistics. New tools ofprobabilistic inference can make these intuitions concrete.This new perspective, called probabilistic scene analysis, has twomain advantages; one practical and one theoretical. The practicaladvantage is that a statistical characterisation of sounds can be usedto produce stimuli with complicated, but controlled structure, for usein experiments. The theoretical benefit is that the list of primitivegrouping rules, and the manner in which they trade off, are nowderived from the statistics of sounds; Heuristic implementation is nolonger required. This enables us to predict the results of theexperiments. In particular, the psychophysics experiments are aimedat resolving both how auditory grouping operates in synthetic auditorytextures (e.g. rain, wind, water etc.) and whether this is consistentwith the probabilistic account. Furthermore, the neural recordingexperiments will investigate the role of auditory cortex in auditoryscene analysis, and the hypothesis that it is representing high levelstatistics of sounds like slowly varying modulatory components.</gtr:abstractText><gtr:fund><gtr:end>2013-01-03</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-01-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>232105</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>MRC Cognition and Brain Sciences Unit</gtr:department><gtr:description>Collaboration with Dr. Carlyon at the MRC CBSU</gtr:description><gtr:id>1714D425-D9E5-443B-B3DE-7B3F40D51884</gtr:id><gtr:impact>-- reveived &amp;pound;17,000 grant from Trinity College to continue research (used to fund a Research Assistant who gathered pilot data for the project)
-- received &amp;pound;100,000 donation from Advanced Bionics to develop a test for fitting cochlear implants (will be used to fund a postdoc starting in May)</gtr:impact><gtr:outcomeId>5453b202632c45.65645825-1</gtr:outcomeId><gtr:partnerContribution>-- provided new learning algorithms that produced stimuli for the experiments
-- experiments were carried out by Dr. Carlyon's research group</gtr:partnerContribution><gtr:piContribution>-- design of stimuli for improved fitting of cochlear implants
-- design of stimuli for tinnitus audio therapy</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The results from this grant have been used in the following ways:
-- formed the basis for an EPSRC First Grant
-- formed the basis for an iindustrial partnership with Google on audio recognition and restoration
-- being applied to improving cochlear implants</gtr:description><gtr:firstYearOfImpact>2011</gtr:firstYearOfImpact><gtr:id>5E5EA985-99FE-46EA-85A1-5688BFD45671</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545f54e907bac7.92644407</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have provided new approaches to a number of classic and widely used signal processing techniques using modern day machine learning methods. The new approaches have two key advantages. First, they adapt to the input signal meaning that they can devote their limited representational resources to where they are most useful. Second, they handle uncertainty which arises from noise and other sources, in an automatic way. This means that the new representations are of higher quality than the old approaches and they are more robust to noise, both of which makes them suitable for real world application. We have demonstrated their usefulness on a range of engineering, scientific, and medical applications. Including the removal of noise from speech and the analysis of brain recordings.</gtr:description><gtr:exploitationPathways>The engineering applications of these techniques include, speech recognition, speaker identification, retrieval of audio for search systems and pitch detection and manipulation. 



The medical application of these methods include, analysis of brain recordings from patients, processing for cochlear implants and hearing aids, and we are currently developing a method to relieve tinnitus.</gtr:exploitationPathways><gtr:id>7167110B-3C35-45D0-B0D0-F19EE46EB1D2</gtr:id><gtr:outcomeId>r-5475967233.5125277711e18</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.gatsby.ucl.ac.uk/~turner/index.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>3F259B1A-D54B-497B-BC73-56B6A904F499</gtr:id><gtr:title>Decomposing signals into a sum of amplitude and frequency modulated sinusoids using probabilistic inference</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/592bdc57433c2bba1cf9ee5ade23576b"><gtr:id>592bdc57433c2bba1cf9ee5ade23576b</gtr:id><gtr:otherNames>Turner R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>doi_53d05805833af912</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AA504142-1F15-4C51-A6F1-91B3A36E095F</gtr:id><gtr:title>Deep Gaussian processes for regression using approximate expectation propagation</gtr:title><gtr:parentPublicationTitle>33rd International Conference on Machine Learning, ICML 2016</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5e8e12b2d4b767a089179433376d47d2"><gtr:id>5e8e12b2d4b767a089179433376d47d2</gtr:id><gtr:otherNames>Bui T.D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c815f3786168.35152735</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>80DB7A28-0665-4B04-80A1-66B79AE6CE90</gtr:id><gtr:title>Rebuilding the limit order book: sequential Bayesian inference on hidden states</gtr:title><gtr:parentPublicationTitle>Quantitative Finance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7309ab5562d758467290071a4701ce1d"><gtr:id>7309ab5562d758467290071a4701ce1d</gtr:id><gtr:otherNames>Christensen H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>54539eb41d6ed7.01852722</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>82AAF67F-2D5D-4BCF-82FA-460DC57C96A3</gtr:id><gtr:title>Probabilistic amplitude and frequency demodulation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/508ae1e8aceff919a21aad586bf7f210"><gtr:id>508ae1e8aceff919a21aad586bf7f210</gtr:id><gtr:otherNames>Richard Turner (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>m_194951278614039ddc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>602468E0-6FCF-470B-9CB5-164255D68248</gtr:id><gtr:title>Time-Frequency Analysis as Probabilistic Inference</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/592bdc57433c2bba1cf9ee5ade23576b"><gtr:id>592bdc57433c2bba1cf9ee5ade23576b</gtr:id><gtr:otherNames>Turner R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545f5984513d36.81762718</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>000CBE4A-4120-49B6-B9B1-8023C996E65F</gtr:id><gtr:title>Demodulation as Probabilistic Inference</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/592bdc57433c2bba1cf9ee5ade23576b"><gtr:id>592bdc57433c2bba1cf9ee5ade23576b</gtr:id><gtr:otherNames>Turner R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d05c05cf06318a</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G050821/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>