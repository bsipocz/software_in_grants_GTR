<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/44B3B477-75B9-44EB-8916-318136B765B2"><gtr:id>44B3B477-75B9-44EB-8916-318136B765B2</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Johnston</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FF01354X%2F1"><gtr:id>2880DEA6-DD45-44AE-AA83-2020AD909B2C</gtr:id><gtr:title>From Local to Global Motion Perception</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/F01354X/1</gtr:grantReference><gtr:abstractText>A good example of global motion is the experience you have of snow flakes blown by the wind. You know there is a global cause - the wind, but that realisation is carried by the motion of each individual snowflake. A single snowflake doesn't carry enough information about the global pattern. The question is, how do visual neurones that only see a small part of the snow storm deliver an impression of the global motion? The standard explanation is that in higher areas of the brain neurones add up the signal from many neurones, each of which respond to a part of the display. The problem with this idea is that these neurones would attribute a single value for their whole field, the motion of each snowflake would be lost and the process would average over areas that need to be kept distinct, like the motion of a person in front of a window with the snow storm behind. The motion of a flock of starlings appears to be directed, but actually it has been shown that one can explain the global collective behaviour with a few simple rules. Idealised versions of these systems have been applied to diverse problems in computer science including solving global optimisation problems. We think that this general approach can resolve the conundrum of how to link local and global motion perception. We intend to build a model to investigate what global effects a particular set of local rules for combining local motion might have. We also intend to investigate visual motion phenomena that appear to indicate (because they show a dependence on spatial density, or evolve over time, or show some change in global motion due to local influences) that the human visual system contains a dynamic, evolving global motion system, which can represent large scale events while remaining locally precise.</gtr:abstractText><gtr:technicalSummary>The linking of local and global information remains a fundamental problem for vision science. We need to characterise the motion of objects and surfaces but neurones in the early part of the cortical pathway only see a very small portion of the object. Because of the aperture problem the average of the local estimates of velocity always provides an underestimate of the true object motion. Information from different parts of the object needs to be combined in a way that takes into account the relationship between local and global motion. In addition, simply averaging local motion signals will blur any motion discontinuities at object boundaries that provide important information for image segmentation. Taking inspiration from work on collective animal behaviour, such a schooling and flocking, in which complex behaviour can be modelled using simple local rules, and recognising the successes in computer science that have come from abstracting and generalising these systems to solve global optimisation problems, we intend to investigate whether global motion percepts can be arrived at by the propagation of information through local interactions. One aim is the partitioning of the velocity estimates locally into global and local motion components. We will also investigate whether the global motion system exhibits behaviour characteristic of a local interactive rule-based system, such a dependency on the density and spatial distribution of elements, evolution of a global solution over time and hysteresis. We will also develop mathematical and computational models to manage the complexity of generating global predictions from local rules.</gtr:technicalSummary><gtr:fund><gtr:end>2011-05-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2008-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>304056</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We discovered that
1) information from local motion signals are integrated before they influence the apparent position of moving objects
2) The motion aftereffect result storm an interaction between local and global levels of processing in the human visual system
3) We discovered two new computational methods for combining local velocity signals in global motion perception through mapping the velocities into an inverse velocity space. This mapping strategy allowed a significant algorithmic simplification that could be exploited by the human visual system.</gtr:description><gtr:exploitationPathways>They add to the understanding of how global motion fields may be calculated from local estimates of motion.</gtr:exploitationPathways><gtr:id>83818119-BA8B-4317-AE91-0B00D835FA21</gtr:id><gtr:outcomeId>56e0a47d641364.72062026</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>2E24B45C-F084-4F6F-9A87-B01F4B7BC029</gtr:id><gtr:title>Multiple-stage ambiguity in motion perception reveals global computation of local motion directions.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e67b5445d26adb6f7b1d6ff03101bf8"><gtr:id>6e67b5445d26adb6f7b1d6ff03101bf8</gtr:id><gtr:otherNames>Rider AT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5a318ab215a821.77996373</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0D205B59-B9F7-41DD-B6A9-70A8F321F050</gtr:id><gtr:title>The role of the harmonic vector average in motion integration.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8aafb8590e656447f6058c577f606dca"><gtr:id>8aafb8590e656447f6058c577f606dca</gtr:id><gtr:otherNames>Johnston A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn><gtr:outcomeId>546257aac881e6.72675572</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D85DBA5D-40AD-4C38-9691-A30B5A89D89E</gtr:id><gtr:title>Perceptual compression of visual space during eye-head gaze shifts.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1366277533069159fe791ce229e0bdbd"><gtr:id>1366277533069159fe791ce229e0bdbd</gtr:id><gtr:otherNames>Richard A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56e0a0d4b1c6e6.18153034</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EA21E906-A1B9-4E93-9421-4152D3DA66B3</gtr:id><gtr:title>The detection of the motion of contrast modulation: a parametric study.</gtr:title><gtr:parentPublicationTitle>Attention, perception &amp; psychophysics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f2e76749f9e39f51aded32ff36aa7c96"><gtr:id>f2e76749f9e39f51aded32ff36aa7c96</gtr:id><gtr:otherNames>Cropper SJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1943-3921</gtr:issn><gtr:outcomeId>56e0a0d58233a7.22086462</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4E5D35B2-FF65-4024-85A6-7BDB86BDB1CC</gtr:id><gtr:title>Motion-induced position shifts in global dynamic Gabor arrays.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e67b5445d26adb6f7b1d6ff03101bf8"><gtr:id>6e67b5445d26adb6f7b1d6ff03101bf8</gtr:id><gtr:otherNames>Rider AT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56e0a0d5b80ec2.96993233</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>86639B9D-0107-4972-8D96-FD83D2C046E3</gtr:id><gtr:title>An Adaptable Metric Shapes Perceptual Space.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f07b14cfbec3fe33bec915625552e84"><gtr:id>2f07b14cfbec3fe33bec915625552e84</gtr:id><gtr:otherNames>Hisakata R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>585d3dcf6afcd4.62843412</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>99842FAA-2DC1-4CEE-93B9-CFC342CE5ED2</gtr:id><gtr:title>Motion drag induced by global motion Gabor arrays.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6403ef9e6e2f224e921aa27ea99266c6"><gtr:id>6403ef9e6e2f224e921aa27ea99266c6</gtr:id><gtr:otherNames>Scarfe P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56e0a0d50ed7d8.04638467</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F251CC30-0682-4890-BE66-705979CD7749</gtr:id><gtr:title>Biologically inspired framework for spatial and spectral velocity estimations.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a11bf0b9bd33b57e69f73d9b7b2af962"><gtr:id>a11bf0b9bd33b57e69f73d9b7b2af962</gtr:id><gtr:otherNames>Liang X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>56e0a0d4cfc778.51002814</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/F01354X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>