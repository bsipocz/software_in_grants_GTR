<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Ear Institute</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8D0DC363-21C3-4376-9F5E-0384E9BAD495"><gtr:id>8D0DC363-21C3-4376-9F5E-0384E9BAD495</gtr:id><gtr:firstName>Jennifer</gtr:firstName><gtr:otherNames>F.</gtr:otherNames><gtr:surname>Linden</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2567E425-43D3-41E0-AC83-DC6C7A0EB10A"><gtr:id>2567E425-43D3-41E0-AC83-DC6C7A0EB10A</gtr:id><gtr:firstName>Arne</gtr:firstName><gtr:otherNames>Freek</gtr:otherNames><gtr:surname>Meyer</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/250CACA5-0E62-4FF6-BC77-131EAD447902"><gtr:id>250CACA5-0E62-4FF6-BC77-131EAD447902</gtr:id><gtr:firstName>Maneesh</gtr:firstName><gtr:surname>Sahani</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FP007201%2F1"><gtr:id>ED309EDF-153D-40F4-AF66-9F52390916FA</gtr:id><gtr:title>Neuronal Substrates of Perceptual Salience in the Auditory System</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/P007201/1</gtr:grantReference><gtr:abstractText>You are standing in the midst of a departmental social event with a plastic cup of wine in your hand, idly thinking about your cat, while the sound of multiple ongoing conversations washes over you. Suddenly, you hear your name mentioned in one of those conversations, and what was formerly an indistinct hum of voices separates into background noise and a foreground conversation that now commands your full attention. How does this happen? How is perceptual salience represented in the auditory brain? How does auditory processing interact with behavioural state and attention to differentiate hearing from listening?

We have recently developed powerful new computational tools for addressing these questions, which have enabled us to analyse how the context in which a sound occurs affects the representation of that sound in the auditory brain. Using these novel tools, we have found that context-sensitive mechanisms in the auditory system implement, at a single-neuron level, well-known perceptual phenomena that describe how humans parse complex sounds into salient events. Therefore, these context-sensitive mechanisms may be the neuronal substrates of perceptual salience in the auditory system. We hypothesise that changes in these context-sensitive mechanisms underlie changes in perceptual salience during active listening - for example, when you suddenly realize that one individual voice in multiple ongoing conversations is talking about you.

We will test this hypothesis by recording the responses of auditory cortical, thalamic and midbrain neurons to complex sounds while animals are attending to auditory or visual cues in two different behavioral tasks. By comparing the context-dependence of neurons between brain areas, sensory attentional states, and behavioural tasks, we aim to determine how perceptual salience arises from interactions between attention and neuronal sensitivity to sound context. Ultimately, this work may not only reveal the neuronal substrates of perceptual salience in the auditory system, but also suggest new approaches to unsolved problems in machine listening -- such as how to extract the sound of an individual voice from multiple ongoing conversations.</gtr:abstractText><gtr:technicalSummary>The ability to parse a complex sound into behaviourally important cues is critical to auditory perception. We have recently developed powerful new computational tools for analysing neuronal responses to complex sounds, which have revealed that context-sensitive mechanisms act to modulate the input gain of auditory neurons in a spectrotemporally localised manner. These mechanisms appear to implement, at a single-neuron level, psychophysical phenomena that have long been recognised as essential to defining how humans parse complex sounds into perceptually salient events. Here, we propose to combine the novel analytical tools developed in our previous work with state-of-the-art methods for large-scale electrophysiological recording and optogenetic manipulation of neuronal population activity in awake behaving mice, to define the contribution of context-sensitive mechanisms to active listening in awake animals. We hypothesise that: (1) context-sensitive mechanisms in auditory cortical, thalamic and midbrain neurons are strongly modulated by attentional state; (2) these attentional effects are more pronounced in cortical and thalamic neurons than in midbrain neurons; and (3) cortical mechanisms of contextual modulation play a crucial role in detection of sound-conjunction cues embedded in a complex background sound. To test these hypotheses, we will record responses of auditory cortical, thalamic and midbrain neurons to complex background sounds while animals are attending to auditory (sound-conjunction) or visual (control) cues in two different behavioural paradigms. By comparing context-dependence of neuronal responses between brain areas, sensory attentional states, and behavioural paradigms, we will determine how perceptual salience arises from interactions between attention and neuronal sensitivity to sound context. These investigations of the neuronal substrates of perceptual salience in the auditory system may also suggest new strategies for machine listening.</gtr:technicalSummary><gtr:potentialImpactText>This work has potential for short-term and medium-term impact on provision of skilled people to the workforce, and long-term impact on human welfare and quality of life.

In the short term, this project will contribute to the career development of the Researcher Co-I, Dr Arne Meyer. Through the research, Meyer will learn a wide range of state-of-the-art techniques in computational and systems neuroscience, including methods for large-scale in vivo electrophysiological recording in awake animals; behavioural testing in mice; optogenetic manipulation of neural circuitry; histological analysis; and mathematical modelling of neural data, including fundamental aspects of machine learning. He will also benefit from interaction with the diverse group of scientists at the UCL Ear Institute, the Gatsby Computational Neuroscience Unit, and also the new Sainsbury Wellcome Centre for Neural Circuits and Behaviour which is co-located with the Gatsby Unit. This research environment, at the interface between experimental and computational neuroscience, will provide Meyer with a uniquely interdisciplinary scientific profile, which will help him to develop his independent scientific career.

In the medium term, the project will contribute to advancement of science and technology education, through involvement of the PI, Co-I and Researcher Co-I in planned public engagement activities. Specifically, Linden will give guest lectures on brain mechanisms of sound perception to students at a comprehensive secondary school in London, and also we will offer one 8-week summer research internship per year to a student interested in science who is unlikely to have had any previous direct interactions with professional scientists. Through these planned yearly activities, we aim to increase awareness of professional scientists among economically and academically disadvantaged students; to provide role models to students interested in science; and ultimately to increase the number of students pursuing careers in science-related subjects.

In the long term, this research could have substantial impact on human welfare and quality of life. The overall goal of the proposed research is to reveal the neuronal substrates of perceptual salience in the auditory system. The ability to separate salient events from a stream of sounds, e.g., an individual voice from multiple ongoing conversations, is crucial to social interaction and therefore to quality of life. However, it is mostly this aspect of hearing that is impaired due to age-related hearing loss. Reliable separation of salient events from background sound is still an unsolved technical problem and therefore conventional hearing aids don't make it easy to distinguish meaningful signals such as speech from background noise. Insights gained from this project could suggest physiologically-inspired algorithms for automatic speech recognition in noisy environments - and indeed Meyer has already contributed to development of such algorithms in his PhD work. Improved algorithms for automatic recognition of speech and other important sounds in noisy environments could transform the lives of millions of people with age-related hearing loss in the UK alone. To take a concrete initial step toward this very long-term possible impact, we will aim to incorporate initial insights gained from this project into the physiologically-inspired algorithms for automatic speech recognition and auditory object detection that Meyer has studied previously.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2017-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>547125</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/P007201/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>4A6E5CEB-ACA3-4301-98AD-C7EC310948FD</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Theoretical biology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>