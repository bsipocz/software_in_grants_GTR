<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/F574E08B-5D1F-4585-A88E-A385E68E4F80"><gtr:id>F574E08B-5D1F-4585-A88E-A385E68E4F80</gtr:id><gtr:name>Science Museum Group</gtr:name><gtr:address><gtr:line1>Science Museum</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2DD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F574E08B-5D1F-4585-A88E-A385E68E4F80"><gtr:id>F574E08B-5D1F-4585-A88E-A385E68E4F80</gtr:id><gtr:name>Science Museum Group</gtr:name><gtr:address><gtr:line1>Science Museum</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2DD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F54C6961-678D-4229-9960-4F1F6D31BF56"><gtr:id>F54C6961-678D-4229-9960-4F1F6D31BF56</gtr:id><gtr:firstName>Marcus</gtr:firstName><gtr:otherNames>Thomas</gtr:otherNames><gtr:surname>Pearce</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM000702%2F1"><gtr:id>53368443-8B03-4CCE-B505-334D8AA2E47A</gtr:id><gtr:title>Predicting musical choices using computational models of cognitive and neural processing</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M000702/1</gtr:grantReference><gtr:abstractText>Music consumption has shifted dramatically in recent years towards streaming from vast music libraries, overloading the user with the enormity of possible musical choices. This new landscape makes it imperative to develop intelligent tools to help listeners choose music to listen to. Research in music technology has traditionally followed a pure engineering approach, which has taken the field some way. However, progress is being hindered by the lack of a robust, scientifically grounded model of the listener, which can be used to inform digital music players (e.g., iTunes, Spotify, Last FM) about users' preferences for selecting music.

The proposed research addresses this gap by developing the scientific knowledge needed to create computational models which can predict listeners' musical choices from features of the music and electrical brain responses recorded using Electroencephalography (EEG). The principal idea is to develop a scientific understanding of the psychological and neural processes involved when a listener chooses music to listen to. The hypothesis is that accurate predictions of a listener's musical choices can be made using a combination of psychological principles, musical features and electrical brain responses recorded from the scalp. This research has two foundations: first, to conduct listener studies to identify those psychological principles, musical features and brain responses; and second, to use that knowledge to build a computational model that predicts a listener's choice of music.

The modelling approach includes three components to capture features of music that have an impact on musical choices. The first component uses acoustic features such as dissonance and temporal regularity extracted from the audio using signal processing methods. The second component takes a higher-level cognitive approach, extracting measures of complexity using information-theoretic models based on note-level representations of music. The third component extracts the emotional intentions of the music from affective textual analysis of the lyrical content. Understanding the exact nature and weighting of these features and how they impact on musical choice requires the detailed examination of the choices that listeners make when listening to music.

Therefore, investigating the behaviour of actual listeners is central to this research and two studies will be performed. The first focuses on collecting EEG data while participants listen to musical excerpts and select them for future listening. Machine learning methods will be used to predict the listeners' decisions using features of the time-varying neural response recorded prior to the choice being made. The purpose of the second user study is to collect data for predict modelling of choices from features of the music itself and attributes of the listener. This will involve a larger range of musical excerpts and a wider range of listeners than is practical for the EEG study. The objective is to understand the psychological processes involved in musical choice and to use this knowledge to refine, parameterise and optimise the computational models of musical choice.

The final stage of the research will develop an integrated predictive model of musical choice by combining predictive models using the musical signal with those making predictions from the neural signal. The development of such an integrated model is highly innovative. The advent within the last two years of affordable, multi-channel, wireless EEG headsets for the consumer market makes the possibility of using these devices to control media players and other interactive systems a real possibility. Therefore, the time is ripe to combine research in neuroscience, music cognition and machine learning, reflecting the unique interdisciplinary expertise of the PI, to understand the mapping between neural signals, musical structure and song selections.</gtr:abstractText><gtr:potentialImpactText>By investigating and modelling the psychological and neural processes involved in musical preference and choice, this project holds benefits to several groups beyond academic researchers, both in the UK and internationally. These include:

1. Commercial Private Sector:
* Digital music software industry: understanding the psychological and neural processes involved in listeners making musical choices, will help the digital music industry develop better software for supporting and enhancing those choices, especially since this research will implement computational models that aim to predict choice;
* Advertising industry: Understanding the psychological and neural principles of musical preference and decision making can help the advertising industry understand how to use music most effectively for marketing products; 
* Musicians and concert organisers: who can use the principles of musical choice to help design better concert programmes and playlists for releases.

2. Public and third sectors:
* music educators: understanding of the psychological principles involved in musical preference and choice can facilitate the selection of repertoire and help design software for inspiring young children in musical education
* Independent organisations promoting STEM (science, technology, engineering and maths) to young people and underrepresented groups, by using music to generate interest in STEM careers.

3. The wider public:
* musical listeners will benefit from better software tools that match their intuitive preferences when making musical choices;
* Students and school children in technical, musical and psychological fields can benefit by creating links between scientific, technical and musical domains to better understand these disciplines.

The ways in which this research will target these beneficiaries is outlined in the Pathways to Impact document. For academic beneficiaries see Section 2 in the Case for Support.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-12-05</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-04-06</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>100224</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Science Museum Group</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>The Science Museum</gtr:department><gtr:description>Live Science Residency at the Science Museum</gtr:description><gtr:id>A3705A33-6C97-4082-B90A-D0E8F6C7A06D</gtr:id><gtr:impact>The collaboration is multi-disiplinary involving psychology, neuroscience, computer science and music. Full details of the outcomes can be found in Narrative Impact.</gtr:impact><gtr:outcomeId>56d9830aacceb7.08451546-1</gtr:outcomeId><gtr:partnerContribution>The Science Museum provided the gallery space, computers, public engagement training for our team and produced final copies of the promotional materials, consent forms and information sheets along with other advice, guidance and support.</gtr:partnerContribution><gtr:piContribution>We developed three experiments, adapted from our lab-based studies to run within a 15-20 minute session with visitors to the museum. We successfully applied for QMUL ethical consent for the project, prepared the text for the promotional materials, consent forms and information sheets and ran the residency over a five week period in the Science Museum. We also sent a report to the Science Museum and we are currently analysing over 470 datasets that we collected.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Workshop on Auditory Neuroscience, Cognition &amp; Modelling (WANCM 2016)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0BAC755C-3DDF-4037-924D-77F8E8558DCA</gtr:id><gtr:impact>We organised a one-day workshop in Auditory Neuroscience, Cognition and Modelling, taking place on 17 February 2016 at QMUL (Charterhouse Square Campus and attended by over 96 participants from the UK and abroad. There were 32 presentations: 3 keynote talks, 6 oral presentations, 23 poster presentations (oral and poster presentations following a public call for abstracts and selection process). The workshop website includes PDF book of abstracts and video recorded oral presentations: http://c4dm.eecs.qmul.ac.uk/wancm2016/.</gtr:impact><gtr:outcomeId>56d989476fec35.86990929</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>http://c4dm.eecs.qmul.ac.uk/wancm2016/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Live Science Residency, Science Museum</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>CD146D1B-FF2F-4DED-B382-D7167B40226F</gtr:id><gtr:impact>During a Live Science residency at the Science Museum, we engaged with 372 visitors over five weeks people ranging in age from 8 to 78. Visitors took part in short experiments and we engaged with them about our research on musical preferences. About 10% of participants completed feedback forms which indicated that they enjoyed the experience (mean rating of 6 out 7) and 71% said they would be more likely to engage with science in the future as a result of taking part in our experiments. See Narrative Impact for full details.</gtr:impact><gtr:outcomeId>56d986a3812982.07562702</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>966</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>QMUL Centre for Public Engagement Small Grants Award</gtr:description><gtr:end>2016-02-02</gtr:end><gtr:fundingOrg>Queen Mary University of London</gtr:fundingOrg><gtr:id>9AFDC131-4FB9-4D1D-BF36-EC205A128B46</gtr:id><gtr:outcomeId>56d984bc05b1a4.61426260</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-11-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We have run a Live Science Residency called &amp;quot;Why do you like the music you like&amp;quot; at the Science Museum, London. The residency ran over 5 weeks in Nov-Dec 2015 and engaged visitors to the museum as participants in research on musical emotion and preferences. The residency included both psychological tasks and neural investigation using a mobile EEG headset, which recorded visitors electrical brain responses while listening to music. In addition to collecting data, we also actively engaged with visitors explaining our research to them and asking for their opinions on our research.

In total, we engaged with 372 people ranging in age from 8 to 78 (308 adults and 64 children), yielding more than 480 sets of data across both tasks. Many people came to the museum specifically to take part in our residency and some brought their whole family. About 10% of participants completed feedback forms. These indicated that the participants enjoyed the experience (mean rating of 6 out 7) and 71% of participants said they would be more likely to engage with science in the future as a result of taking part in our experiments.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>58D3BFE5-ED9B-44D7-878C-149CE5EEBB32</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d721ffa477a2.67222528</gtr:outcomeId><gtr:sector>Education,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project is not yet complete (it has been running for about 11 months) so our results are not yet fully analysed. However, we have reached the appropriate objectives for this stage in the project. 

Specifically, we have discovered that listeners preferences for music vary as a function of the activity that they are undertaking concurrently (e.g., driving, working, exercising). Further research will investigate how these context-related preferences are related to features of the music (e.g., tempo, dynamics, dissonance, complexity). 

We have also discovered that overall people prefer music that expresses a calm or peaceful mood (compared with happy, sad and angry). In some situations listeners choose to listen to music that is mood congruent (e.g., a listener in a peaceful mood listening to peaceful music) while in other situations they choose music that is mood-incongruent (e.g., a listener in an angry mood choosing music that is peaceful). We are currently investigating what might explain these different listening strategies.</gtr:description><gtr:exploitationPathways>Understanding why people like to listen to music raises profound questions for academic research and exciting opportunities for practical application in the non-academic world. 

Regarding academic developments, further research is required on how the context (e.g., social or task-related factors) interacts with individual factors (e.g., personality, genre preferences, current emotional state, motivations, goals and desires) and attributes of the music (e.g., loudness, dissonance, complexity, familiarity, prototypicality) to determine the musical choices that individuals make in particular situations. In particular, it seems that in some situations individuals make mood-congruent (e.g., a person feeling sad choosing to listen to sad music) choices and in others they make mood-incongruent choices (e.g,. the same person choosing to listen to happy music) but currently we don't understand why this is. Research using EEG has focused to date on emotional responses to music and there is very little scientific understanding of neural correlates of musical pleasure or liking, let alone preference decisions. 

Although there is much research to be done, understanding the factors - psychological, neuroscientific, musical and contextual - that determine musical preference decisions would be of great benefit beyond academia. It would allow the development of more sophisticated music recommendation engines which could be used in industries ranging from online radio stations, personal listening, retail and advertising. It may also be useful in music therapy allowing a therapist to select appropriate music for particular patients.</gtr:exploitationPathways><gtr:id>217280B5-E478-4286-9BE1-8BA95DCCE460</gtr:id><gtr:outcomeId>56d72eb7eaad25.87003794</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>60C23748-BF29-4703-8E5E-CF97880A84B0</gtr:id><gtr:title>Compression-based Modelling of Musical Similarity Perception</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cd0df43efd0a21de39b49f10430306c5"><gtr:id>cd0df43efd0a21de39b49f10430306c5</gtr:id><gtr:otherNames>Pearce M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2feb47563870.41618473</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A68DD3E6-1CA2-44C2-9D76-1E321837735E</gtr:id><gtr:title>Simulating melodic and harmonic expectations for tonal cadences using probabilistic models</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c80ce6148994065b5d6bf7c37767b64b"><gtr:id>c80ce6148994065b5d6bf7c37767b64b</gtr:id><gtr:otherNames>Sears D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fe885c58a54.17248613</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M000702/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>5</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>