<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:department>Computing Department</gtr:department><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/D7F1AC03-B6B4-4873-A327-7982A80636A1"><gtr:id>D7F1AC03-B6B4-4873-A327-7982A80636A1</gtr:id><gtr:firstName>Keith</gtr:firstName><gtr:surname>Potter</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/62D3CD4B-2318-4A02-B23E-646358C34B6D"><gtr:id>62D3CD4B-2318-4A02-B23E-646358C34B6D</gtr:id><gtr:firstName>Geraint</gtr:firstName><gtr:otherNames>Anthony</gtr:otherNames><gtr:surname>Wiggins</gtr:surname><gtr:orcidId>0000-0002-1587-112X</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/800B0C52-A327-4F71-BE37-7145C9C67FCB"><gtr:id>800B0C52-A327-4F71-BE37-7145C9C67FCB</gtr:id><gtr:firstName>Joydeep</gtr:firstName><gtr:surname>Bhattacharya</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F54C6961-678D-4229-9960-4F1F6D31BF56"><gtr:id>F54C6961-678D-4229-9960-4F1F6D31BF56</gtr:id><gtr:firstName>Marcus</gtr:firstName><gtr:otherNames>Thomas</gtr:otherNames><gtr:surname>Pearce</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FH01294X%2F1"><gtr:id>1509966C-4583-4CAF-8314-22C1D410A387</gtr:id><gtr:title>Information and neural dynamics in the perception of musical structure</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H01294X/1</gtr:grantReference><gtr:abstractText>Music is one of the things that makes us human. No known human society exists without music; and no other species seems to exhibit musical behaviour, in the same sense as humans. It is an open question where music came from (in terms of evolution), but it is self-evident that it arises from the human brain: for there to be music, a brain was involved somewhere, even if only in listening. What is not evident at all is how brains (or the minds to which they give rise) make, or even perceive, music. This project aims to understand how human musical behaviour can be modelled using computers, by building programs which embody theories of how the musical mind works, and then comparing them with humans engaged in musical activity and also by comparing their predictions with those of an expert music analyst. This means that the project will contribute to various areas of study: computer music, statistical methods for cognitive modelling (and therefore to cognitive linguistics, because the same kinds of models can be used there), musicology, and neuroscience (both in a better understanding of brain function and with new methods for neural signal analysis). Long term outcomes are likely to be computer systems that help music education, that play music musically, and that interact with human musicians musically; understanding that helps musicians do what they do more effectively; and understanding that helps brain scientists and psychologists understand more about how the brain and the mind work. Above all, since musicality is so fundamental to humanity, the project aims to help understand some of what it means to be human.</gtr:abstractText><gtr:fund><gtr:end>2011-11-01</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>757554</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Music</gtr:department><gtr:description>IDyOM</gtr:description><gtr:id>B619936F-A0F4-4161-AF4E-8A108DC253CE</gtr:id><gtr:impact>Multi-disciplinary: Computer Science, Psychology, Music</gtr:impact><gtr:outcomeId>b99cfd38b99cfd4c-2</gtr:outcomeId><gtr:partnerContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:partnerContribution><gtr:piContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Psychology</gtr:department><gtr:description>IDyOM</gtr:description><gtr:id>7FA7A242-1C43-4374-BBB0-DEA97BEC097A</gtr:id><gtr:impact>Multi-disciplinary: Computer Science, Psychology, Music</gtr:impact><gtr:outcomeId>b99cfd38b99cfd4c-1</gtr:outcomeId><gtr:partnerContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:partnerContribution><gtr:piContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>School of Electronic Engineering and Computer Science</gtr:department><gtr:description>IDyOM</gtr:description><gtr:id>42D430BE-55D5-41AC-BF95-BDE22551ECF9</gtr:id><gtr:impact>Multi-disciplinary: Computer Science, Psychology, Music</gtr:impact><gtr:outcomeId>b99cfd38b99cfd4c-3</gtr:outcomeId><gtr:partnerContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:partnerContribution><gtr:piContribution>This was a collaborative research project funded by EPSRC. We supplied computer science; partners supplied expertise in music and psychology, respectively.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>BBC News interview</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>B7CF901C-4D9B-45F1-91CB-E1DEF1C19744</gtr:id><gtr:impact>I was interviewed, along with my doctoral student, Tom Hedges, about production of computer-created music. The article was carried on BBC News (6 o'clock and 10 o'clock) and on BBC World (international). A longer version was run on BBC Radio 4's Today programme.</gtr:impact><gtr:outcomeId>56dc8639b7d9a7.52857926</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1931663</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Learning To Create</gtr:description><gtr:end>2016-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>Lrn2Cre8</gtr:fundingRef><gtr:id>C3390490-2DE9-4FAE-9C97-E93E83CE030C</gtr:id><gtr:outcomeId>5ec684d45ec684f2</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2013-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1931591</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>ConCreTe</gtr:description><gtr:end>2016-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>ConCreTe</gtr:fundingRef><gtr:id>432E70F7-54CC-4475-9265-49AAEB4351D0</gtr:id><gtr:outcomeId>5ec604645ec6046e</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2013-10-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have demonstrated that a particular kind of computer modelling, using Markov chains and information theory, can robustly simulate various aspects of the perception of music. In particular, it is possible to automatically predict the expectation of listeners, and the level of certainty with which they expect it, during a musical melody, and to relate this to various aspects of musical structure and experience, such as phrase segmentation, and emotional response. We have supplied further evidence of the relationship between neural responses (as measured by EEG) and the information theoretic measures used. Overall, we have made substantial progress in understanding the relationship between information in music and its processing in the brain, and the effects on the mind of doing so. We have demonstrated this in the musical context, by showing that the system is capable to some degree of simulating the work of music analysts. We have also shown that the same kind of model can segment linguistic elements correctly, lending weight to the hypothesis that music and language are related in terms of processing.</gtr:description><gtr:exploitationPathways>The outcomes of the project may be used, in the medium term, in generative music systems and in music education tools. In the very long term, the models of general creativity arising from the project may give rise to more human-like, creative computers. The work carried out here is basic science, and therefore is most likely to be exploited, in the short term, in further research. However, in the longer term, we expect that developments of these systems will be used in automatic or semi-automatic music generators, in music eduction, and as experimental tools for composers. This will be explored in the EU FP7 Lrn2Cre8 project (see Outcomes). On the more speculative level, the work has led to a proposal for a cognitive architecture for creativity, possibly admitting human-like creativity in computers, and this will be further examined in the EU FP7 ConCreTe project (see Outcomes).</gtr:exploitationPathways><gtr:id>93D78D80-9C43-4998-A26A-A1152091FAC3</gtr:id><gtr:outcomeId>r-8772204638.2466377760b99c</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors><gtr:url>http://www.idyom.org</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This is a suite of software, designed and built by Dr Marcus Pearce, that predicts human expectation during perception of musical melodies.</gtr:description><gtr:id>72D0F2EF-FEC4-4960-B3F5-9E50F7FF6161</gtr:id><gtr:impact>Other researchers are using it for their work.</gtr:impact><gtr:outcomeId>56dc8785dd5c41.14065915</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>IDyOM software</gtr:title><gtr:type>Computer model/algorithm</gtr:type><gtr:url>https://code.soundsoftware.ac.uk/projects/idyom-project/files</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>358895DB-E422-4E85-8EFF-239C4B591B34</gtr:id><gtr:title>Cue Abstraction, Paradigmatic Analysis and Information Dynamics: Towards Music Analysis by Cognitive Model</gtr:title><gtr:parentPublicationTitle>Musicae Scientiae</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_21271505271375ad9c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AF0ED120-9A85-4D4C-AE53-94724823B3D5</gtr:id><gtr:title>A Cognitive Mechanism for Spontaneous Musical Creativity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c6d840ac47ee1ba793d53728602510b5"><gtr:id>c6d840ac47ee1ba793d53728602510b5</gtr:id><gtr:otherNames>Wiggins. G. A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_909008791613e11c08</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F5B6EF91-B666-4B55-A9A3-90ECA4A33387</gtr:id><gtr:title>Implicit Brain Responses During Fulfillment of Melodic Expectations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/898d22ec4193c383a679613ef3627eb9"><gtr:id>898d22ec4193c383a679613ef3627eb9</gtr:id><gtr:otherNames>Lindsen, J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_857217711864324f34</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>35420BE0-E6CF-4EB7-B5C4-A3EEBE181801</gtr:id><gtr:title>A measure of statistical complexity based on predictive information with application to finite spin systems</gtr:title><gtr:parentPublicationTitle>Physics Letters A</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1fa60ebb5510005177bc3608f9d39d4f"><gtr:id>1fa60ebb5510005177bc3608f9d39d4f</gtr:id><gtr:otherNames>Abdallah S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>5675edd1cf1ef</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0E8D2049-3B89-420C-89FF-4BC976A6363C</gtr:id><gtr:title>Entrainment of Premotor Cortex Activity by Ambiguity in Musical Metre.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/58d1c18446b38b30ea8ee2acfd526111"><gtr:id>58d1c18446b38b30ea8ee2acfd526111</gtr:id><gtr:otherNames>Cameron, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_709464033813e572d0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9F979518-208D-4A2A-A031-E4EF8F82E778</gtr:id><gtr:title>Modeling the implicit learning of metrical and non-metrical rhythms.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d050c47ac7050ff882e117fbf21c9258"><gtr:id>d050c47ac7050ff882e117fbf21c9258</gtr:id><gtr:otherNames>Schultz, B.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_205767080813ef922e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>942A612E-D05D-4FD7-B9DA-ED97093A90E8</gtr:id><gtr:title>Harmonising Melodies: Why Do We Add the Bass Line First?</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/83ad6ef9d99e624a7f275688b6539d1d"><gtr:id>83ad6ef9d99e624a7f275688b6539d1d</gtr:id><gtr:otherNames>Whorley, R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_118198734413e11d66</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CDAE344E-31FE-48F6-BCEF-732D8933794E</gtr:id><gtr:title>Crossmodal transfer of arousal, but not pleasantness, from the musical to the visual domain.</gtr:title><gtr:parentPublicationTitle>Emotion (Washington, D.C.)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c67bf3ed73709e59fad6b8b6c7735a57"><gtr:id>c67bf3ed73709e59fad6b8b6c7735a57</gtr:id><gtr:otherNames>Marin MM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1528-3542</gtr:issn><gtr:outcomeId>doi_53d024024dd81a67</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BD9411FB-BE95-4537-86BE-D3B25EAD0F57</gtr:id><gtr:title>Music, mind and mathematics: theory, reality and formality</gtr:title><gtr:parentPublicationTitle>Journal of Mathematics and Music</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d03e03ebf9970c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F390DCE1-1007-4738-A840-25BC7B37B6E4</gtr:id><gtr:title>How music can brighten our world: emotions induced by music affect brightnessperception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e6f4b2dc732691bcccfc13c4b2177680"><gtr:id>e6f4b2dc732691bcccfc13c4b2177680</gtr:id><gtr:otherNames>Lindsen Job (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_267163022864324c14</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6B33A1FA-8E99-47F0-A978-6AF257DEA0C7</gtr:id><gtr:title>Principles of structure building in music, language and animal song.</gtr:title><gtr:parentPublicationTitle>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c06b8d6e91a270a58844b7b6c07e7378"><gtr:id>c06b8d6e91a270a58844b7b6c07e7378</gtr:id><gtr:otherNames>Rohrmeier M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0962-8436</gtr:issn><gtr:outcomeId>56dc79a6cf6fd1.09476373</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>994178E8-E75B-4581-99DA-C662ECA4165B</gtr:id><gtr:title>On the correctness of imprecision and the existential fallacy of absolute music</gtr:title><gtr:parentPublicationTitle>Journal of Mathematics and Music</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d03e03ec026564</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>609624D8-DA29-40E9-8CF0-A472EFE9AFB1</gtr:id><gtr:title>Linking melodic expectation to expressive performance timing and perceived musical tension.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4cbeb084a35b9c82cc3d206d7b0c4395"><gtr:id>4cbeb084a35b9c82cc3d206d7b0c4395</gtr:id><gtr:otherNames>Gingras B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>56dc7917117f03.51926944</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>59932B62-CA9C-4506-B103-533AE426A69A</gtr:id><gtr:title>Unsupervised statistical learning underpins computational, behavioural, and neural manifestations of musical expectation.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e6356612edd2781ea7ceef04c802a6b"><gtr:id>1e6356612edd2781ea7ceef04c802a6b</gtr:id><gtr:otherNames>Pearce MT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>doi_53d002002634a5f8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>351F4A75-5F67-490C-978E-78465A52BB6E</gtr:id><gtr:title>The neuroaesthetics of music.</gtr:title><gtr:parentPublicationTitle>Psychology of Aesthetics, Creativity, and the Arts</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/df90eeced5d1548e01dc1fbe4798da77"><gtr:id>df90eeced5d1548e01dc1fbe4798da77</gtr:id><gtr:otherNames>Brattico E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>585d7a7a86a888.11771746</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5059316B-3CA7-4417-A9D7-262A5646565B</gtr:id><gtr:title>Probabilistic models of expectation violation predict psychophysiological emotional responses to live concert music.</gtr:title><gtr:parentPublicationTitle>Cognitive, affective &amp; behavioral neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/535acc3e8ad592b562ed219d9ea16454"><gtr:id>535acc3e8ad592b562ed219d9ea16454</gtr:id><gtr:otherNames>Egermann H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1530-7026</gtr:issn><gtr:outcomeId>doi_53d0880882a9ff6c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4F5B4CCF-244E-497C-A35F-AB8D1ECE9C54</gtr:id><gtr:title>On the non-existence of music: Why music theory is a figment of the imagination</gtr:title><gtr:parentPublicationTitle>Musicae Scientiae</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_86772940751375ae50</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>61078F03-0E97-4F31-B6DC-836BF2B7DF4D</gtr:id><gtr:title>Auditory expectation: the information dynamics of music perception and cognition.</gtr:title><gtr:parentPublicationTitle>Topics in cognitive science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e6356612edd2781ea7ceef04c802a6b"><gtr:id>1e6356612edd2781ea7ceef04c802a6b</gtr:id><gtr:otherNames>Pearce MT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1756-8757</gtr:issn><gtr:outcomeId>doi_53d06b06b9b4760c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8FB15C67-9CF8-42BC-B8A3-3A2A53918F9C</gtr:id><gtr:title>The future of (mathematical) music theory</gtr:title><gtr:parentPublicationTitle>Journal of Mathematics and Music</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d03e03ec0b4b0c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>874E8155-C1CF-40AC-B3A9-68642565BD56</gtr:id><gtr:title>Perception of Rhythmic Similarity in Reich's Clapping Music: Factors and Models.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/58d1c18446b38b30ea8ee2acfd526111"><gtr:id>58d1c18446b38b30ea8ee2acfd526111</gtr:id><gtr:otherNames>Cameron, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_112134356813ef9350</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A158DBC1-C62B-4177-ACA6-52BA2AD66C2C</gtr:id><gtr:title>Crossing the Threshold Paradox: Creative Cognition in the Global Workspace</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da815ce3ac94123f0cddb635725b6d37"><gtr:id>da815ce3ac94123f0cddb635725b6d37</gtr:id><gtr:otherNames>Wiggins, G. A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_547769242413e11cbc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEBE5079-E133-432E-8147-C91FB30E7A77</gtr:id><gtr:title>A pilot investigation on electrical brain responses related to melodic uncertainty andexpectation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/898d22ec4193c383a679613ef3627eb9"><gtr:id>898d22ec4193c383a679613ef3627eb9</gtr:id><gtr:otherNames>Lindsen, J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_987473312964324d9a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>45CFF6F4-05EA-4C9F-91C1-17EFF66E56D6</gtr:id><gtr:title>Multiple Viewpoint Systems: Time Complexity and the Construction of Domains for Complex Musical Viewpoints in the Harmonization Problem</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cd4d7446e0431bb9efe100ce91b47c62"><gtr:id>cd4d7446e0431bb9efe100ce91b47c62</gtr:id><gtr:otherNames>Whorley R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_8302364577136bb210</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>53B6A213-CA14-4945-975C-EDA9AC27DD55</gtr:id><gtr:title>Conference report: The Neurosciences and Music-IV-Learning and Memory.</gtr:title><gtr:parentPublicationTitle>Psychomusicology: Music, Mind, and Brain</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cd0df43efd0a21de39b49f10430306c5"><gtr:id>cd0df43efd0a21de39b49f10430306c5</gtr:id><gtr:otherNames>Pearce M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>585d7a779c9719.18439695</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0C5BE8A9-BB21-4B63-972E-C466E94B45A7</gtr:id><gtr:title>The effect of melodic expectation on language processing at different levels of task difficulty and working memory load</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c3ecce101ba1a1c67560f4f74b8072a5"><gtr:id>c3ecce101ba1a1c67560f4f74b8072a5</gtr:id><gtr:otherNames>Carrus, E.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_864872870213ed5d6a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D1A8E75B-7E6D-4B58-8755-BB6B0C1D90D8</gtr:id><gtr:title>The evolutionary roots of creativity: mechanisms and motivations.</gtr:title><gtr:parentPublicationTitle>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/db6919ee8a5ef19f668356babd3bce4e"><gtr:id>db6919ee8a5ef19f668356babd3bce4e</gtr:id><gtr:otherNames>Wiggins GA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0962-8436</gtr:issn><gtr:outcomeId>56dc79a6efbb21.17971932</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1287D406-7F45-459A-84F6-C235B7761E36</gtr:id><gtr:title>The Mind's Chorus: Creativity Before Consciousness</gtr:title><gtr:parentPublicationTitle>Cognitive Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/caa8930d408bd909d12bf80d3ccbbcd0"><gtr:id>caa8930d408bd909d12bf80d3ccbbcd0</gtr:id><gtr:otherNames>Wiggins G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53cfe0fe052de23c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1C5EBB4A-E76B-4BDA-A4E0-7ADB552EB6C7</gtr:id><gtr:title>Predicting expressive timing and perceived tension in performances of an unmeasured prelude using the IDyOM model.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8b373edb45315050a975db32d2c09d8e"><gtr:id>8b373edb45315050a975db32d2c09d8e</gtr:id><gtr:otherNames>Gingras, B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_943370579313ef947c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9162F528-7174-4516-8B6A-195EA6F86176</gtr:id><gtr:title>The Role of Expectation and Probabilistic Learning in Auditory Boundary Perception: A Model Comparison</gtr:title><gtr:parentPublicationTitle>Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cd0df43efd0a21de39b49f10430306c5"><gtr:id>cd0df43efd0a21de39b49f10430306c5</gtr:id><gtr:otherNames>Pearce M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d0390395f60d3d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>49240E99-8A65-44A0-9140-B1C7AAE888F1</gtr:id><gtr:title>Melodic pitch expectation interacts with neural responses to syntactic but not semantic violations.</gtr:title><gtr:parentPublicationTitle>Cortex; a journal devoted to the study of the nervous system and behavior</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/44d6474cc0e8c27e5d55feb7a5ecb4da"><gtr:id>44d6474cc0e8c27e5d55feb7a5ecb4da</gtr:id><gtr:otherNames>Carrus E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0010-9452</gtr:issn><gtr:outcomeId>doi_53cfeafeae3c8716</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H01294X/1</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>1509966C-4583-4CAF-8314-22C1D410A387</gtr:id><gtr:grantRef>EP/H01294X/1</gtr:grantRef><gtr:amount>757554.19</gtr:amount><gtr:start>2010-02-01</gtr:start><gtr:end>2011-11-01</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>99B62A61-268E-4EA6-86E8-0D0723754BA3</gtr:id><gtr:grantRef>EP/H01294X/2</gtr:grantRef><gtr:amount>344471.73</gtr:amount><gtr:start>2011-11-01</gtr:start><gtr:end>2013-04-30</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>