<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:department>Institute of Neuroscience</gtr:department><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/12F8C476-29C9-4A2E-BFC1-C3A9FD0A0A00"><gtr:id>12F8C476-29C9-4A2E-BFC1-C3A9FD0A0A00</gtr:id><gtr:name>Italian Institute of Technology</gtr:name><gtr:address><gtr:line1>Via Morego 30</gtr:line1><gtr:postCode>16163</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Italy</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/C40BD75B-8379-41FE-AFA0-4FA786429ED8"><gtr:id>C40BD75B-8379-41FE-AFA0-4FA786429ED8</gtr:id><gtr:firstName>Evelyne</gtr:firstName><gtr:surname>Sernagor</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FH023569%2F1"><gtr:id>1D85E496-C210-4F7C-98C8-484529F197CE</gtr:id><gtr:title>Novel analytical and datasharing tools for rich neuronal activity datasets obtained with a 4096 electrodes array</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/H023569/1</gtr:grantReference><gtr:abstractText>The functional intricacy of the central nervous system (CNS) arises from the complex anatomical and dynamic interactions between different types of neurones involved in specific networks. Hence, the encoding of information in neural circuits occurs as a result of interactions between individual neurones as well as through the interplay within both microcircuits (made of few neurones) and large scale networks involving thousands to millions of cells. One of the great challenges of neuroscience nowadays is to understand how these neural networks are formed and how they operate. Such challenge can be resolved only through simultaneous recording from thousands of neurones that become active during specific neuronal tasks. One of the experimental approaches to fulfil this goal is to use multielectrode arrays (MEAs) that consist of several channels (electrodes) that can each record (and/or stimulate) from few adjacent neurones within a particular area of the CNS. MEAs can be used in vitro to record from dissociated neuronal cultures or from brain slices or isolated retinas. These MEAs consist of assemblies of electrodes embedded in planar substrates. Typical commercial MEAs consist of 60-128 electrodes with a spacing of 100-200 um. Considering that a generic neurone in the mammalian CNS has a diameter of about 10 um, it is obvious that such MEAs cannot convey information on the activity of all neurones involved in a specific network, but rather just from a sample of these cells. To overcome this activity under-sampling, in this project, we will use the Active Pixel Sensor (APS) MEA, a novel type of MEA platform developed in a NEST-EU Project by our collaborator Luca Berdondini (Italian Institute of Technology, Genova). This MEA consists of 4,096 electrodes with near cellular resolution (21x21 um, 42 um centre-to-centre separation, covering an active area of 2.5 mm x 2.5 mm), where recording is possible from all channels at the same time. We will use the APS MEA to record spontaneous waves of activity that are present in the neonatal vertebrate retina. These waves occur during a short period of development during perinatal weeks and they are known to play an important role in guiding the precise wiring of neural connections in the visual system, both at the retinal and extra-retinal levels. The APS-MEA, thanks to its unmet size and resolution, will enable us to reach new insights into the precise dynamics of these waves as never achieved before. Recordings from such large scale networks at near cellular resolution generate extremely rich datasets with the drawback that these datasets are very large and difficult to handle, thus necessitating the development of new powerful analytical tools enabling to decode in a fast, efficient and user-friendly way how cellular elements interact in the network. The development of such computational tools is the central goal of this project, while the experimental work on the retina defines a challenging and unique scientific context. The tools we plan to develop will yield parameters that will help us reach better understanding of network function, from the temporal firing patterns of individual neurones to how activity precisely propagates within the network. We will also develop novel tools for easier visualisation of the dynamical behaviour of the activity within the network. These tools will be developed in a language that could be easily utilized by other investigators using the same recording system or other platforms of their choice. Finally, to ensure that these tools are accessible to the wide neurophysiology community, they will be deployed on CARMEN (Code Analysis, Repository and Modelling for e-Neuroscience), a new internet-based neurophysiology sharing resource designed for facilitating worldwide communication between collaborating neurophysiologists.</gtr:abstractText><gtr:technicalSummary>publicly available if the proposal is funded. [up to 2000 characters] The complexity of neuronal communication arises from the exquisite precision of anatomical and functional connectivity within neuronal assemblies. To understand how neural connectivity is formed and operates, it is crucial to record simultaneously at high spatiotemporal precision from large scale neuronal networks. Multielectrode array (MEA) recordings have become one of the best experimental approaches for this purpose. Although MEAs offer excellent temporal resolution, their spatial resolution is poor, with typical commercial MEAs consisting of 60-128 electrodes with 30 um diameter and 200 um spacing, which is insufficient to study fine-grain spatiotemporal cellular interactions. In this project we will use the novel APS MEA platform developed by L. Berdondini and collaborators. The APS MEA is unique in terms of spatiotemporal resolution. It consists of 4,096 channels with near cellular resolution (21 um electrode diameter and separation) that can record simultaneously at a full frame rate of 7.8 kHz, which is high enough to reliably discriminate single spikes. We will use the APS MEA to record neonatal mouse retinal waves. Retinal waves undergo substantial changes in their spatiotemporal properties as the retina develops and the APS MEA will enable us to investigate these properties with a precision never been achieved before. The generation of such large and rich datasets necessitates the development of new powerful computational analytical tools, and this will be the central goal of this project. We will develop user-friendly new statistical approaches to decode large neuronal networks and new computational and visualization tools to quantify fine-grain spatiotemporal properties in neural networks. To allow community-wide access to these novel tools, they will be deployed on CARMEN, a new UK-based neurophysiology code development and data sharing facility developed in the past 3 years.</gtr:technicalSummary><gtr:potentialImpactText>Although our project will be the first one using the APS MEA to study an intact neural network (e.g. the retina) rather than interactions between dissociated neurones, we have no doubt that the APS MEA (or other similar developments) will soon become sought after by many neuroscientists seeking deeper understanding of precise interactions within large neuronal assemblies. From that point of view, this project will bring a strong proof of concept for the development and use of large scale MEAs. An entire session on MEAs at the last Society for Neuroscience meeting in Chicago (October 17-21 2009, ~30,000 participants) has revealed the fast growing interest of the neuroscience community in these large arrays that are becoming increasingly sophisticated thanks to new developments in nanotechnology and microfabrication. At the same time it is obvious that the APS MEA is the best performing platform available nowadays (in terms of the number of channels that can be used at any single time at high acquisition rate). The system was highly praised at the Chicago meeting, and we are in the very fortunate position of being at the forefront of research and development of the APS MEA through our collaboration with Luca Berdondini. We believe that we will be able to generate data of superior quality that will generate strong interest amongst neurophysiologists and computational neuroscientists. Because recordings with the APS MEA generate data that has no precedents in terms of spatiotemporal resolution, our results will undoubtedly shed new light on how to analyse, visualise and quantify neural network function, and this will be of great interest for the development of new software resources that will be used by systems neuroscientists. Because our experimental data and new analytical tools will be deployed on an open access data sharing facility, the impact of our research will be of much wider extent and will facilitate the dissemination of important scientific knowledge. All aspects of our research fall within the remit of research supported by the BBSRC, with special emphasis on the Tools and Resources Development Fund.</gtr:potentialImpactText><gtr:fund><gtr:end>2012-04-26</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2010-10-27</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>99539</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>I have created a composition of retinal waves recorded with the 4096 electrodes array system, inspired from Any Warhol
This work has been selected to be showcased in the new entrance lobby of the Institute of Neuroscience in Newcastle University</gtr:description><gtr:id>7BF8C147-5581-4B6E-BA79-480934EFA2F2</gtr:id><gtr:impact>The artwork has only just been hung in the lobby, it is too early to measure impact</gtr:impact><gtr:outcomeId>58c15b015cc0d7.97374733</gtr:outcomeId><gtr:title>Retinal wave picture</gtr:title><gtr:type>Artwork</gtr:type><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Giving support (talking to potential customers at company booth at conferences, providing example recordings for website) to 3Brain, the manufacturer of the recording device used in this project</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FCE4D003-C08B-4C37-A671-2F288B5E20C1</gtr:id><gtr:impact>3Brain is the pioneer in high density multielectrode array technology, and I was the first one to acquire their system commercially. I have since developed a very close relationship with them and regularly assist them at conference, talking to potential customers, from my biological, rather than technological perspective. I also provided 3Brain with very high quality recording examples which they showcase on their website.</gtr:impact><gtr:outcomeId>58c15768719e79.13545931</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www.3brain.com/home</gtr:url><gtr:year>2011,2012,2013,2014,2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>2200000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>FP7 FET NBIS</gtr:description><gtr:end>2016-02-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>600847</gtr:fundingRef><gtr:id>A26143AD-E61F-4855-AC23-C89789203AD1</gtr:id><gtr:outcomeId>54526d27dd9f64.73524157</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2013-03-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>274437</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Project Grant</gtr:description><gtr:end>2020-09-02</gtr:end><gtr:fundingOrg>The Leverhulme Trust</gtr:fundingOrg><gtr:fundingRef>RPG-2016-315</gtr:fundingRef><gtr:id>70561BCD-64B3-44AB-9264-9231FFAA5F72</gtr:id><gtr:outcomeId>58c152fb968e75.16715179</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2017-04-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>A large-scale, high density multielectrode array platform recording neural activity simultaneously with 4,096 electrodes was successfully installed at Newcastle, and the recordings were analysed at Edinburgh. 
We found the array to be an excellent system for recording spontaneous neuronal activity from the neonatal retina (retinal waves) at a near cellular resolution.

The grant enabled us, as planned, to develop a suite of tools for the analysis of these large scale MEA recordings. In particular, we devised a new improved detection method for neural spikes. This was necessary as we found that conventional methods were not suitable for these systems 
because of a very different noise profile caused by the densely integrated electronic circuits. Furthermore, we developed several methods for quantitative analysis of spatio-temporal activity patterns observed in the developing retina.

The analysis of retinal waves with these methods revealed several previously unknown features. Most strikingly, we found that late stage waves appear in spatially constrained hot-spots, which move over the course of hours (in vitro). Our analysis also enabled us to publish the most comprehensive characterisation of their ontogeny during the 
first two postnatal weeks in mice available in the literature.

The complete data set generated during the project is available for download for further analysis.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>E60B5E2F-954D-4983-A4FB-88A20A4EF14D</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5460ac9edd5fe5.67149222</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>A large-scale, high density multielectrode array platform recording neural activity simultaneously with 4,096 electrodes was successfully installed at Newcastle, and the recordings were analysed at Edinburgh. 
We found the array to be an excellent system for recording spontaneous neuronal activity from the neonatal retina (retinal waves) at a near cellular resolution.

The grant enabled us, as planned, to develop a suite of tools for the analysis of these large scale MEA recordings. In particular, we devised a new improved detection method for neural spikes. This was necessary as we found that conventional methods were not suitable for these systems 
because of a very different noise profile caused by the densely integrated electronic circuits. Furthermore, we developed several methods for quantitative analysis of spatio-temporal activity patterns observed in the developing retina.

The analysis of retinal waves with these methods revealed several previously unknown features. Most strikingly, we found that late stage waves appear in spatially constrained hot-spots, which move over the course of hours (in vitro). Our analysis also enabled us to publish the most comprehensive characterisation of their ontogeny during the 
first two postnatal weeks in mice available in the literature.

The complete data set generated during the project is available for download for further analysis.</gtr:description><gtr:exploitationPathways>We have pioneered a powerful approach to investigate neural networks with unprecedented detail</gtr:exploitationPathways><gtr:id>B3EA5374-E074-49F4-8EE7-24199E2E50C5</gtr:id><gtr:outcomeId>5460b7e4732e24.14931001</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare,Pharmaceuticals and Medical Biotechnology,Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>We recently developed a new powerful analytical tool to isolate signals originating from different neurones recorded with the high density system used in the original project</gtr:description><gtr:id>37DCAFD6-A597-414A-8823-D05DCD7784A1</gtr:id><gtr:impact>It is too early to know how it will impact other researchers (our first paper came out this week, in Cell Reports)
For our research group, this new tool has vastly improved the accuracy and quality of our data analysis</gtr:impact><gtr:outcomeId>58c1599bcc6a62.86071306</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>New method for spike sorting</gtr:title><gtr:type>Physiological assessment or outcome measure</gtr:type><gtr:url>https://github.com/martinosorb/herding-spikes</gtr:url><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>0C209252-4B1A-4D4E-A133-E1F81D6F2054</gtr:id><gtr:title>Pan-retinal characterisation of Light Responses from Ganglion Cells in the Developing Mouse Retina.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/07b2284e0832eaf541a58ba02fe15ae7"><gtr:id>07b2284e0832eaf541a58ba02fe15ae7</gtr:id><gtr:otherNames>Hilgen G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn><gtr:outcomeId>58c150f60a5af9.94835601</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11A3439D-D3BD-40CC-ABE3-B716B6DCB7D9</gtr:id><gtr:title>Rank Order Coding: a Retinal Information Decoding Strategy Revealed by Large-Scale Multielectrode Array Retinal Recordings.</gtr:title><gtr:parentPublicationTitle>eNeuro</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/265849713f17bebbb65e99bb71362ee1"><gtr:id>265849713f17bebbb65e99bb71362ee1</gtr:id><gtr:otherNames>Portelli G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2373-2822</gtr:issn><gtr:outcomeId>58c14f887218d1.65550313</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8CA0BDBD-6C0F-4974-9521-47DC7A8D2D2C</gtr:id><gtr:title>Dampening Spontaneous Activity Improves the Light Sensitivity and Spatial Acuity of Optogenetic Retinal Prosthetic Responses.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6984431ba06766bca0ec440a5e0ea179"><gtr:id>6984431ba06766bca0ec440a5e0ea179</gtr:id><gtr:otherNames>Barrett JM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn><gtr:outcomeId>58c15053533739.78731613</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D35090F5-AD05-46AD-B856-0E39F18F3D8E</gtr:id><gtr:title>Spike Detection for Large Neural Populations Using High Density Multielectrode Arrays.</gtr:title><gtr:parentPublicationTitle>Frontiers in neuroinformatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1d430e7a9cf15b090ef26f761d92643a"><gtr:id>1d430e7a9cf15b090ef26f761d92643a</gtr:id><gtr:otherNames>Muthmann JO</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1662-5196</gtr:issn><gtr:outcomeId>56dd94bc3f6499.98414396</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4381092E-75F7-4C38-AEA2-211299DD5F82</gtr:id><gtr:title>A data repository and analysis framework for spontaneous neural activity recordings in developing retina.</gtr:title><gtr:parentPublicationTitle>GigaScience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d0de9e4ac8784eeaffd8ac3d334109e"><gtr:id>5d0de9e4ac8784eeaffd8ac3d334109e</gtr:id><gtr:otherNames>Eglen SJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>2047-217X</gtr:issn><gtr:outcomeId>545269052bb3d9.12718438</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EA69B3AB-15C0-4DE2-AC8D-7E63DC3FE28C</gtr:id><gtr:title>Following the ontogeny of retinal waves: pan-retinal recordings of population dynamics in the neonatal mouse.</gtr:title><gtr:parentPublicationTitle>The Journal of physiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f323e1c149a9423f85c468c360282fb2"><gtr:id>f323e1c149a9423f85c468c360282fb2</gtr:id><gtr:otherNames>Maccione A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0022-3751</gtr:issn><gtr:outcomeId>5452696eb13573.09632333</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5E7E42CC-5D6B-44A2-BF97-EDF92959BCCC</gtr:id><gtr:title>Unsupervised Spike Sorting for Large-Scale, High-Density Multielectrode Arrays.</gtr:title><gtr:parentPublicationTitle>Cell reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/07b2284e0832eaf541a58ba02fe15ae7"><gtr:id>07b2284e0832eaf541a58ba02fe15ae7</gtr:id><gtr:otherNames>Hilgen G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58c150f5cb19a6.36735941</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/H023569/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>