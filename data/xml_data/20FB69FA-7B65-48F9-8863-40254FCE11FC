<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/CB0CAE33-BE7E-4663-AED8-394C7FB665D0"><gtr:id>CB0CAE33-BE7E-4663-AED8-394C7FB665D0</gtr:id><gtr:firstName>Timothy</gtr:firstName><gtr:otherNames>Miguel</gtr:otherNames><gtr:surname>Hospedales</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FL023385%2F1"><gtr:id>20FB69FA-7B65-48F9-8863-40254FCE11FC</gtr:id><gtr:title>Transfer Learning for Person Re-identification</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/L023385/1</gtr:grantReference><gtr:abstractText>Person re-identification is an important task in distributed multi-camera surveillance. This is currently performed manually at great economic cost, and with high error rates due to operator attentive gaps. In this project we aim to achieve fast accurate and robust automated person re-identification that can be deployed to any given camera network scenario, without any expensive calibration steps.

Automated person re-identification is the task of associating people based on images captured in video across diverse spatially distributed camera views at different times. This is challenging because the articulation of the human body and variety of viewing conditions such as lighting, angle and distance means that observed appearance typically differs more for the same person in different views than it does for different people. At the same time, it is an important task to solve because re-identification underpins many key capabilities in visual surveillance such as multi-camera tracking. This in turn is a key capability for end-user organizations which need video analytics to achieve a variety of ends including retail optimization, operational efficiency, public safety, security, infrastructure protection and terrorism prevention. Moreover, it is important to automate re-identification because the manual process in large camera networks is both prohibitively costly and inaccurate due to attentive gaps.

Current state of the art re-identification systems use machine learning techniques to produce models for re- identifying across a particular pair of cameras based on manual annotation of person identity in those cameras. However, this is not scalable in practice, because every unique pair of cameras would need calibration with training data. In this project, we will develop new machine learning models that can automatically adapt re-identification models created for an initial set of source cameras to address the re-identification problem in each new pair of cameras without requiring new annotation. This will dramatically improve the practical impact of re-identification technology by making it significantly more accurate as well as cheaper and easier to deploy.</gtr:abstractText><gtr:potentialImpactText>In the short to medium term, beneficiaries of advances in re-identification (ReId) specifically include:

* UK ReId research community. Despite initial groundbreaking impact in the early days of the field, the UK is in danger of loosing leadership to Asian competitors which are investing heavily (CUHK alone 7 people working on ReID).

* Video-content analytics companies who could commercialize the ReId IP outcomes of this project, includ- ing both SMEs like VSL (see included letter of support) as well as big industry such as BAE and IBM (who have submitted a flurry of patents in this area recently). ReId technology is used in a variety of downstream analytics tasks such as long-term tracking and person search, thus impacting the breadth of the analytics industry.

* End-user organizations tasked with video analytics for retail optimization, operational efficiency, public safety, security, infrastructure protection and terrorism prevention. Previous end user partners with whom we have partnered via VSL for trailing this type of research outputs include: Tesco, BAA (Heathrow Airport), BAE, UK MOD and London Metropolitan Police. As two specific examples:

- The London Met would like to use ReId technology for, among other tasks, automatic long-term monitoring of well known professional thieves. This is in order to catch them in the act so as to be able to secure arrests, convictions and deportations. Without this technology, the manpower does not exist to consistently keep tabs on these criminals, allowing thefts to go on unfettered. The thieves are fully aware of the Met's limitations and brazenly industrialize and professionalize their activities as a result.

- BAA have trialled person ReId for both security and operational efficiency reasons: In security they would like to perform long-term tracking of the whereabouts of someone leaving an illegally parked vehicle (a potential car-bomb danger). This is so they can intercept this person as soon as possible and resolve the situation quickly so as to minimize both risk of &amp;quot;true positives&amp;quot; and disruption to the airport by the numerous &amp;quot;false positives&amp;quot; (most violators are not of malicious intent, but all need to be dealt with just in case). On efficiency, monitoring how long it takes airport users to get through various checks and queues is key to optimizing operational processes. Without ReId technology, this information is actually quite hard to get. Thus ReId technology is being trialled to provide this information to help improve procedure efficiency.

- In each case, ReId technology has not yet fulfilled its promise well enough for operational deployment. This is because of limited practicality (annotation requirements) and the inter-related issue of significantly weaker performance out of the lab (change of domains). These are exactly issues which this proposal will address (annotation requirements, WP1), performance improvements (all WPs, but especially WP3).

* Citizens will enjoy more efficient service, increased safety and reduced crime resulting from more effective ReId.

* Other QMUL research groups. Imminent projects include: a Spanish collaboration on gait-based ReId will exploit our results (gait recognition needs to transfer across covariates of ground surface type); and an FP7 project on UAV-based surveillance will test our ReId algorithms from an overhead perspective: in which zero view annotation models are an intrinsic requirement since the view changes dynamically.

In the longer term, unsupervised transfer learning outcomes have potential to impact to a wide variety of applications including for example, transferring music recognition models across various acoustic conditions (work being done at QMUL's C4DM), transferring medical diagnosis and risk assessment Bayesian networks (work being done at QMUL's RIM).

These impacts will be achieved via trials through VSL and various collaborations and seminars - please see PTI for details.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-12-26</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-10-27</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>98569</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Bristol</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Computer Science</gtr:department><gtr:description>Contributing Re-ID to SPHERE-IRC</gtr:description><gtr:id>B76E6EBE-7E02-492E-8DD8-178D6853F0CC</gtr:id><gtr:impact>Paper submitted / under review.

The partnership contributes to the overall aims of the sphere project which have economic (saving on health spending), and societal (improving wellbeing) impact goals.</gtr:impact><gtr:outcomeId>56bce92f068ac2.82445946-1</gtr:outcomeId><gtr:partnerContribution>The partners in the sphere project contribute experiment setup, data collection, person detection and tracking.</gtr:partnerContribution><gtr:piContribution>Our research team contracted to contribute methods and expertise in person re-identification to the bigger sphere-irc project (http://www.irc-sphere.ac.uk/).</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Presentation and Networking (Defence Academy of the United Kingdom)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>4BEC246C-910D-4C90-AA00-478C41C520E8</gtr:id><gtr:impact>Presented a research poster and engaged in discussion and networking throughout a new, two-day conference (&amp;quot;UK Defence and Security Doctoral Symposium&amp;quot;) at the UK Defence Academy, Swindon. The purpose of our participation was to i) represent and disseminate the quality and scope of our research at a rare event with unprecedented attendance by members of the UK government, security services, military, and a broad multi-disciplinary cross-section of our academic peers from across the UK; ii) engage and network with potential stakeholders, collabourative partners and further dissemination candidates; iii) obtain policy and strategy information from attendees with potential for directing future research efforts. Around 11-12 interested parties engaged in discussion and requested further information on our work, including members of the UK armed forces, various government departments and satellite offices of the UK Home Office and MoD; one invitation to us was made to give a talk at the University of York; channels of communication with a view to possible future collaboration were opened between ourselves and academics at Imperial, UCL, and Southampton Universities. Our poster was given an 'honourable mention', for nearly winning the best poster prize.</gtr:impact><gtr:outcomeId>56be12dd96e489.11034958</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>10000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Queen Mary Innovation Fund (For commercialising EPSRC funded research)</gtr:description><gtr:end>2016-07-02</gtr:end><gtr:fundingOrg>Queen Mary University of London</gtr:fundingOrg><gtr:id>43F86757-D2D8-4B19-95FB-3D737A2BBDDB</gtr:id><gtr:outcomeId>56bcea826cc405.00436712</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>QMUL has a spinout company VSL makes video surveillance software sold nationally and internationally. We have worked with them to explore integrating the algorithm developed during this research project into their software product. This impacts the UK economy (spinout growth) and society (improved public safety and security).

In a followup collaboration, we also worked with University of Bristol to transfer some of the research to the systems being developed in the EPSRC IRC SPHERE project. This impacts society (improved healthcare).</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>D58D3B95-3A9C-401F-9881-D9CDE056C1F2</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d0a0829c3999.70309669</gtr:outcomeId><gtr:sector>Aerospace, Defence and Marine,Healthcare,Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>In this project we significantly advanced the power of soft biometric person search technology in video surveillance, in particular such that any attribute of interest can be queried without requiring to be pre-programmed in advance.

Context: Person search is an important capability for law-enforcement and national security. It addresses the task of quickly finding a particular suspect/person of interest either in a large set of live video streams or historic video surveillance archives. In the case where only eyewitness descriptions are available, this query should be done by soft biometrics, aka person attributes. E.g., &amp;quot;Find in the video database the person who is: male, 30s, ponytail, wearing baseball cap, leather jacket and carrying a purple rucksack&amp;quot;. The key limitation of existing person search methods is the need to pre-program in every possible attribute query that needs to be supported. This means that in practice such systems may fail to be useful in practice if elements of the given description have not been programmed in. For example, in the earlier illustration, there would be a problem if the system designer had overlooked programming in knowledge of baseball caps or purple rucksacks.

Our Key Finding: We created a method for person search which is completely unconstrained by such pre-programmed knowledge. A security operator can query a video database for absolutely any suspect profile which can be described in words. The accuracy for a priori unknown description words is typically reduced compared to anticipated and pre-programmed query terms. However, the major new capability is that no matter what unforeseen query attributes arise in a practical scenario (e.g., imperial moustache, carrying LV handbag, wearing Arsenal FC scarf, etc) the system has a chance to find the person of interest.</gtr:description><gtr:exploitationPathways>Academic: While we defined a new problem (unconstrained soft biometric person search), and the first solution to it, the accuracy is still not perfect. Future academic studies can improve on our method and obtain better accuracy.

Industry/Society: The next step to impact is for suppliers of video surveillance software to integrate our algorithm to their product. Thus benefiting both industry through more sales of higher quality product, and society thorough improved safety/security provided by it.</gtr:exploitationPathways><gtr:id>B6D9EC16-61BC-4934-BB00-0DC50D4FE2EA</gtr:id><gtr:outcomeId>56d09f59b278f9.47826513</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Retail,Security and Diplomacy,Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>FAD84B23-36F2-486E-990A-832C34FD69B1</gtr:id><gtr:title>Multivariate Regression on the Grassmannian for Predicting Novel Domains</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/614499d6dfd60e0aac13fcc6156c92cd"><gtr:id>614499d6dfd60e0aac13fcc6156c92cd</gtr:id><gtr:otherNames>Yang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c2edd3710654.91349494</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/L023385/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>