<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:department>Sch of Life and Health Sciences</gtr:department><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A306E84B-3117-4BE1-9760-FA0E44EA3BB3"><gtr:id>A306E84B-3117-4BE1-9760-FA0E44EA3BB3</gtr:id><gtr:name>Audience Inc</gtr:name><gtr:address><gtr:line1>331 Fairchild Drive</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3520E6DF-FD6B-4533-AB49-1F3AC1E1197B"><gtr:id>3520E6DF-FD6B-4533-AB49-1F3AC1E1197B</gtr:id><gtr:firstName>Brian</gtr:firstName><gtr:surname>Roberts</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/684D93E7-61D9-4FE1-8076-436E2CCF4987"><gtr:id>684D93E7-61D9-4FE1-8076-436E2CCF4987</gtr:id><gtr:firstName>Robert</gtr:firstName><gtr:otherNames>James</gtr:otherNames><gtr:surname>Summers</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FK004905%2F1"><gtr:id>9D0E08B9-968B-45B1-B5C4-AAACBC84EB66</gtr:id><gtr:title>Understanding speech in the presence of other speech: Perceptual mechanisms for auditory scene analysis in human listeners</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/K004905/1</gtr:grantReference><gtr:abstractText>&lt;p>It is unusual to hear the speech of a particular talker in isolation; speech is typically heard in the presence of interfering sounds, such as the voices of other talkers. This project will elucidate the mechanisms by which listeners segregate the formants constituting one speech sound from another.&lt;/p>

&lt;p>There is extensive evidence that grouping ?primitives? such as common onset time are important for the perceptual grouping of non-speech sounds, but few studies have investigated the role of such cues in the grouping of speech formants. Psychophysical experiments will be conducted using simplified speech stimuli that permit at least two possible perceptual organisations to compete with each other. These competitive configurations will be used to quantify the relative impact of extraneous formants on speech intelligibility as their acoustic properties are manipulated. This will enable a detailed investigation of the extent to which across-formant grouping is determined by general-purpose grouping cues and by speech-specific grouping cues.&lt;/p>

&lt;p>The relationship between primitive and high-level grouping constraints will also be explored, by determining whether linguistic information presented just prior to a speech stimulus can increase the perceptual exclusion of a competitor formant.&amp;nbsp;&lt;/p></gtr:abstractText><gtr:potentialImpactText>Private-sector companies who develop robust automatic speech recognition (ASR) devices and techniques for speech enhancement:

Robust performance in unpredictable noise remains a key problem for ASR and mobile telephony. The project will provide perceptual data needed by researchers in computational auditory scene analysis (CASA) to develop further models and algorithms for separating speech from interfering sounds. This in turn offers the prospect of improved front-end processors for ASR and speech enhancement systems, which is likely to improve the performance of commercial systems. Our industrial advisor, Audience, is one of the leading commercial developers of speech enhancement technology. Our research findings will be communicated to Audience via email and at regular review meetings, timed to coincide with jointly attended international conferences. A report will also be made available to other key companies in ASR and speech enhancement technology.

Private-sector companies who develop hearing aids and cochlear implants:

Effective separation of a target voice from interfering sounds is one of the key problems facing designers of hearing aids and cochlear implant (CI) processors. Our findings on the perceptual grouping of formants will potentially improve the coding of speech in CI processors. The first benefits of enhanced CASA solutions for improving hearing aids and CI processors are likely to emerge after about 5 years, which is typical for development lead-time of such devices. Our findings will be communicated to hearing aid and CI manufacturers by sending them a bespoke report, by visits to selected companies, and meetings with their representatives at conferences.

Charities that support the hearing impaired:

Our research findings will be communicated to major UK charities that support the hearing impaired (Action on Hearing Loss, Deafness Research UK). The improved understanding of the perceptual processes underpinning successful auditory grouping will encourage the development of collaborative psychophysical and modelling studies. Such cross-disciplinary interaction is likely to stimulate the funding by these charities of research projects on advanced hearing aids and CI algorithms. Our findings will be communicated to hearing charities via a report tailored to their interests, and by conference presentations.

The general public:

Indirectly, the impact on the beneficiaries listed above will also benefit the general public within a timescale of 5-10 years. Improvements to hearing aid technology will benefit the estimated 9 million deaf and hard-of-hearing people in the UK. Similarly, there are about 180,000 CI users worldwide who would benefit from better techniques for encoding noisy speech in CI processors. Improved ASR and speech enhancement for mobile telephony, which may arise from our project via its impact on enhanced CASA solutions, will impact on quality of life through improved speech-based communication with machines, and enhanced electronically-mediated vocal communication between individuals. The outcomes of the project will also be communicated directly to the public via a website, which will include a lay summary of our findings, and by public lectures.

The research fellow:

Summers will receive communication skills training from the Royal Society to prepare him for public lectures, report writing and company visits. This will provide transferable skills that are relevant to many professional careers. His involvement in writing technical reports and visits to leading hearing-technology companies will foster links with the commercial sector likely to enhance the prospect of future employment either in academic or industrial research.

The project team has the expertise needed to implement this impact plan. We have already established contacts with CASA researchers and with major commercial organisations with interests in ASR, mobile communications, and hearing prostheses.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2013-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>356868</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Pathways to Impact - 2 presentations at the Big Bang Young Scientists and Engineers Fair (NEC, Birmingham, 11-14 March 2015 and 16-19 March 2016).</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>15ABD625-E389-4FF5-B731-2612F3DE451F</gtr:id><gtr:impact>Involvement of the general public - mainly families with children - in interactive demonstrations involving the presentation of synthetic speech, plus discussion of the meaning and importance of research in this area to a lay audience.

High level of engagement with the general public - considerable interest in our interactive exhibit throughout the day, which used materials created as part of our ESRC-funded project.</gtr:impact><gtr:outcomeId>550882b559aad6.72013886</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.thebigbangfair.co.uk/Play-your-part/Volunteer-roles/</gtr:url><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Pathways to Impact - Dissemination visit to Oticon's Eriksholm Research Centre (Snekkersten, Denmark, 23-24 February 2016)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>28AA4D38-22B3-45F6-B6C8-BB280D0C92BA</gtr:id><gtr:impact>Oticon is one of Europe's leading hearing-technology companies, and a major manufacturer of hearing aids and cochlear implants. We (Brian Roberts and Rob Summers) were hosted at Oticon's Eriksholm Research Centre by Niels Pontoppidan (Group Manager, Advanced Algorithms) and Lars Bramslow (Project Manager, Competing Voices). Our visit involved giving a presentation on our ESRC-funded research, including extensive round-table discussion, and receiving a briefing on related research and development taking place at Oticon. In addition to extending our relationship with this company, we identified areas for further consideration that might form the basis for future collaboration. The next stage will involve discussions with Dr Huw Cooper (Consultant Clinical Scientist, Audiology) at University Hospital Birmingham.</gtr:impact><gtr:outcomeId>56d876741ac9c3.85111668</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Pathways to Impact - Dissemination visit to Phonak HQ (Staefa, Switzerland, 2-3 February 2016)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FFFE74F9-7943-4F1D-BC81-D163EAC5F25C</gtr:id><gtr:impact>Phonak is one of Europe's leading hearing-technology companies, and a major manufacturer of hearing aids and cochlear implants. We were hosted at Phonak HQ by Stefan Launer (Vice President for Advanced Concepts and Technologies) and Michael Boretzki (research scientist with interests in psychophysics, experimental psychology, and speech and language pathology). Our visit involved giving a presentation on our ESRC-funded research, including extensive round-table discussion, and receiving a briefing on related research and development taking place at Phonak. In addition to extending our relationship with this company, we identified areas for further consideration that might form the basis for future collaboration.</gtr:impact><gtr:outcomeId>56d86048cb0c84.57401955</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This research project was primarily theoretical, and so its economic and societal impact at this early stage is limited. Nonetheless, two routes of potential impact are beginning to emerge:

(1) Scientists interested in computational solutions for auditory scene analysis (CASA) are beginning to use the results of this project to inform developments in these solutions. Notably, we are in periodic contact with Martin Cooke (University of the Basque Country, Spain) and DeLiang Wang (Ohio State University, USA). In the longer term, improved CASA solutions offer the prospect of enhanced performance by hearing prostheses and automatic speech recognition systems operating in noisy environments. Such enhancements will produce benefits in healthcare and societal outcomes.

(2) Scientists employed by private-sector companies who develop hearing aids and cochlear implants are beginning to consider the results of this project in guiding their own research and development projects. We have carried out two dissemination visits on our funded research, one to Phonak in Switzerland (2-3/Feb/2016) and one to Oticon in Denmark (23-24/Feb/16). As a result, we now have established contacts with their research teams (Stefan Launer at Phonak; Niels Pontoppidan and Michael Boretzki at Oticon).</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>1BB92310-B660-4A12-BAD2-1D230CB8E293</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d87941e0fd93.37013841</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Ten experiments were completed during the course of this project. To summarise the key outcomes, these experiments are considered in five groups (each corresponding to either a published or anticipated journal article):

[EXPERIMENTS 1-2] Roberts, B., Summers, R.J., and Bailey, P.J. (2015). &amp;quot;Acoustic source characteristics, across-formant integration, and speech intelligibility under competitive conditions,&amp;quot; Journal of Experimental Psychology: Human Perception &amp;amp; Performance, 41, 680-691.

Key Outcomes: The results indicate that the contribution of a formant to the phonetic identity of a speech sound is governed by the nature of that formant's acoustic source properties, rather than by whether or not it matches the source properties of the other formants. This outcome is incompatible with a major role for target-masker similarity in determining across-formant grouping, as might have been expected based on studies of informational masking using non-speech materials. The results add to a growing body of evidence from studies and simulations of combined acoustic and electro-acoustic hearing that listeners can integrate phonetic information across radically different modes of stimulation.

[EXPERIMENTS 3-4] Roberts, B., and Summers, R.J. (2015). &amp;quot;Informational masking of monaural target speech by a single contralateral formant,&amp;quot; Journal of the Acoustical Society of America, 137, 2726-2736.

Key Outcomes: The results indicate that a single formant presented in the contralateral ear can produce substantial informational masking of target speech, despite the availability of a &amp;quot;clean&amp;quot; signal at the auditory periphery. The impact of an extraneous interfering formant on speech intelligibility depends primarily on the extent of variation of its frequency contour; variation of its amplitude contour has relatively little effect on the interference produced. There is no evidence that &amp;quot;speech-like variation&amp;quot; per se - i.e., distinctive acoustical correlates of particular articulatory movements - influences across-formant grouping and interference.

[EXPERIMENTS 5-7] Summers, R.J., Bailey, P.J., and Roberts, B. (2016). &amp;quot;Across-formant integration and speech intelligibility: Effects of acoustic source properties in the presence and absence of a contralateral interferer.&amp;quot; Journal of the Acoustical Society of America (accepted subject to minor revision).

Key Outcomes: The results extend those from our earlier research using dichotic targets. Acoustic source type and competition, rather than acoustic similarity, govern the phonetic contribution of a formant, even when target and interfering formants that differ in bandwidth (harmonic = wide, tonal = narrow) are matched for equal loudness rather than for equal RMS power. Furthermore, the integration of phonetic information across formants with different source characteristics may be greatly affected not only by the presence of interferers, but also by the spatial configuration of formants. In particular, the informational masking produced by an interfering formant may be exacerbated under circumstances requiring the integration of target formants across ears. Such a situation may arise for cochlear-implant listeners with residual low-frequency hearing in the non-implanted ear.

[EXPERIMENTS 8-9] Roberts, B., Summers, R.J., and Bailey, P.J. (2016, poster presentation, see Other Outputs and Knowledge / Future Steps). &amp;quot;Effects of differences in fundamental (F0) frequency and F0 contour on phonetic integration in a formant ensemble.&amp;quot;

Key Outcomes: In the absence of interference, a mismatch in F0 (pitch) contour between one target formant (F2) and the others (F1+F3) has no detrimental effect on intelligibility. Intelligibility is reduced when an interfering formant is added whose F0 contour matches that of F1+F3. As the difference in F0 between F2 and the other formants increases, intelligibility falls further. Where F0 differences between formants arise from differences in time-varying F0 contours, the fall in intelligibility depends on the mean difference in F0 between contours rather than differences in contour shape per se. There is no evidence that the natural variation of voice pitch over the course of a sentence increases the likelihood that a particular formant contributes to the speech percept.

[EXPERIMENT 10] Roberts, B., and Summers, R.J. (2016, poster presentation, see Other Outputs and Knowledge / Future Steps). &amp;quot;Exploring the effects of masker spectro-temporal coherence on the informational masking of speech.&amp;quot;

Key Outcomes: The impact of a time-varying interferer on intelligibility depends critically on the overall extent of its formant-frequency variation, but not on its spectro-temporal coherence. Specifically, the extent to which the interfering formant reduces intelligibility does not depend on either the segmentation of the amplitude contour (unbroken vs. divided into 100- or 200-ms-long segments) or the randomization of segment order used for the frequency contour (coherent vs. incoherent). This outcome suggests that an extraneous formant may act as an interferer primarily by increasing the overall cognitive load on the listener, rather than from the intrusion of specific acoustic-phonetic properties from the extraneous formant into the target speech percept. Once again, there is no evidence that &amp;quot;speech-like variation&amp;quot; influences across-formant grouping and interference.</gtr:description><gtr:exploitationPathways>The results obtained during this project suggest approaches by which engineers and computer scientists might improve the performance of devices such as hearing aids and automatic speech recognizers when they are operating in noisy environments.</gtr:exploitationPathways><gtr:id>C54F6654-B678-4255-AC86-184531AB5C53</gtr:id><gtr:outcomeId>56d87f9e0a32c3.67821547</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.aston.ac.uk/lhs/staff/az-index/robertsb/understanding-speech-in-the-presence-of-other-speech/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>These datasets comprise listeners' transcriptions of sentence-length speech stimuli for Experiments 1 and 2 of the article by Roberts, Summers, and Bailey (2015). Each spreadsheet comprises a summary worksheet and the raw data for each listener. The summary worksheet contains aggregated scores (keywords correct by tight scoring) for each listener in each condition, with relevant demographic information. Subsequent worksheets comprise the raw data for each listener and stimulus.</gtr:description><gtr:id>32999E6E-D8B6-46D8-9BCC-9AC0F368C117</gtr:id><gtr:impact>None at this stage. These datasets has only recently been published.</gtr:impact><gtr:outcomeId>55ad19fa733727.28015678</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Dataset for published article in JEP:HPP by Roberts, Summers, and Bailey (2015).</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://dx.doi.org/10.17036/7428fbe0-d7fe-41f5-a53a-32e9726254cd</gtr:url></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>These datasets comprise listeners' transcriptions of sentence-length speech stimuli for Experiments 1 and 2 of the article of the same title (Summers, Bailey, and Roberts, 2016, Hearing Research). Each spreadsheet comprises two summary worksheets and the raw data for each listener. The summary worksheets contain aggregated scores (keywords correct by tight and loose scoring, see below) for each listener in each condition, with relevant demographic information. Subsequent worksheets comprise the raw data for each listener and stimulus.</gtr:description><gtr:id>B68DA3C3-DB60-47CD-88B1-3B512881325E</gtr:id><gtr:impact>None at this stage. These datasets has only recently been published.</gtr:impact><gtr:outcomeId>58aed3054d4140.65869693</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Dataset for published article in Hearing Research by Summers, Bailey, and Roberts (2017).</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://dx.doi.org/10.17036/030af3e1-064c-4b80-b478-f17fa0e64842</gtr:url></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>These datasets comprise listeners' transcriptions of sentence-length speech stimuli for Experiments 1, 2, and 3 of the article of the same title (Summers, Bailey, and Roberts, 2016, J. Acoust. Soc. Am.). Each spreadsheet comprises a summary worksheet and the raw data for each listener. The summary worksheet contains aggregated scores (keywords correct by tight scoring, see below) for each listener in each condition, with relevant demographic information. Subsequent worksheets comprise the raw data for each listener and stimulus.</gtr:description><gtr:id>55E121AA-04FA-442A-BA93-15BEAC7C3F47</gtr:id><gtr:impact>None at this stage. These datasets has only recently been published.</gtr:impact><gtr:outcomeId>58aed2ac7e0540.82626482</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Dataset for published article in JASA by Summers, Bailey, and Roberts (2016).</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://dx.doi.org/10.17036/832e5972-0344-4ae5-b38c-0ff066de3a5f</gtr:url></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>These datasets comprise listeners' transcriptions of sentence-length speech stimuli for Experiments 1 and 2 of the article by Roberts and Summers (2015). Each spreadsheet comprises a summary worksheet and the raw data for each listener. The summary worksheet contains aggregated scores (keywords correct by tight scoring) for each listener in each condition, with relevant demographic information. Subsequent worksheets comprise the raw data for each listener and stimulus.</gtr:description><gtr:id>4AAA2267-36A6-4B7E-8837-1E36BAF797CC</gtr:id><gtr:impact>None at this stage. These datasets have only recently been published.</gtr:impact><gtr:outcomeId>55ad1bb7ab2d47.13616616</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Dataset for published article in JASA by Roberts and Summers (2015).</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://dx.doi.org/10.17036/Roberts_20150427_A01</gtr:url></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>Datasets for all ten experiments completed for this grant are available on the ReShare repository; these datasets comprise listeners' transcriptions of sentence-length speech stimuli. Each spreadsheet comprises a summary worksheet and the raw data for each listener. The summary worksheets contain aggregated scores (keywords correct by tight and/or loose scoring) for each listener in each condition. Subsequent worksheets comprise the raw data for each listener and stimulus. Each dataset is accompanied by a short text description; in cases where the associated article has not yet been published, a pdf summary report is also provided.</gtr:description><gtr:id>F932D2C6-B641-4AB7-B584-0876A2B36908</gtr:id><gtr:impact>None at this stage. These datasets have only recently been published.</gtr:impact><gtr:outcomeId>57680b8cd03136.11793606</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Entries in the UK Data Service (ReShare) repository.</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>975F61BD-9DC5-47CD-A70D-A1E3AFB39949</gtr:id><gtr:title>Informational masking and the effects of differences in fundamental frequency and fundamental-frequency contour on phonetic integration in a formant ensemble.</gtr:title><gtr:parentPublicationTitle>Hearing research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/77b4ebd385367d16c6b1c21141c7ec84"><gtr:id>77b4ebd385367d16c6b1c21141c7ec84</gtr:id><gtr:otherNames>Summers RJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0378-5955</gtr:issn><gtr:outcomeId>585d530cc403a0.34269237</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3D11EF4-A8EA-463D-858E-34E798C19583</gtr:id><gtr:title>Acoustic source characteristics, across-formant integration, and speech intelligibility under competitive conditions.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c9556e3979759b6654d5c6370d7ebeb3"><gtr:id>c9556e3979759b6654d5c6370d7ebeb3</gtr:id><gtr:otherNames>Roberts B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>55087a743a27d5.58340829</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2EC7DF90-84E6-4F1C-8770-B780F1D217DD</gtr:id><gtr:title>Across-formant integration and speech intelligibility: Effects of acoustic source properties in the presence and absence of a contralateral interferer.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/77b4ebd385367d16c6b1c21141c7ec84"><gtr:id>77b4ebd385367d16c6b1c21141c7ec84</gtr:id><gtr:otherNames>Summers RJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>57bc5fd2341933.44174043</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8A46A099-F8FA-40BF-8689-972674B7837A</gtr:id><gtr:title>Informational masking of monaural target speech by a single contralateral formant.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c9556e3979759b6654d5c6370d7ebeb3"><gtr:id>c9556e3979759b6654d5c6370d7ebeb3</gtr:id><gtr:otherNames>Roberts B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>556f0f97162f29.67122597</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/K004905/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>78C47607-4818-4A9C-B510-D5D9A368C83F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Phonetics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>