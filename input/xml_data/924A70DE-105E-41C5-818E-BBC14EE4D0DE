<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/FE8EF780-983C-4E93-BBAD-A06CCAA42EC0"><gtr:id>FE8EF780-983C-4E93-BBAD-A06CCAA42EC0</gtr:id><gtr:name>University of Genoa</gtr:name><gtr:address><gtr:line1>5 Via Balbi</gtr:line1><gtr:line4>I-16126 Genoa</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>Italy</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/425C1994-4AF3-4F87-AA91-B980EF37664C"><gtr:id>425C1994-4AF3-4F87-AA91-B980EF37664C</gtr:id><gtr:name>University at Buffalo</gtr:name><gtr:address><gtr:line1>12 Capen Hall</gtr:line1><gtr:postCode>14260</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/C96DB0B8-CEAC-4B25-B19B-81F9AF857DFF"><gtr:id>C96DB0B8-CEAC-4B25-B19B-81F9AF857DFF</gtr:id><gtr:name>University of Paris 6</gtr:name><gtr:address><gtr:line1>Bat 121</gtr:line1><gtr:line4>Paris</gtr:line4><gtr:postCode>F-75252</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FE8EF780-983C-4E93-BBAD-A06CCAA42EC0"><gtr:id>FE8EF780-983C-4E93-BBAD-A06CCAA42EC0</gtr:id><gtr:name>University of Genoa</gtr:name><gtr:address><gtr:line1>5 Via Balbi</gtr:line1><gtr:line4>I-16126 Genoa</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>Italy</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/425C1994-4AF3-4F87-AA91-B980EF37664C"><gtr:id>425C1994-4AF3-4F87-AA91-B980EF37664C</gtr:id><gtr:name>University at Buffalo</gtr:name><gtr:address><gtr:line1>12 Capen Hall</gtr:line1><gtr:postCode>14260</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C96DB0B8-CEAC-4B25-B19B-81F9AF857DFF"><gtr:id>C96DB0B8-CEAC-4B25-B19B-81F9AF857DFF</gtr:id><gtr:name>University of Paris 6</gtr:name><gtr:address><gtr:line1>Bat 121</gtr:line1><gtr:line4>Paris</gtr:line4><gtr:postCode>F-75252</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/BAB88C7A-BAEE-4C37-8607-41E7D988C94E"><gtr:id>BAB88C7A-BAEE-4C37-8607-41E7D988C94E</gtr:id><gtr:firstName>Massimiliano</gtr:firstName><gtr:surname>Pontil</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FH027203%2F1"><gtr:id>924A70DE-105E-41C5-818E-BBC14EE4D0DE</gtr:id><gtr:title>Structured Sparsity Methods in Machine Learning an Convex Optimisation</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H027203/1</gtr:grantReference><gtr:abstractText>Over the past ten years theoretical developments in machine learning (ML) have had a significant impact in statistics, applied mathematics and other fields of scientific research. In particular, fruitful interactions between ML and numerical optimisation have emerged that are expected to lead to theoretical and algorithmic breakthroughs with the potential to render ML methodologies significantly more applicable to many problems of practical importance. The proposed project aims to make significant UK contributions at a crucial juncture in this emerging interdisciplinary field that has so far been dominated by the US and France. Many ML techniques can be cast as problems of minimising an objective function over a large set of parameters. Examples include support vector machines as well as more recent techniques for semi-supervised learning and multi-task learning. Often the objective function is convex. Consequently, ideas from convex optimisation are becoming increasingly important in the design, implementation and analysis of learning algorithms. Up to now, however, ML has almost exclusively resorted to off the shelf methods for convex optimisation, without substantially exploiting the rich theory which lies behind this field. A thesis of this proposal is that there is a need for a deeper interplay between ML and numerical optimisation. Ultimately, bridging the two communities will facilitate communication and the power of core optimisation will be more easily brought to bear in ML and lead to new frontiers in optimisation. An area in which the interplay between ML and optimisation has a particularly important role to play is in the use of sparsity inducing optimisation problems. A rationale that drives the use of sparsity-inducing models is the observation that when the number of model parameters is much larger than the number of observations, a sparse choice of parameters is strongly desirable for fast and accurate learning. Building on this success, we believe that the time is now right for the development of a new line of algorithms for matrix learning problems under structured sparsity constraints. This means that many of the components of the parameter matrix or a decomposition thereof are zero in locations that are related via some rule (e.g the matrix may be constrained to have many zero rows, many zero eigenvalues, to have sparse eigenvectors, etc.).Perhaps the most well-know examples in which structured sparsity has proven beneficial are in collaborative filtering, where the objective function is chosen to favour low rank matrices, and in multi-task learning where the objective function is chosen to favour few common relevant variables across different regression equations. These types of optimisation problems have only recently started to be addressed in ML and optimisation, and several fundamental problems remain open, most importantly the study of efficient algorithms which exploit the underlying sparsity assumptions and a statistical learning analysis of the methods.Our proposal is multidisciplinary and involves substantial exchange of ideas between Computer Science (Machine Learning) and Mathematics (Numerical Optimisation), with three main goals. Firstly, we aim to develop novel and efficient algorithms for learning large structured matrices; fast convergence of the algorithms should be guaranteed when applied to problem data that have a sparse solution. Secondly, in the cases where the assumed sparsity structure leads to NP-hard problems and the first goal is unachievable (this is often the case under low-rank assumptions), we aim to identify tractable convex relaxations and understand their impact on sparsity. Thirdly, we aim for models and algorithms that have a more natural interpretation than generic solvers (e.g., a minimax statistical justification), which should make it more likely that practitioners will embrace the new methodology.</gtr:abstractText><gtr:potentialImpactText>As data collection continues, the design of methods for ''learning from data'' may have a major impact on the way our economy evolves, and may aid societal development. The methods developed in the proposed project may prove to be a valuable approach to handle large amount of data in a more efficient manner. We expect these methods to have a significant impact in improving current systems in several areas outside the academic community, including both the industrial and public sectors. Some of our matrix learning methods may be of significant practical value in the retail industrial sector, where data of customers' preferences to products abound. For example, we expect that our work may be valuable to companies such as GlaxoSmithKline, Unilever, and Fortent, with whom UCL have established links. At the same time our methodology has the potential of being used by health organisations in a variety of prediction problems. We believe that, by appropriately engaging potential users and making them aware of the novelty of our methodology, the proposed project may have a noticeable impact outside the academic community within the next 5 years. This impact may be measured in terms of transfer of knowledge, improved technology and job creation. In the longer term (more than 10 years), the methods and principles developed in this project may influence both social organisations and companies to redevelop their data analysis software and products, which may be crucially important in improving quality of life, health care and creation of wealth. In order to increase the impact of the proposed project in the real world, we shall promote our research findings in different ways. These include: consultation meetings, workshops, an interactive website, and publications for the wider public. In particular, we plan a two-day workshop in Oxford (at the beginning of the second year of the project) where people from industry will be encouraged to participate. This will ensure that the potential users become aware of our methodology and will facilitate transfer of knowledge outside the academic environment. Furthermore, the Centre for Computational Statistics and Machine Learning (CSML) at UCL provides an excellent means through which to pursue further contacts with industry and promote the new methodology in the wider industrial sectors. As a further means of dissemination by direct training, we aim to develop and offer a graduate course on sparsity inducing optimisation and its applications via the Oxford Taught Course Centre (TCC). Lectures will be videotaped and made available to the wider public via podcasts on a special project website. The website will be designed to have both material that is easy to understand and appeals to the mathematically untrained public, as well as mathematically rigorous material aimed at university students with a mathematical or technical background and at colleagues in the field. The material aimed at the general public could motivate high-school pupils and young adults to undertake studies in computer science or applied mathematics. The principal investigators already have relevant prior expertise in achieving successful knowledge exchange. Furthermore, UCL and Oxford have professional experts in place who can provide feedback on building up communication skills and writing to the wider public. Moreover, if needed, the postdocs and students will undertake skill developments courses, which are freely available at both institutions.</gtr:potentialImpactText><gtr:fund><gtr:end>2014-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>220702</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Pierre and Marie Curie University - Paris 6</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>Collaboration with Prof. Alexandr Tsybakov (Universit&amp;eacute; Paris 6 Pierre et Marie Curie)</gtr:description><gtr:id>593CF1DC-F811-486F-A43F-720BD0B66DAF</gtr:id><gtr:impact>Please see the section &amp;quot;Publications&amp;quot;.</gtr:impact><gtr:outcomeId>5460963445f1d4.12847393-1</gtr:outcomeId><gtr:partnerContribution>Please see above</gtr:partnerContribution><gtr:piContribution>Prof. Tsybakov is a world leading expert on mathematical statistics. He helped with the study of statistical properties of certain multitask learning and structured sparsity methods.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Genoa</gtr:collaboratingOrganisation><gtr:country>Italy, Italian Republic</gtr:country><gtr:description>University of Genoa</gtr:description><gtr:id>97A705D8-010F-49E0-990A-07DE634B1B9B</gtr:id><gtr:impact>Submitted a EU proposal.</gtr:impact><gtr:outcomeId>5457c77c723724.92892717-1</gtr:outcomeId><gtr:partnerContribution>Prof. Piana provides expertise on the theory of inverse problems and has real-data where the methods developed in this project could be applied.</gtr:partnerContribution><gtr:piContribution>We have written two European Projects (one under submission, the other unfortunately unsuccessful) which relates to machine learning in general and sparsity methods in particular.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University at Buffalo</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Collaboration with Prof. Charles Micchelli, University at Albany SUNY</gtr:description><gtr:id>9E200825-8195-49E1-BEF3-B4BB7CDE85FE</gtr:id><gtr:impact>This is multidisciplinary collaboration across Computer Science and Applied Mathematics
Please see the section &amp;quot;Publications&amp;quot; for specific research outputs.</gtr:impact><gtr:outcomeId>b99c0dbab99c0dce-1</gtr:outcomeId><gtr:partnerContribution>Prof. Micchelli provided key insight into issues pertaining the study of convex learning algorithm, the study of so-called representer theorem and the analysis of certain regularisers which arise in structured sparsity learning problems and in multitask learning.</gtr:partnerContribution><gtr:piContribution>Prof. Micchelli is an expert in approximation theory and convex analysis</gtr:piContribution><gtr:sector>Academic/University</gtr:sector></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>New machine learning methods for both supervised and unsupervised learning, which encourage a sparse solution of parameters. The methods have been studied both theoretically (using tools from convex optimisation, statistical learning theory and empirical processes) as well as practically, on problems ranging from affecting computing, to neuroimaging and to bioinformatics.

Among the results obtained, we highlight is the study of sharp error bounds on the statistical performance multitask learning methods based upon joint sparsity regularisation. Our analysis required new tools from computational learning theory and statistical estimation theory, some of which are of independent interest.</gtr:description><gtr:exploitationPathways>Several researchers are working on sparsity regularization and sparse methods in general. The papers which came out from this project (as listed in the section &amp;quot;Publications&amp;quot;) are well cited within machine learning and statistical communities. The machine learning algorithms studied in this project can have broad applications to other areas in science and engineering. Therefore, we believe the impact of this research will further grow in the next years.</gtr:exploitationPathways><gtr:id>28AD826D-FFA5-4AC6-9CFC-0A90BB6BBD3C</gtr:id><gtr:outcomeId>5457bf205bba75.70608542</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Transport</gtr:sector></gtr:sectors><gtr:url>http://www0.cs.ucl.ac.uk/staff/M.Pontil/pubs.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>68FFAC5F-A84D-40BB-A03D-43D3AB2AB600</gtr:id><gtr:title>Conditional mean embeddings as regressors</gtr:title><gtr:parentPublicationTitle>Proceedings of the 29th International Conference on Machine Learning, ICML 2012</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7b0eb9db9461086963fced2bbab6a725"><gtr:id>7b0eb9db9461086963fced2bbab6a725</gtr:id><gtr:otherNames>Gr?new?lder S.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545d02f6b193b8.89628714</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BBDC977D-FB56-4FDE-B538-4D1AEAB6B38A</gtr:id><gtr:title>Incorporating Additional Constraints in Sparse Estimation*</gtr:title><gtr:parentPublicationTitle>IFAC Proceedings Volumes</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da9f358744e21d83401ee6d518ece150"><gtr:id>da9f358744e21d83401ee6d518ece150</gtr:id><gtr:otherNames>Baldassarre L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545d02f68a9617.17331675</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D2FA072B-C364-4024-88FE-4CA6410A6D67</gtr:id><gtr:title>Multilinear multitask learning</gtr:title><gtr:parentPublicationTitle>30th International Conference on Machine Learning, ICML 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4bacdb1f6c25df4d2bbd9b8189f74d3c"><gtr:id>4bacdb1f6c25df4d2bbd9b8189f74d3c</gtr:id><gtr:otherNames>Romera-Paredes B.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545d036c949638.44430309</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F93745FF-6D53-4997-9501-AD8D95AF1ED0</gtr:id><gtr:title>A new convex relaxation for tensor completion</gtr:title><gtr:parentPublicationTitle>Advances in Neural Information Processing Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4bacdb1f6c25df4d2bbd9b8189f74d3c"><gtr:id>4bacdb1f6c25df4d2bbd9b8189f74d3c</gtr:id><gtr:otherNames>Romera-Paredes B.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>10495258</gtr:issn><gtr:outcomeId>545d0370ce0c72.33582451</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DD8C3C0B-6A2B-46B8-BB00-E9F2326052CC</gtr:id><gtr:title>Excess risk bounds for multitask learning with trace norm regularization</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4ca32b763e5c7105ca9ffbf66639a89"><gtr:id>c4ca32b763e5c7105ca9ffbf66639a89</gtr:id><gtr:otherNames>Maurer A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>15337928 15324435</gtr:issn><gtr:outcomeId>545d036f368cc1.33189918</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DCF7C9B7-C71D-47C7-B0DC-5F8C3DD852E6</gtr:id><gtr:title>PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments.</gtr:title><gtr:parentPublicationTitle>Bioinformatics (Oxford, England)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/edeb76ec9584c9365930d349525b1cca"><gtr:id>edeb76ec9584c9365930d349525b1cca</gtr:id><gtr:otherNames>Jones DT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1367-4803</gtr:issn><gtr:outcomeId>545d02f616f8b9.75664946</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>40E0E30E-79F6-4656-B851-1B67470497FB</gtr:id><gtr:title>Sparse coding for multitask and transfer learning</gtr:title><gtr:parentPublicationTitle>30th International Conference on Machine Learning, ICML 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4ca32b763e5c7105ca9ffbf66639a89"><gtr:id>c4ca32b763e5c7105ca9ffbf66639a89</gtr:id><gtr:otherNames>Maurer A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545d036b181852.45041988</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D406B054-012F-4B88-8D85-22DBA52A45D2</gtr:id><gtr:title>Structured sparsity and generalization</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4ca32b763e5c7105ca9ffbf66639a89"><gtr:id>c4ca32b763e5c7105ca9ffbf66639a89</gtr:id><gtr:otherNames>Maurer A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>15324435 15337928</gtr:issn><gtr:outcomeId>545d036a858175.71344969</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>797E649D-901C-46D3-BB5C-7AC17DB91FBA</gtr:id><gtr:title>Conditional mean embeddings as regressors</gtr:title><gtr:parentPublicationTitle>Proceedings of the 29th International Conference on Machine Learning, ICML 2012</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7b0eb9db9461086963fced2bbab6a725"><gtr:id>7b0eb9db9461086963fced2bbab6a725</gtr:id><gtr:otherNames>Gr?new?lder S.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545d036f5bddb8.76136936</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>12AA5139-1999-4A3B-BF32-DBD92A60EE23</gtr:id><gtr:title>Sparsity Is Better with Stability: Combining Accuracy and Stability for Model Selection in Brain Decoding.</gtr:title><gtr:parentPublicationTitle>Frontiers in neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da9f358744e21d83401ee6d518ece150"><gtr:id>da9f358744e21d83401ee6d518ece150</gtr:id><gtr:otherNames>Baldassarre L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1662-453X</gtr:issn><gtr:outcomeId>5aaa2282576e56.39576061</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B498A5EB-6E7A-4D9E-9253-2FDC1D62DD51</gtr:id><gtr:title>A family of penalty functions for structured sparsity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6d5be8ba14dc5d07061d2b45b416c970"><gtr:id>6d5be8ba14dc5d07061d2b45b416c970</gtr:id><gtr:otherNames>Jean Morales</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>r_9348034824cac1a6b2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F2EA9694-6238-4F8E-81D9-E0F760F0C7CA</gtr:id><gtr:title>Regularizers for structured sparsity</gtr:title><gtr:parentPublicationTitle>Advances in Computational Mathematics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/37adc85f4eb7471710a09b3a53590a11"><gtr:id>37adc85f4eb7471710a09b3a53590a11</gtr:id><gtr:otherNames>Micchelli C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53cfd9fd900db90c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>89655459-C12E-4242-A536-0F2EE3F660E1</gtr:id><gtr:title>A regularized matrix factorization approach to induce structured sparse-low-rank solutions in the EEG inverse problem</gtr:title><gtr:parentPublicationTitle>EURASIP Journal on Advances in Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/92c42768de8b3279f9281d6e03668cbd"><gtr:id>92c42768de8b3279f9281d6e03668cbd</gtr:id><gtr:otherNames>Montoya-Mart?nez J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545d020d3c8a18.46795649</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>82D05E1C-758C-452F-B8EC-AB1EB66B3B64</gtr:id><gtr:title>Oracle inequalities and optimal inference under group sparsity</gtr:title><gtr:parentPublicationTitle>The Annals of Statistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b59984939c6c4eacf4d3946767a3c8f3"><gtr:id>b59984939c6c4eacf4d3946767a3c8f3</gtr:id><gtr:otherNames>Lounici K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>546090a7630a00.63133620</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H027203/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>DEA11FBC-BEED-4EDD-890B-97D728462D26</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Mathematical sciences</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F0F2F1A7-287A-4B6F-AA0E-74A55BB4DEE4</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Mathematical Aspects of OR</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>