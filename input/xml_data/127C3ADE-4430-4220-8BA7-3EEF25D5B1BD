<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8AA8ADA9-9769-4E76-98A3-4F6DAB2C545B"><gtr:id>8AA8ADA9-9769-4E76-98A3-4F6DAB2C545B</gtr:id><gtr:name>Smallfry</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/E27575EF-ABFB-484B-BEEF-53343150A49E"><gtr:id>E27575EF-ABFB-484B-BEEF-53343150A49E</gtr:id><gtr:name>Bill and Melinda Gates Foundation</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:department>Dept of Computing</gtr:department><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8AA8ADA9-9769-4E76-98A3-4F6DAB2C545B"><gtr:id>8AA8ADA9-9769-4E76-98A3-4F6DAB2C545B</gtr:id><gtr:name>Smallfry</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E27575EF-ABFB-484B-BEEF-53343150A49E"><gtr:id>E27575EF-ABFB-484B-BEEF-53343150A49E</gtr:id><gtr:name>Bill and Melinda Gates Foundation</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/181DF4D7-24EC-4FBB-A46E-1BE4F95FC0BF"><gtr:id>181DF4D7-24EC-4FBB-A46E-1BE4F95FC0BF</gtr:id><gtr:name>SmallFry Ltd</gtr:name><gtr:address><gtr:line1>The Old School Building</gtr:line1><gtr:line2>Wolston</gtr:line2><gtr:postCode>CV8 3HF</gtr:postCode><gtr:region>West Midlands</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/070E0D0C-68C5-4EF3-9160-40AC4479E3BB"><gtr:id>070E0D0C-68C5-4EF3-9160-40AC4479E3BB</gtr:id><gtr:name>Bill &amp; Melinda Gates Foundation</gtr:name><gtr:address><gtr:line1>PO Box 23350</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/A0E50DC1-FABD-4A6D-8891-DCA5E37FD958"><gtr:id>A0E50DC1-FABD-4A6D-8891-DCA5E37FD958</gtr:id><gtr:firstName>Michael</gtr:firstName><gtr:surname>Hughes</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6EB766C7-CF7E-47FD-8F42-2F6211709069"><gtr:id>6EB766C7-CF7E-47FD-8F42-2F6211709069</gtr:id><gtr:firstName>Guang-Zhong</gtr:firstName><gtr:surname>Yang</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN022521%2F1"><gtr:id>127C3ADE-4430-4220-8BA7-3EEF25D5B1BD</gtr:id><gtr:title>Translational Alliance: SMART-Endomicroscopy</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N022521/1</gtr:grantReference><gtr:abstractText>Optical 'biopsy' is a concept whereby traditional histology is replaced with non-invasive, real-time imaging techniques such as endomicroscopy. This new probe-based technology provides live microscopy images to the operator, allowing for immediate cellular tissue characterisation in situ and in vivo. With recent advances in endomicroscopy, including the latest technological progress from the EPSRC SMART-Endomicroscopy project, it is timely to address the potential of endomicroscopy for assessing gut dysfunction, particularly given the large burden of enteric disease in all countries and across different age groups. The aim of this project is to form a new translation alliance in collaboration with a leading industrial design SME (Smallfry Ltd) and the Gates Foundation, exploring applications of the new endomicroscopy/robotics technology in global health. In particular, and in line with the Gates Foundation Enteric and Diarrheal Diseases Strategy, it focuses on how low-cost (yet high impact/tech) robotic technologies can provide a practical optical biopsy system for gut disease. This rather unexpected application of our research would complement the planned pathways to impact of the original grant supported by EPSRC, making the technology relevant to both specialised and global health settings, addressing additional challenges imposed by frugal innovation.</gtr:abstractText><gtr:potentialImpactText>The proposed project is in response to the current paradigm shift and clinical demand in healthcare for bringing cellular and molecular imaging modalities to an in vivo, in situ setting to allow for real-time tissue characterisation, functional assessment, and intraoperative guidance. It also aims to deliver the mission of the partners in developing safe, effective, and accessible technologies that are of global relevance. The focus of the endomicroscopy technology on gut dysfunction has significant value on global health, particularly given the large burden of enteric disease in all countries and across different age groups. The ability to provide non-invasive, real-time, large area surveillance, with suitability for long-term follow-up examinations, is attractive, particularly for low and middle income countries where enteric disease in infants is prevalent. These childhood gut infections are known to lead first to malnutrition, and subsequently to long-term developmental problems, including stunted growth and poor response to vaccines. By focussing on how low-cost (yet high tech) robotic technologies can provide a practical optical biopsy system for gut disease, we aim to make SMART-Endomicroscopy relevant to both specialised and global health settings, addressing specific challenges imposed by frugal innovation. 
 
The stakeholders who will benefit from this research include: Academia (both UK and international) in medical imaging, biophotonics, sensing, vision, robotics, general biomedical engineering and global health research; Non-governmental organisations focussed on global health and charities championing improved healthcare provision and disease focussed organisations; Public and private sectors in healthcare provision; Medical devices industry; and more importantly patients and the general public. 
 
The benefit from this research includes potentially significant technological, social, commercial and economic impact. It not only enhances research capacity but also brings tangible knowledge transfer opportunities. The project addresses important research and development challenges related to robotics and frugal innovation, and the end results are likely to transform the innovation pathways of new device designs that are of global value. Robotic technologies are often regarded as expensive and only relevant to the privileged few. The proposed translational alliance aims to challenge this by further advancing SMART-Endomicroscopy under the constraints and principles of frugal innovation, leading to a long-term partnership in addressing some of the unmet global health challenges in future.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>249492</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Smallfry</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>SMART TAP: Collaboration with Smallfry</gtr:description><gtr:id>ACBFD0F0-E3C8-4A7D-94B2-6C7C6910AA9B</gtr:id><gtr:impact>Initial workshops held between Imperial College, Smallfry and clinical collaborators have already influenced the design of our devices and future research directions.</gtr:impact><gtr:outcomeId>58c91aad0613c3.03049028-1</gtr:outcomeId><gtr:partnerContribution>Smallfry have strong experience working across the healthcare industry, from medical device manufacturers to NHS Trusts, and are bringing this to bear on the project. They are contributing expertise in the '3P' chronology (people, product, place) of product design and frugal innovation.</gtr:partnerContribution><gtr:piContribution>Imperial College is working to translate its endomicroscopy technology to cost-critical applications, particularly in global healthcare.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Bill and Melinda Gates Foundation</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>SMART TAP: Bill and Melinda Gates Foundation</gtr:description><gtr:id>25CECB47-D80D-490B-99C4-8BC2F474B959</gtr:id><gtr:impact>This is an on-going collaboration which will impact all output of this grant.</gtr:impact><gtr:outcomeId>58c9195737dd84.60255624-1</gtr:outcomeId><gtr:partnerContribution>The Bill and Melinda Gates Foundation will support the project through advice on the application of endomicroscopy technology to global health problems in developing countries, as well as providing access to a wide range of experts.</gtr:partnerContribution><gtr:piContribution>Imperial College is working to translate our endomicroscopy technology to global health applications.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The aim of this alliance is to develop clinical applications of the basic technology developed under the SMART Endomicroscopy Project (EP/I027769/1 ), with a particular focus on low-cost, accessible solutions for global healthcare. The first full prototype handheld endomicroscope scanner has been fabricated and integrated with a fibred ablation laser and is currently being tested on ex vivo tissue samples at a partner hospital. We have already held several workshops with the industrial partner, including visits to see frontline medical procedures and are now jointly working on the design of the next generation device with improved ergonomics and clinical applicability.</gtr:description><gtr:exploitationPathways>The findings, once complete, will support clinical trials and commercialisation of endomicroscopy-related technology.</gtr:exploitationPathways><gtr:id>72D5A06A-856D-4C65-B464-AEDCEAA71BDE</gtr:id><gtr:outcomeId>58c15eed296947.23944730</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>F781C704-D558-4540-8577-236AAD270799</gtr:id><gtr:title>Fiber-shifting endomicroscopy for enhanced resolution imaging</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3aa675613281202774129f27a91c942b"><gtr:id>3aa675613281202774129f27a91c942b</gtr:id><gtr:otherNames>Vyas K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9e8a282315d2.82549372</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9554BD61-DE36-4DC7-8A44-D49559D5FB5A</gtr:id><gtr:title>From Macro to Micro: Autonomous Multiscale Image Fusion for Robotic Surgery</gtr:title><gtr:parentPublicationTitle>IEEE Robotics &amp; Automation Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/917fedf7d4ac4a5d4fbb9db6070723d7"><gtr:id>917fedf7d4ac4a5d4fbb9db6070723d7</gtr:id><gtr:otherNames>Zhang L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1070-9932</gtr:issn><gtr:outcomeId>5a351c07a31928.80824480</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B180DC5F-C5A8-48E8-822E-EA448F688FBF</gtr:id><gtr:title>A balloon endomicroscopy scanning device for diagnosing barrett's oesophagus</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/78327d80f4bfd61b1f1989a7cad1f70b"><gtr:id>78327d80f4bfd61b1f1989a7cad1f70b</gtr:id><gtr:otherNames>Zuo S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9ed1fa0a6bd8.40514897</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DE07DAF3-364B-4FDC-B28D-D357B599A8C9</gtr:id><gtr:title>Autonomous scanning for endomicroscopic mosaicing and 3D fusion</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/917fedf7d4ac4a5d4fbb9db6070723d7"><gtr:id>917fedf7d4ac4a5d4fbb9db6070723d7</gtr:id><gtr:otherNames>Zhang L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a578aec3e1066.65486729</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>66E9AC22-7B06-4A33-8FCB-0CF99B142B54</gtr:id><gtr:title>Endomicroscopy for Computer and Robot Assisted Intervention.</gtr:title><gtr:parentPublicationTitle>IEEE reviews in biomedical engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/78327d80f4bfd61b1f1989a7cad1f70b"><gtr:id>78327d80f4bfd61b1f1989a7cad1f70b</gtr:id><gtr:otherNames>Zuo S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1937-3333</gtr:issn><gtr:outcomeId>5a578af4692f89.66841186</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FBA08685-3F3F-48FC-B4B0-383C9FEB0362</gtr:id><gtr:title>Multi-view Multi-modal Feature Embedding for Endomicroscopy Mosaic Classification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f2ff93192dec71a3af4d8933d02728f3"><gtr:id>f2ff93192dec71a3af4d8933d02728f3</gtr:id><gtr:otherNames>Gu Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a9e8bd9c1a792.54905661</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D107E291-A132-4103-8922-688DDB96FC26</gtr:id><gtr:title>U.K. Robotics Week [Competitions]</gtr:title><gtr:parentPublicationTitle>IEEE Robotics &amp; Automation Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/97a2d622d7f36f5a14d63106d30e887d"><gtr:id>97a2d622d7f36f5a14d63106d30e887d</gtr:id><gtr:otherNames>Merrifield R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa6c1ab0bfd13.39242695</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>978C08A9-5128-466E-A608-A556B7E9E294</gtr:id><gtr:title>Methylene-blue aided rapid confocal laser endomicroscopy of breast cancer</gtr:title><gtr:parentPublicationTitle>Journal of Biomedical Optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3aa675613281202774129f27a91c942b"><gtr:id>3aa675613281202774129f27a91c942b</gtr:id><gtr:otherNames>Vyas K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58c15a4ea42a75.87678651</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>35385F43-EDC4-4A7E-BF8B-20F9EAE831D6</gtr:id><gtr:title>Three-dimensional robotic-assisted endomicroscopy with a force adaptive robotic arm</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d0a08ba5ec1655906ce5c19b6e256cb"><gtr:id>3d0a08ba5ec1655906ce5c19b6e256cb</gtr:id><gtr:otherNames>Wisanuvej P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a578aeacf4557.56869481</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AE9058CE-5F86-4DE3-A36F-348A8B680450</gtr:id><gtr:title>Line-scanning fiber bundle endomicroscopy with a virtual detector slit.</gtr:title><gtr:parentPublicationTitle>Biomedical optics express</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/61f0cf0f16d76c3fe54012bce667060a"><gtr:id>61f0cf0f16d76c3fe54012bce667060a</gtr:id><gtr:otherNames>Hughes M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2156-7085</gtr:issn><gtr:outcomeId>585d48323566d6.38171310</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0DBDE2A3-54D8-4426-AC3C-45AC14FA8DA8</gtr:id><gtr:title>A Journey to the Surgical Robot Challenge [History]</gtr:title><gtr:parentPublicationTitle>IEEE Robotics &amp; Automation Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/97a2d622d7f36f5a14d63106d30e887d"><gtr:id>97a2d622d7f36f5a14d63106d30e887d</gtr:id><gtr:otherNames>Merrifield R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa6c0a0c90123.89496126</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>580754F9-3A0B-441F-9592-FB6AEF1591EE</gtr:id><gtr:title>Flexible Robotic Scanning Device for Intraoperative Endomicroscopy in MIS</gtr:title><gtr:parentPublicationTitle>IEEE/ASME Transactions on Mechatronics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/78327d80f4bfd61b1f1989a7cad1f70b"><gtr:id>78327d80f4bfd61b1f1989a7cad1f70b</gtr:id><gtr:otherNames>Zuo S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9ed229798f54.80048159</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N022521/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>