<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:department>Newcastle Institute for the Arts</gtr:department><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/C671299D-BE6D-4308-98CD-0DD8934A4A77"><gtr:id>C671299D-BE6D-4308-98CD-0DD8934A4A77</gtr:id><gtr:firstName>Sally Jane</gtr:firstName><gtr:surname>Norman</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE005624%2F1"><gtr:id>C3F3E0C4-F386-48EA-A256-5245AA96881B</gtr:id><gtr:title>MOTION CAPTURE DATA SERVICES FOR MULTIPLE USER CATEGORIES</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E005624/1</gtr:grantReference><gtr:abstractText>The project proposes to address the issue of cross-sector usability of data made available through distributed computing, identifying Grid services which optimise interdisciplinary exploitation of a given data set for diverse end-users. Choice of the area of motion capture is driven by the wish to get beyond historicist archival practices characteristic of early arts and humanities forays into e-science, to move into a more volatile sector of data acquisition and management tuned to the urgency of creative arts and in vivo science research. The proposed team features expertise in the scientific and artistic sectors via performing arts and technology, bioengineering/ motion capture, e-science development and visualization. Through arts and humanities project leadership, the e-demonstrator will be informed by and geared towards a highly motivated interest group susceptible to play a strong dissemination role. Within the six-month time frame, emphasis will be placed on service integration and key commonalities and differences discerned in user behaviours and requirements. As far as possible, these will be reviewed without preconceptions, on the assumption that both the scientific and arts and humanities sectors employ tacit terminologies and methodologies which, once made explicit, may prove to be mutually beneficial in enriching future Grid developments. The project is structured to instantiate and maintain constant dialogue between the partner disciplines, from the initial requirements review phase through to the final evaluation and dissemination phases, to ensure feedback that will make its outputs credible and robust. This exchange will be facilitated by the interdisciplinary steering group led by the arts and humanities based principal investigator. The project is designed to serve as an exploratory, pilot scheme for future in-depth research in the area of motion capture and distributed computing, and will be carefully monitored to identify the areas that represent the strongest mutual interest for future developments.Use of high-end display possibilities offered by a virtual reality platform, in addition to conventional distributed desktop environments will enhance comparison of the different types of processing and visualisation required by scientific and artistic users of the data. Moreover, the Informatics Research Institute's virtual reality suite will serve as a strategic dissemination platform, as indicated by previous highly successful interdisciplinary encounters it has hosted in conjunction with Culture Lab, attracting large groups of arts and humanities researchers.The work packages are designed for optimum clarity and differentiation of the project phases, with a view to serving as a useful methodological basis for future e-science projects undertaken by humanities scholars. Dissemination of findings as both academic papers and creative work (electronic multimedia documentation) will likewise target a broad public not familiar with distributed computing, employing lay terminology and simple explanation of aims, methods and results.</gtr:abstractText><gtr:fund><gtr:end>2007-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>40506</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C75AAED9-7D35-4689-A19B-AC85045696BF</gtr:id><gtr:title>AMUC: Associated Motion capture User Categories.</gtr:title><gtr:parentPublicationTitle>Philosophical transactions. Series A, Mathematical, physical, and engineering sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/92ec164409719c885d1853abab5a4a09"><gtr:id>92ec164409719c885d1853abab5a4a09</gtr:id><gtr:otherNames>Norman SJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1364-503X</gtr:issn><gtr:outcomeId>doi_53d04a04af64d48f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>60D4281E-04AB-48FF-B605-925C02284C54</gtr:id><gtr:title>Generic Versus Idiosyncratic Expression in Live Performance Using Digital Tools</gtr:title><gtr:parentPublicationTitle>Performance Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/841a411a19b24dc286359a66bfcf0624"><gtr:id>841a411a19b24dc286359a66bfcf0624</gtr:id><gtr:otherNames>Jane Norman S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:outcomeId>doi_53d03d03dc176080</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E005624/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>FA4A8455-3074-48A4-B0CD-5B85D94B79F5</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>eScience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>