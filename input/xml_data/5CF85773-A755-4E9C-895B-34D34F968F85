<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Statistics</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/9690E3E2-6367-4F15-BC1F-9DFFE5958FE2"><gtr:id>9690E3E2-6367-4F15-BC1F-9DFFE5958FE2</gtr:id><gtr:firstName>Arnaud</gtr:firstName><gtr:surname>Doucet</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FK009850%2F1"><gtr:id>5CF85773-A755-4E9C-895B-34D34F968F85</gtr:id><gtr:title>Bayesian Inference for Big Data with Stochastic Gradient Markov Chain Monte Carlo</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K009850/1</gtr:grantReference><gtr:abstractText>We are in the midst of an information revolution, where advances in science and technology, as well as the day-to-day operation of successful organisations and businesses, are increasingly reliant on the analyses of data. Driving these advances is a deluge of data, which is far outstripping the increase in computational power available. The importance of managing, analysing, and deriving useful understanding from such large scale data is highlighted by high-profile reports by McKinsey and The Economist as well as other outlets, and by the EPSRC's recent ICT priority of &amp;quot;Towards an Intelligent Information Infrastructure&amp;quot;.

Bayesian analysis is one of the most successful family of methods for analysing data, and one now widely adopted in the statistical sciences as well as in AI technologies like machine learning. The Bayesian approach offers a number of attractive advantages over other methods: flexibility in constructing complex models from simple parts; fully coherent inferences from data; natural incorporation of prior knowledge; explicit modelling assumptions; precise reasoning of uncertainties over model order and parameters; and protection against overfitting. 

On the other hand, there is a general perception that they can be too slow to be practically useful on big data sets. This is because exact Bayesian computations are typically intractable, so a range of more practical approximate algorithms are needed, including variational approximations, sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC). MCMC methods arguably form the most popular class of Bayesian computational techniques, due to their flexibility, general applicability and asymptotic exactness. Unfortunately, MCMC methods do not scale well to big data sets, since they require many iterations to reduce Monte Carlo noise, and each iteration already involves an expensive sweep through the whole data set.

In this project we propose to develop the theoretical foundations for a new class of MCMC inference procedures that can scale to billions of data items, thus unlocking the strengths of Bayesian methods for big data. The basic idea is to use a small subset of the data during each parameter update iteration of the algorithm, so that many iterations can be performed cheaply. This introduces excess stochasticity in the algorithm, which can be controlled by annealing the update step sizes towards zero as the number of iterations increases. The resulting algorithm is a cross between an MCMC and a stochastic optimization algorithm. An initial exploration of this procedure, which we call stochastic gradient Langevin dynamics (SGLD), was initiated by us recently (Welling and Teh, ICML 2011). 

Our proposal is to lay the mathematical foundations for understanding the theoretical properties of such stochastic MCMC algorithms, and to build on these foundations to develop more sophisticated algorithms. We aim to understand the conditions under which the algorithm is guaranteed to converge, and the type and speed of convergence. Using this understanding, we aim to develop algorithmic extensions and generalizations with better convergence properties, including preconditioning, adaptive and Riemannian methods, Hamiltonian Monte Carlo methods, Online Bayesian learning methods, and approximate methods with large step sizes. These algorithms will be empirically validated on real world problems, including large scale data analysis problems for text processing and collaborative filtering which are standard problems in machine learning, and large scale data from ID Analytics, a partner company interested in detecting identity theft and fraud.</gtr:abstractText><gtr:fund><gtr:end>2016-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>158970</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We are studying sophisticated new statistical methods to analyze big data sets. Current methods are very computationally intensive and do not scale in presence of big data. We are developing scalable yet sophisticated techniques to extract useful information from massive datasets.</gtr:description><gtr:exploitationPathways>There is still a lot of room for improvement, both methodologically and theoretically. So we expect over the forthcoming year to develop further our new algorithms.</gtr:exploitationPathways><gtr:id>59B49C30-DA8F-4854-B8A2-95ADF5475E8E</gtr:id><gtr:outcomeId>5463e3547ce971.07840924</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Electronics,Security and Diplomacy</gtr:sector></gtr:sectors><gtr:url>http://www.stats.ox.ac.uk/~doucet/journalsbysubject.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>039486C5-1933-4AF6-888E-8CD1E5A78331</gtr:id><gtr:title>Exploration of the (non-) asymptotic bias and variance of stochastic gradient Langevin dynamics</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/32d1cf6d78bf45c3f111e006126108cd"><gtr:id>32d1cf6d78bf45c3f111e006126108cd</gtr:id><gtr:otherNames>Vollmer, SJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d70441e06921.78135017</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A24CD5C3-ABB9-4C04-B794-2663B526F804</gtr:id><gtr:title>Unbiased Monte Carlo: posterior estimation for intractable/infinite-dimensional models</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a0a94885d80579a88587c7c7e7d59579"><gtr:id>a0a94885d80579a88587c7c7e7d59579</gtr:id><gtr:otherNames>Agapiou, S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56d704f6c1f594.28947500</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>57DB1E0F-AE91-43E9-817E-C155385EBDD3</gtr:id><gtr:title>Interacting particle markov chain monte carlo</gtr:title><gtr:parentPublicationTitle>33rd International Conference on Machine Learning, ICML 2016</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/965aca713bca8d712c1dbefb10f2c28c"><gtr:id>965aca713bca8d712c1dbefb10f2c28c</gtr:id><gtr:otherNames>Rainforth T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c6b9f284c1b2.20866195</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>72C3BCEE-B55B-4CD3-BBF6-4E02B4E69BD1</gtr:id><gtr:title>Towards scaling up Markov chain Monte Carlo: An adaptive subsampling approach</gtr:title><gtr:parentPublicationTitle>31st International Conference on Machine Learning, ICML 2014</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7a2e6cba1b7f260190d2c7e7561ab776"><gtr:id>7a2e6cba1b7f260190d2c7e7561ab776</gtr:id><gtr:otherNames>Bardenet R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>58c6bad9e799e1.06936442</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4B557F4B-21D4-415D-8B93-D983FD3FAE69</gtr:id><gtr:title>Asynchronous anytime sequential Monte Carlo</gtr:title><gtr:parentPublicationTitle>Advances in Neural Information Processing Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce8837dde11c70eefaeaf79e7545891f"><gtr:id>ce8837dde11c70eefaeaf79e7545891f</gtr:id><gtr:otherNames>Paige B.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>10495258</gtr:issn><gtr:outcomeId>58c6bb9ab65bf8.12570585</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8050C4D7-D263-4DBC-AE12-675C54B78D9A</gtr:id><gtr:title>The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov Chain Monte Carlo Method</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ae24d600aa2d8ac50577ee3979664c2c"><gtr:id>ae24d600aa2d8ac50577ee3979664c2c</gtr:id><gtr:otherNames>A Bouchard-C?t?</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d703e730e1e3.21220976</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E04F3170-E354-44B6-9EEA-AD8319B910CF</gtr:id><gtr:title>An Online Expectation&amp;acirc;??Maximization Algorithm for Changepoint Models</gtr:title><gtr:parentPublicationTitle>Journal of Computational and Graphical Statistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c415264e9f99111368e5cfb1e612cd19"><gtr:id>c415264e9f99111368e5cfb1e612cd19</gtr:id><gtr:otherNames>Yildirim S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5463dbcb9561e1.62416823</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A23B3562-4155-4102-B3E6-B7D38F7F98A1</gtr:id><gtr:title>Distributed Bayesian Learning with Stochastic Natural-gradient Expectation Propagation and the Posterior Server</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce8e46f2272baa849e4e6886b051d733"><gtr:id>ce8e46f2272baa849e4e6886b051d733</gtr:id><gtr:otherNames>Teh, YW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d7038e312227.14057827</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>62CD02D8-702F-4126-B5EE-D6B117CE62DF</gtr:id><gtr:title>Distributed Nonlinear Consensus in the Space of Probability Measures</gtr:title><gtr:parentPublicationTitle>IFAC Proceedings Volumes</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fa443d5dfa5021117d20c67482073708"><gtr:id>fa443d5dfa5021117d20c67482073708</gtr:id><gtr:otherNames>Bishop A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5463e08a7e5055.27095882</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1C2C8C98-6F6A-4C33-83DE-DB22DD5947A4</gtr:id><gtr:title>On Markov chain Monte Carlo methods for tall data</gtr:title><gtr:parentPublicationTitle>JOURNAL OF MACHINE LEARNING RESEARCH</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c66f5e609907b2bbcba3767786fb5133"><gtr:id>c66f5e609907b2bbcba3767786fb5133</gtr:id><gtr:otherNames>Bardenet Remi</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1532-4435</gtr:issn><gtr:outcomeId>5a361c2fd7e521.93874479</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9ACD04A8-1AE2-485D-B74B-DBD3ADCD77EF</gtr:id><gtr:title>Expectation particle belief propagation</gtr:title><gtr:parentPublicationTitle>Advances in Neural Information Processing Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1f87b8161bcd79d1f666e0bbce267cea"><gtr:id>1f87b8161bcd79d1f666e0bbce267cea</gtr:id><gtr:otherNames>Lienart T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>10495258</gtr:issn><gtr:outcomeId>58c6b9c1e27613.96908359</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B9036676-0FB8-4006-8AED-EFF0DC67410D</gtr:id><gtr:title>An iterative technique for bounding derivatives of solutions of Stein equations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8934b350eb60e90f0e2a14a48d6324b0"><gtr:id>8934b350eb60e90f0e2a14a48d6324b0</gtr:id><gtr:otherNames>D?bler, C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d702fe6a0f92.90284271</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DC57C3FD-F113-4DFA-A53A-B2A2357A2361</gtr:id><gtr:title>The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov Chain Monte Carlo Method</gtr:title><gtr:parentPublicationTitle>Journal of the American Statistical Association</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2e6c52a9a44d7585ff5dbab61590f3b8"><gtr:id>2e6c52a9a44d7585ff5dbab61590f3b8</gtr:id><gtr:otherNames>Bouchard-C?t? A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708cf5680600.28047106</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>40911FA0-352F-47AF-922D-4B618D256E97</gtr:id><gtr:title>Uniform Stability of a Particle Approximation of the Optimal Filter Derivative</gtr:title><gtr:parentPublicationTitle>SIAM Journal on Control and Optimization</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e2757d6bd5a33e59ef64623c315d0fa"><gtr:id>3e2757d6bd5a33e59ef64623c315d0fa</gtr:id><gtr:otherNames>Del Moral P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0363-0129</gtr:issn><gtr:outcomeId>56cdb6cbdde240.60412546</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7693874E-CBE6-4430-8509-E89A99BDD01E</gtr:id><gtr:title>On Markov chain Monte Carlo Methods for Tall Data</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f3d945d662121b1d0b9eedab8d0494f9"><gtr:id>f3d945d662121b1d0b9eedab8d0494f9</gtr:id><gtr:otherNames>Bardenet R</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>58c6b5fd7341c0.99767825</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K009850/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>DEA11FBC-BEED-4EDD-890B-97D728462D26</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Mathematical sciences</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>62309876-5C71-411C-B1A7-1B2907AFB5A8</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Statistics &amp; Appl. Probability</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>