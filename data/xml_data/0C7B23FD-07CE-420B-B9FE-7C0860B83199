<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/7D76EBCF-EC19-4D94-8F9A-891E96618C12"><gtr:id>7D76EBCF-EC19-4D94-8F9A-891E96618C12</gtr:id><gtr:firstName>Shonit</gtr:firstName><gtr:surname>Punwani</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2C0B30F5-1072-42DB-9C3E-90270248AA67"><gtr:id>2C0B30F5-1072-42DB-9C3E-90270248AA67</gtr:id><gtr:firstName>Iasonas</gtr:firstName><gtr:surname>Kokkinos</gtr:surname><gtr:orcidId>0000-0002-2606-6476</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/1304D061-A5C0-4394-AB3A-68D2D61C08D5"><gtr:id>1304D061-A5C0-4394-AB3A-68D2D61C08D5</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Hawkes</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/59B08208-1FCC-46DA-8DCA-77C47302D4D5"><gtr:id>59B08208-1FCC-46DA-8DCA-77C47302D4D5</gtr:id><gtr:firstName>Eleftheria</gtr:firstName><gtr:surname>Panagiotaki</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/0709CB3C-D473-4D0E-83FE-420D2757943F"><gtr:id>0709CB3C-D473-4D0E-83FE-420D2757943F</gtr:id><gtr:firstName>Thomy</gtr:firstName><gtr:surname>Mertzanidou</gtr:surname><gtr:orcidId>0000-0001-9706-7399</gtr:orcidId><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/077BD985-50EA-486F-A761-CB599D6D2780"><gtr:id>077BD985-50EA-486F-A761-CB599D6D2780</gtr:id><gtr:firstName>Alex</gtr:firstName><gtr:surname>Freeman</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/46015271-9BA9-4097-9043-5125FEB722C2"><gtr:id>46015271-9BA9-4097-9043-5125FEB722C2</gtr:id><gtr:firstName>Daniel</gtr:firstName><gtr:surname>Alexander</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FR006032%2F1"><gtr:id>0C7B23FD-07CE-420B-B9FE-7C0860B83199</gtr:id><gtr:title>Learning MRI and histology image mappings for cancer diagnosis and prognosis</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/R006032/1</gtr:grantReference><gtr:abstractText>This project aims to exploit recent advances in machine learning to address acute problems in cancer management - most directly prostate cancer. The current standard approach of making treatment decisions via biopsy and histology has two key limitations; it is invasive and subjective/inconsistent. We will develop the computational tools supporting new solutions that resolve both issues. Specifically, we aim to enable non-invasive MRI to become the primary diagnostic tool. This would avoid a large number of unnecessary biopsies, which carry significant risk of life-changing side-effects, reserving the procedure for only marginal cases. We also plan to relate MR signals to quantitative tissue features enabling consistent assessment and thus more reliable treatment decisions.

The use of MRI in prostate cancer has become routine only in the last few years. Thus, data relating MRI to patient outcome (e.g. 5-10 year survival) is not available. However, we are uniquely positioned to obtain i) associated MRI and histology images, and ii) associated histology and patient outcome. In combination, these support a two-step learning and estimation process: from MRI to histological features; and from histological features to patient prognosis. Such mappings can provide invaluable new information for clinical decision making, as well as guide the design of maximally informative future MRI protocols. Such protocols will enable long-term data collection initiatives that support direct mappings from MRI to outcome.

The project involves engineering challenges that demand innovations at the cutting edge of image-based machine learning technology: i) accommodating uncertainty in the alignment of training images; ii) quantification and visualization of uncertainty in the output of learned models; iii) salient feature selection in high-dimensional input data; iv) development of experiment design optimization algorithms driven by implicit computational models (such as neural networks). We build on the latest ideas in deep learning to address these challenges. We tailor solutions relevant to the immediate problems at hand in prostate cancer, but that extend to related tasks in cancer imaging and medical imaging in general.</gtr:abstractText><gtr:potentialImpactText>Prostate cancer is the most common type of cancer in males in many countries worldwide, including the UK. Currently more than 8 in 10 men in England and Wales survive prostate cancer for ten years or more since the time of diagnosis. Early and accurate diagnosis is key for improved prognosis. It is important to identify early both high-risk cases of invasive cancer that require immediate treatment and additionally low-risk cases that grow slowly and might never develop into a life-threatening disease. The latter becomes increasingly important as a large number of patients are subjected to unnecessary biopsies and treatments (over-treatment) and their associated side-effects. 

Management and treatment of cancer is one of the biggest challenges in medicine worldwide, costing the UK economy more than &amp;pound;15bn a year. Prostate cancer is the most common type of cancer in males with around 47,300 cases diagnosed annually. This project advances towards the use of MRI for early and accurate patient stratification of prostate cancer patients with significant socio-economic impact. 

From an economic point of view, early diagnosis minimises the negative impact of cancer on the active workforce, as it is associated with increased survival rates. In addition, addressing the problem of over-treatment, by identifying the patients with low-risk disease that will not progress to be life-threatening, has the advantage of avoiding costly treatments that are unnecessary. 

From a societal point of view, the benefits of early patient stratification are evident both for the patients and their families. This project makes an important advance in early and accurate diagnosis based on patient-specific in-vivo imaging, enabling subsequent personalised treatment. This involves immediate cancer therapy options for high-risk cases, while potentially sparing severe discomfort and side-effects from unnecessary biopsy and loss of quality of life from unnecessary chemotherapy treatments and surgica interventions for low-risk prostate cancer cases. In both cases the patient will benefit from improved quality of life. 

The project uses prostate cancer as its demonstrator, but the framework has wider applications with similar impact both in a range of other solid cancers (for example breast, brain, pancreas, liver etc) as well as other medical domains that currently rely on histology, such as neuroscience.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-12-14</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-12-15</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>774254</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/R006032/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>A759BB04-AFFE-4780-BD31-9A2707BC44BA</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Medical Imaging</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>