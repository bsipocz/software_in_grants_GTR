<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/ED6A6B32-663C-4A62-A33B-2C6A68E2E102"><gtr:id>ED6A6B32-663C-4A62-A33B-2C6A68E2E102</gtr:id><gtr:name>University of Essex</gtr:name><gtr:department>Computer Sci and Electronic Engineering</gtr:department><gtr:address><gtr:line1>Wivenhoe Park</gtr:line1><gtr:line4>Colchester</gtr:line4><gtr:line5>Essex</gtr:line5><gtr:postCode>CO4 3SQ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/ED6A6B32-663C-4A62-A33B-2C6A68E2E102"><gtr:id>ED6A6B32-663C-4A62-A33B-2C6A68E2E102</gtr:id><gtr:name>University of Essex</gtr:name><gtr:address><gtr:line1>Wivenhoe Park</gtr:line1><gtr:line4>Colchester</gtr:line4><gtr:line5>Essex</gtr:line5><gtr:postCode>CO4 3SQ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/520736CD-5651-400D-BBAD-EFF670CC7014"><gtr:id>520736CD-5651-400D-BBAD-EFF670CC7014</gtr:id><gtr:name>Prensilia</gtr:name><gtr:address><gtr:line1>Via Boccioni, 2</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6EE3CDF6-DFD1-4849-BF0B-41ED776D70E5"><gtr:id>6EE3CDF6-DFD1-4849-BF0B-41ED776D70E5</gtr:id><gtr:firstName>Luca</gtr:firstName><gtr:surname>Citi</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN031806%2F1"><gtr:id>22F3684A-A487-4C4B-A8CF-D3F05021D06C</gtr:id><gtr:title>Decoding the neural drive for finer and more intuitive control of a myoelectric robotic hand</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N031806/1</gtr:grantReference><gtr:abstractText>The loss of an upper limb is often caused by traumatic events, such as work-related injuries, road traffic accidents, and military casualties. Unlike other types of amputation, almost three quarters of upper limb referrals are young (less than 55 years) and otherwise healthy individuals. Despite decades of research, commercial active prostheses still use technology developed in the sixties, namely myoelectric control via superficial electrodes. Stated simply, they are controlled by electrical impulses recorded from the patient's residual forearm muscles using a small number of surface electrodes. Their functionality is constrained by the limited amount of voluntary information that can be extracted from the small number of surface electrodes adopted. As a result, even the most advanced of these prostheses only allow a small number of pre-defined simple grip shapes that the user can select from. Users of myoelectric prostheses often express a desire for improved functionality, wider range of grip shapes, and more intuitive proportional control. A main problem of today's prostheses is that the movements are decoded through classifiers (i.e. algorithms trained to recognize patterns in the electromyographic signal), which must be trained for the specific movement.

Within this project, we conduct ambitious research into the development of novel decoding algorithms to make the control of myoelectric hand prostheses more natural, intuitive, and accurate. Our approach uses recently developed high-density surface electromyographic (hd-sEMG) arrays, which record from a high number of closely spaced electrodes, combined with the most advanced signal processing and neural decoding techniques.
The use of hd-sEMG allows the extraction of more information by giving access to individual motor unit action potentials which can be used to reconstruct the neural drive, i.e. the train of electrical pulses (spikes) that encode the information on the motor task sent to the muscles.
Access to these spike trains allows the use of a type of statistical models and algorithms, called &amp;quot;point processes&amp;quot;, of which the principal investigator is an expert. These algorithms work by first trying to understand how the motor task is &amp;quot;encoded&amp;quot; in the spike spike trains and then reverting this process in order to infer the most likely motor task given the observed signal. They can be trained with arbitrary movements and have the potential to decode complex movements that were never observed during training. The ultimate goal is to have a controller that allows arbitrary movements rather than a set of pre-defined movements.

Throughout the project, the principal investigator and the research assistant will benefit from collaborating with world experts in the field of robotic prosthetic hands and neural signal processing.</gtr:abstractText><gtr:potentialImpactText>Impact for end users.
The main impact of the proposed research will be on upper-limb amputees. Their quality of life would be improved if myoelectric hand prostheses could be controlled in a more natural, intuitive, and accurate way. Users often complain about the fact that commercial myoelectric hands only allow the selection of pre-defined hand shapes and decide to revert to purely aesthetic prostheses, which are lighter and simpler to maintain.

By directly accessing the neural drive to the muscle and by adopting advanced decoding algorithms instead of pattern-recognition classifiers, the approach proposed has the potential to allow fine, proportional and simultaneous control of individual fingers, thus giving the possibility to perform arbitrary shapes. Another important limitation of current prostheses is the lack of feedback, meaning that the user has to rely on visual feedback even to perform simple daily tasks like holding a paper cup without dropping it nor crushing it. We envision that our algorithm will one day be part of a smart closed-loop hand prosthesis able to perform complex shapes and provide the user with neural sensory feedback. To this end, we will work closely with the group of Professor Micera (Dr Citi's doctoral advisor) at EPFL in order to integrate the control algorithm developed during this project with the neural feedback module that they have developed and that showed the possibility of providing neural feedback, allowing the user to manipulate objects without having to rely on visual feedback.

Impact on training activities.
The proposed research will also offer opportunities to train the next generation of researchers and engineers in the areas of machine learning and rehabilitation engineering. MSc students in our school will have the opportunity to conduct research in the areas of this project as part as their dissertation.

Economic impact.
Two of the world-leading producers of commercial advanced prosthetics are British: RSL-Steeper (Leeds) and Touch Bionics (Livingston). Their most advanced products, bebionic and i-limb embed hardware allowing for arbitrary finger movements but, because of the bottleneck represented by traditional surface EMG, the user can only select a limited number of pre-defined shapes by using hand gestures, smart tags, or a mobile application. This project has the potential to allow a quantum leap in the control of these prostheses with significant potential economic effects for the UK by helping consolidate its role as provider of world-leading prosthetic technologies.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>100950</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/N031806/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>FD25826C-8B50-43A3-8871-3FF08D051906</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Biomechanics &amp; Rehabilitation</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>