<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/F9F1D136-12E3-4BE4-9668-0C9BC4A7C1BF"><gtr:id>F9F1D136-12E3-4BE4-9668-0C9BC4A7C1BF</gtr:id><gtr:name>Bangor University</gtr:name><gtr:department>Sch of Computer Science</gtr:department><gtr:address><gtr:line1>Bangor University</gtr:line1><gtr:line4>Bangor</gtr:line4><gtr:line5>Gwynedd</gtr:line5><gtr:postCode>LL57 2DG</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F9F1D136-12E3-4BE4-9668-0C9BC4A7C1BF"><gtr:id>F9F1D136-12E3-4BE4-9668-0C9BC4A7C1BF</gtr:id><gtr:name>Bangor University</gtr:name><gtr:address><gtr:line1>Bangor University</gtr:line1><gtr:line4>Bangor</gtr:line4><gtr:line5>Gwynedd</gtr:line5><gtr:postCode>LL57 2DG</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/07C9CEA3-C84B-4D0B-B88F-0D1FE4FDC5C6"><gtr:id>07C9CEA3-C84B-4D0B-B88F-0D1FE4FDC5C6</gtr:id><gtr:firstName>Nigel</gtr:firstName><gtr:otherNames>W</gtr:otherNames><gtr:surname>John</gtr:surname><gtr:orcidId>0000-0001-5153-182X</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG055246%2F1"><gtr:id>FED8BF3F-3B6B-4526-8C21-4BD05E3A027B</gtr:id><gtr:title>Feasibility study - The coloured brain: a photorealistic virtual model of living brain tissue</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G055246/1</gtr:grantReference><gtr:abstractText>Although cadaver dissection is widely accepted as being the 'gold standard' for anatomy education, its availability and usage is decreasing due to financial and ethical pressures. Even for those with access to cadaveric-based training, they find that the differences between the colour and appearance of living tissues that may be observed in the operating theatre are vastly different from what they first observed with the dead tissues of a cadaver. Their anatomy knowledge must therefore adapt to the reality of their working environment. Digital anatomy tools can provide a partial alternative to cadavaric-based training. One of the limitations here, however, is that grey scale or pseudo colour are typically used when rendering the anatomy as 3D models. Although we can attempt to use colours that more closely match that of real tissues, or maybe a texture map, it is difficult to reproduce an exact match of the colours and shading of living tissues. In computer graphics a technique that can be used for photorealistic rendering is to apply a bidirectional reflectance distribution function (BRDF), which is a 4-dimensional function that defines how light is reflected at an opaque surface. BDRFs have not yet been extensively applied to digital anatomy models.The aim of this feasibility study is to develop and pilot techniques that will allow us to significantly improve the quality of virtual anatomy teaching tools by incorporating the appearance of live tissues. It will bring together the research expertise in computer modelling and material capture as well as access to operating theatre and teaching forum. We propose to combine the knowledge and technological achievements of two labs to realise this unusual collaboration: Marina Bloj is a colour scientist with a background in physics; Nigel John is an established expert with over 15 years experience in medical virtual environments and data visualisation. This collaborative project will allow us to integrate techniques from these two groups for the first time and establish the platform for future extended collaborative projects.</gtr:abstractText><gtr:fund><gtr:end>2010-02-28</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>20084</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1200000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Call for Biomedical Research Centres and Units</gtr:description><gtr:end>2015-03-02</gtr:end><gtr:fundingOrg>Health and Care Research Wales</gtr:fundingOrg><gtr:id>F8B4F8DF-F219-4F65-8FF5-D128E6030A64</gtr:id><gtr:outcomeId>544e5893d40cc6.66163392</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-11-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The realistic rendering technique has been used for some of the surgical simulators that we continue to develop at Bangor University</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>BDE0F845-E70E-42B6-8AF4-2EAB8CFD2ED3</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>544e5305531f21.94781650</gtr:outcomeId><gtr:sector>Education,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>From calibrated photography of exposed brain tissue and suitable alternatives,experiments provided data for a bidirectional reflectance distribution function, which was then used for rendering. Employing a GPU, real-time visualization of the brain's surface supported ambient occlusion, advanced texturing, subsurface scattering, and specularity.</gtr:description><gtr:exploitationPathways>The technique can be used in any software that is rendering anatomy models.</gtr:exploitationPathways><gtr:id>50C8059C-77C4-4A62-86DA-1E27938B346B</gtr:id><gtr:outcomeId>544e53ce7205e3.68866336</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.vmg.cs.bangor.ac.uk/projects.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>9293D00F-FEDC-4C5D-8A7D-A160BC2E7330</gtr:id><gtr:title>Realistic visualization of living brain tissue.</gtr:title><gtr:parentPublicationTitle>Studies in health technology and informatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cebf509ffbeba4073ae64310f435a9b6"><gtr:id>cebf509ffbeba4073ae64310f435a9b6</gtr:id><gtr:otherNames>ap Cenydd L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0926-9630</gtr:issn><gtr:outcomeId>544e5d81192835.85054622</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>19E48167-5B67-43A2-9B7E-C15D632BF79F</gtr:id><gtr:title>Visualizing the surface of a living human brain.</gtr:title><gtr:parentPublicationTitle>IEEE computer graphics and applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cebf509ffbeba4073ae64310f435a9b6"><gtr:id>cebf509ffbeba4073ae64310f435a9b6</gtr:id><gtr:otherNames>ap Cenydd L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0272-1716</gtr:issn><gtr:outcomeId>doi_53d05b05b7f4e13d</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G055246/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>