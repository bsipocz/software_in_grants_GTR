<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:department>Sch of Life Sciences</gtr:department><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/113AB417-F607-4F2F-9367-870B6E7E1A05"><gtr:id>113AB417-F607-4F2F-9367-870B6E7E1A05</gtr:id><gtr:firstName>Marina</gtr:firstName><gtr:surname>Bloj</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG038597%2F1"><gtr:id>D0555570-E2A1-4686-864D-7C20C7237AFB</gtr:id><gtr:title>Perception of colour gradients in real and computer-simulated scenes: effects on depth</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G038597/1</gtr:grantReference><gtr:abstractText>Can you tell the difference between real filmed footage of an event, and a computer-rendered counterpart? Despite tremendous progress in animation and graphics, the answer is most likely yes. We still have a long way to go in generating high quality realistic rendered worlds, that have a wide variety of applications, from gaming, through medical and industrial simulators, to architect-designed walk-throughs that give us a feel for how a new building could look. Improving the naturalness and realism of such virtual environments is a key challenge for those involved in computer graphics and rendering, particularly when there is a demand for interactive, real-time applications: we want to walk around in that simulated new building, not just view static photograph-like scenes. One of the reasons that our progress is slow, is that the extraordinary visual capabilities of most humans, though apparently effortless, hide a complex web of visual processing that is not yet fully understood. If we do not yet understand what enhances realism for the human visual system, it is not surprising that progress is slow in developing technology to improve the realism of simulations. The aim of this work will be to elucidate some of the basic perceptual processes that underlie how subtle changes in colour and lightness enhance the realism of our perception of a three-dimensional scene. This human behavioural research underpins the development of graphics and rendering technologies that will deliver enhanced realism for virtual environments.One of the reasons why this problem is so hard is that the real world contains very complex patterns of light and colour that somehow translate into our perceptions of whether something is green, light, dark, near or far away. For example, my coffee cup on the table in front of me contains white, bright specular highlights that contribute to it looking glossy. There are also reflections of the stripy table mat on which it sits, yet I know these to be reflections, not part of the pattern on the mug. There is an attached shadow, cast by light from the window, and I know that is not part of my mug. And there are changes in lightness and colour across the surface, yet I see the mug as being a single colour, made from a single material. In this project we will study how humans distinguish between depth, light source, and material properties. For most real scenes, this is a very difficult computational problem because specific local patches that appear, for example, darker than those around them, can have the value they do for a variety of reasons. For example, the side of your grey filing cabinet may have a very different lightness than the front, because it slopes away from you in depth, and is at a different angle with the light source, compared with the front of the cabinet (and it could actually be a different colour). How does the human visual system achieve a coherent perception of a solid, non-deforming world, despite changes in view-point and lighting? This is a huge question in both human and computer vision research, with direct implications for computer graphics and virtual environment development, but one that is still poorly understood. We will start by exploring very simple visual scenes containing isolated objects, and study how colour and luminance information can influence depth perception. This data will be used to create models that predict when the luminance/colour information will be most useful. In other experiments we will use real objects and realistically computer-rendered scenes that preserve the relationship between objects and light source that would occur in the real world. Our work will give us immediate information about basic visual mechanisms of depth and scene perception that directly informs the fields of computer graphics and image processing, giving guidelines for when realistic luminance and colour gradients are required for a rendered scene to look realistic.</gtr:abstractText><gtr:fund><gtr:end>2013-02-13</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-05-14</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>376715</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The findings from the experiments and modelling carried out as part of this project go some way towards answering the question of whether the human visual system can make use of the complicated luminance and chromatic gradients that occur as part of object shading in the real world to estimate three-dimensional shape. We found that:
-the human visual system is capable of accounting for the complex interactions of illumination, surface reflectance and 3D object shape, and to some extent can disentangle these factors in real three-dimensional scenes.
-humans can accurately estimate 3D object shape when complex colour shading is the only information available, provided they have some opportunity to assess the scene and conclude a reasonable set of assumptions about object and lighting properties. 
-the visual system appears to treat the luminance and chromatic gradients in colour shading as separate cues to shape, and can use either in isolation, or combine them optimally.</gtr:description><gtr:exploitationPathways>Mutual illumination is a feature of more complex three-dimensional scenes, where light is reflected between the surfaces of different objects, the ability to use mutual illuminations and the resulting chromatic gradients as effective cues to 3D shape allows the visual system to more effectively build an accurate representation of the relative positions of object and surfaces within such (real world typical) complex scenes than would otherwise be possible. It is important that such richness is incorporated in computer generated and/or virtual scenes to ensure that the user experience is comparable to that in the real world.</gtr:exploitationPathways><gtr:id>D79F770E-4B33-40F5-800B-D245AEC7425F</gtr:id><gtr:outcomeId>56cc4f6b54fd16.44864191</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Manufacturing, including Industrial Biotechology,Culture, Heritage, Museums and Collections,Retail,Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C2692FF9-5143-4C48-8634-E6EC2D8E0303</gtr:id><gtr:title>Learning to use illumination gradients as an unambiguous cue to three dimensional shape.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d5f568901db088d8531160c1d1ca083"><gtr:id>5d5f568901db088d8531160c1d1ca083</gtr:id><gtr:otherNames>Harding G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>doi_53d0810815607496</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6622812B-A0EB-455F-9D59-5A9814394EC2</gtr:id><gtr:title>Depth perception of the Chromatic Mach Card (CNC): Influence of colour gradients and outline</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/52a22add471cb1d584e549280a236721"><gtr:id>52a22add471cb1d584e549280a236721</gtr:id><gtr:otherNames> Glen Harding (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_29028160066430f170</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>80FAAB39-9A3C-4210-A070-F1E12097158F</gtr:id><gtr:title>Visual search in depth: cue combination during natural behaviour</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b9f418382c9ef23e5e706f91cbc80657"><gtr:id>b9f418382c9ef23e5e706f91cbc80657</gtr:id><gtr:otherNames>PG Lovell</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>546222f1634fb8.90556952</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>101A5334-AC52-4A51-B074-729C40856823</gtr:id><gtr:title>Learning to use illumination gradients as shape cues.</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d07707749db1e2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>107F5414-8E56-4173-A85F-D448EBA940DB</gtr:id><gtr:title>Gradient processing: excitatory and inhibitory interactions between achromatic and chromatic mechanisms</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f0e8351cd08f76d6c0984900f82549c0"><gtr:id>f0e8351cd08f76d6c0984900f82549c0</gtr:id><gtr:otherNames> Luis Garcia-Suarez (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_71130349546430fe90</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CF229AC6-4E4C-4B8D-8198-1A9936F5DFA0</gtr:id><gtr:title>Relative contribution of outline (perspective) and shading cues to monocular depth perception</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d5f568901db088d8531160c1d1ca083"><gtr:id>5d5f568901db088d8531160c1d1ca083</gtr:id><gtr:otherNames>Harding G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d07707739d5a52</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>303BCAEA-119E-410C-8863-D7FA6E7B0CB0</gtr:id><gtr:title>Learning a 3-D Visual Light Field: Effects of Exploration on Lightness Constancy.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e4e13d56759093642eda0d0f6dac500"><gtr:id>6e4e13d56759093642eda0d0f6dac500</gtr:id><gtr:otherNames> George Lovell (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_79640128756425a446</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6966AE5E-1AB4-48A3-BEEF-5CBC9067376F</gtr:id><gtr:title>Handbook of Visual Display Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-3-540-79566-7</gtr:isbn><gtr:outcomeId>546223a04744c5.85779484</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>51F90FB8-E17D-4D8F-ABD1-4DD2EE3ED760</gtr:id><gtr:title>Effects of chromatic (red-green) and achromatic orthogonal masks on perceived contrast of luminance targets</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1aa69a0ec79820f44568a14f0fd21624"><gtr:id>1aa69a0ec79820f44568a14f0fd21624</gtr:id><gtr:otherNames> Stephane Clery (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_607228516564310070</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AC591588-C6A4-4098-BBA4-BB783FA9A7CB</gtr:id><gtr:title>Critical timing in combinations of stereo-disparity and shading</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6851a3dad564bcae60dbb220ef8db9f5"><gtr:id>6851a3dad564bcae60dbb220ef8db9f5</gtr:id><gtr:otherNames>Lovell P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d077077403d0f3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7E9689CF-9762-4232-A2D8-2BB815208BB3</gtr:id><gtr:title>What can observation variance tell us about the visual system's use of shape information?</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d5f568901db088d8531160c1d1ca083"><gtr:id>5d5f568901db088d8531160c1d1ca083</gtr:id><gtr:otherNames>Harding G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d0770774a6f05c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>907A56C4-718A-44C6-899A-D0DAD1EB07E3</gtr:id><gtr:title>Interactions between shading and disparity for depth perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aeb987dcd537751960f02bc8554f119b"><gtr:id>aeb987dcd537751960f02bc8554f119b</gtr:id><gtr:otherNames> Julie Harris (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>r_76891208166425a590</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2540DE7A-9CCC-4B0E-8AEC-6CF78EEDEF88</gtr:id><gtr:title>Interactions between luminance and color signals: effects on shape.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a85b09b9534ba277bc2b67e120fcd060"><gtr:id>a85b09b9534ba277bc2b67e120fcd060</gtr:id><gtr:otherNames>Clery S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5460f307b207b2.22000063</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>765C4194-05F3-4344-8268-DDF85B51EC18</gtr:id><gtr:title>Efficient cue-combination even at the temporal limits of perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b9f418382c9ef23e5e706f91cbc80657"><gtr:id>b9f418382c9ef23e5e706f91cbc80657</gtr:id><gtr:otherNames>PG Lovell</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>5462258aa049b9.17893835</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FE892A1C-8331-48BE-8AEF-45FD72C894B7</gtr:id><gtr:title>Effects of chromatic (red-green) and achromatic orthogonal masks on perceived contrast of luminance targets</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bb6b94b0424668504fd13e3b3d55b3f8"><gtr:id>bb6b94b0424668504fd13e3b3d55b3f8</gtr:id><gtr:otherNames>Cleary S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>546221f2296212.56475444</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>02F7BFFC-D57F-4F47-B067-4D9024A94B33</gtr:id><gtr:title>Size, shading and disparity: studying cue combination using visual search</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6851a3dad564bcae60dbb220ef8db9f5"><gtr:id>6851a3dad564bcae60dbb220ef8db9f5</gtr:id><gtr:otherNames>Lovell P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d07707748ab6c0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>09D7ABDF-AB8E-45A2-B94F-67F572E799DE</gtr:id><gtr:title>Optimal integration of shading and binocular disparity for depth perception.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2d8abe4e7022b16d78a97a86546b2989"><gtr:id>2d8abe4e7022b16d78a97a86546b2989</gtr:id><gtr:otherNames>Lovell PG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d07707744174b8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1343D035-9BC4-437D-A082-6D36FBD3C9D1</gtr:id><gtr:title>Learning to use the lightfield for shape and lightness perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aeb987dcd537751960f02bc8554f119b"><gtr:id>aeb987dcd537751960f02bc8554f119b</gtr:id><gtr:otherNames> Julie Harris (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_31642965856430f652</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EA9FC667-11B5-48FB-9FF6-FD757E3CE024</gtr:id><gtr:title>Co-occurrence of luminance and chromatic edges does not always result in suppressed perception of depth from shading</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a85b09b9534ba277bc2b67e120fcd060"><gtr:id>a85b09b9534ba277bc2b67e120fcd060</gtr:id><gtr:otherNames>Clery S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>54621eb901d516.25258857</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2F43D0F6-45C9-4130-A889-92FE49F254A9</gtr:id><gtr:title>How Do Reliability and Timing Influence Cue-Combinations for Shading and Stereo-Disparity?</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6851a3dad564bcae60dbb220ef8db9f5"><gtr:id>6851a3dad564bcae60dbb220ef8db9f5</gtr:id><gtr:otherNames>Lovell P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d0390395b3785a</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G038597/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F6909716-124F-49F7-A551-465264E4D2F7</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Displays</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>