<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/30A429E3-83B7-4E41-99C0-14A144F07DFE"><gtr:id>30A429E3-83B7-4E41-99C0-14A144F07DFE</gtr:id><gtr:name>University of Southampton</gtr:name><gtr:department>Faculty of Engineering &amp; the Environment</gtr:department><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Highfield</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO17 1BJ</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/30A429E3-83B7-4E41-99C0-14A144F07DFE"><gtr:id>30A429E3-83B7-4E41-99C0-14A144F07DFE</gtr:id><gtr:name>University of Southampton</gtr:name><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Highfield</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO17 1BJ</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/42A54D16-702C-49F2-8076-3E7D00FC60E4"><gtr:id>42A54D16-702C-49F2-8076-3E7D00FC60E4</gtr:id><gtr:name>Interacoustics</gtr:name><gtr:address><gtr:line1>orsteds plads</gtr:line1><gtr:line2>Building 352, Room 117</gtr:line2><gtr:line3>c/o technical University of Denmark</gtr:line3><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/054E6753-C647-4320-BDF6-662B68D5DBDF"><gtr:id>054E6753-C647-4320-BDF6-662B68D5DBDF</gtr:id><gtr:firstName>David</gtr:firstName><gtr:otherNames>Martin</gtr:otherNames><gtr:surname>Simpson</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/011C50E7-97D3-455C-8361-BC5E7BE774D6"><gtr:id>011C50E7-97D3-455C-8361-BC5E7BE774D6</gtr:id><gtr:firstName>Patrick</gtr:firstName><gtr:otherNames>A</gtr:otherNames><gtr:surname>Naylor</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F3FE4E00-C384-416C-83DB-F0442D23F00B"><gtr:id>F3FE4E00-C384-416C-83DB-F0442D23F00B</gtr:id><gtr:firstName>Tobias</gtr:firstName><gtr:surname>Reichenbach</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/AC6CED72-138D-4302-9428-44F3BBC1DF11"><gtr:id>AC6CED72-138D-4302-9428-44F3BBC1DF11</gtr:id><gtr:firstName>Ben</gtr:firstName><gtr:surname>Lineton</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8A03C0D2-5D59-4E84-A209-EEA9128FC5DD"><gtr:id>8A03C0D2-5D59-4E84-A209-EEA9128FC5DD</gtr:id><gtr:firstName>Karolina</gtr:firstName><gtr:surname>Kluk-de Kort</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D86D3775-AE22-497E-A196-5C6EEE8122FC"><gtr:id>D86D3775-AE22-497E-A196-5C6EEE8122FC</gtr:id><gtr:firstName>Steven</gtr:firstName><gtr:surname>Bell</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM026728%2F1"><gtr:id>D4A8821B-BBCB-41C4-988A-9E39389D8490</gtr:id><gtr:title>Personalized fitting and evaluation of hearing aids with EEG responses</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M026728/1</gtr:grantReference><gtr:abstractText>It has been estimated that some 6 million people in the UK could benefit from hearing aids, but there are only approximately 2 million hearing aid users, and of these, only 70% use their hearing aids regularly. Modern hearing aids are complex devices with advanced features (gain in different frequency bands, amplitude compression, feedback cancellation, noise reduction, directional microphones etc.) and require professionals to fit them. Limited benefit from hearing aids is a major reason why many patients do not use their devices regularly. Conventionally, hearing aids are fitted based primarily on the 'audiogram', which informs on the quietest sounds (short tones) that the patient can hear at different frequencies and is obtained from patients' voluntary and subjective response (usually by clicking a button) to progressively quieter sounds. However, it is clear that the audiogram only provides limited insight into hearing loss, and fitting hearing aids based on this alone can lead to very diverse results in what is of most importance to patients, namely understanding speech. The difficulty of understanding speech in noise is one of the chief complaints of hearing aid users. 

The current project aims to improve personalized fitting of hearing aids to individual patients. The key technique will be the use of measurements taken directly from the brain's response to sound, by analysing the electroencephalographic (EEG) responses obtained from electrodes placed on the scalp. The analysis is 'objective', without requiring patients' voluntary and 'subjective' (and not always reliable) response to stimuli. We think this is important as it can be carried out in patients who are unable to provide such voluntary responses, for example infants or the elderly with dementia. By monitoring hearing without constant interruption to assess patients' perception, the performance of the hearing aid can also be assessed in natural listening conditions and over a longer time period. Ultimately this approach may also allow hearing aid settings to be adjusted without the presence of an audiologist, as users' needs and the auditory environment change. The test stimuli (hearing challenges) we will develop for the project will include a wider range of sounds than are currently routinely used in clinics, allowing for more subtle (differential) diagnosis of hearing loss, and a focus on the response to speech (including speech-in-noise).

The key research aim in this project is to achieve a robust assessment of hearing function and speech processing in the brain (from the cochlea to the brain stem and cerebral cortex) by the computer analysis of EEG responses to complex real-world signals. This presents major scientific and technical challenges, needing the development of novel signal-analysis methods for speech and EEG data, which can be related to hearing impairment, cognition, as well as hearing aid settings and performance. The combination of these major challenges and a focus on patient benefit makes this an exciting and adventurous project. 

The main objectives of this proposal are to propose, assess and recommend:
1. Signal processing methods to extract information from EEG signals on hearing performance and patients' access to speech
2. Stimuli to use in assessing hearing
3. Algorithms to optimize hearing aid fitting, based on parameters extracted from EEG responses 

This interdisciplinary work will be carried out as a collaboration between universities (hearing science, speech processing, signal analysis), industry (hearing technologies) and patients (choosing hearing challenges). The benefits of undertaking this work are expected to be to patients and their family and carers (improved quality of life from using hearing aids), the health-services (improved efficiency), industry (new diagnostic technologies) and the scientific community (better understanding of hearing; improved methods for analysing EEG signals).</gtr:abstractText><gtr:potentialImpactText>This project is expected to have academic, economic and societal impact. Improving hearing aids has been identified as a priority for EPSRC in this particular call for research proposals and fits within its broader strategic goal of improving health-care technologies. This proposal specifically addresses the research challenges in the call for proposals of Optimising hearing aid devices for individuals and Speech-in-noise performance in hearing aid devices. 

Research interest related to the effect of speech on the EEG signals and the use of EEG signals in fitting hearing aids has recently increased greatly. This project will be at the leading edge of this international research effort, with a multidisciplinary team that is well placed to spearhead studies in this area, generating new knowledge, understanding and research methods for the field. The currently growing interest in the field makes this project very timely. Through a collaborative approach, sharing data (when possible, given constraints of ethics and data protection) and methods, together with current and up-coming networking activities, we expect this project to further enhance the leadership of UK science in the field. The multidisciplinary team will provide excellent training opportunities, not only for those directly employed in this project, but also for undergraduate and postgraduate students working on projects within related fields. The working environment will allow them to experience close collaborations between engineering, hearing science and audiology, and to obtain hands-on experience in data collection and interaction with clinical scientists and patients. This field of research is also highly amenable to public engagement activities, since it addresses a well-known societal problem whose impact and alleviation can readily be shown with engaging audio demonstrations - and this will be pursued as part of this project. 

Of the approximately 6 million people in the UK who could benefit from hearing aids, currently only approximately 2 million have hearing aids, but only some 1.4 million use them regularly. It is now known that hearing impairment is related to depression, reduced educational opportunities and relationship difficulties. Improving hearing aid fitting will result in improved quality of life for an increasing number of patients through better social and work interactions, and this in turn will result in improved economic productivity and societal benefit. Our work also has the potential to improve the efficiency of hearing-aid services through automated fitting approaches. Additional economic impact is expected from new commercial opportunities as the project develops innovative technologies and new diagnostic/treatment services in the public and private sectors. The potential impact of this research has been recognised by the charity Action on Hearing Loss, The British Society of Audiology Special Interest Group in Electrophysiology and a clinician, Katie Ireland, who works with infants with hearing impairment, all of whom have provided supporting statements for this application.

At the end of this project, we expect to leave a legacy of new knowledge and methods with a fresh approach to the field, a closely collaborating research team, well-trained young researchers working on hearing aid technologies within and beyond our group, and follow-on projects moving into clinical trials.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>908086</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Science and Engineering Open Day</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>5CE0AE1B-4687-4A33-98E2-F95B05D568AA</gtr:id><gtr:impact>The open day demonstration intended to show the impact of hearing loss and living with hearing aids to the general public. It consisted of allowing general public to have their ears checked using a video-otoscope, such that they could be made aware of how their ear can be damaged in case of occlusion (wax or foreign objects). There were 3D ear models displayed which could be taken apart and build up again by members of the public. A demonstrator would also give an overview of how sound is transmitted through the ear. Besides this, there were real-time simulations of hearing impairment and listening through a hearing aid and cochlear implant. Many participants showed an increased awareness of hearing function and the importance of avoiding loud sounds to ensure they would not need a hearing aid.</gtr:impact><gtr:outcomeId>5757d7bf8d9158.23296527</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.southampton.ac.uk/per/university/festival/science-and-engineering-day.page</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Cheltenham Science Festival</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>91D1F47E-CD18-4DA7-9F27-1C84A28F5C09</gtr:id><gtr:impact>Activities were organised for people to experience hearing loss and listening through a hearing aid and cochlear implant using real-time simulators and a music quiz. A demonstration regarding sound localisation was also organised, letting people listen through giant pinnas. The simulations sparked an increased awareness of the effects of hearing loss and an increased appreciation of the difficulties on living with a hearing aid or cochlear implant. Many hearing impaired came over to the demonstration site to ask questions about their hearing loss. Overall, people seemed very satisfied about the performance (based on an informal questionnaire which could be completed on site).</gtr:impact><gtr:outcomeId>575fb643d6c792.03101392</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.cheltenhamfestivals.com/science/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation at a meeting of the Institution of Engineering and Technology</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>DB576544-F7B4-4AF9-B9FA-CE61A67A46AA</gtr:id><gtr:impact>David Simpson and Steven Bell gave an invited presentation to a regional meeting of the Institution of Engineering and Technology on 2/2/6016 entitled 'Modern Aided Hearing: More than just an electronic ear trumpet'. The aim was to give a general introduction to a lay audience with technical background on the consequences of hearing loss and the technology of hearing aids. This form part of our proposed outreach activity regarding increasing awareness of the impacts of hearing impairment on quality of life. We also highlighted how our current research for EP/M026728/1 aligns with some of the challenges for the hearing impaired. Quite a few members of the audience were hearing aid users and there was a good discussion around the challenges facing hearing aid users. We intend to use the presentation that was developed for future outreach activities.</gtr:impact><gtr:outcomeId>56b37388c14196.81031909</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>2EEF48E4-6A80-46CC-A7EA-33A878D1ECE7</gtr:id><gtr:title>The human auditory brainstem response to running speech reveals a subcortical mechanism for selective attention.</gtr:title><gtr:parentPublicationTitle>eLife</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/57b7295133870aadd5c0c8f1ec419d71"><gtr:id>57b7295133870aadd5c0c8f1ec419d71</gtr:id><gtr:otherNames>Forte AE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2050-084X</gtr:issn><gtr:outcomeId>5a2fe854a7f2a6.00066928</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C8C3F742-77D0-4DE8-80A6-FA029B3D7021</gtr:id><gtr:title>The Auditory-Brainstem Response to Continuous, Non-repetitive Speech Is Modulated by the Speech Envelope and Reflects Speech Processing.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0bc1410589f774f8564f0ee6ffb39f62"><gtr:id>0bc1410589f774f8564f0ee6ffb39f62</gtr:id><gtr:otherNames>Reichenbach CS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn><gtr:outcomeId>585d4d0fe4a090.35837264</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9FA70420-3ACB-48E8-9819-088D4995E66C</gtr:id><gtr:title>Analysis of envelope following responses to natural vowels using a Fourier analyzer</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/14c05df0dc0f3c33842316ca2b680736"><gtr:id>14c05df0dc0f3c33842316ca2b680736</gtr:id><gtr:otherNames>Vanheusden, FJ</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>56b3756f492994.97138985</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>39E1EA67-8475-463B-BCDB-2A3B3714311A</gtr:id><gtr:title>The steady-state response of the cerebral cortex to the beat of music reflects both the comprehension of music and attention.</gtr:title><gtr:parentPublicationTitle>Frontiers in human neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7590a63cb46f4c79408808915c24e481"><gtr:id>7590a63cb46f4c79408808915c24e481</gtr:id><gtr:otherNames>Meltzer B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1662-5161</gtr:issn><gtr:outcomeId>5675eaa09f3b3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CA28672B-73D8-4C32-80EB-AE1C6897F8E3</gtr:id><gtr:title>Objective measures for detecting the auditory brainstem response: comparisons of specificity, sensitivity and detection time.</gtr:title><gtr:parentPublicationTitle>International journal of audiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/66126c021bd9d4b264ea64f518ed6109"><gtr:id>66126c021bd9d4b264ea64f518ed6109</gtr:id><gtr:otherNames>Chesnaye MA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>1499-2027</gtr:issn><gtr:outcomeId>5aa95c03214b14.72922731</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M026728/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>