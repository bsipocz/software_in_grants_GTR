<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/FA143EC1-E637-4E0C-80ED-0EA8ED214038"><gtr:id>FA143EC1-E637-4E0C-80ED-0EA8ED214038</gtr:id><gtr:name>University of Leuven</gtr:name><gtr:address><gtr:line1>Oude Markt 13</gtr:line1><gtr:line2>Box 5005</gtr:line2><gtr:region>outside UK</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/B80FA015-FF48-471E-839C-CB0CD2B7E9AD"><gtr:id>B80FA015-FF48-471E-839C-CB0CD2B7E9AD</gtr:id><gtr:name>Imanova</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:department>Dept of Medicine</gtr:department><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FA143EC1-E637-4E0C-80ED-0EA8ED214038"><gtr:id>FA143EC1-E637-4E0C-80ED-0EA8ED214038</gtr:id><gtr:name>University of Leuven</gtr:name><gtr:address><gtr:line1>Oude Markt 13</gtr:line1><gtr:line2>Box 5005</gtr:line2><gtr:region>outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B80FA015-FF48-471E-839C-CB0CD2B7E9AD"><gtr:id>B80FA015-FF48-471E-839C-CB0CD2B7E9AD</gtr:id><gtr:name>Imanova</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/022A9260-2571-4228-9E7B-05CFE6DE1FC1"><gtr:id>022A9260-2571-4228-9E7B-05CFE6DE1FC1</gtr:id><gtr:firstName>William</gtr:firstName><gtr:otherNames>Andrew</gtr:otherNames><gtr:surname>Hallett</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/B73D3567-D3B9-4FB7-9D67-C11475FC6E7F"><gtr:id>B73D3567-D3B9-4FB7-9D67-C11475FC6E7F</gtr:id><gtr:firstName>Eugenii</gtr:firstName><gtr:otherNames>Alfredovich</gtr:otherNames><gtr:surname>Rabiner</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/446560FC-ECB6-4A5F-B672-C4B8A4589166"><gtr:id>446560FC-ECB6-4A5F-B672-C4B8A4589166</gtr:id><gtr:firstName>Jonathan</gtr:firstName><gtr:otherNames>Worth</gtr:otherNames><gtr:surname>Howard</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9B07155C-EF57-41F9-85DB-2C69DC08D70F"><gtr:id>9B07155C-EF57-41F9-85DB-2C69DC08D70F</gtr:id><gtr:firstName>Roger</gtr:firstName><gtr:otherNames>N</gtr:otherNames><gtr:surname>Gunn</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/E7410EF7-9051-4F95-8981-1D02ED062618"><gtr:id>E7410EF7-9051-4F95-8981-1D02ED062618</gtr:id><gtr:firstName>Ben</gtr:firstName><gtr:surname>Glocker</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/293FF588-9C2E-4359-8074-CF6EE117F6C1"><gtr:id>293FF588-9C2E-4359-8074-CF6EE117F6C1</gtr:id><gtr:firstName>Graham</gtr:firstName><gtr:otherNames>Ellis</gtr:otherNames><gtr:surname>Searle</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MR%2FM025004%2F1"><gtr:id>8280EC27-A91D-4F63-9FD6-6173BD703B45</gtr:id><gtr:title>Repurposing Low-Cost Consumer Technology for Motion Correction in Dementia Neuroimaging</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>MR/M025004/1</gtr:grantReference><gtr:abstractText>Advances in human brain imaging are now about to make it possible to measure the two key biochemical processes involved in dementia. The central underlying biochemistry of dementia involves the accumulation of two misfolded proteins amyloid beta (Ab) and hyperphosphorylated tau (tau) in the brain. Using the clinical imaging technique Positron Emission Tomography (PET) and specific radiolabelled tracers that bind to these proteins it is possible to measure their concentration in the human brain. 

This promises to allow us to better understand the disease process and in addition it provides us with the opportunity to use them in clinical trials to test the effectiveness of new therapies that are currently being developed by the pharmaceutical industry. To date, clinical trials have suffered from the problem that clinical assessment is an insufficiently accurate predictor of the disease time course. Further, it is believed that in order to intervene successfully in the disease one will have to treat subjects early when clinical measures do not provide a signal. 

Thus, it is imperative to develop biomarkers that are able to i) identify subjects early on in the clinically silent phase of the disease so that they can be enrolled into clinical trials (Stratification) and ii) accurately measure changes in the brain of Ab and tau so that these can be used as measures of whether a therapy is impacting the disease time course (Therapy Monitoring).

Given the opportunities offered by misfolded protein imaging, the UK Dementia Platform initiative is proposing to establish a UK wide network of PET/MR imaging capabilities for early and differential diagnosis of neuro-degenerative pathology enabling improved risk-stratification, targeted hypothesis testing and more efficient early phase clinical trials.

However, currently the acquisition of imaging data is limited by subject motion during the period of scanning. This has the effect of degrading the quality of the images introducing errors that mean the scans may invalidated or at best reduce their accuracy and power to determine the levels of the misfolded protein concentrations. The consequence of this is that scans are wasted or the information obtained from them is reduced.

Our proposal will address this by using the low cost consumer technology (Xbox Kinect sensor) to measure the position of the subject continuously during the scanning period based on the measurement of the head position. Mathematical algorithms are then employed to reposition the data prior to reconstruction of the PET image of misfolded proteins. This enables the generation of an image that is equivalent to one that would have been obtained had the subject not moved. 

We will implement our hardware and software solution to this problem and make it available to the UK dementia platform which will perform a range of imaging studies in pursuit of improved diagnosis and treatment for dementia.

We will acquire Clinical data validation packages in both the PET and MRI environment that demonstrate the value of the technology. We will show that it is accurate, easy to use and can be easily implemented in a standard clinical imaging environment. 

This data will provide confidence for us to engage with Scanner manufacturers to discuss future licensing arrangements and standard incorporation into their commercial scanners.</gtr:abstractText><gtr:technicalSummary>Subject motion has long been recognised as a limiting factor in many medical imaging procedures, and remains an unsolved problem, producing inaccurate data that impacts on costs and effective diagnosis/treatment. This is particularly so for the latest generation of scanners whose intrinsic resolution exceeds the ability of patients to remain still, for example in neurodegenerative disorders. Algorithms to correct for motion are well established, yet the lack of effective, affordable, reliable motion tracking hardware has prevented widespread adoption in both research and clinical settings. Currently, there are no commercially available solutions and motion correction is limited to post-processing of scan data with its inherent limitations. 

PET is a well-established neuroimaging research tool, becoming ever more important for dementia in the clinic and in drug development with novel tracers for amyloid and tau offering unique biochemical information. For these patient populations motion is a significant problem. 

In a recent EPSRC/GSK CASE PhD, we acquired promising pilot data by repurposing a low cost mass-market consumer technology (Microsoft Kinect), coupling it with machine vision techniques to accurately measure PET head motion in real time with sub-mm accuracy providing confidence it could be developed into an effective device for the clinical environment. This is all achieved without special lighting, subject contact or attachment of markers that have compromised previous efforts. We have recently obtained evidence that this hardware will also work within an MRI scanning environment. 

More work is required to optimise, evaluate and commercialise our applications. We will work with Imanova, with access to key expertise, to develop the technology for PET and PET/MR research imaging in neurodegeneration where it will provide an immediate impact in particular for the new MRC Dementia Platform (http://dementiasplatform.uk).</gtr:technicalSummary><gtr:potentialImpactText>This proposal aims to develop methods to improve the quality and accuracy of noninvasive imaging of misfolded proteins in the brain for diagnosis, stratification and treatment monitoring in clinical trials of dementia therapies.

In December 2013 the UK government hosted a summit as part of its presidency of the G8 to discuss the impending crisis for health care systems posed by dementia, and more importantly, to establish plans to mitigate this crisis. Of all possible mitigation strategies the one with most sustainable outcomes would be an intervention for prevention of the disease. Many approaches are under investigation but the one with considerable promise is secondary prevention using small molecules or biologics given in the pre-clinical phase of neurodegenerative diseases such as, but not limited to, Alzheimer's disease (AD). 

Who will benefit from the proposed research? 
1. Imaging Centers (Academic and NHS)
2. UK Dementia Platform
3. Scanner Vendors
4. Pharmaceutical industry who are trying to develop new medicines to meet the enormous healthcare challenge of dementia. 
5. Dementia patients themselves as well as their relatives and carers. In addition, clinicians and nurses involved in the care of these patients as well as charities promoting dementia will benefit. 

Other beneficiaries of this work include researchers in medicine, life science, mathematical and computer science. Finally, governments and organisations who are facing the future economic crisis resulting from the increased incidence of dementia in the ageing population will benefit.

How will they benefit? 
Improved imaging techniques that will provide an increase in quality of imaging data, reduction in the numbers of invalidated scans and associated costs savings. Scanner vendors will benefit from increased performance of their systems and competitive advantage over rival manufacturers. Currently there are no effective treatments for dementia. The diagnosis of dementia itself will be of little value without the development of effective therapies, thus it is the development of techniques that will enable the stratification of subjects and the measurement of sensitive endpoints in clinical trials that is essential. The development of improved imaging methods that will provide more sensitive imaging biomarkers for clinical trials will have a tremendous impact on the pharmaceutical industry which recognises from the sobering recent experience in trials that clinical assessment is an insufficiently accurate or sensitive predictor of the pathology. Further, the necessity to identify subjects who are in the preclinical phase of the disease where therapies will have the greatest impact is imperative. 

Imaging misfolded proteins with PET will form a major component of the proposed UK Dementia Platform that will establish a UK wide network of facilities for early and differential diagnosis of neuro-degenerative pathology enabling improved risk-stratification, targeted hypothesis testing and more efficient early phase clinical trials. The development of more accurate imaging techniques will be essential for realizing UKDP's potential and providing pharma with the vehicle they need to efficiently investigate novel therapies.

Patients, carers, clinicians, nurses, healthcare systems and governments will all benefit from the development of effective therapies that will reduce the impact of the disease on the patient and the burden on society and healthcare costs. Sensitive noninvasive imaging biomarkers for dementia pathology will provide researchers with better tools to understand the disease process itself. A better understanding of the evolution of the key pathological hallmarks of the disease may offer insights into new therapeutic opportunities. Finally, the research will strengthen the international position of UK Life Sciences in the area of clinical trials and pharmaceutical development.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2015-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>204400</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Imperial College London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Exploring the use of Geometry Enhanced Markers (GEM) for stereo calibration of multiple Kinect depth sensors</gtr:description><gtr:id>BE11ED90-BBC3-443E-B5CE-2E006DDDD8A9</gtr:id><gtr:impact>An oral presentation at the IEEE Medical Imaging Conference in San Diego with associated conference proceedings to be published. This collaboration involved computer sciences with medical physics and engineering.</gtr:impact><gtr:outcomeId>56dfee87ef9e33.91444961-1</gtr:outcomeId><gtr:partnerContribution>BG + JM developed the GEM software for augmented reality applications. They assisted in 3D printing phantoms used to enable successful stereo calibration of the Kinect sensors.</gtr:partnerContribution><gtr:piContribution>We implemented and evaluated GEM software (developed by Dr B Glocker and Dr J Ma) modified to use multiple Kinect v2 sensors for increased field of view motion tracking in a PET/CT scanner.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Leuven</gtr:collaboratingOrganisation><gtr:country>Belgium, Kingdom of</gtr:country><gtr:description>Evaluating the Kinect Based Head Motion Tracking With Motion Correction Enabled Listmode Based&amp;nbsp;PET Image Reconstruction</gtr:description><gtr:id>6076FB0A-77BD-4BFC-B429-1DD992FDB663</gtr:id><gtr:impact>We are keen to further explore how we can joitly progress with using the Kinect and a listmode based image reconstruction pipeline.</gtr:impact><gtr:outcomeId>58a3100ec6a520.91574687-1</gtr:outcomeId><gtr:partnerContribution>The Listmode based reconstruction pipeline was developed by researchers at KU Leuven.&amp;nbsp;</gtr:partnerContribution><gtr:piContribution>We evaluated the Kinect motion tracking system&amp;nbsp;on head phantom&amp;nbsp;data using KU Leuven developed Listmode based PET image reconstruction software.&amp;nbsp;The Kinect motion tracking&amp;nbsp;data was successfully integrated with the reconstruction pipeline and demonstrated accurate motion tracking results demonstrating the potential benefits a listmode based pipeline could provide.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Imanova</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Validating the Kinect&amp;nbsp;based motion tracking system on clinical dynamic brain PET</gtr:description><gtr:id>370FF5EF-09D1-4638-9F02-86D2FFBC92AB</gtr:id><gtr:impact>Imanova will continue to&amp;nbsp;use the motion tracking system developed as part of this collaboration.</gtr:impact><gtr:outcomeId>58a33c5d032dc9.70180558-1</gtr:outcomeId><gtr:partnerContribution>Imanova is especially well equipped with PET and MR imaging technologies (clinical PET/MRI: GE SIGNA, clinical PET: 2xSiemens Biograph, preclinical PET: Inveon PET/CT, clinical MRI: Siemens TIM Trio, Siemens Verio, 2xCyclotrons and 24xhot cells enabling imaging with C11 and F18 labelled radiotracers).&amp;nbsp;These&amp;nbsp;resources enabled the timely acquisition of the&amp;nbsp;PET and motion tracking data sets.</gtr:partnerContribution><gtr:piContribution>We&amp;nbsp;provided motion tracking using the Kinect on 40 dynamic brain PET studies that were imaged at Imanova on their Siemens Biograph 6 PET/CT scanners.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Demonstrating head tracking at the Imperial College London BRC Hammersmith Open Day</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>1D18592C-2128-4F6B-A08A-3F38A04C6CD3</gtr:id><gtr:impact>General public, students, and clinicians were able to come and interact with a live demonstration of the head motion tracking system designed for motion correction brain PET/CT scans. We were able to discuss the importance of the problem and how modern technology and various parts of ICL were able to contribute to developing the motion tracking system.</gtr:impact><gtr:outcomeId>56dff4bb890bd5.95102648</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Demonstrating Medical Augmented Reality using depth sensors and the Occulus Rift head  mounted display at the Imperial Festival, 2015.</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>2E30EB26-CF2B-4F36-AC4E-B9B63F90E86B</gtr:id><gtr:impact>Imperial Festival showcases work performed at Imperial to the public, Friends of Imperial, and any other interested attendees. Over 12,000 people attended the festival in 2015.</gtr:impact><gtr:outcomeId>56dfeda0c10520.74090134</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.imperial.ac.uk/be-inspired/festival/about/festival-2015/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Publication on the Microsoft Kinect for Windows Blog</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>28E051A1-C281-4400-B575-215AE40E43DE</gtr:id><gtr:impact>We were invited to showcase our work on head tracking on the Microsoft Kinect for Window Blog.</gtr:impact><gtr:outcomeId>56dff54557c4c8.12185804</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://blogs.msdn.microsoft.com/kinectforwindows/2015/04/22/can-kinect-technology-improve-brain-imaging/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs><gtr:productOutput><gtr:description>The system consists of a modified Microsoft Kinect v2 which is rigidly mounted inside the scanner bore of a PET/CT scanner. Software tracks the position of the subject's head using the 3D data provided by the Kinect v2. Currently we are acquiring 40 research PET/CT clinical brain scans with motion data to perform motion correction in the aim of reducing image blur. This is funded using a Medical Research Council Development Pathway Funding Scheme.</gtr:description><gtr:id>9045C811-7A2D-4E6B-9827-068FB2F3B75F</gtr:id><gtr:impact>The software and techniques developed could be applied to other aspects of healthcare such as respiratory monitoring.</gtr:impact><gtr:outcomeId>56dfef583c0767.86797723</gtr:outcomeId><gtr:stage>Refinement.  Clinical</gtr:stage><gtr:status>Under active development/distribution</gtr:status><gtr:title>System for measuring head motion during Positron Emission Tomography.</gtr:title><gtr:type>Support Tool - For Fundamental Research</gtr:type><gtr:yearDevCompleted>2015</gtr:yearDevCompleted></gtr:productOutput></gtr:productOutputs><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>We have written an application using the kfusion implementation of the KinectFusion algorithm which is able to monitor the position of the subject's head in realtime while they undergo a PET/CT scan. 
The underlying framework for processing the Kinect depth data has been finalised and we are now working on developing the front end system for optimal ease of use in the PET/CT scanning environment.</gtr:description><gtr:id>62394DFA-931D-454E-82C1-3D734FA4502E</gtr:id><gtr:impact>This software was validated for the first Milestone of our MRC DPFS grant enabling us to proceed to obtain and process 40 clinical PET/CT scans, demonstrating the clinical efficacy of the software.</gtr:impact><gtr:outcomeId>56dff09c295bf9.64104134</gtr:outcomeId><gtr:title>Software to track head motion during brain PET/CT</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>We have developed a suite of tools that are centred around using a depth sensor, such as the Kinect, to&amp;nbsp;enable head and whole body motion tracking. We have integrated marker tracking, stereo vision, optical flow, and facial feature identification to enable robust motion tracking for use in a clinical imaging environment.</gtr:description><gtr:id>4C1E4AF8-3DFE-4505-BCDC-2B0F976F392F</gtr:id><gtr:impact>This software was developed as part of the MRC DPFS grant and will be continued to be&amp;nbsp;developed and evaluated&amp;nbsp;after the project closes.</gtr:impact><gtr:outcomeId>58a3111911f0c0.40058783</gtr:outcomeId><gtr:title>Motion Tracking Using Depth Sensors</gtr:title><gtr:type>Software</gtr:type><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>495A71BA-A4C5-48BE-8712-31FA0CD49902</gtr:id><gtr:title>Simultaneous multiple kinect v2 for extended field of view motion tracking</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fa5039881f06d3d886da455b2ff322cd"><gtr:id>fa5039881f06d3d886da455b2ff322cd</gtr:id><gtr:otherNames>Noonan P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>588b5bcac4fce5.70543905</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DC4ABF85-8AD7-438C-9DFC-F13AF0958A16</gtr:id><gtr:title>Repurposing the Microsoft Kinect for Windows v2 for external head motion tracking for brain PET.</gtr:title><gtr:parentPublicationTitle>Physics in medicine and biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9ef89c2d206e280c539a6bcfb55c7c84"><gtr:id>9ef89c2d206e280c539a6bcfb55c7c84</gtr:id><gtr:otherNames>Noonan PJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0031-9155</gtr:issn><gtr:outcomeId>56c881de854312.91076941</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">MR/M025004/1</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>041997EB-CFD8-493D-B0F8-DFA35451D0BE</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Neurological</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>3BEA012A-C817-4067-8BE1-05331EBB5152</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>4.2  Evaluation of markers and technologies</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>