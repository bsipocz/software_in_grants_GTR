<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Ophthalmology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/7D9AD350-3C6D-4125-9B81-3C98D6C005B4"><gtr:id>7D9AD350-3C6D-4125-9B81-3C98D6C005B4</gtr:id><gtr:firstName>Sylvia</gtr:firstName><gtr:surname>Schroeder</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/C2C88929-06E1-4317-A8C1-42B32A70BC3F"><gtr:id>C2C88929-06E1-4317-A8C1-42B32A70BC3F</gtr:id><gtr:firstName>Matteo</gtr:firstName><gtr:surname>Carandini</gtr:surname><gtr:orcidId>0000-0003-4880-7682</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FP003273%2F1"><gtr:id>9198C641-1EC4-4993-AC6C-D1AE6AA1E276</gtr:id><gtr:title>Combining Vision with Action one Synapse from the Eye</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/P003273/1</gtr:grantReference><gtr:abstractText>One synapse away from the eye lies a fundamental brain structure, the superior colliculus, responsible for integrating sensory input, allocating attention to spatial locations, and generating orienting movements of the head and body to those locations. The inputs from the eye go to the superficial portion of the superior colliculus (sSC), which is thought to contain a mostly visual representation of the external world. Recent observations in our laboratory, however, suggest that sSC does much more than pure vision: its visual responses are strongly shaped by non-sensory signals. 
The proposed project will reveal how this key brain region combines visual signals with non-sensory signals reflecting brain and behavioral state, decision processes and motor actions. Further, it will help reveal the sources of non-sensory signals, and provide a simple model of the functional effects of this combination of visual and non-sensory signals, and of the underlying neural circuits. 
To achieve these goals, we will leverage novel neural imaging and behavioral techniques that we have developed in our laboratory. We will use two-photon imaging to record activity of hundreds of genetically identified neurons within the sSC of awake mice. The same technique will reveal the activity of the inputs to those neurons originating in the eye or in the cerebral cortex. These imaging measurements will be made while mice are passively viewing a stimulus or actively performing a visual task. 
Our first objective focuses on how sSC is affected by brain and behavioral state such as arousal and locomotion. We will image responses in sSC to a range of visual stimuli and relate them to the level of arousal, as reflected by pupil diameter, and to locomotion. Preliminary data indicate that these factors have an enormous effect on the responses of some cells and a negligible one on others. We will distinguish cell classes to map these effects onto the circuits of sSC. 
Our second objective focuses on how sSC is affected in interactive conditions where visual stimuli are used for specific decisions and actions. We will image different cell classes in the sSC while the animal performs a visual task requiring a goal-directed movement. We will relate responses to stimulus, performance, and action using simple correlation measures and a predictive model of neural responses. The data will characterize how the sSC combines visual signals with signals related to decision and action.
Our third objective focuses on the sources and circuits that provide the sSC with non-sensory signals. The main visual inputs to sSC originate from the eye and from the cerebral cortex. To assess their role in providing visual and non-sensory signals, we will image the activity of their axon terminals in sSC and the activity of cortical neurons projecting to the sSC. We will then inactivate the cortex to reveal its effect on sSC. The results will characterize the signals that sSC inherits from the eye and from the cortex, and will indicate if the latter is necessary to explain the combination of visual and non-sensory signals seen in sSC. 
Results from all objectives will allow us to build simple functional and circuit models for the combination of visual and non-sensory signals in the sSC.
These experiments have the potential to change the way we think about how the brain integrates sensory and non-sensory inputs, showing how neurons getting direct input from the eye combine visual signals with signals related to brain and behavioural state, decisions, and actions.
Expanding our understanding of the function and circuitry of the superior colliculus will eventually enable us to simulate and replicate how this brain area transforms sensory input into commands that allocate attention and generate actions. It may also help to understand attentional deficits in disease and develop cures and therapies.</gtr:abstractText><gtr:technicalSummary>The superior colliculus is a midbrain area responsible for sensorimotor integration. Its superficial layers (sSC) are thought to be mostly visual, but recent observations in our laboratory show that its visual responses are shaped by non-sensory signals. 
We seek to understand how sSC combines visual with non-sensory signals related to brain or behavioural state (Objective 1), and to decision and action (Objective 2), and we seek to characterize the underlying projections and circuits (Objective 3).
Objective 1. We will use two-photon imaging to record the visual responses of different cell classes in sSC in awake mice. We will relate these responses to the level of arousal, as reflected by pupil diameter, and to the speed of locomotion. Preliminary data indicate that these factors have an enormous effect on some cells, but a negligible one on others. We will study how these effects map to different cell classes using transgenic mouse lines, and we will summarize these effects with simple functional and circuit models.
Objective 2. We will ask how different cell classes in sSC are affected when the animal performs a visual discrimination task. We will relate responses to stimulus, task, and action using correlation measures and a model that predicts neural activity based on those events. These data will help refine the functional and circuit models.
Objective 3: To characterize the signals that sSC inherits from retina and visual cortex, we will image the terminals of those projections in sSC, and we will image the activity of cortical neurons projecting to the sSC. We will then inactivate visual cortex and corticotectal neurons to assess the cortical role in the combination of visual and non-sensory signals seen in sSC. The findings will be incorporated into the circuit model of sSC.
These experiments will show how neurons one synapse away from retina combine visual signals with non-sensory signals related to brain and behavioural state, decision, and action.</gtr:technicalSummary><gtr:potentialImpactText>The proposed work is at the level of fundamental science and its main impact is in the generation of essential knowledge about how the brain works. In addition, the proposed work may have impact in the following domains. 
(1) &amp;quot;Understanding and treating disease&amp;quot;. The superior colliculus is responsible for orienting toward unexpected stimuli. It is thus intimately linked to distractibility and is thought to play a role in attention deficit hyperactivity disorder (ADHD). ADHD affects 5-7% of adolescents worldwide (see www.adhd-institute.com) and is a major risk factor for later substance abuse, delinquency, and personality disorder [Sagvolden T, Sergeant JA, Behav Brain Res, 1998]. In a rat model of ADHD, visual responses in sSC were greater than in normal rats and D-Amphetamine, a drug commonly administered to ADHD patients, reduced these responses in diseased and normal rats [Clements KM et al, Neuroscience, 2014]. It is hypothesized that these amplified visual responses lead to a higher probability of orienting movements towards salient stimuli, and thus to a larger degree of distractibility. The proposed project will reveal the influence of several non-visual factors (level of arousal, locomotion, and decision-related signals) on the visual response properties of the sSC. Preliminary results suggest that these signals do affect responses to visual stimuli. The project will also investigate the origin of these non-sensory signals and how different cell types are affected by them. Understanding the modulation of visual responses in healthy subjects may help to understand the abnormal changes in responsivity in ADHD, or may lead to the development of compensatory interventions to restore normal activity patterns.
(2) &amp;quot;Development of artificial intelligence&amp;quot;. Modern technology that uses some form of artificial intelligence is an integral part of everyday life. Machines and electronic devices take over typical human skills like understanding and producing human language, or autonomously driving cars. The implementation of such complex functions is often inspired by the brain. A prominent case is deep learning, which is based on the concept of neural networks and hierarchical processing in the brain. The superior colliculus is an important part of the sensorimotor system, which processes low-level visual information, identifies the most relevant input, and generates motor commands to orient towards these inputs. The ability to suppress orienting towards just any new or salient stimulus may be due to input from other brain areas such as cortex or basal ganglia. These functions are vital to our behaviour and their implementation in artificial systems, e.g. self-driving cars, may prove equally vital. The proposed project may help the progress in this field by elucidating how visual input is processed in goal-directed decision making compared to passive viewing, how cortical input influences this processing, and what role different cell types in the circuit play in that processing.
Our project falls firmly under Response Priority Mode &amp;quot;Systems approaches to the biosciences&amp;quot; because we will study a complex biological system and use statistics and modelling to capture relevant features of the system. The system involves several components at different hierarchical levels, namely different cell classes and different brain areas, that interact in complex ways, and will be studied during behaviour (decisions, actions, arousal). Our final computational model of the neural circuitry will capture the different components and their interactions so that it can be used to predict functional and anatomical features of the circuit. We build on strong collaborations with bioscientists (e.g. Prof. Robin Ali, Dr. Matteo Rizzi and Prof. Leon Lagnado to develop a viral vector for the imaging of retinal ganglion cell axons) and computational neuroscientists (e.g. Prof. Kenneth Harris who runs the laboratory with Prof. Carandini).</gtr:potentialImpactText><gtr:fund><gtr:end>2019-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2016-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>496002</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/P003273/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>