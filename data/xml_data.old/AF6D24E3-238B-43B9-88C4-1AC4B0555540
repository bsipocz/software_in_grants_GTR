<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:department>School of Psychology</gtr:department><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:line4>Swindon</gtr:line4><gtr:line5>Wiltshire</gtr:line5><gtr:postCode>SN2 1ET</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/909AB72E-53E6-4760-A09B-B0A579050A61"><gtr:id>909AB72E-53E6-4760-A09B-B0A579050A61</gtr:id><gtr:firstName>Si</gtr:firstName><gtr:surname>Wu</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DBDC1CCD-262F-4853-9980-F5485BC55149"><gtr:id>DBDC1CCD-262F-4853-9980-F5485BC55149</gtr:id><gtr:firstName>Gareth</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Barnes</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/29719790-697D-410F-86B0-395994E70156"><gtr:id>29719790-697D-410F-86B0-395994E70156</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:otherNames>Philip</gtr:otherNames><gtr:surname>Bagshaw</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/72B46776-987B-451D-B441-84A63046DEC3"><gtr:id>72B46776-987B-451D-B441-84A63046DEC3</gtr:id><gtr:firstName>Zoe</gtr:firstName><gtr:surname>Kourtzi</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FE017436%2F1"><gtr:id>AF6D24E3-238B-43B9-88C4-1AC4B0555540</gtr:id><gtr:title>Classification decisions in machines and human brains</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/E017436/1</gtr:grantReference><gtr:abstractText>In our everyday interactions we encounter a plethora of novel experiences in different social contexts that require prompt decisions for successful actions. Extracting the key information from the highly complex input of the natural world and deciding how to interpret it is a computationally challenging task that is far from understood. In particular, our perceptual decisions are determined not only by the sensory evidence available but also by abstract rules that allow us to be flexible in interpreting novel experiences based on our previous knowledge about the likelihood of an event with a desired outcome, its social context, and the magnitude and rate of reward associated with the anticipated action choice. For example, deciding how to act (reserved vs. extroverted) when encountering an acquaintance depends on sensory evidence (we recognise the specific person or they simply appear familiar), our knowledge and feelings about this person based on previous encounters, the social context (business meeting or social event) and the reward associated with this social interaction (new friendship or partnership). We propose to examine the neural basis of perceptual decisions in complex, novel and uncertain environments that map sensory experiences into actions by bringing together interdisciplinary expertise in advanced mathematical approaches (i.e. machine learning), established behavioural methods and multimodal brain imaging (fMRI, MEG, EEG) techniques that allow us to study the human brain at work in real time. Our goal is to understand the neural computations that allow humans to make categorical decisions based on adaptive learning. This challenging problem of visual categorisation is known in engineering as the pattern classification problem. In this framework, we will examine how the human brain extracts important features from complex inputs and classifies them to meaningful perceptual categories by comparing the performance of human observers with that of statistical learning machines. The aim of this interdisciplinary project is threefold. First, we will develop and validate novel analysis methods for psychophysical and multimodal imaging data based on elegant mathematical approaches that test for feature selection and multi-dimensional classification in rich biological data sets. Second, we will use these machine classifiers as sensitive and powerful tools for decoding the internal representation of the physical world in the human brain. Third, we will optimise and constrain these algorithms based on biophysical models (human observers' performance, neural responses) that will allow closer comparison between machine and human classification and have direct applications for the design of artificial systems (e.g. expert systems for face, fingerprint or hand-writing recognition, gene or tumour classification). This collaborative work will initiate a new line of UK collaborative research that will bridge physical and biological sciences and provide novel insights and tools in understanding the link between behaviour and neural plasticity. Further, this research has implications for understanding the development of our social cognition functions, their disruption in ageing and neurological disorders and the potential for recovery of function through learning. In sum, the proposed work has strong potential for building and enhancing interdisciplinary, high-end, competitive research in the UK, improving the long-term quality of life through basic research with potential applications in engineering and medicine, and thus contributing to the general health and wealth in the UK.</gtr:abstractText><gtr:technicalSummary>Our ability to extract abstract information from our experiences and group it into meaningful units (categories) is a fundamental cognitive skill for interpreting the complex environments we inhabit. How does the human brain learn about the regularities and context of novel perceptual experiences that have not been honed by evolution and development and decide on their interpretation and classification? We propose a novel interdisciplinary approach that integrates advanced multimodal imaging (fMRI, MEG, EEG) methods and state-of-the art machine learning algorithms to examine the neural architecture that underlies classification learning and decisions in the human brain. We aim to a) create an electrical-haemodynamic signal space in which neuronal assemblies and their interactions can be characterised, and b) to develop a unified algorithmic method for efficiently analyzing neural imaging and behavioural data. In particular, we will use machine pattern classifiers to define perceptual decision images that reveal the critical stimulus features on which the observers base their perceptual classifications, and neural decision images that reveal the neural selectivity, plasticity and dynamics with which these features are encoded and learnt by the human brain. Our methodological and theoretical developments will provide a) novel and sensitive tools for the assessment of the behavioural and neural signatures of perceptual decisions in neuroscience, and b) novel challenges and insights in machine learning for the optimisation of biologically-constrained algorithms with direct applications for expert recognition systems. Further, our findings will advance our understanding of the link between sensory input, neural code and human behaviour and have potential applications for studying the development of perceptual decision processes across the life span, and their impairment and potential for recovery of function in ageing and disorders of visual and social cognition.</gtr:technicalSummary><gtr:fund><gtr:end>2010-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2007-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>936093</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Invited talk at the Science Festival, Bradford, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>90CFD34C-B89F-4CF1-BAD0-69BB6837C668</gtr:id><gtr:impact>The talk inspired lively discussions about rehabilitation programmes in healthy ageing and disease

Follow up talks were requested on the topic of cognitive ageing</gtr:impact><gtr:outcomeId>546144d70690a0.04378610</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>449843</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Attentional demands of state transitions in posture and balance</gtr:description><gtr:end>2011-12-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:fundingRef>BB/F010087/1</gtr:fundingRef><gtr:id>A5DDEECB-B6F0-409F-BD1F-0BD45537A910</gtr:id><gtr:outcomeId>5ee47dd65ee47dea</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>44637</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Learning and brain plasticity: understanding individual variability across the lifespan.</gtr:description><gtr:end>2013-10-02</gtr:end><gtr:fundingOrg>The Leverhulme Trust</gtr:fundingOrg><gtr:fundingRef>RF-2011-378</gtr:fundingRef><gtr:id>5B46E85D-4599-4A68-9FD6-13A587CBE996</gtr:id><gtr:outcomeId>5ec3477e5ec34792</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2011-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>767105</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Unified probabilistic modeling of adaptive spatio-temporal structures in the human brain</gtr:description><gtr:end>2013-08-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:fundingRef>BB/H012508/1</gtr:fundingRef><gtr:id>8CDB9070-F095-44D0-BE49-FF8FBFC35FE6</gtr:id><gtr:outcomeId>5ee4e6545ee4e668</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2010-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>3000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Lifelong learning and cortical plasticity in the human brain</gtr:description><gtr:end>2011-09-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:id>8FC05402-6301-40F4-9001-D32283E8CB4B</gtr:id><gtr:outcomeId>5ee62a825ee62a96</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>2923000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>ABC: Adaptive Brain Computations</gtr:description><gtr:end>2016-05-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>FP7-PEOPLE-2011-1-1-ITN 290011</gtr:fundingRef><gtr:id>F7DD1DAE-52D3-4E6E-8947-143191A73C85</gtr:id><gtr:outcomeId>5ec647805ec64794</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2012-06-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work advances our understanding of the human brain mechanisms that underlie our ability to learn. Our findings have potential applications in the development of training programmes tailored to individual needs in health (i.e. education, ageing) and disease (e.g. neurodegenerative disorders).</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>00A38171-DCCD-46AD-BDC6-56AD0C4D237B</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5460adb6794a70.13506705</gtr:outcomeId><gtr:sector>Education,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This is a Cognitive Foresight award that brings together experts in cognitive neuroscience (Kourtzi) physics (Barnes, Bagshaw) and mathematics (Wu) to understand the neural basis of perceptual decisions in the human brain. The proposal focuses on the development of a novel unified algorithmic approach based on machine learning systems for the analysis of multimodal imaging (fMRI, MEG, EEG) that will allow us to investigate quantitatively the link between physical input, neural processing, and human behaviour.
During the first two years, this collaborative effort has resulted in several high-end publications across the team members focusing on computational (Neural Networks) fMRI (Neuron, J Neuroscience, J Neurophysiology) and MEG-EEG (NeuroImage, J Vision) studies as well as several presentations at UK and international meetings. Below we summarise the results from the main sets of studies completed as of now, while several other studies are still on-going. The methodology and findings emerging from this research provide the basis for current work in my lab that aims to understand the neural mechanisms that mediate experience-based plasticity in the human brain across the lifespan. 

Computational Studies: Our computational work (Neural Networks) focuses on statistical learning methods that are emerging as a valuable tool for decoding information from neuroimaging data. Noise in the brain imaging measurements and the limited number of training patterns typically recorded pose a challenge for the application of statistical learning methods in the analyses of brain data. To overcome this difficulty, we propose an approach of using prior knowledge from the behavioural performance of human observers in a task to enhance the training of Support Vector Machines (SVMs). Specifically, we collected behavioural responses from human observers performing a categorization task during scanning. We use the psychometric function generated based on the observers responses to different stimulus conditions as a distance constraint for training an SVM on the discrimination of brain imaging data (fMRI). Our findings confirm that this behaviour constrained SVM (BCSVM) outperforms standard SVM algorithms consistently. This methodology of constraining machine learning algorithms based on biophysical data allows closer comparison of machine and human classification performance.
fMRI Studies: Our fMRI studies use advanced pattern classification techniques that take advantage of information across brain activation patterns to overcome the limitations of standard fMRI analysis methods and extract informative signals related to the perceptual interpretations of the visual input. 
In a first set of studies (J Neurophysiology), we used these sensitive multivariate analysis methods to examine fMRI selectivity for global forms in the human visual pathways. We used Glass pattern stimuli, parametrically varying the perceived global form (concentric, radial, translational) whilst ensuring that the local statistics remain similar. Our findings demonstrate a continuum of integration processes that convert selectivity for local signals (orientation, position) in early visual areas to selectivity for global form structure in higher occipitotemporal areas. Interestingly, higher occipitotemporal areas discern differences in global form structure rather than low-level stimulus properties with higher accuracy than early visual areas while relying on information from smaller but more selective neural populations (smaller voxel pattern size), consistent with global pooling mechanisms of local orientation signals. These findings suggest that the human visual system employs a code of increasing efficiency across stages of analysis that is critical for the successful detection and recognition of objects in complex environments.
In a second set of studies (J Neuroscience), we asked which human brain areas contain information about diagnostic features that define perceptual categories and the rules that guide the observers' categorical decisions. In particular, we used psychophysics and fMRI pattern classification to predict the features critical for categorical decisions from brain activity when observers categorized the same stimuli using different rules. We reasoned that signals from brain areas encoding behaviourally relevant information would be decoded more reliably when we classify brain responses for stimulus categories based on the categorization rule used by the observers rather than a rule that does not match the perceived stimulus categories. Although a large network of cortical and subcortical areas contain information about visual categories, we showed that only a subset of these areas shape their selectivity to reflect the behaviourally relevant features rather than simply physical similarity between stimuli. Specifically, temporal and parietal areas show selectivity for the perceived form and motion similarity, respectively. In contrast, frontal areas and the striatum represent the conjunction of spatio-temporal features critical for complex and adaptive categorization tasks and potentially modulate selectivity in temporal and parietal areas. These findings provide novel evidence for flexible neural coding in the human brain that translates sensory experiences to categorical decisions by shaping neural representations across a network of areas with dissociable functional roles in visual categorization.
In a third study (Neuron), we investigated how category learning shapes decision processes in the human brain. We compared behavioural choices of human observers with those of a pattern classifier based on multi-voxel single-trial fMRI signals. Our findings show that category learning shapes processes related to decision variables in frontal and higher occipitotemporal regions rather than signal detection or response execution in primary visual or motor areas. In particular, fMRI signals in prefrontal regions reflect the observers' behavioural choice according to the learned decision criterion only in the context of the categorization task. In contrast, higher occipitotemporal areas show learning-dependent changes in the representation of perceived categories that are sustained after training independent of the task. These findings demonstrate that learning shapes selective representations of sensory readout signals in accordance with the decision criterion to support flexible decisions. On-going studies using simultaneous fMRI-EEG recordings investigate the temporal dynamics between occipitotemporal and frontal circuits that underlie the ability for flexible decisions. 
Multimodal Imaging Studies: The aim of these studies is to link EEG activity recorded in the fMRI scanner to the haemodynamic signals. The EEG signal measured on the scalp is a complex function of many (lead-field) parameters (such as conductivity and thickness of skull, scalp etc). These parameters vary from person to person. In contrast, the MEG is relatively insensitive to these parameters and has been shown to produce images which directly correspond to fMRI using very simple (single sphere or multiple local sphere) head models. The rationale is to tune the EEG lead-fields based on the MEG recordings using simple visual stimuli (already shown to correspond to fMRI images). Then to take these optimized lead-fields into the magnet. We have encountered a number of technical obstacles but are now at the point where we can produce EEG images, for simple visual stimuli, which concur with those obtained both with fMRI and MEG. In parallel with this activity we have examined pattern classification analysis of MEG/EEG recorded data on the same stimulus set (NeuroImage). This work shows that stimulus related information is not only contained in the electrical onset transient but also in the sustained oscillatory activity (or network state) that follows. This makes a robust link between the modalities all the more critical. The fMRI classifiers work on haemodynamic changes, but at this stage we do not know whether these changes are due to the network state, or the transient activity. Our on-going work shows that there appears to be both a behavioural and evoked response link to the pre-stimulus network state.</gtr:description><gtr:exploitationPathways>The work advances our understanding of the human brain mechanisms that underlie our ability to learn. Our findings have potential applications in the development of training programmes tailored to individual needs in health (i.e. education, ageing) and disease (e.g. neurodegenerative disorders).</gtr:exploitationPathways><gtr:id>803997D2-9154-46D3-8C65-B5F7D0955ED3</gtr:id><gtr:outcomeId>5460ad46803da9.45989083</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>44D554A4-29CD-4662-88F1-2FC43F015BBB</gtr:id><gtr:title>A spatial mixture approach to inferring sub-ROI spatio-temporal patterns from rapid event-related fMRI data.</gtr:title><gtr:parentPublicationTitle>Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8519379ca74594bab2b6baf7028f7afa"><gtr:id>8519379ca74594bab2b6baf7028f7afa</gtr:id><gtr:otherNames>Shen Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5460a9ea9e6a07.75674044</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3BB69D1-B89F-4FDF-A6A7-9DFD58C174A8</gtr:id><gtr:title>Learning shapes the representation of behavioral choice in the human brain.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b8a46f3752fd4026773cf1b531707cbf"><gtr:id>b8a46f3752fd4026773cf1b531707cbf</gtr:id><gtr:otherNames>Li S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn><gtr:outcomeId>5460a9e6c28245.10492219</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9E224180-7EDE-4924-B772-7676ED0C6D87</gtr:id><gtr:title>Can we observe collective neuronal activity from macroscopic aggregate signals?</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dcd4a6e9a787327184681e9325101b22"><gtr:id>dcd4a6e9a787327184681e9325101b22</gtr:id><gtr:otherNames>Hadjipapas A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>doi_55f94a94ab9c3123</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>74F4A0E8-A2A1-4F1C-8A79-5D44EA43C5F8</gtr:id><gtr:title>Behavior-constrained support vector machines for fMRI data analysis.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on neural networks</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2ef91a6d242b3418b3065118aa4f2f60"><gtr:id>2ef91a6d242b3418b3065118aa4f2f60</gtr:id><gtr:otherNames>Chen D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1045-9227</gtr:issn><gtr:outcomeId>5460a9e826afe6.63503040</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2F2F8606-8D2B-4887-924F-83CDC63E7FC0</gtr:id><gtr:title>Training transfers the limits on perception from parietal to ventral cortex.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8be4baaafd6976b5b2cc6f8fcd0e74de"><gtr:id>8be4baaafd6976b5b2cc6f8fcd0e74de</gtr:id><gtr:otherNames>Chang DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>5460a9eac074f8.11967566</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1AC107F6-43EC-446F-AEBA-09CF82FD65AD</gtr:id><gtr:title>Ideal observer analysis for task normalization of pattern classifier performance applied to EEG and fMRI data.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7d0abb86727efd576f6703144fa6aadc"><gtr:id>7d0abb86727efd576f6703144fa6aadc</gtr:id><gtr:otherNames>Peterson MF</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>5460a9e8722e35.20747980</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7ECF9FB4-86F5-4609-81CC-FE595C19C378</gtr:id><gtr:title>Dissociable circuits for visual shape learning in the young and aging human brain.</gtr:title><gtr:parentPublicationTitle>Frontiers in human neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab5f7a2f2226b7a2ecec9dc849ba674b"><gtr:id>ab5f7a2f2226b7a2ecec9dc849ba674b</gtr:id><gtr:otherNames>Mayhew SD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1662-5161</gtr:issn><gtr:outcomeId>5460a9e9845d63.20637119</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D4F44612-A174-4A94-946B-CE9687F39C9B</gtr:id><gtr:title>Identifying spatially overlapping local cortical networks with MEG.</gtr:title><gtr:parentPublicationTitle>Human brain mapping</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/10417aab9cd8ed1656c4afad86238d0e"><gtr:id>10417aab9cd8ed1656c4afad86238d0e</gtr:id><gtr:otherNames>Duncan KK</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1065-9471</gtr:issn><gtr:outcomeId>5460a9e77fb4b4.82987262</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>37291B9F-59F7-4F3C-B31B-5D4050A7AE8F</gtr:id><gtr:title>Differences in the time course of learning for hard compared to easy training.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5848af9090ac908c9b37eb79b22ae846"><gtr:id>5848af9090ac908c9b37eb79b22ae846</gtr:id><gtr:otherNames>Garcia A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>5460a9e96100d6.99594216</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7B6CEEFF-20C0-44EC-82F8-0C6E97208C63</gtr:id><gtr:title>Learning alters the tuning of functional magnetic resonance imaging patterns for visual forms.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6f5ff2310b21823fdc45326aba6a7d2d"><gtr:id>6f5ff2310b21823fdc45326aba6a7d2d</gtr:id><gtr:otherNames>Zhang J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>5460a9e84f6b36.09941301</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1CD3D17C-016D-4C07-9100-8A75F86F527E</gtr:id><gtr:title>Visual learning for perceptual and categorical decisions in the human brain.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/57117bff75ebe4634790ddc48ba7f9ab"><gtr:id>57117bff75ebe4634790ddc48ba7f9ab</gtr:id><gtr:otherNames>Kourtzi Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>5460a9e73a7095.37505420</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6770062E-2924-4A97-8326-BE19C210AFE8</gtr:id><gtr:title>Learning to predict: exposure to temporal sequences facilitates prediction of future events.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d8960949b7145d41cb88c41c76118195"><gtr:id>d8960949b7145d41cb88c41c76118195</gtr:id><gtr:otherNames>Baker R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>5460a9ea751814.97366437</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A2A118EE-8F70-44DB-B7A4-983B83CAEDD1</gtr:id><gtr:title>Learning optimizes decision templates in the human visual cortex.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b59a4cd8ca3c270bc26a40468441bc86"><gtr:id>b59a4cd8ca3c270bc26a40468441bc86</gtr:id><gtr:otherNames>Kuai SG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>5460a9e9ccc879.61647867</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C930367E-EA0B-49B7-925D-8B628E997099</gtr:id><gtr:title>Spatial-temporal modelling of fMRI data through spatially regularized mixture of hidden process models.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8519379ca74594bab2b6baf7028f7afa"><gtr:id>8519379ca74594bab2b6baf7028f7afa</gtr:id><gtr:otherNames>Shen Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>5460a9ea041709.14686555</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5EA5D52A-44E5-461D-A961-494879988DA5</gtr:id><gtr:title>Dynamics and computation of continuous attractors.</gtr:title><gtr:parentPublicationTitle>Neural computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d93e0d9984e7d52bb28236d6ce868b44"><gtr:id>d93e0d9984e7d52bb28236d6ce868b44</gtr:id><gtr:otherNames>Wu S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0899-7667</gtr:issn><gtr:outcomeId>56758a06ce2af</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DB4C475B-A5DF-410F-B83D-3ED7AE60E93C</gtr:id><gtr:title>Learning acts on distinct processes for visual form perception in the human brain.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab5f7a2f2226b7a2ecec9dc849ba674b"><gtr:id>ab5f7a2f2226b7a2ecec9dc849ba674b</gtr:id><gtr:otherNames>Mayhew SD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>5460a9e8e06241.39499124</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A735D7D2-3417-4F21-940D-4D9492DECC05</gtr:id><gtr:title>Learning shapes spatiotemporal brain patterns for flexible categorical decisions.</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b8a46f3752fd4026773cf1b531707cbf"><gtr:id>b8a46f3752fd4026773cf1b531707cbf</gtr:id><gtr:otherNames>Li S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>5460a9e8bccab4.51528424</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3ED99BDB-BAE4-495C-9D3F-82639013A6BD</gtr:id><gtr:title>Mechanisms for extracting a signal from noise as revealed through the specificity and generality of task training.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8be4baaafd6976b5b2cc6f8fcd0e74de"><gtr:id>8be4baaafd6976b5b2cc6f8fcd0e74de</gtr:id><gtr:otherNames>Chang DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>5460a9e9a98bb2.89468298</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C9AE71CA-EB23-48A6-8058-7849ABCE0AC4</gtr:id><gtr:title>Neural coding of global form in the human visual cortex.</gtr:title><gtr:parentPublicationTitle>Journal of neurophysiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4f109aaafa05a5d7e0369cac8e95812f"><gtr:id>4f109aaafa05a5d7e0369cac8e95812f</gtr:id><gtr:otherNames>Ostwald D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0022-3077</gtr:issn><gtr:outcomeId>5460a9e6729505.17953762</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C5AA6FAC-7B72-4BD7-AB81-BE2E4426FB04</gtr:id><gtr:title>Learning to see, but not discriminate, visual forms is impaired in aging.</gtr:title><gtr:parentPublicationTitle>Psychological science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b59a4cd8ca3c270bc26a40468441bc86"><gtr:id>b59a4cd8ca3c270bc26a40468441bc86</gtr:id><gtr:otherNames>Kuai SG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0956-7976</gtr:issn><gtr:outcomeId>5460a9e939bdf1.53555626</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94F93456-3CBD-4844-859E-8FF50E41A90F</gtr:id><gtr:title>Learning-dependent plasticity with and without training in the human brain.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6f5ff2310b21823fdc45326aba6a7d2d"><gtr:id>6f5ff2310b21823fdc45326aba6a7d2d</gtr:id><gtr:otherNames>Zhang J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>5460a9e7cbff91.71434943</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2B62AFCD-CB47-45D3-82C6-26CD81B34704</gtr:id><gtr:title>Learning shapes the representation of visual categories in the aging human brain.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab5f7a2f2226b7a2ecec9dc849ba674b"><gtr:id>ab5f7a2f2226b7a2ecec9dc849ba674b</gtr:id><gtr:otherNames>Mayhew SD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5460a9e7a4e026.93607245</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94EFC259-8FE5-43D8-A3A1-15A6A17A956C</gtr:id><gtr:title>A moving bump in a continuous manifold: a comprehensive study of the tracking dynamics of continuous attractor neural networks.</gtr:title><gtr:parentPublicationTitle>Neural computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4f24cae9f650fea2af66b1688a5c2b09"><gtr:id>4f24cae9f650fea2af66b1688a5c2b09</gtr:id><gtr:otherNames>Fung CC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0899-7667</gtr:issn><gtr:outcomeId>doi_55f94a94aba5f773</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AB525F73-C584-44C9-823B-C123A0F56DB7</gtr:id><gtr:title>Neural representations for object perception: structure, category, and adaptive coding.</gtr:title><gtr:parentPublicationTitle>Annual review of neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/57117bff75ebe4634790ddc48ba7f9ab"><gtr:id>57117bff75ebe4634790ddc48ba7f9ab</gtr:id><gtr:otherNames>Kourtzi Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0147-006X</gtr:issn><gtr:outcomeId>5460a9e8999c64.80038103</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/E017436/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>