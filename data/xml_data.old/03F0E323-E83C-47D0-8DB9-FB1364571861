<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/4DB630C7-7E13-4610-A1C3-29601903CEE3"><gtr:id>4DB630C7-7E13-4610-A1C3-29601903CEE3</gtr:id><gtr:name>National Oceanography Centre</gtr:name><gtr:department>Science and Technology</gtr:department><gtr:address><gtr:line1>Waterfront Campus</gtr:line1><gtr:line2>European Way</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO14 3ZH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4DB630C7-7E13-4610-A1C3-29601903CEE3"><gtr:id>4DB630C7-7E13-4610-A1C3-29601903CEE3</gtr:id><gtr:name>National Oceanography Centre</gtr:name><gtr:address><gtr:line1>Waterfront Campus</gtr:line1><gtr:line2>European Way</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO14 3ZH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/860775DF-7393-41C0-ABB6-F2ACDF7646F9"><gtr:id>860775DF-7393-41C0-ABB6-F2ACDF7646F9</gtr:id><gtr:firstName>Henry</gtr:firstName><gtr:surname>Ruhl</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F081B075-5AC4-44D9-8AAF-ED92CC985BEA"><gtr:id>F081B075-5AC4-44D9-8AAF-ED92CC985BEA</gtr:id><gtr:firstName>Veerle</gtr:firstName><gtr:otherNames>Ann</gtr:otherNames><gtr:surname>Huvenne</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=NE%2FP020739%2F1"><gtr:id>03F0E323-E83C-47D0-8DB9-FB1364571861</gtr:id><gtr:title>BioCam - Mapping of Benthic Biology, Geology and Ecology with Essential Ocean Variables</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>NE/P020739/1</gtr:grantReference><gtr:abstractText>The UK and international governments need to understand the effects of human activities on deep-sea ecosystems in order to make well informed decisions on how to protect and preserve them for future generations. In particular, deep-water coral reefs can be thought of a hotspot for biological activity, providing a rich habitat for diverse communities of marine life at depths of up to ~2000 m. At the same time deep-sea corals grow slowly, taking several thousands of years to form these reefs, are fragile and extremely sensitive to changes in the environment. As such, failure to protect them from trawling and industrial activities may have irreversible effects not only on the distribution of coral, but also on the distribution of the marine communities they support. 

However, monitoring of live coral distribution is expensive and time consuming. The main reason for this is that while deep-water corals are sparsely distributed over areas the size of a large city, the features that need to be observed to identify them reliably are on the scale of centimetres. Furthermore, colour is often used to tell apart healthy live coral from dead coral, which means that direct visual observation using underwater cameras is often necessary. Unfortunately, taking images underwater requires vehicles equipped with cameras and powerful lighting systems to operate within one or two meters of the seafloor. Since vehicles operating this close to the seafloor need to avoid obstacles, they can only travel at about a fifth of the speed people walk. In addition to these limitations, while an image can tell us if live coral is present or not, more advanced 3D imaging methods are needed to also tell us how much coral there is, which is important to know when monitoring changes in their abundance.

In this project, we will develop a 3D underwater camera system that is capable of measuring the distribution of live coral on the seafloor over areas that are more than 50 times larger than is currently possible. The system will use a pair of highly sensitivity cameras, a powerful flashed lighting system and a pulsed laser to obtain full colour images and high resolution 3D shape information at a range of almost 10 m (~5 times higher than is typical) from the seafloor. Being able to take high-resolution images from further away will increase the area that can be observed in a single frame and also allow underwater vehicles to operate at safer altitudes and so travel significantly faster than previously possible. Furthermore, images obtained by the 3D camera system will be processed to generate large 3D image landscapes that cover areas of several hundreds of hectares (1 hectare = 10,000m2). These landscapes will each consist of several hundreds of thousands of images of the seafloor obtained over several days using an underwater vehicle. The landscapes will provide scientists with a rich, explorable computer generated reconstruction of deep-sea environments that they can use to visualise and study patterns in the distribution of live coral that would not be immediately obvious in a folder consisting of several hundreds of thousands of raw image frames. Furthermore, the reconstructions will be made compatible with existing web-based interfaces that will potentially allow scientists from all over the world to directly identify live coral and make measurements of their size and distribution over the internet. 

The technology developed in this project will allow live coral distributions to be studied over spatial scales that were not previously possible. By revisiting sites over several years, the high-resolution data obtained by the proposed sensor will help facilitate a better understand of the changes that take place on the seafloor, and allow our governments to make better informed decisions regarding the best strategies to preserve and protect these habitats without unnecessarily compromising commercial and industrial activities in the ocean.</gtr:abstractText><gtr:potentialImpactText>This research will develop a compact, low power 3D imaging system that is capable of generating high-resolution digital reconstructions of underwater scenes. The representation of underwater scenes offered by commercial underwater camera systems is limited to the footprint of a single image frame. However, the extent visible in a single image frame is often not well matched to the task of observing or inspecting natural scenes or artificial structures since it yields little insight into features and patterns that exist on broader scales. The advantage of the system proposed in this work is that it will deliver digital 3D reconstructions of underwater scenes composed of several thousands of images or more, as a packaged data product. The use of standard data and metadata formats will also allow organisations to share data when necessary, and will allow features covering the full range of spatial scales observed to be seamlessly visualised, explored and interrogated by its users using existing software infrastructures. The capabilities offered will allow users to optimise the way in which observation and inspection tasks are performed as well as provide an opportunity to consider the most effective way to archive and maintain data. 

The sensor hardware will have integrated lighting control and data storage, and will use standard communication protocols that will make it possible to integrate the device into existing platforms with minimal disruption. Furthermore, the capabilities offered by the device can fulfil the role played by standard underwater cameras, which means that it has a potential market of several thousands of underwater platforms, including low-cost, compact (human deployable) remotely operated vehicles (ROVs). The application areas for such systems span natural science, mineral resource prospecting, environmental monitoring, mapping of debris and plastics, and industrial inspection. The main non-academic beneficiaries of such a system are commercial and government marine conservation groups and industrial groups involved with the installation, maintenance and decommissioning of artificial structures in freshwater and oceanic environments.

With regards to seafloor monitoring, long range autonomous underwater vehicles (AUVs) equipped with the 3D imaging system developed in this work can provide a cost effective solution for sustained monitoring of the seafloor. In particular, the high-level of autonomy can offer a significant reduction in cost through reduced reliance on crewed research vessels. The availability of high-resolution imagery poses advantages from an operational perspective since it can improve navigational estimates and so improve the localisation accuracy of specific features of significance. This capability can be extended to improve position estimates in real-time to increase the repeatability of seafloor observations by allowing specific areas to be revisited for more efficient temporal monitoring.

With regard to inspection of simple structures (e.g. pipelines, damns), pre-inspection planning surveys and the inspection of decommissioned sites, these are operationally comparable to monitoring surveys. These can benefit from the 3D reconstruction capabilities developed in this proposal. However, the economic pressures and risks associated with inspecting more complex structures (e.g. rigging, plants, hulls) demands low-cost, highly manoeuvrable platforms that can operate near their targets, such as compact, human deployable ROVs. For such systems, the relative localisation (i.e. knowing where the platform is with respect to the target) is a major operational bottleneck that makes complete inspection a time consuming task. Extension of the mapping capabilities described in this proposal to enable real-time generation of 3D reconstructions would allow ROV operators with an approximate knowledge of the targeted structure's shape to perform more efficient and complete inspections.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/8A03ED41-E67D-4F4A-B5DD-AAFB272B6471"><gtr:id>8A03ED41-E67D-4F4A-B5DD-AAFB272B6471</gtr:id><gtr:name>NERC</gtr:name></gtr:funder><gtr:start>2017-06-30</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>85552</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">NE/P020739/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>1A1A6805-9DC4-4BCE-BC70-9F2AA4FD093B</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Ecol, biodivers. &amp; systematics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>E05CFC1B-8264-49AB-8A54-E3A86F404707</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Marine environments</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F4786876-D9A9-404D-8569-BBC813C73074</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Community Ecology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>12C7A68B-3922-4925-9C0B-7FACEC921815</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Ecosystem Scale Processes</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>189E1F60-BF95-405D-A6F0-62BBD78E2DD5</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Survey &amp; Monitoring</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>98C0D11F-5C27-40CE-A895-54E4C61784B1</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Technol. for Environ. Appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>