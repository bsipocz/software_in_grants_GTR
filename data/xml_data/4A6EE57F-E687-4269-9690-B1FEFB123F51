<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Ophthalmology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/655934E2-68DD-46DD-82AB-EAB98B663D9C"><gtr:id>655934E2-68DD-46DD-82AB-EAB98B663D9C</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:surname>Stockman</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ005193%2F1"><gtr:id>4A6EE57F-E687-4269-9690-B1FEFB123F51</gtr:id><gtr:title>Rank based spectral estimation</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J005193/1</gtr:grantReference><gtr:abstractText>The colours, or RGB pixels, recorded by a digital camera are the result of the interaction of the prevailing light in the scene striking and being reflected by objects and the characteristics of the camera itself. The complexity is such that different cameras see differently and no cameras see the world exactly as we do. You will have noticed this when looking at photos where sometimes the colours don't look right or the pictures captured by one camera look 'better' than another. Moreover, sometimes we see colours change dramatically. We have all probably observed that white clothes can look bluish under ultra violet light (say in a night club). But, in fact the colours we see change subtly, all the time, as we move from one light to another (which is why it is always a good idea to check the colour of your clothes outside the shop). Here, even small changes can lead to poor customer satisfaction or, potentially, in a medical imaging application the wrong diagnosis.

Good pictures, by which we might mean accurate 'colour measurement' are possible if we know the spectral colour characteristics of a camera and/or the spectrum of light in a scene. While we can, in principle, measure these quantities the measurement is not easy to do so and is expensive (not easy as it requires considerable (Physics) lab time and expensive because spectral measurement devices cost many thousands of pounds). When measurement is not feasible, there do in fact exist methods for estimating (say) the spectrum of light in a scene. Yet, these methods only tend work if the camera is accurately calibrated first (a sort of chicken and the egg situation). Our 'Rank Based Spectral Estimation' Project aims to make it much easier to calibrate a camera or measure the illuminant in situ (and as such also make it easier to measure reflectance too)

So, how does our method work. Well suppose we gave you 50 grey tiles all of which appeared to have a different brightness. It would be an easy task for you to rank them from darkest to brightest. But, now suppose we change the colour of the light. Depending on the spectral shape of the grey reflectances, the ranking order can change (sometimes considerably). No problem, it is a simple matter to reorder the tiles. Remarkably, for specially chosen reflectances, the rank order will strongly correlate with the spectral shape of the light. Thus a simple ranking experiment gives us a strong clue to the colour of the light. (And, if we knew the colour of the light we could, for example predict whether the colour of our clothes might change when we go outdoors.)

The Rank Based Spectral Estimation project aims to take this simple ranking idea and provide simple, and accurate, estimation tools for deriving the spectral shape of the prevailing light, the spectral characteristics of a camera and the spectral reflectances of surfaces. At the heart of our method is a specially designed reflectance target containing many reflectances (whose design is part of the proposed research). Ranking these reflectances will allow us to accurately estimate the light spectrum and the spectral attributes of a camera. Accurate spectral estimates are required in many applications from photography, through, visual inspection to forensic imaging and telepresence (e.g. remote diagnosis).

Remarkably, we believe the methods we develop will also prove useful in understanding how we see. Indeed, it is very likely that you see the world a little differently than I do. Yet estimating an individual's spectral response is notoriously difficult. To the extent it can be done at all, it requires many hours of (tedious) detailed visual experiments. Through ranking it will be possible to uncover an observers spectral response (technically called 'colour matching curves') quickly and simply. We simply ask the observer to carry out a simple ranking of the kind mentioned above.</gtr:abstractText><gtr:fund><gtr:end>2016-02-29</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-03-21</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>57270</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>TEDxUAL talk on Color Vision</gtr:description><gtr:form>A broadcast e.g. TV/radio/film/podcast (other than news/press)</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>5BF68EA6-F05E-4426-920D-08979A54A6C4</gtr:id><gtr:impact>TEDxUAL speaker, University of the Arts London. On-line</gtr:impact><gtr:outcomeId>58b3071d247625.18338326</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.tedxual.com/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP Canterbury</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>B7DBBDAD-F21B-4BDE-9843-CFB25D6076B4</gtr:id><gtr:impact>Public lecture on Human Colour Vision IOP Canterbury</gtr:impact><gtr:outcomeId>58b307983eb053.09111873</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP London</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>37E61EA7-E07F-4435-8BA8-7B5025E2E87F</gtr:id><gtr:impact>Colour Vision
Public lecture at the Institute of Physics London</gtr:impact><gtr:outcomeId>58b305d4966c03.50738837</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>PI was chair and co-chair of the Colour Group GB</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>E0FDF089-D131-41CE-A3CD-FBB0207AD835</gtr:id><gtr:impact>The Colour Group GB organizes public meetings, school lectures and events on the broad topic of colour.

Wider interest and appreciation of the scientific and artistic aspects of colour.</gtr:impact><gtr:outcomeId>54625beaee6ec0.27661532</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.colour.org.uk</gtr:url><gtr:year>2009,2010,2011,2012,2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP Open University</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>5A987057-16A0-4E41-994E-8AF41A14EA98</gtr:id><gtr:impact>Colour vision
Invited public lecture, Institute of Physics, Open University, Milton Keynes</gtr:impact><gtr:outcomeId>58b305262fbaa0.02167492</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Human colour perception depends initially on the responses of the long(L-), middle(M-) and short(S-) wavelength-sensitive cones. These signals are then transformed post-receptorally into cone-opponent (L-M and S-(L+M)) and colour-opponent (red/green and blue/yellow) signals and perhaps at some later stage into categorical colour signals.
Here, we investigate the transformations from the cone spectral sensitivities to the hypothetical internal representations of 8 colour categories by applying a novel technique known as &amp;quot;Rank-Based Spectral Estimation&amp;quot;. Pairs of colours were ranked by 12 observers according to which appeared more representative of eight different colour categories: red-green-blue-yellow-pink-purple-brown-orange. Stimuli comprised circular patches of 32 colours presented on a CRT monitor chosen to cover as large a volume of LMS colour space as possible. In separate blocks, observers judged pairs of colours as to which appeared more like the reference colour name. Pairs for which judgement could not be made, because neither colour appeared like the reference, were recorded but not used.
To derive the spectral sensitivities of the colour categories (the 8 &amp;quot;colour sensors&amp;quot;) using the rank-based technique, we assumed that the relationship between cone responses and colour appearance can be described by a linear transform followed by a rank-preserving non-linearity. The estimated sensor transformations could account for over 85% of the rank orders. Sensor shapes were generally plausible; those for red and green were consistent across observers, while the yellow and blue ones showed more variability in spectral position. Other sensors, such as brown, pink and purple, showed large inter-observer variability, which might be due in part to cultural differences in colour naming. Sensors were generally restricted to limited regions of colour space. As expected from colour opponent theory, the red and green sensors formed relatively distinct regions with limited overlap as did the yellow and blue ones. Other sensors were spectrally shifted or bimodal.</gtr:description><gtr:exploitationPathways>We are still writing up and modelling these data. One fruitful new area of research will be to vary colours in the surround or on a background to see how they alter colour sensors operating on a central patch of colour.</gtr:exploitationPathways><gtr:id>902BE077-D87E-44CE-B04F-06681C6FF35C</gtr:id><gtr:outcomeId>56c72e8e499982.84638084</gtr:outcomeId><gtr:sectors><gtr:sector>Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This web resource provides an annotated database of downloadable standard functions and data sets relevant to colour and vision research and to colour technology, as well as providing information about the research outputs of our group. Updated frequently.</gtr:description><gtr:id>13AFA960-D66F-4E36-8C2A-1115ECE389A0</gtr:id><gtr:impact>Widely used in science and industry, the site started at UC San Diego in 1995 and moved to UCL with the PI in 2001.</gtr:impact><gtr:outcomeId>546148de469b05.25093708</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CVRL database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.cvrl.org</gtr:url><gtr:yearFirstProvided>2006</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>0DD7FC6E-5A5F-4E2F-BC88-99D2BDB9C8C0</gtr:id><gtr:title>Hue shifts produced by temporal asymmetries in chromatic signals.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5aa1600ad87f44.47673858</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>20B630CA-AEB9-4427-935E-966E9839B3D6</gtr:id><gtr:title>Cone dystrophy with &amp;quot;supernormal&amp;quot; rod ERG: psychophysical testing shows comparable rod and cone temporal sensitivity losses with no gain in rod function.</gtr:title><gtr:parentPublicationTitle>Investigative ophthalmology &amp; visual science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0146-0404</gtr:issn><gtr:outcomeId>54620eef821f28.50055674</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94FA1C96-0893-4B76-85F3-0E78E8DB9394</gtr:id><gtr:title>Encyclopedia of Color Science and Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4419-8071-7</gtr:isbn><gtr:outcomeId>58b30357cd8d22.68738180</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B1B470B5-6CD5-4B4B-982C-A14B16B7955F</gtr:id><gtr:title>Hue shifts produced by temporal asymmetries in chromatic signals depend on the alignment of the first and second harmonics.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5a35115e938c44.96907483</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>65511776-7DDD-4AB4-8EA6-3A5693AA07ED</gtr:id><gtr:title>Handbook of Color Psychology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>9781107337930</gtr:isbn><gtr:outcomeId>56c717d9e2c024.26627121</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7B1CD5C8-EFFD-4B2A-A8E5-0AF5781E1302</gtr:id><gtr:title>Spectral sensitivity measurements reveal partial success in restoring missing rod function with gene therapy.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eac5db3178ad0308d8f39daf63bce9b0"><gtr:id>eac5db3178ad0308d8f39daf63bce9b0</gtr:id><gtr:otherNames>Ripamonti C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56c70ee127e3a1.07689910</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4381D961-EC45-4F4E-9FD4-EA20266AF9A5</gtr:id><gtr:title>Visual consequences of molecular changes in the guanylate cyclase-activating protein.</gtr:title><gtr:parentPublicationTitle>Investigative ophthalmology &amp; visual science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0146-0404</gtr:issn><gtr:outcomeId>54620e62686322.05183419</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>53F8F5D7-705C-4B14-AAA9-DD8D08D3E5FD</gtr:id><gtr:title>Linear-nonlinear models of the red-green chromatic pathway.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5aa15fb7b229e8.53282213</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4CA203B9-1D33-4495-87F1-C7E000BE673E</gtr:id><gtr:title>Encyclopedia of Color Science and Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4419-8071-7</gtr:isbn><gtr:outcomeId>58b303e9b2e6c2.70427563</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7737F7C3-6D7C-4BCE-A78B-53BD6C770F4B</gtr:id><gtr:title>Long-term effect of gene therapy on Leber's congenital amaurosis.</gtr:title><gtr:parentPublicationTitle>The New England journal of medicine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/302e5d4c10875c411f1549c6c495119d"><gtr:id>302e5d4c10875c411f1549c6c495119d</gtr:id><gtr:otherNames>Bainbridge JW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0028-4793</gtr:issn><gtr:outcomeId>56c70ee0ed4773.96085354</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>858F149C-9358-4D79-9F2D-4C9B5C41EF0C</gtr:id><gtr:title>Vision in observers with enhanced S-cone syndrome: an excess of s-cones but connected mainly to conventional s-cone pathways.</gtr:title><gtr:parentPublicationTitle>Investigative ophthalmology &amp; visual science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eac5db3178ad0308d8f39daf63bce9b0"><gtr:id>eac5db3178ad0308d8f39daf63bce9b0</gtr:id><gtr:otherNames>Ripamonti C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0146-0404</gtr:issn><gtr:outcomeId>54620cb20b4ed7.99890611</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D1D0CD5D-4D5F-4EA6-8E60-F529CACEE1D4</gtr:id><gtr:title>Nature of the visual loss in observers with Leber's congenital amaurosis caused by specific mutations in RPE65.</gtr:title><gtr:parentPublicationTitle>Investigative ophthalmology &amp; visual science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eac5db3178ad0308d8f39daf63bce9b0"><gtr:id>eac5db3178ad0308d8f39daf63bce9b0</gtr:id><gtr:otherNames>Ripamonti C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0146-0404</gtr:issn><gtr:outcomeId>5462188984a860.03099707</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J005193/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>