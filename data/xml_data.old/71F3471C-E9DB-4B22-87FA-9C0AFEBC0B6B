<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AD312F7D-DA25-45B8-9CCB-E4F565306DD4"><gtr:id>AD312F7D-DA25-45B8-9CCB-E4F565306DD4</gtr:id><gtr:name>Lightpoint Medical Ltd</gtr:name><gtr:address><gtr:line1>Cardinal Point</gtr:line1><gtr:line2>Park Road</gtr:line2><gtr:postCode>WD3 1RE</gtr:postCode><gtr:region>East of England</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/EB4118EE-7395-4BE1-9EFE-80B2962FB869"><gtr:id>EB4118EE-7395-4BE1-9EFE-80B2962FB869</gtr:id><gtr:firstName>Danail</gtr:firstName><gtr:surname>Stoyanov</gtr:surname><gtr:orcidId>0000-0002-0980-3227</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/EF7495A9-B9E3-44A9-973E-FF3CB9C0D10D"><gtr:id>EF7495A9-B9E3-44A9-973E-FF3CB9C0D10D</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Arridge</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN022750%2F1"><gtr:id>71F3471C-E9DB-4B22-87FA-9C0AFEBC0B6B</gtr:id><gtr:title>Dynamic Peri-operative Cerenkov Luminescence Imaging for Robotic Assisted Surgery (EDCLIRS)</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N022750/1</gtr:grantReference><gtr:abstractText>Prostate cancer occurs in about one in seven of the male population and is fatal in about 20% of those cases, being the second most common cancer after lung cancer. Surgical intervention seeks to remove sufficient malignant tissue without leaving residuals that can lead to recurrence. At the same time new surgical techniques are emerging to minimise the impact on healthy tissue and preserve nerves and the quality of life. However, currently, the assessment of the success in removing all cancerous tissue depends on evaluation in a pathology lab and means that the surgery will not be curative or needs to be revisited. It is therefore crucial to develop technology that can allow the surgeon to make decisions during surgery that can reduce the chances of recurring disease. One well established indicator of cancerous tissue is the injection of a radioactively labelled tracer that differentiates between malignancy and normal tissue. This tracer can be imaged using positron emission tomography, but this is not a technology that can be utilized within a surgical setting. Recently a new methodology has been developed which allows the radioactive tracer to be imaged using ordinary cameras, by exploiting the emission by radioactive particles of Cerenkov light, in the visible spectrum. This phenomenon opens the possibility to place cameras on endoscopes and combine them with existing methods for robotic assisted surgery. In this project, we will pursue this idea, and make use of techniques for tracking movement of the cameras and the patient, including them in a model of light emission and detection, and realizing a real-time dynamic imaging system assisting the surgeon to excise all cancerous tissue while preserving as much healthy tissue as possible.</gtr:abstractText><gtr:potentialImpactText>Impact on Healthcare

The primary intention of the grant and the proposed Translational Alliance is to enable a real-time imaging technique as adjunct to existing peri-operative technology with the potential to reduce the expensive and invasive requirement for patient readmission to surgery, disease recurrence, co-morbidity and death. We expect this objective, if achieved, to have a significant impact on reducing mortality in the 41,736 people diagnosed with prostate cancer every year in UK (Cancer Research UK, 2011). Starting from this ambitious aim the long-term impact of the technology we develop has much wider potential with possible applications across a range of major cancer indications. These can only be targeted through a long-term collaboration between the project partners facilitated through an EPSRC Translational Alliance. 

Impact on Medical Technology

The systems we are developing are cutting edge in medical imaging technology. By alliance with LightPoint Medical we will have a translational path much faster than in typical research projects and expect to collaborate in detail with this company to realise next-generation peri-operative imaging technology. The proposed technology directly addresses the EPSRC grand challenges in Healthcare Technologies for developing new ways to enhance efficacy and reduce the risk to patients during surgery. Our cross-cutting technology aims to deliver new capabilities to the surgeon allowing repeatable precision with minimal invasiveness through novel imaging technologies by enabling imaging of dynamic tissues without signal loss through spatiotemporal low-rank plus sparse plus motion modelling. The project and alliance will benefit from our recent our EPSRC Capital Equipment Award in Robotics and Autonomous Systems, which will provide the robotic architectures and laboratory platforms for developing the proposed computational imaging research.

Academic Impact

The incorporation of computer vision techniques within real-time surgical procedures is a highly active and challenging area that is strongly represented at international conferences such as MICCAI and IPCAI. Including tomographic medical imaging modalities through registration and augmented reality visualisation is a more difficult problem but has made notable advances in recent years. Active imaging and new modalities for molecular imaging during surgery are an exciting new development in the field that can have disruptive impact. To achieve this, the acceleration of image reconstruction through spatial-temporal subsampling is a topic of strong interest, with connections to the very active area of Compressed Sensing. What we are proposing is an intersection of these areas incorporating highly novel non-linear motion models, coupled imaging physics, and high performance model based reconstruction algorithms supported by a robotic platform. We will disseminate these ideas through publication in high-impact journals and presentation at the leading conferences in the field. 

Impact on wider research community

The cross-cutting combination of robotics and imaging methodologies, through i) data fusion, ii) multimodality systems, and iii) coupled Physics imaging are recognised as a highly active topic, not only in medical imaging, but more widely e.g. in seismology and non-destructive testing. Through the UCL Centre for Medical Image Computing and the UCL Centre for Inverse Problems we are active in encouraging cross-fertilization between such different application areas. Furthermore the recently initiated Alan Turing Institute, which will be located in close proximity to UCL, will allow participation in wider programmes of research in large scale data processing, combing with state-of-the-art theoretical developments in mathematics, statistical and machine learning techniques. This will allow a rapid and effective mechanism to present our results to the wider UK community and internationally.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>242828</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The possibility of tomosynthesis of beta-emitting sources has been investigated. The industrial partner (LightPoint) is considering this as an alternative to Cerenkov imaging</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>A2B924B8-551F-48D3-9834-1727CCB6F8DF</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58c2d145e17948.26850349</gtr:outcomeId><gtr:sector>Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>64C5ED37-EBE0-4E07-9600-4F139888B8F5</gtr:id><gtr:title>Robust Catheter and Guidewire Tracking Using B-Spline Tube Model and Pixel-Wise Posteriors</gtr:title><gtr:parentPublicationTitle>IEEE Robotics and Automation Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8d2f2a3c329a2fa17c2343c3bd114ff5"><gtr:id>8d2f2a3c329a2fa17c2343c3bd114ff5</gtr:id><gtr:otherNames>Chang P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a915d800e9e15.94517632</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11D7A9B9-DF0F-407A-937A-ABF8F1D79259</gtr:id><gtr:title>Intelligent viewpoint selection for efficient CT to video registration in laparoscopic liver surgery.</gtr:title><gtr:parentPublicationTitle>International journal of computer assisted radiology and surgery</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1bf62e8acb886961558ef9ca8eb64624"><gtr:id>1bf62e8acb886961558ef9ca8eb64624</gtr:id><gtr:otherNames>Robu MR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1861-6410</gtr:issn><gtr:outcomeId>5a915d7d19da71.16411250</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0DCA6748-91D6-4209-BC8D-CECCB658EA86</gtr:id><gtr:title>A Combined EM and Visual Tracking Probabilistic Model for Robust Mosaicking: Application to Fetoscopy</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da881b8e0743bb2f36f4fd4ef8f97ca6"><gtr:id>da881b8e0743bb2f36f4fd4ef8f97ca6</gtr:id><gtr:otherNames>Tella M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a915d7df14164.58582401</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7D242520-CFB2-49A0-82F5-E06A65BA123A</gtr:id><gtr:title>Medical-grade Sterilizable Target for Fluid-immersed Fetoscope Optical Distortion Calibration.</gtr:title><gtr:parentPublicationTitle>Journal of visualized experiments : JoVE</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8cf0ef52097e9d1cb8c89754ff2e5dd1"><gtr:id>8cf0ef52097e9d1cb8c89754ff2e5dd1</gtr:id><gtr:otherNames>Nikitichev DI</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1940-087X</gtr:issn><gtr:outcomeId>5a35e4837cba42.36319524</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D3F91B60-7D16-4339-8290-DB63A916CDC6</gtr:id><gtr:title>Bayesian Estimation of Intrinsic Tissue Oxygenation and Perfusion From RGB Images.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on medical imaging</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bd82d2282685ad5be4a70b6d49034f67"><gtr:id>bd82d2282685ad5be4a70b6d49034f67</gtr:id><gtr:otherNames>Jones G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0278-0062</gtr:issn><gtr:outcomeId>58c1924d566a03.20355296</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>37AE646B-1EF6-4F10-B53F-19AC9C3B15F4</gtr:id><gtr:title>Hand-eye calibration for robotic assisted minimally invasive surgery without a calibration object</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/214b46cf11ba3e4f4d8ac262190f6b33"><gtr:id>214b46cf11ba3e4f4d8ac262190f6b33</gtr:id><gtr:otherNames>Pachtrachai K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a915d7eb9bfd2.67203953</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6F229ACE-8DB7-4C8B-B78E-B31C5CEC26B0</gtr:id><gtr:title>Comparative Validation of Polyp Detection Methods in Video Colonoscopy: Results From the MICCAI 2015 Endoscopic Vision Challenge.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on medical imaging</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/03f89715eadb12ffe2134bda0a0d84ee"><gtr:id>03f89715eadb12ffe2134bda0a0d84ee</gtr:id><gtr:otherNames>Bernal J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0278-0062</gtr:issn><gtr:outcomeId>5a915d7b822d88.20689171</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N022750/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A759BB04-AFFE-4780-BD31-9A2707BC44BA</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Medical Imaging</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>