<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D8078271-71D5-4EFF-AA6A-BDD77E59FD47"><gtr:id>D8078271-71D5-4EFF-AA6A-BDD77E59FD47</gtr:id><gtr:name>Emteq Limited</gtr:name><gtr:address><gtr:line1>ACRE HOUSE , 11/15 WILLIAM ROAD</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>NW1 3ER</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D8078271-71D5-4EFF-AA6A-BDD77E59FD47" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>D8078271-71D5-4EFF-AA6A-BDD77E59FD47</gtr:id><gtr:name>Emteq Limited</gtr:name><gtr:address><gtr:line1>ACRE HOUSE , 11/15 WILLIAM ROAD</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>NW1 3ER</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>31715.0</gtr:offerGrant><gtr:projectCost>50000.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/4E1614A4-2E97-4019-8F88-2D80EBFBE758"><gtr:id>4E1614A4-2E97-4019-8F88-2D80EBFBE758</gtr:id><gtr:firstName>Jacob</gtr:firstName><gtr:surname>Skinner</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=132050"><gtr:id>6F4EFFBB-58FE-4055-A934-6E07FDA0289D</gtr:id><gtr:title>Feasibility of emotion detection via facial muscle activity sensors embedded in glasses frame - FEDEm-Glasses</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Feasibility Studies</gtr:grantCategory><gtr:grantReference>132050</gtr:grantReference><gtr:abstractText>We have developed novel, miniaturised muscle activity sensors that work without the need for invasive procedures. We aim to integrate these into a glasses frame. In combination with a six-axis motion sensor (gyroscope and accelerometer) we want to demonstrate:
-Detection of corrugator (frown) muscle activity, without drawbacks of EMG (skin preparation, obtrusive caps)
-Accurate detection of head position, without drawbacks of remote cameras (occlusion, reference objects)
-Gesture recognition through a combination of the above
-Assessment of emotional state, through head position and corrugator response to IAPS images
-Performance compared to conventional EMG technology
This work could lead to gesture activated devices, enhanced software that detects user engagement and entertainment that detects emotional state of the user.</gtr:abstractText><gtr:fund><gtr:end>2017-05-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2016-12-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>31715</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">132050</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>