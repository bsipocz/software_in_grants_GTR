<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:department>Philosophy</gtr:department><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/89CCEFDB-AAF3-40FF-BB88-BD314A5D08DA"><gtr:id>89CCEFDB-AAF3-40FF-BB88-BD314A5D08DA</gtr:id><gtr:firstName>Shalom</gtr:firstName><gtr:surname>Lappin</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FJ022969%2F1"><gtr:id>285F224E-729F-4F36-B435-A7DD567C07E4</gtr:id><gtr:title>The Probabilistic Representation of Linguistic Knowledge</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>ES/J022969/1</gtr:grantReference><gtr:abstractText>&lt;p>The current research focusses on the problem of how to specify the class of representations encoding the syntax of natural languages. It is pursues the hypothesis that a syntactic representation is best expressed as an enriched statistical language model that assigns probability values to the sentences.&lt;/p>

&lt;p>A central part of the model consists of a procedure for determining the acceptability of a sentence as a graded value, relative to the properties of that sentence. This procedure avoids the simple reduction of grammaticality to it probability of occurrence, while still characterising grammaticality in probabilistic terms. Such an enriched model provides a straightforward explanation for the fact that individual native speakers generally judge the well formedness of sentences along a continuum, rather than through sharp boundaries between acceptable and unacceptable sentences. The pervasiveness of gradedness in the linguistic knowledge of individual speakers poses a serious problem for classical theories of syntax, which partition strings into the grammatical sentences of a language and ill formed strings of words. This research holds out the prospect of important impact in the study of language acquisition, and in the development of improved language technology.&lt;/p>

&lt;p>&lt;a href=&quot;http://www.dcs.kcl.ac.uk/staff/lappin/smog/&quot; rel=&quot;nofollow&quot;>Project website (external link)&lt;/a>&lt;/p></gtr:abstractText><gtr:potentialImpactText>The proposed research is highly interdisciplinary. It is situated at the intersection of computational linguistics, cognitive science, artificial intelligence, and natural language technology. 

The first area of impact is in computational modeling of linguistic knowledge. The proposed research will yield a language model that will not simply assign a probability distribution to the set of possible strings of words in a language, but will provide a probabilisitc measure of well formedness. This will give a precise measure of the gradient nature of grammaticality judgements that characterize individual native speakers' intuitions about the syntactic well formedness of sentences. Traditional theories of syntax generally use categorical rule and constraint systems to express grammatical knowledge. Gradience has been treated as the side effect of performance factors (memory and processing mechanisms) through which these grammars are applied to the parsing of strings. In fact, this idealized view of linguistic knowledge (syntactic competence) fails to provide a precise explanation for gradience, or to predict the judgement patterns that speakers actually exhibit. The enriched language model that the proposed research aims to produce will treat gradience as intrinsic to linguistic knowledge and predict gradience values for sentences as expressions of grammatical knowledge, rather than simple probability of occurrence. This approach integrates the representation of linguistic knowledge into the mainstream of contemporary research in cognitive science, which uses probabilistic models of learning and knowledge representation across a variety of cognitive domains. The proposed research will, then, have a significant impact on work in linguistic theory, and the psychological study of language. 

The research also specifies a direct connection between the computational properties of language learning, and the nature of the target representation that is the object of learning. The function that assigns graded acceptability values to sentences is constructed on analogy with the schematic function that Clark and Lappin (2009, 2011) suggest as a stochastic model of indirect negative evidence for grammar induction. The latter formalizes a procedure with which language learners can query the relative well formedness of a string on the basis of its frequency in the primary linguistic data, normalized through several of its properties. Therefore, the proposed project will have an impact on computational learning theory and machine learning applied to parsing and syntactic structure. These are core areas of articial intelligence with direct application to both cognitive modeling, and natural language technology. See the letters of support from Professor Rens Bod and Professor Khalil Sima'an of the Computational Linguistics Group in the Institute of Logic, Language, and Computation, University of Amsterdam. 

Finally, the research will be relevant to software engineering work in natural language processing. The proposed enriched language model will provide the basis for more accurate, fine grained parsing of text, which can be used to support a variety of language technologies. It will also be exceedingly useful to NLP tasks like natural language generation and machine translation, as it will provide a wide coverage automatic procedure for evaluating the output of such systems. See the letter of support from Dr. Peter Norvig, Director of Research at Google.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2012-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>458817</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Our data bases on speakers acceptability judgements for sentences in a variety of languages have been accessed by natural language processing researchers. Our software for generating and training machine learning models for predicting these judgements has been used by several of these researchers. our recent publications on our research in this area is being cited by scientists in industrial research laboratories, as well as computational linguists and AI researchers in unibersities.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>2558A847-D283-4BFD-ACDA-630CB9C6FA11</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545a3ca3755096.16475119</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Using enriched probabilistic models generated by machine learning, particularly Recurrent Neural Networks, it is possible to predict speakers' acceptability judgments with an encouraging degree of accuracy.</gtr:description><gtr:exploitationPathways>Our main experimental findings are being discussed in the computational linguistics literature and cognitive science. Several researchers in these fields are citing these results in connection with their work on related issues.</gtr:exploitationPathways><gtr:id>CF709217-A82C-4696-9CEB-F57785F175F4</gtr:id><gtr:outcomeId>545a3dbce068a8.21776463</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Other</gtr:sector></gtr:sectors><gtr:url>http://clasp.gu.se/about/people/shalom-lappin/smog</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>1. Software for generating enriched language models:
(i) N-gram models
(ii) several types of Bayesian Hidden Markov Models 
(iii) Recurrent Neural Network Language Models 
(iv) normalising grammaticality scoring functions that map the probability distributions generated by the models into acceptability values by neutralising the effect of sentence length and word frequency on probability value.

2. Annotated corpora of crowd sourced grammaticality judgements, with data sets from:
(i) the British National Corpus
(ii) randomly selected examples from Adger, D. (2003), Core syntax: A minimalist approach,Oxford University Press, Oxford.
(iv) the (near) full set of Adger (2003) examples, filtered for semantic/pragmatic anomaly
(v) English Wikipedia text
(vi) German Wikipedia text
(vii) Spanish Wikipedia text
(viii) Russian Wikipedia text</gtr:description><gtr:id>66D85E80-9B1D-4B5F-8FF2-EDB14B1D45C9</gtr:id><gtr:impact>Provides important resources for developing and testing natural language software for evaluating grammaticality/syntactic well-formedness</gtr:impact><gtr:outcomeId>541a06689324c3.49661210</gtr:outcomeId><gtr:title>Software for generating enriched language models; annotated corpora of crowd sourced grammaticality judgements from different domains and languages, available from the SMOG website at http://www.dcs.kcl.ac.uk/staff/lappin/smog/</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://clasp.gu.se/about/people/shalom-lappin/smog</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>F281AF78-6061-4EFE-97B2-24CEE22D1ADF</gtr:id><gtr:title>Robin Copper, Simon Dobnik, Shalom Lappin, and Staffan Larsson (2015), Probabilistic Type Theory and Natural Language Semantics</gtr:title><gtr:parentPublicationTitle>Linguistic Issues in Language Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e40899b071bd05149282970572c2237f"><gtr:id>e40899b071bd05149282970572c2237f</gtr:id><gtr:otherNames>Cooper,, R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56274b1742b5d5.63881308</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CBADBCBB-3BC1-4D51-A906-F25A172A8DB1</gtr:id><gtr:title>Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality, Proceedings of EACL 2014, Gothenburg, pp. 530-539.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f6f0c75d106410e50ab0ae3dc3b0c433"><gtr:id>f6f0c75d106410e50ab0ae3dc3b0c433</gtr:id><gtr:otherNames> Jey Han Lau, David Newman, and Timothy Baldwin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>m_765036286413c6ae4a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A3873D16-DFE1-4BA1-9F25-BE4F56032A13</gtr:id><gtr:title>Modelling Speakers' Grammaticality Judgements</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dfc322ef9e6cb5daceed83beb78fa9b9"><gtr:id>dfc322ef9e6cb5daceed83beb78fa9b9</gtr:id><gtr:otherNames>Jey Han Lau, Alexander Clark, and Shalom Lappin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545a3ad00b4ae8.06376342</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>915DB893-85FC-4247-A00F-1D616DF30EF6</gtr:id><gtr:title>Statistical Representation of Grammaticality Judgements: The Limits of N-Gram Models, Proceedings of the ACL Workshop on Cognitive Modelling and Computational Linguistics, Sophia, August 2013, pp. 28-36.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/319021009160a0340af842897964f9d2"><gtr:id>319021009160a0340af842897964f9d2</gtr:id><gtr:otherNames>Alexander Clark, Gianluca Giorgolo, and Shalom Lappin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_233088018613c3fa74</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>16DB7391-D44D-4A28-AEA4-69E648FD51BA</gtr:id><gtr:title>Unsupervised Prediction of Acceptability Judgements, Proceedings of the 53rd Annual Conference of the Association of Computational Linguistics, Beijing, 2015.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8b2b57985847a76103a9fcb0a2bef443"><gtr:id>8b2b57985847a76103a9fcb0a2bef443</gtr:id><gtr:otherNames> Jay Han Lau, Alexander S. Clark, and Shalom Lappin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>554d032ddffdc9.28753150</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7B5D4E35-2065-484F-BDC8-7B2A259BB447</gtr:id><gtr:title>Towards a Statistical Model of Grammaticality, Proceedings of the 35th Annual Conference of the Cognitive Science Society, Berlin, July-August 2013, pp. 2064-2069.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/50f5347f85f1419a504b05af91c7a770"><gtr:id>50f5347f85f1419a504b05af91c7a770</gtr:id><gtr:otherNames> Alexander Clark, Gianluca Giorgolo, and Shalom Lappin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>m_344960235413c3fbb4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>43DCD888-AA53-4A60-82EC-D2E450432FC0</gtr:id><gtr:title>Grammaticality, Acceptability, and Probability: A Probabilistic View of Linguistic Knowledge.</gtr:title><gtr:parentPublicationTitle>Cognitive science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f0148f9e2ddcf1af86329b3e1d76dee3"><gtr:id>f0148f9e2ddcf1af86329b3e1d76dee3</gtr:id><gtr:otherNames>Lau JH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0364-0213</gtr:issn><gtr:outcomeId>585d5606b17867.20324570</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F84A5E77-40C6-45F8-A5AE-7750603D5018</gtr:id><gtr:title>Measuring Gradience in Speakers' Grammaticality Judgements</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dc6d8bd1bf6347fed18bda808f2c76eb"><gtr:id>dc6d8bd1bf6347fed18bda808f2c76eb</gtr:id><gtr:otherNames> Jey Han Lau, Alexander Clark, and Shalom Lappin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>m_611561093313c6aeea</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>52A271FC-B96C-41D8-BC49-663FBFE0E791</gtr:id><gtr:title>A Probabilistic Rich Type Theory for Semantic Interpretation, Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), Gothenburg, pp. 72-79.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/594f9bc7b6cdcd4f5f088f0a4ec9f0b8"><gtr:id>594f9bc7b6cdcd4f5f088f0a4ec9f0b8</gtr:id><gtr:otherNames> Robin Cooper, Simon Dobnik, Shalom Lappin, and Staffan Larsson</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>m_792808539713c917ac</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2AA0F4A0-EF76-43A7-A008-9E4C8F5AD28A</gtr:id><gtr:title>Jey Han Lau, Alexander Clark, and Shalom Lappin, Grammaticality, Acceptability, and Probability: A Probabilistic View of Linguistic Knowledge</gtr:title><gtr:parentPublicationTitle>Cognitive Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/787042303200813141cdb73341f421b3"><gtr:id>787042303200813141cdb73341f421b3</gtr:id><gtr:otherNames>Lau, J.H.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>57febea94d85a9.30812622</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CF571D36-F767-409D-9118-6DBE5F583FD8</gtr:id><gtr:title>Jey Han Lau, Alexander Clark, and Shalom Lappin, Predicting Acceptability Judgements with Unsupervised Language Models, Proceedings of the Israeli Seminar in Computational Linguistics, Open University of Israel, June 2015.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76a0974fac00c601a8808ac92f0ac44f"><gtr:id>76a0974fac00c601a8808ac92f0ac44f</gtr:id><gtr:otherNames>Jey Han Lau</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>5570857179b5c4.14886813</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/J022969/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>87A865C6-1151-4169-B57A-6B39807A3BE2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Intelligent Measurement Sys.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>FFA3A6C9-532B-4B83-B6F7-AAF3E63D34F0</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Social Stats., Comp. &amp; Methods</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>EF570B48-CCF2-4278-BD44-F58AD6C36BDA</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Syntax</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>