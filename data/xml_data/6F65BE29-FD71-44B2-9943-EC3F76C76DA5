<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:department>School of Psychology</gtr:department><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3E87D3E8-C96D-42EA-A553-D7C40908C3B8"><gtr:id>3E87D3E8-C96D-42EA-A553-D7C40908C3B8</gtr:id><gtr:name>Philips Medical Systems U K Ltd</gtr:name><gtr:address><gtr:line1>Linac House</gtr:line1><gtr:line2>Fleming Way</gtr:line2><gtr:line4>Crawley</gtr:line4><gtr:line5>West Sussex</gtr:line5><gtr:postCode>RH10 9RR</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C2EB0344-CA7B-414D-9CAF-15B6E17BF263"><gtr:id>C2EB0344-CA7B-414D-9CAF-15B6E17BF263</gtr:id><gtr:name>Advanced Medical Equipment Ltd</gtr:name><gtr:address><gtr:line1>Advanced Medical Equipment Ltd</gtr:line1><gtr:line2>City Business Centre, Unit 14</gtr:line2><gtr:line3>6-8 Brighton Road</gtr:line3><gtr:line4>Horsham</gtr:line4><gtr:line5>West Sussex</gtr:line5><gtr:postCode>RH13 5BA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B3E9F0AA-D0D6-493A-8C7F-57DBFA2ADF0A"><gtr:id>B3E9F0AA-D0D6-493A-8C7F-57DBFA2ADF0A</gtr:id><gtr:name>Brain Vision UK Ltd</gtr:name><gtr:address><gtr:line1>Brain Vision UK Ltd</gtr:line1><gtr:line2>Suite 4, Zeal House</gtr:line2><gtr:line3>8 Deer Park Road</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SW19 3GY</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5F0AF345-40B8-48DC-B4A1-4ECC0BF9479C"><gtr:id>5F0AF345-40B8-48DC-B4A1-4ECC0BF9479C</gtr:id><gtr:firstName>Stuart</gtr:firstName><gtr:otherNames>William</gtr:otherNames><gtr:surname>Derbyshire</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8DEAAAC4-25C0-438D-82FA-FD9732BA593F"><gtr:id>8DEAAAC4-25C0-438D-82FA-FD9732BA593F</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Wing</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/801513B6-872E-43AF-9016-8C5DE89F7515"><gtr:id>801513B6-872E-43AF-9016-8C5DE89F7515</gtr:id><gtr:firstName>Rowland</gtr:firstName><gtr:otherNames>Christopher</gtr:otherNames><gtr:surname>Miall</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/29719790-697D-410F-86B0-395994E70156"><gtr:id>29719790-697D-410F-86B0-395994E70156</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:otherNames>Philip</gtr:otherNames><gtr:surname>Bagshaw</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/72B46776-987B-451D-B441-84A63046DEC3"><gtr:id>72B46776-987B-451D-B441-84A63046DEC3</gtr:id><gtr:firstName>Zoe</gtr:firstName><gtr:surname>Kourtzi</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/A536DD0C-05E7-4DCE-899C-25B41BFA1DBB"><gtr:id>A536DD0C-05E7-4DCE-899C-25B41BFA1DBB</gtr:id><gtr:firstName>Glyn</gtr:firstName><gtr:surname>Humphreys</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FE012604%2F1"><gtr:id>6F65BE29-FD71-44B2-9943-EC3F76C76DA5</gtr:id><gtr:title>High-resolution multimodal imaging for multisensory interactions</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/E012604/1</gtr:grantReference><gtr:abstractText>Recent developments in functional magnetic resonance imaging (fMRI) have transformed our understanding of the human brain, its sensory processing and cognitive functions by providing a means of localising the cortical regions that are involved in a wide variety of tasks. Despite this progress, the link between brain structure, function and behaviour that guides human actions and interactions remains a key unresolved issue in cognitive neuroscience. To address this issue we propose multimodal imaging methods (high resolution fMRI combined with EEG) that have complementary high spatial and temporal resolution and will allow us to study the human brain in real time action. In particular, the proposed research has the following main objectives. First, we will take advantage of the capabilities of the state-of-the-art MR scanner in our imaging centre (3T Phillips, Achieve) and develop high resolution fMRI protocols using a surface coil that will allow us to study the human brain at a higher spatial resolution, that is, at a finer scale of neural ensembles within cortical areas. Second, we will combine these high spatial resolution fMRI measurements with EEG recordings in the scanner that have high temporal resolution critical for studying the fast cognitive processes that guide our actions and interactions. Third, we will use these combined high resolution imaging methods (EEG-fMRI) to study the human brain in real time action. Our aim is to understand how the human brain integrates multiple sources of information from different sensory modalities (vision, audition, touch) and translates them to fast and successful actions. The existing MR compatible equipment allows visual and tactile stimulation and recordings of eye and limb movements. We will integrate these devices with the proposed equipment for auditory and heat stimulation to investigate the neural circuits that mediate the integration of sensory, proprioceptive and motor signals in the human brain that guide our categorical perception, attention, learning and actions in the complex environments we inhabit. Finally, we will extend the application of these methods and protocols to the study of multisensory and motor integration across the life span and in the adverse event of brain damage. We aim to examine the mechanisms that lead to rapid cognitive decline in some older adults while others maintain high levels of cognitive performance using sensitive tools for the measurement and analysis of age-related changes in behaviour, brain structure and neural function. Further, we will conduct high resolution imaging studies in patients with neuropsychological deficits that offer the potential of determining which areas are necessary for behaviour. We will examine the effects of brain lesions on activation in structurally intact regions of cortex, in order to gain new information about the functional connectivity between brain areas and potential cortical reorganisation that may support recovery of function in the impaired brain. As such this work has the potential to provide novel methods and findings that advance our understanding of the link between brain and behaviour and thus contribute to the general health and wealth as well the development of interdisciplinary and internationally competitive research in the UK.</gtr:abstractText><gtr:technicalSummary>Understanding the link between brain structure, function and behaviour is a key question in cognitive neuroscience. Recent advances in functional magnetic resonance imaging (fMRI) provide powerful tools for studying this question in a non-invasive manner in the human brain. However, the nature of the BOLD signal measured by fMRI imposes limitations in the spatial and temporal resolution of this technique. To overcome these limitations, we propose multimodal imaging methods (high spatial resolution fMRI combined with high temporal resolution EEG) that allow us to characterise the neural dynamics and function of fine neural ensembles within cortical areas. In particular we aim to study the neural circuits that mediate multisensory (vision, audition, touch) and motor interactions in the normal, ageing and impaired human brain. First, we will develop high resolution fMRI methods using a flexible surface coil that will allow us to zoom into their neural processing of cortical regions of interest and characterise the distribution and function of different neural populations within these regions. Second, we will develop protocols for combined EEG-fMRI recordings in the scanner that allow the electrical and haemodynamic responses to be recorded simultaneously during the same session. Third, we will exploit and advance analysis methods for combined EEG-fMRI measurements based on statistical learning approaches and single trial analyses. Fourth, we will combine these high resolution imaging methods (EEG-fMRI) with multimodal stimulation (visual, auditory, tactile) for examining the link between multisensory perception and action in the human brain in real time. These combined high resolution EEG-fMRI methods provide a unique tool for studying neurovascular coupling non-invasively in the human brain and monitoring neural changes due to learning-based plasticity or cortical reorganisation in the intact or neuropsychologically impaired brain across the life span.</gtr:technicalSummary><gtr:fund><gtr:end>2008-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2007-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>65691</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>44637</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Learning and brain plasticity: understanding individual variability across the lifespan.</gtr:description><gtr:end>2013-10-02</gtr:end><gtr:fundingOrg>The Leverhulme Trust</gtr:fundingOrg><gtr:fundingRef>RF-2011-378</gtr:fundingRef><gtr:id>1FB0E460-64C9-472F-A959-887780EE980A</gtr:id><gtr:outcomeId>5ec3477e5ec34792</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2011-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>2923000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>ABC: Adaptive Brain Computations</gtr:description><gtr:end>2016-05-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>FP7-PEOPLE-2011-1-1-ITN 290011</gtr:fundingRef><gtr:id>9BB7B3D9-22E5-46F7-A2DF-AD9A79D0182D</gtr:id><gtr:outcomeId>5ec647805ec64794</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2012-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>2438000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Co-ordination for optimal decisions in dynamic environments</gtr:description><gtr:end>2012-12-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>FP7-PEOPLE-2007-1-1-ITN 214728</gtr:fundingRef><gtr:id>BDF50849-DA2D-442E-B2D4-5F4BB156520D</gtr:id><gtr:outcomeId>5ec63cf45ec63d08</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>3000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Lifelong learning and cortical plasticity in the human brain</gtr:description><gtr:end>2011-09-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:id>9DB6485D-47E1-47C3-AB95-FDAE5C0143A5</gtr:id><gtr:outcomeId>5ee62a825ee62a96</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>133000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Visual-spatiotemporal integration for recognition</gtr:description><gtr:end>2012-08-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>FP7-PEOPLE-2009-IIF 255577</gtr:fundingRef><gtr:id>48DC8BD6-73A2-4061-82BB-15D90F315221</gtr:id><gtr:outcomeId>5ec641f45ec64208</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2010-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>449843</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Attentional demands of state transitions in posture and balance</gtr:description><gtr:end>2011-12-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:fundingRef>BB/F010087/1</gtr:fundingRef><gtr:id>625FB6EA-5E8A-497A-AD52-D39213DCFE97</gtr:id><gtr:outcomeId>5ee47dd65ee47dea</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1170116</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Classification decisions in machines and human brains</gtr:description><gtr:end>2010-10-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:fundingRef>BB/E027436/1</gtr:fundingRef><gtr:id>DDA3AA3F-9349-48A7-B4AF-5629D43F84BC</gtr:id><gtr:outcomeId>5ee477645ee47778</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2007-04-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>767105</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Unified probabilistic modeling of adaptive spatio-temporal structures in the human brain</gtr:description><gtr:end>2013-08-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:fundingRef>BB/H012508/1</gtr:fundingRef><gtr:id>126BB1C3-8B4F-4453-B32F-2D6A1C209587</gtr:id><gtr:outcomeId>5ee4e6545ee4e668</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2010-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>All methods developed during the duration of these award are now available to all users of the facilities at the Birmingham University Imaging Centre. Further, these methods are made available to the wider scientific community through interactions and collaborations with other imaging centres in the UK and abroad</gtr:description><gtr:firstYearOfImpact>2008</gtr:firstYearOfImpact><gtr:id>BC0A4B26-1247-4A3A-8DB9-1B5D54C6D9DF</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5460b18a686644.44593858</gtr:outcomeId><gtr:sector>Manufacturing, including Industrial Biotechology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>During the duration of the grant we established the following methodologies that have been implemented in the proposed research projects.
1. We developed high resolution functional imaging methods (EPI data collected at 1x1x1mm resolution and 1.5 x1.5x 1.5 mm that extend beyond the standard resolution used for fMRI data collection (3x3x5mm). This high resolution imaging allows us to study the human brain at the level of increasingly finer neural populations within large cortical areas.
2. We developed state-of-the-art statistical learning analysis methods that extend beyond the resolution of conventional fMRI analysis methods. In combination with high resolution imaging these methods allow us to discern different neural populations within cortical areas and their representations.
3. We developed protocols for combined EEG (MR-compatible 64 channel EEG system) and fMRI recordings at the BUIC scanner that allow the electrical and haemodynamic responses to be recorded simultaneously during the same session.
4. We have successfully interfaced MR-compatible equipment at BUIC for visual, tactile stimulation and movement recordings (eye, limbs) with the proposed equipment for auditory and noxious heat stimulation.
5. We have successfully piloted procedures to create &amp;quot;offset analgesia&amp;quot; in and out of the scanner using CHEPS and this work has been accepted for publication.
6. We developed EEG procedures using CHEPS and this work has been submitted for publication. We are now able to begin combined EEG/fMRI projects.
7. We successfully piloted signal detection studies using CHEPS and this work has been accepted for publication. We are now able to move this work into the scanner for combined EEG/fMRI studies.</gtr:description><gtr:exploitationPathways>All methods developed during the duration of these award are now available to all users of the facilities at the Birmingham University Imaging Centre. Further, these methods are made available to the wider scientific community through interactions and collaborations with other imaging centres in the UK and abroad</gtr:exploitationPathways><gtr:id>DE5827EA-E090-452F-927D-23F593C27269</gtr:id><gtr:outcomeId>r-4513139188.76754779e2340</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>E8778A60-87B6-47C6-A19C-D45EF570F2AC</gtr:id><gtr:title>Prior knowledge of illumination for 3D perception in the human brain.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f8c9835d9135b5b9378fa14c52ec0913"><gtr:id>f8c9835d9135b5b9378fa14c52ec0913</gtr:id><gtr:otherNames>Gerardin P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>5460a9e7f2f297.77618498</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CCB2134B-90F9-45AE-BFB8-4775D9D130A9</gtr:id><gtr:title>Training transfers the limits on perception from parietal to ventral cortex.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8be4baaafd6976b5b2cc6f8fcd0e74de"><gtr:id>8be4baaafd6976b5b2cc6f8fcd0e74de</gtr:id><gtr:otherNames>Chang DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>5460a9eac074f8.11967566</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1E596B86-4E6C-451C-80AA-9F1965322227</gtr:id><gtr:title>Ideal observer analysis for task normalization of pattern classifier performance applied to EEG and fMRI data.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7d0abb86727efd576f6703144fa6aadc"><gtr:id>7d0abb86727efd576f6703144fa6aadc</gtr:id><gtr:otherNames>Peterson MF</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>5460a9e8722e35.20747980</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E21A906B-E121-4C3D-97B3-AB9A3F14C952</gtr:id><gtr:title>Identifying spatially overlapping local cortical networks with MEG.</gtr:title><gtr:parentPublicationTitle>Human brain mapping</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/10417aab9cd8ed1656c4afad86238d0e"><gtr:id>10417aab9cd8ed1656c4afad86238d0e</gtr:id><gtr:otherNames>Duncan KK</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1065-9471</gtr:issn><gtr:outcomeId>5460a9e77fb4b4.82987262</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F55663D7-1505-4D4D-BF1B-66CB85C757A8</gtr:id><gtr:title>A dorsal visual route necessary for global form perception: evidence from neuropsychological fMRI.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8f29a031806796594db4176e6c08cebd"><gtr:id>8f29a031806796594db4176e6c08cebd</gtr:id><gtr:otherNames>Lestou V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5460a9ea2ea9f4.85481219</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B88A7C7-6131-49C9-9A4B-79F7769F40AF</gtr:id><gtr:title>Behavior-constrained support vector machines for fMRI data analysis.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on neural networks</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2ef91a6d242b3418b3065118aa4f2f60"><gtr:id>2ef91a6d242b3418b3065118aa4f2f60</gtr:id><gtr:otherNames>Chen D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1045-9227</gtr:issn><gtr:outcomeId>5460a9e826afe6.63503040</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/E012604/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>