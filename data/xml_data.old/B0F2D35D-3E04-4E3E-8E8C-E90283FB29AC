<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Ophthalmology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8699CE23-FC30-45C6-A0ED-9F4159BFBB25"><gtr:id>8699CE23-FC30-45C6-A0ED-9F4159BFBB25</gtr:id><gtr:firstName>John</gtr:firstName><gtr:otherNames>Christopher</gtr:otherNames><gtr:surname>Dainty</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/655934E2-68DD-46DD-82AB-EAB98B663D9C"><gtr:id>655934E2-68DD-46DD-82AB-EAB98B663D9C</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:surname>Stockman</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM01858X%2F1"><gtr:id>B0F2D35D-3E04-4E3E-8E8C-E90283FB29AC</gtr:id><gtr:title>At and beyond the neural limits: visual psychophysics using an adaptive-optics visual stimulator</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M01858X/1</gtr:grantReference><gtr:abstractText>The optics of all of our eyes are to some degree imperfect, even those of individuals with &amp;quot;20/20 vision&amp;quot;. These imperfection produce small, often imperceptible, aberrations in the images that we see and limits both image quality and visual acuity.

New technology first developed for astronomy, called &amp;quot;adaptive optics&amp;quot; or AO for short, can correct those aberrations and produce nearly perfect, aberration-free images in the eye. Most AO relies on the use of a flexible mirror that can be deformed in a controlled away. The optical aberrations present in the eye are measured and the inverse of those distortions are applied to the mirror, thus correcting the image quality and overcoming the optical aberrations that usually limit image quality in the eye.

AO instruments can be used in two ways in visual science: either to look into the eye or to look out of it. Looking into the eye, instruments that image the retina at the back of the eye can be improved by AO to the extent that individual cells can be resolved. Looking out of the eye, the resolution of a visual image projected onto to retina can be increased by AO to beyond normal visual acuity, producing so called &amp;quot;super-vision&amp;quot;. The instrument that we will design and build will be a user-friendly AO visual stimulator with which we can do both of these things. The device will include a digital light projector-normally used to project images in cinemas-that will project super high resolution images directly onto the retina. The primary purpose of the instrument is to investigate the underlying properties of the eye and brain beyond the normal limits imposed by the optics of the eye. Experiments will be conducted to test how well observer are able to see by asking them to make judgments about what they can see. 

Once the device is constructed, we will embark on a series of standard measurements of human visual performance. Rather than trying to measure the response to complex visual scenes, we will measure an observer's sensitivity to simple spatial patterns made up of periodic patterns of light and dark. These simple &amp;quot;sinusoidal&amp;quot; patterns are the building blocks from which we can predict the responses to any complex stimuli. To fully characterise the vast space of possible visual scenes, the simple sinusoidal patterns will be systematically varied from coarse to fine. For each pattern, we will determine how much contrast the observer needs to just see the pattern. From these measurements, we derive the spatial contrast sensitivity function (or spatial CSF) that defines the visual performance of the human observer. The importance of the AO system is that we can use it to measure spatial CSFs without the measurements being limited by the optics of the eye. Moreover, we can make those measurements for chromatic stimuli, achromatic stimuli and stimuli detected by single classes of light-sensitive detectors. By using different stimuli, we can investigate different neural pathways in the visual system.

The AO stimulator will also allow us to investigate human vision beyond the usual neural limits of the system. Visual patterns produced by the AO stimulator that are too fine to be seen directly (and are therefore &amp;quot;invisible&amp;quot;) can be seen indirectly due to interactions between pairs of patterns or due to changes in apparent intensity when a pattern is turned on and off. Using these patterns we will be able to investigate the underlying properties of the neurons in the visual system. Again, we can make measurements using chromatic stimuli, achromatic stimuli and stimuli detected by single classes of light-sensitive detectors. The indirect detection of these &amp;quot;invisible&amp;quot; patterns allows us to probe the inner working of the pathways answer specific questions about how the retina works.</gtr:abstractText><gtr:technicalSummary>We propose to design and build a user-friendly, adaptive-optics (AO) visual stimulator with which to simultaneously image the retina at high resolution and to present high-resolution visual stimuli. The optical system will include a 3-channel projector capable of running at 120 Hz with a resolution of 1920 x 1080 pixels and with 12-bits of resolution per channel. This will allow us to generate images with high temporal and spatial resolution, high dynamic range and wide colour gamut over an extended intensity range. The components of the system and the technology are proven, so that its development has low technical risk.

Once constructed, we will carry out a series of fundamental measurements of human visual performance. We will determine the human spatial contrast sensitivity functions (CSFs) for detecting achromatic, chromatic, and L-, M- and S-cone-isolating stimuli in the absence of the limitations normally imposed by the optics of the eye. The use of an AO stimulator has significant advantages over the previous measurements obtained using laser interferometric gratings. Steady or drifting equiluminant, equichromatic or cone-isolating gratings or Gabor patches can be presented without the problems of combining spatially-unstable interferometric gratings. In addition, spatial and/or temporal noise can be added to the stimuli to better isolate different channels or processes Measurements will be made over a range of luminances to investigate the effects of adaptation on spatial processing.

As well as going beyond the optical limit, we will investigate retinal processing beyond the usual neural limit. By measuring the distortion products generated by perceptually unresolvable gratings or pairs of gratings, and by applying the linear-nonlinear-linear &amp;quot;sandwich&amp;quot; model, we can separately characterize the spatial filters before and after the site(s) of nonlinear distortion. Initially, gratings that isolate L-, M- or S-cone responses will be used.</gtr:technicalSummary><gtr:potentialImpactText>The primary goal of this research project is the elucidation of the fundamental spatial properties of the human visual system. Thus, the initial beneficiaries are likely to be other scientists studying the visual system. They will include visual psychophysicists, sensory physiologists, electrophysiologists and cognitive neuroscientists working on visual processing in the human and primate visual system. Other beneficiaries will include scientists and clinicians comparing normal and abnormal spatial vision. 

The spatial contrast sensitivity functions (CSFs) measured with and without adaptive optical (AO) correction will enable vision scientists to predict how well human observers can see other arbitrarily complex visual stimuli both with respect to the image entering the eye and with respect to the image on the retina. Knowing the limits to the performance of the visual system is vitally important, and will allow more precise modelling of visual and neural function. The spatial CSF data will be made available in publications and also on-line at our web resource at http://www.cvrl.org 

Clinical vision scientists, optometrists and ophthalmologists will also benefit. The publication of normative spatial CSF data will enable them to assess the extent of the clinical deficits in comparable measurements made in patients, thus aiding in the interpretation and understanding of the disease process and in the design of visual aids that will help patients to improve their quality of life. 

While we are using the device mainly to project high resolution images onto the retina, the device can also be used to take high resolution pictures of the retina. This is important not only for basic vision science, since we will able to visualize photoreceptors and link the photoreceptor array to our measurements, but it will be important in the longer term for clinical measurements and diagnosis. In combination, high resolution projection and imaging will allow stimuli targeted to specific areas of the retina that might be of interest or damaged. Early diagnosis of retinal disease is vital and can potentially greatly improve the quality of life of patients. Indeed, a future possibility, given the need and given additional clinical funding, is that we could replicate our instrument at Moorfields Eye Hospital.

The data will also help in the derivation of physiologically-relevant models of human vision as applied in the fields of artificial intelligence or robotics. Knowing the limits of the physiological system will help to define the sensory capabilities required of such systems.

The AO vision system we are building is flexible, so that it can be used for other purposes. For example, it can be used to simulate the visual efficacy of new designs of inter-ocular lenses (IOLs) before they are used in the eye. Other areas of research within spatial vision are all possibilities.

Given the wide range of interest in vision research across many disciplines it will be important that our results and models are widely disseminated. We will publish our work in open source journals and present the data at international conferences. As part of this project, we also propose to make our data available at the Colour and Vision Research Laboratory (CVRL) website run by the PI at http://www.cvrl.org This resource is well-known and widely used in colour research both by academics and in industry. We propose to develop this resource further to provide general information on vision.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2015-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>501463</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This web resource provides an annotated database of downloadable standard functions and data sets relevant to colour and vision research and to colour technology, as well as providing information about the research outputs of our group. Updated frequently.</gtr:description><gtr:id>6C7E59BC-056D-46D3-8760-1EF661425DEF</gtr:id><gtr:impact>Widely used in science and industry, the site started at UC San Diego in 1995 and moved to UCL with the PI in 2001.</gtr:impact><gtr:outcomeId>546148de469b05.25093708</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CVRL database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.cvrl.org</gtr:url><gtr:yearFirstProvided>2006</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>92BF0564-B410-4A6E-975D-0B4061EFE2EC</gtr:id><gtr:title>Hue shifts produced by temporal asymmetries in chromatic signals.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5aa1600ad87f44.47673858</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEE768EB-8BE7-4BAA-856F-B6A6CFD69068</gtr:id><gtr:title>Hue shifts produced by temporal asymmetries in chromatic signals depend on the alignment of the first and second harmonics.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5a35115e938c44.96907483</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DC0786BB-2B1E-4221-84DD-0BB9D54FF66B</gtr:id><gtr:title>Delayed cone-opponent signals in the luminance pathway.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5aa1604661eb15.76170883</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0D89AADC-A559-4279-BADA-2D2D1B216929</gtr:id><gtr:title>Linear-nonlinear models of the red-green chromatic pathway.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5aa15fb7b229e8.53282213</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M01858X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>