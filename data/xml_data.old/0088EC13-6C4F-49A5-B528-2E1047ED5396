<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Gatsby Computational Neuroscience Unit</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F11E21C9-E05F-4173-939C-61F868FE1FBA"><gtr:id>F11E21C9-E05F-4173-939C-61F868FE1FBA</gtr:id><gtr:name>The Wellcome Trust Ltd</gtr:name><gtr:address><gtr:line1>215 Euston Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>NW1 2BE</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:line4>Swindon</gtr:line4><gtr:line5>Wiltshire</gtr:line5><gtr:postCode>SN2 1ET</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/0582CA61-7A23-42B3-B744-86F5BF8F9841"><gtr:id>0582CA61-7A23-42B3-B744-86F5BF8F9841</gtr:id><gtr:firstName>Li</gtr:firstName><gtr:surname>Zhaoping</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/C303B1C4-4482-4A89-914A-861E447FD1E3"><gtr:id>C303B1C4-4482-4A89-914A-861E447FD1E3</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:surname>Dayan</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FE002536%2F1"><gtr:id>0088EC13-6C4F-49A5-B528-2E1047ED5396</gtr:id><gtr:title>Contextual Influences on Orientation Perception</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/E002536/1</gtr:grantReference><gtr:abstractText>Forty years of neuroscience have cemented the notion that vision depends on a population of brain cells whose individual responses depend both on the contrast and the spatial orientation of visual stimuli. Consequently, our ability to discriminate between different contrasts should be related to our ability to discriminate between different orientations. However, it is only recently that biologically inspired models have had any success in explaining both of these abilities. Naturally, these early successes have focused on simple targets, like line segments, which are thought to optimally stimulate individual neurons. To parallel neuroscience's progress understanding brain connectivity, we propose to extend (or refine) contemporary models in order to explain how our perception of simple targets depends on visual context.</gtr:abstractText><gtr:technicalSummary>We propose to investigate contextual influences on visual perception, using orientation as a key example. Orientation perception has a long and distinguished experimental history, but most previous investigations of visual context have used either a psychophysical or a computational perspective. Support from the Foresight Project will help forge a link between these two disciplines. When an oriented line segment appears in an array of other oriented line segments, three well-known phenomena typically occur. One is the tilt illusion; an exaggeration of the difference between the orientations of adjacent line segments. The second is acuity loss; it becomes more difficult to identify the orientation of any individual line segment. The third is facilitation; a low-contrast target becomes easier to see when aligned with high-contrast flanks. (NB: Certain viewing conditions produce the opposite effects.) Various mathematical and computational models have been suggested to account for each of these contextual effects, but no model has yet to account for all of them. The initial focus of our research will be to collect experimental results against which the predictions of these models can be tested. Existing models can then be refined or replaced in the light of our results.</gtr:technicalSummary><gtr:fund><gtr:end>2011-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2007-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>402264</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>They have been used by the scientific community.</gtr:description><gtr:firstYearOfImpact>2011</gtr:firstYearOfImpact><gtr:id>E51C863D-16FA-4DBB-AB59-23B4F2C717E0</gtr:id><gtr:impactTypes><gtr:impactType>Cultural</gtr:impactType></gtr:impactTypes><gtr:outcomeId>546b7274c392f9.09953017</gtr:outcomeId><gtr:sector>Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The key experimental questions concern the effects of context on bias and acuity in orientation estimation as a function of
physical and perceived tilt, the structure and relative contrast of the context, and the retinal position of the whole array.
We will assess these issues and design the stimuli in the light of the models. These results will illuminate, and be
illuminated by, analysis of the relationships amongst the two classes of model that can currently explain some, but not all,
aspects of the existing results.
(Objective 1): To what extent is context-induced acuity loss due to the oblique effect? Using a surrounding context, we will
psychophysically map how acuity varies with target and surround tilts, and describe any departure from the baseline
oblique effect (obtained without a surround).
(Objective 2): How do bias and acuity vary as a function of flank phase, orientation and position relative to the target? For
these psychophysical experiments we will use localized flanks in addition to annular surrounds. Previous psychophysical
work has systematically varied both position and orientation at spatial scales commensurate with individual receptive
fields in V1. By systematically varying the size of our stimuli we will be able to identify those fundamental contextual
effects that are more-or-less independent of spatial scale.
(Objective 3): How do the fovea and the periphery differ in terms of bias and acuity, and is there any interaction between
stimulus configuration and retinal position? We will use stimuli at various spatial scales and separations in order to
overcome the effects of finer foveal sampling. From a modeling perspective, this experiment will provide critical
information as to how orientation processing is translation variant, which is important for both classes of models.
(Objective 4): How do bias and acuity vary as a function of the contrast of target and surrounding context? The V1 model
incorporates the known dynamical balance between excitatory and inhibitory contextual influences, favouring the latter for
high contrast targets and the former for low contrast ones. The Bayesian model suggests that there is greater uncertainty
associated with low contrast targets, and therefore a greater effect of the surround. By parametrically varying the
contrasts of the surround and the target, we will gather critical information on the interaction.
(Objective 5): How are detection and contrast discrimination affected by the contexts that change acuity and bias?
Sensitivity to contrast and acuity for orientation are likely limited at the same, early stage of visual processing, where
visual stimuli evoke a profile of activity across a population of oriented filters. Measurements of detection and contrast
discrimination made using the same stimuli described in objective 2 promise to provide tight constraints for any unified
model of sensitivity and orientation perception.
(Objective 6): As is apparent, the models are inter-related in a complex set of ways. Using the rich data collected
throughout the project, we will study these relations, to understand lateral excitation and inhibition as an extreme, and
geometrically reduced, abstraction of the dynamical model of V1, and how or whether the Bayesian model can be seen as
a computational-level description of both. Forging a theoretically tight link will allow apparently disparate insights and
evidence about each to be applied to the other. It will also highlight differences susceptible to experimental test.

Objective 1: Met. See Solomon &amp;amp; Morgan (2009).
Objective 2: Partly met by another lab! Levi and Carney (Current Biology 2009) parametrically
manipulated flanker size and position, and reported their effects on acuity.
Objective 3: Met. See Mareschal, Morgan, &amp;amp; Solomon (2010).
Objective 4: Met. See Solomon &amp;amp; Morgan (2006).
Objective 5: Met. Initially covered in See Solomon &amp;amp; Morgan (2006), but re-considered in
Solomon &amp;amp; Mareschal (in press).
Objective 6: Pretty vague objective, but certainly met by Dayan &amp;amp; Solomon (2010) and Schwartz,
Hsu, &amp;amp; Dayan (2007).</gtr:description><gtr:exploitationPathways>Forty years of neuroscience have cemented the notion that vision depends on a population of brain cells whose individual
responses depend both on the contrast and the spatial orientation of visual stimuli. Consequently, our ability to
discriminate between different contrasts should be related to our ability to discriminate between different orientations.
However, it is only recently that biologically inspired models have had any success in explaining both of these abilities.
Naturally, these early successes have focused on simple targets, like line segments, which are thought to optimally
stimulate individual neurons. To parallel neuroscience's progress understanding brain connectivity, we have extended
and refined contemporary models in order to explain how our perception of simple targets depends on visual context.</gtr:exploitationPathways><gtr:id>E5685FE3-370B-4FD7-9EC6-5652F75A1F89</gtr:id><gtr:outcomeId>546b72125bdcb4.09773317</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Other</gtr:sector></gtr:sectors><gtr:url>http://www.staff.city.ac.uk/~solomon/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>78710A73-8C8B-49F1-9A37-FEC00206ADC6</gtr:id><gtr:title>Strong tilt illusions always reduce orientation acuity.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f009d618</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3F6A20A9-7405-4C96-80C0-A765B96F0ED8</gtr:id><gtr:title>The relationship between search efficiency and crowding.</gtr:title><gtr:parentPublicationTitle>Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76ff838d2a89237b34204576e11c4d3f"><gtr:id>76ff838d2a89237b34204576e11c4d3f</gtr:id><gtr:otherNames>Gheri C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0301-0066</gtr:issn><gtr:outcomeId>doi_53d0390395d724cf</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8907BBB8-7AC6-4FF7-B7E8-98E971F6B3BC</gtr:id><gtr:title>Selective Bayes: attentional load and crowding.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a174694b0cf823ef0ef302f0ed72485"><gtr:id>6a174694b0cf823ef0ef302f0ed72485</gtr:id><gtr:otherNames>Dayan P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f050d5ba</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>25ED88F1-98A9-4E76-BDA5-39E3C1767831</gtr:id><gtr:title>Filling-in and suppression of visual perception from context: a Bayesian account of perceptual biases by contextual influences.</gtr:title><gtr:parentPublicationTitle>PLoS computational biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/12d9134631b8100805de7aa978072ef6"><gtr:id>12d9134631b8100805de7aa978072ef6</gtr:id><gtr:otherNames>Zhaoping L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1553-734X</gtr:issn><gtr:outcomeId>pm_5435aaf5aaf7a8a7b</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>79E58842-9BF3-4324-B577-F7EB358FA7F6</gtr:id><gtr:title>The role of background statistics in face adaptation.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3eae989d7fe2595c2c6dea57f94ec9e5"><gtr:id>3eae989d7fe2595c2c6dea57f94ec9e5</gtr:id><gtr:otherNames>Wu J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>pm_5435aaf5aaf9904b3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>90C1A146-9EF5-4424-AECE-72EDAA77A477</gtr:id><gtr:title>A clash of bottom-up and top-down processes in visual search: the reversed letter effect revisited.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/12d9134631b8100805de7aa978072ef6"><gtr:id>12d9134631b8100805de7aa978072ef6</gtr:id><gtr:otherNames>Zhaoping L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>doi_53d024024db757f5</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8BB99147-57F3-4342-84CB-01AE2BC0B7AD</gtr:id><gtr:title>Cortical distance determines whether flankers cause crowding or the tilt illusion.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/401c0ce7d6aa382702eecf8a236112d0"><gtr:id>401c0ce7d6aa382702eecf8a236112d0</gtr:id><gtr:otherNames>Mareschal I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770773b8ade7</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>77DEB665-3AB1-40E6-973D-D890D54FB6ED</gtr:id><gtr:title>After-search--visual search by gaze shifts after input image vanishes.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/12d9134631b8100805de7aa978072ef6"><gtr:id>12d9134631b8100805de7aa978072ef6</gtr:id><gtr:otherNames>Zhaoping L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d077077578db81</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEE30C3B-F0A5-480B-B2D3-A908B83F2964</gtr:id><gtr:title>Adaptation across the cortical hierarchy: low-level curve adaptation affects high-level facial-expression judgments.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/278fcc443baec484a682f08515697559"><gtr:id>278fcc443baec484a682f08515697559</gtr:id><gtr:otherNames>Xu H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>doi_53d0820827cb75f7</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D7477452-9890-4B03-85B8-D40CBDB8C17C</gtr:id><gtr:title>Stochastic re-calibration: contextual effects on perceived tilt.</gtr:title><gtr:parentPublicationTitle>Proceedings. Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0962-8452</gtr:issn><gtr:outcomeId>doi_53d049049b9470c6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>232F0D7F-05F7-4307-893A-3A9D1468048B</gtr:id><gtr:title>Perceptual organization in the tilt illusion.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a7d6708320a126484db71f213258ec7"><gtr:id>6a7d6708320a126484db71f213258ec7</gtr:id><gtr:otherNames>Schwartz O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d077077634dc77</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>12ACA36D-D69E-4879-874B-3D3662830D6C</gtr:id><gtr:title>Contextual effects on decision templates for parafoveal orientation identification.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/401c0ce7d6aa382702eecf8a236112d0"><gtr:id>401c0ce7d6aa382702eecf8a236112d0</gtr:id><gtr:otherNames>Mareschal I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00e00efce604d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4A5585CE-809A-4D5D-B96E-A295C8CEF56A</gtr:id><gtr:title>Attention capture by eye of origin singletons even without awareness--a hallmark of a bottom-up saliency map in the primary visual cortex.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/12d9134631b8100805de7aa978072ef6"><gtr:id>12d9134631b8100805de7aa978072ef6</gtr:id><gtr:otherNames>Zhaoping L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770775ac0dfd</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3D68E902-2F92-4EA5-BAAD-9D54F536DCBB</gtr:id><gtr:title>Relative contributions of 2D and 3D cues in a texture segmentation task, implications for the roles of striate and extrastriate cortex in attentional selection.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/12d9134631b8100805de7aa978072ef6"><gtr:id>12d9134631b8100805de7aa978072ef6</gtr:id><gtr:otherNames>Zhaoping L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>pm_5435aaf5aaf843081</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A0A288F1-4C7F-40EF-85F8-EF5C55A0C8FE</gtr:id><gtr:title>Contrast discrimination: second responses reveal the relationship between the mean and variance of visual signals.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>pm_5435aaf5aaf6eb07b</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>82AFE902-5147-4E21-AE6D-5B2F459D2182</gtr:id><gtr:title>Exploring the roles of saturating and supersaturating contrast-response functions in conjunction detection and contrast coding.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_55f94a94a793b475</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0E0FEBFD-AA75-4CDB-9C81-7E90A2A119E5</gtr:id><gtr:title>The history of dipper functions.</gtr:title><gtr:parentPublicationTitle>Attention, perception &amp; psychophysics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1943-3921</gtr:issn><gtr:outcomeId>doi_53d088088251aa60</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/E002536/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>