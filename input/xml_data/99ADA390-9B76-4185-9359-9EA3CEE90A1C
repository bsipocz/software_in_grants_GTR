<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/ED9F729C-2075-4EBC-A0EB-7DED71AF17E1"><gtr:id>ED9F729C-2075-4EBC-A0EB-7DED71AF17E1</gtr:id><gtr:name>Identity Solutions Ltd</gtr:name><gtr:address><gtr:line1>Robert Denholme House</gtr:line1><gtr:line2>Bletchingley Road</gtr:line2><gtr:line4>Redhill</gtr:line4><gtr:postCode>RH1 4NW</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/9D12884B-3F95-49B0-8E1E-02200AC126C3"><gtr:id>9D12884B-3F95-49B0-8E1E-02200AC126C3</gtr:id><gtr:name>Home Office</gtr:name><gtr:address><gtr:line1>Policing &amp; Crime Reduction Group</gtr:line1><gtr:line2>Police Standards Unit, 5th Floor</gtr:line2><gtr:line3>50 Queen Annes Gate</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SW1H 9AT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/B3BCF875-030A-4852-8E8F-5F8914C1A7FD"><gtr:id>B3BCF875-030A-4852-8E8F-5F8914C1A7FD</gtr:id><gtr:name>General Dynamics</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2A80FFDA-3B8B-43BA-80C3-3AA850B49BA1"><gtr:id>2A80FFDA-3B8B-43BA-80C3-3AA850B49BA1</gtr:id><gtr:name>University of the West of England</gtr:name><gtr:department>Faculty of Environment and Technology</gtr:department><gtr:address><gtr:line1>Coldharbour Lane</gtr:line1><gtr:line2>Frenchay</gtr:line2><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS16 1QY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2A80FFDA-3B8B-43BA-80C3-3AA850B49BA1"><gtr:id>2A80FFDA-3B8B-43BA-80C3-3AA850B49BA1</gtr:id><gtr:name>University of the West of England</gtr:name><gtr:address><gtr:line1>Coldharbour Lane</gtr:line1><gtr:line2>Frenchay</gtr:line2><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS16 1QY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/ED9F729C-2075-4EBC-A0EB-7DED71AF17E1"><gtr:id>ED9F729C-2075-4EBC-A0EB-7DED71AF17E1</gtr:id><gtr:name>Identity Solutions Ltd</gtr:name><gtr:address><gtr:line1>Robert Denholme House</gtr:line1><gtr:line2>Bletchingley Road</gtr:line2><gtr:line4>Redhill</gtr:line4><gtr:postCode>RH1 4NW</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9D12884B-3F95-49B0-8E1E-02200AC126C3"><gtr:id>9D12884B-3F95-49B0-8E1E-02200AC126C3</gtr:id><gtr:name>Home Office</gtr:name><gtr:address><gtr:line1>Policing &amp; Crime Reduction Group</gtr:line1><gtr:line2>Police Standards Unit, 5th Floor</gtr:line2><gtr:line3>50 Queen Annes Gate</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SW1H 9AT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B3BCF875-030A-4852-8E8F-5F8914C1A7FD"><gtr:id>B3BCF875-030A-4852-8E8F-5F8914C1A7FD</gtr:id><gtr:name>General Dynamics</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A6B38CC8-A92D-41D6-8DC4-7ABEACF48E6B"><gtr:id>A6B38CC8-A92D-41D6-8DC4-7ABEACF48E6B</gtr:id><gtr:name>General Dynamics UK Ltd</gtr:name><gtr:address><gtr:line1>Bryn Brithdir</gtr:line1><gtr:line2>Oakdale Business Park</gtr:line2><gtr:postCode>NP12 4AA</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2BA3C484-FA19-4E5D-BBB7-2FCFAD740307"><gtr:id>2BA3C484-FA19-4E5D-BBB7-2FCFAD740307</gtr:id><gtr:name>The Home Office</gtr:name><gtr:address><gtr:line1>3rd floor, Seacole Bldg</gtr:line1><gtr:line2>2 Marsham Street</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW1P 4DF</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/AC8F9318-33D3-4E3D-BF7D-8D6049847F4D"><gtr:id>AC8F9318-33D3-4E3D-BF7D-8D6049847F4D</gtr:id><gtr:firstName>Lyndon</gtr:firstName><gtr:otherNames>Neal</gtr:otherNames><gtr:surname>Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/ED82DD59-59D7-4BB0-98E3-3F0855524F98"><gtr:id>ED82DD59-59D7-4BB0-98E3-3F0855524F98</gtr:id><gtr:firstName>Melvyn</gtr:firstName><gtr:surname>Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE028659%2F1"><gtr:id>99ADA390-9B76-4185-9359-9EA3CEE90A1C</gtr:id><gtr:title>Face Recognition using Photometric Stereo</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E028659/1</gtr:grantReference><gtr:abstractText>We propose to construct a system for 3D face recognition. We propose to use photometric stereo for face reconstruction in order to by pass the problems of conventional stereo (that needs to solve the matching problem first), structured light (that does not supply colour information) and photometric stereo with spectrally distinct light sources (that relies on the assumption of uniformly coloured imaged objects). Photometric stereo (PS) can reproduce structural details and colour on a per pixel basis in a way that no other 3D system can. The proposed scheme will be appropriate for use in a controlled environment for authentication purposes, but also in a general environment e.g. the entrance of a public event. We shall use two routes: surface reconstruction from the data and direct extraction of facial characteristics from the PS set. In the first approach, once surface normal and albedo is recovered, images of the face may be synthetically rendered under arbitrary new pose and illumination conditions to allow novel viewing conditions. We also aim to use a new multi-scale facial feature matching approach in the recognition process, where facial features range from overall face and head shape to fine skin dermal topography, reflectance and texture. The latter may be thought of as a form of detailed surface bump map forming a unique skin-print or signature and represents a new approach. Hence both the 3D shape and 2D intensity data will be used in recognition or authentication tasks. We propose to use scalable methods for matching, so we can cope with large databases. 3D matching will be done with the newly proposed invaders algorithm which is FFT cross-correlation based, and more detailed matching will be done by using features and classifier combination. The novelty of our approach lies in the use of PS to extract 3D information, the use of detailed facial characteristics like moles, scratches, and skin texture, and in the design of the system so that it can operate while the person is moving, with minimum intrusion and maximum efficiency. We have two industrial collaborators who will contribute in system design, data gathering and exploitation and support from the Home Office. We shall evaluate our system following three possible scenaria: a face searched in the crowd (real time face recognition), a person has to be identified (off-line face recognition) and a person has to be checked against a claimed identity (face authentication). We shall install the first prototype system in the offices of one of our industrial partners in month 12, so that data can be collected. We envisage a door like structure with lights flashing in succession as a person walks through, while a camera is capturing images. We propose to investigate the optimal number of lights in terms of efficiency and accuracy of the reconstruction, and the option of using non-visible light to avoid problems with people sensitive to flashes. We shall also investigate the relationship between detail that has to be captured and the geometry of the construction.</gtr:abstractText><gtr:fund><gtr:end>2010-05-28</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-05-29</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>257046</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>General Dynamics</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>General Dynamics UK Ltd (Wales)</gtr:description><gtr:id>FAF616EB-1972-4F67-B668-5E2CC8B148F6</gtr:id><gtr:outcomeId>b9c9f3d8b9c9f3ec-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2007-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Home Office</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Home Office Scientific Development Branch</gtr:department><gtr:description>Home Office Science</gtr:description><gtr:id>F2C12410-CA91-471C-98CC-52AF6A9EF62E</gtr:id><gtr:outcomeId>b9c8d5f2b9c8d610-1</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2007-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Identity Solutions Ltd</gtr:collaboratingOrganisation><gtr:country>New Zealand</gtr:country><gtr:description>Identity Solutions Ltd</gtr:description><gtr:id>58FD8C60-9A24-4B1F-BFED-8E07428117A7</gtr:id><gtr:outcomeId>b9c9ebfeb9c9ec1c-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2007-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Several broadcast items on Photoface and related follow-on work</gtr:description><gtr:form>A broadcast e.g. TV/radio/film/podcast (other than news/press)</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C135206D-CACA-4E15-9A2B-810D3517D1B6</gtr:id><gtr:impact>A program item was produced with Discovery Channel for their flagship program Daily Planet and for a BBC World Service program called ''4tech''. A related item also appeared in New Scientist (http://bit.ly/hhteeF), 2011 and on BBC's 'Bang goes the Theory' and a Channel 4 documentary entitled 'End of the World Night' in 2015. Also interviewed for BBC Radio Bristol, BBC Radio 2's Symon Mayo Show, Heart Radio, Three Counties Radio, BBC World Service about Photoface project. Items also appeared on BBC Points West, ITV West Tonight News, and BBC's The Bubble, March 2010. The discovery Item led to contact with Aralia Systems Ltd and several successful follow-on projects in closely related areas.</gtr:impact><gtr:outcomeId>56cb40edd275f2.77275029</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.youtube.com/watch?v=L5NPGbJnte4&amp;feature=youtu.be</gtr:url><gtr:year>2011,2012,2013,2014,2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>30000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Shape and outline amplification using 2.5D and 3D imaging.</gtr:description><gtr:end>2013-04-02</gtr:end><gtr:fundingOrg>Ministry of Defence (MOD)</gtr:fundingOrg><gtr:fundingRef>CDE29353</gtr:fundingRef><gtr:id>066DA6F9-E7B3-40B3-AFAD-3139F1B07E57</gtr:id><gtr:outcomeId>56cb34e43a3076.55072568</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>25610</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Sustainable Agriculture Innovation Call May 2016</gtr:description><gtr:end>2018-09-02</gtr:end><gtr:fundingOrg>Natural Environment Research Council</gtr:fundingOrg><gtr:fundingRef>NE/P007945/1</gtr:fundingRef><gtr:id>77AA552E-CCE7-4FE0-AD08-E80F2FBA2487</gtr:id><gtr:outcomeId>58be8b629cfd52.30039861</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2016-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>168205</gtr:amountPounds><gtr:country>Unknown</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Knowledge Transfer Partnership</gtr:description><gtr:end>2019-05-02</gtr:end><gtr:fundingOrg>Innova UK</gtr:fundingOrg><gtr:fundingRef>KTP010680</gtr:fundingRef><gtr:id>F05705AD-A6A6-468D-B1A9-2CD3F1BC1B4A</gtr:id><gtr:outcomeId>58be840a1eef72.88021485</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2017-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>143904</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Future Railway</gtr:description><gtr:end>2017-04-02</gtr:end><gtr:fundingOrg>Rail Safety and Standards Board</gtr:fundingOrg><gtr:id>FD0939D6-F8D4-4FBE-AA18-C85532A9CA63</gtr:id><gtr:outcomeId>58be892ae5c121.35412308</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2016-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>215081</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Knowledge Transfer Partnership</gtr:description><gtr:end>2013-01-02</gtr:end><gtr:fundingOrg>Knowledge Transfer Partnerships</gtr:fundingOrg><gtr:fundingRef>ktp008278</gtr:fundingRef><gtr:id>A67DCDB8-15C7-4AAF-8DAA-90EBD9AA7C55</gtr:id><gtr:outcomeId>56cb1f571c6747.17394025</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>150000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Seeing More</gtr:description><gtr:end>2015-09-02</gtr:end><gtr:fundingOrg>TSB</gtr:fundingOrg><gtr:fundingRef>131749</gtr:fundingRef><gtr:id>48A76129-71AD-450D-BA49-8120818F3268</gtr:id><gtr:outcomeId>56cb26a4a210c0.12813137</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2014-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>56000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Intelligent Advertising Proof of Concept</gtr:description><gtr:end>2014-05-02</gtr:end><gtr:fundingOrg>Technology Strategy Board (TSB)</gtr:fundingOrg><gtr:fundingRef>710243</gtr:fundingRef><gtr:id>E31F3F7D-1885-4122-8662-EC1AA8F9339C</gtr:id><gtr:outcomeId>56cb338a870507.56372422</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2012-11-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>145000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Future Ticket Detection (Gateless Gate-lines)</gtr:description><gtr:end>2017-03-02</gtr:end><gtr:fundingOrg>Rail Safety and Standards Board</gtr:fundingOrg><gtr:id>45FFF0A0-E06F-4207-B828-F93A46C27471</gtr:id><gtr:outcomeId>56cb31b1c6ba92.53700680</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2016-04-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>A demonstrator 3D face recognition system was developed. The system uses a photometric stereo technique.</gtr:description><gtr:exploitationPathways>We are currently discussing commercial application with Aralia Systems Ltd</gtr:exploitationPathways><gtr:id>D16AB0D6-CC69-438D-94E0-00ED646246A1</gtr:id><gtr:outcomeId>56cc66c9e5a901.01763652</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Security and Diplomacy,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.youtube.com/watch?v=L5NPGbJnte4&amp;feature=youtu.be</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This unique 3D face database is amongst the largest currently available, containing 3187 sessions of 453 subjects, captured in two recording periods of approximately six months each. Our Photoface device was located in an unsupervised corridor allowing real-world and unconstrained capture. Each session comprises four differently lit colour photographs of the subject, from which surface normal and albedo estimations can be calculated (photometric stereo MATLAB code implementation included). This allows for many testing scenarios and data fusion modalities.
Eleven facial landmarks have been manually located on each session for alignment purposes.
Additionally, the Photoface Query Tool is supplied (implemented in MATLAB), which allows for subsets of the database to be extracted according to selected metadata e.g. gender, facial hair, pose, expression. The Photoface database is available to download for research purposes</gtr:description><gtr:id>92C0B40C-44CF-43D7-8DEF-E03013106847</gtr:id><gtr:impact>The Photoface database has been accessed worldwide by 12 institutes (as of Sept 2013)
We've had 44 downloads from 19 countries for face database. (Feb 2016)</gtr:impact><gtr:outcomeId>546a2d7649f982.87974380</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Photoface Database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www1.uwe.ac.uk/et/mvl/projects/facerecognition.aspx</gtr:url><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>A general purpose portable, high speed, high resolution photometric stereo (PS) device. The device is intended as a general purpose experimental tool. The initial application will be to investigate contactless extraction of biometrics from hands such as palm prints, fingerprints, and vascular structures.</gtr:description><gtr:id>88E7DFCB-D42E-4B87-8318-0E7DE7CD66CB</gtr:id><gtr:impact>Nothing yet.</gtr:impact><gtr:outcomeId>56cc5899c0ee73.60919730</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Contactless 3D Hand Recognition from Photometric Stereo</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type></gtr:researchMaterialOutput><gtr:researchMaterialOutput><gtr:description>A second system, evolved from the Photoface system, was developed as a research tool in high spatial resolution moving 3D face imaging and analysis. The availability of this technology formed the bases of a pilot study collaboration with Prof Marcus Munaf&amp;ograve;, Professor of Biological Psychology in the School of Experimental Psychology at Bristol University into the dynamics of changing facial expressions in depressed subjects. The system was loaned to Prof Munaf&amp;ograve;'s team as part of a collaborative pilot study. The system also supported an internally funded PhD bursary (Laurence Broadbent) in automated expression recognition using moving facial dynamics.</gtr:description><gtr:id>EA945BFC-072C-4315-9542-BD11B9D80F20</gtr:id><gtr:impact>Successful PhD project</gtr:impact><gtr:outcomeId>56cc3788018a24.65483085</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Very high resolution moving 3D face data capture system</gtr:title><gtr:type>Model of mechanisms or symptoms - human</gtr:type><gtr:url>http://www.newscientist.com/blogs/nstv/2011/03/4d-system-recreates-your-face.html</gtr:url><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>8265BE39-371C-4999-A24B-9D4BF413A747</gtr:id><gtr:title>3D face recognition using photometric stereo</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eba62395debbe294f9944ca54e75bcc4"><gtr:id>eba62395debbe294f9944ca54e75bcc4</gtr:id><gtr:otherNames>Hansen Mark F.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>58be7fc3204da4.07603828</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7575EC0D-81C0-4793-945C-F3EE3052C96D</gtr:id><gtr:title>A robust multi-scale integration method to obtain the depth from gradient maps</gtr:title><gtr:parentPublicationTitle>Computer Vision and Image Understanding</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1924a4619a61cb36e5681f8cfa5de5ad"><gtr:id>1924a4619a61cb36e5681f8cfa5de5ad</gtr:id><gtr:otherNames>Saracchini R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_55fa9ea9eeea7a2e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6C8BEE9D-232F-485B-9E4F-A6B0E8DDA277</gtr:id><gtr:title>Sampling Light Field for Photometric Stereo</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Theory and Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3fbee13de0f083ea68ae008d704b0ddd"><gtr:id>3fbee13de0f083ea68ae008d704b0ddd</gtr:id><gtr:otherNames>Sun J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>56cb13ba6c0560.52867725</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>02E0CC57-44E3-409A-AB4F-18177972C1C1</gtr:id><gtr:title>Realistic and interactive high-resolution 4D environments for real-time surgeon and patient interaction.</gtr:title><gtr:parentPublicationTitle>The international journal of medical robotics + computer assisted surgery : MRCAS</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/053d30b77aeaa018103744e309f3265c"><gtr:id>053d30b77aeaa018103744e309f3265c</gtr:id><gtr:otherNames>Smith LN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1478-5951</gtr:issn><gtr:outcomeId>58be6ed7d645f1.96704848</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>577425E2-3E8A-4082-B4F2-32072F33C750</gtr:id><gtr:title>The Photoface database</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-0529-8</gtr:isbn><gtr:outcomeId>58be7d664efd54.91018995</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7658686B-3DE0-44C5-AB15-06F04A90C02A</gtr:id><gtr:title>Robust 3D face capture using example-based photometric stereo</gtr:title><gtr:parentPublicationTitle>Computers in Industry</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1924a4619a61cb36e5681f8cfa5de5ad"><gtr:id>1924a4619a61cb36e5681f8cfa5de5ad</gtr:id><gtr:otherNames>Saracchini R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>58be6fb0b0d7b8.00035272</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E5D25334-6D14-4CEC-B8F1-F2671B65FE3A</gtr:id><gtr:title>The nose on your face may not be so plain: using the nose as a biometric</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2453a9209527299d8b2a44b70ea653ca"><gtr:id>2453a9209527299d8b2a44b70ea653ca</gtr:id><gtr:otherNames>Moorhouse A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978 1 84919 207 1</gtr:isbn><gtr:outcomeId>doi_53d0310315e67bb1</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>495994F1-F8BD-4C4C-A806-C76366F19B7D</gtr:id><gtr:title>Twins 3D face recognition challenge</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aa18dc9ad4f5c289619c07a5c4fe3d25"><gtr:id>aa18dc9ad4f5c289619c07a5c4fe3d25</gtr:id><gtr:otherNames>Vijayan V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-1358-3</gtr:isbn><gtr:outcomeId>58be7e276dc813.77230017</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>79D115CC-042A-4B33-83B6-298AF67916DE</gtr:id><gtr:title>Psychologically inspired dimensionality reduction for 2D and 3D Face Recognition</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef3b7a2145e7e5fa5b217b4e5375d92b"><gtr:id>ef3b7a2145e7e5fa5b217b4e5375d92b</gtr:id><gtr:otherNames>Hansen M F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>58c17ee119cb04.23846353</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B15F0D09-548C-4920-A4D3-196D0E1799CA</gtr:id><gtr:title>Nonnegative tensor factorization as an alternative Csiszar-Tusnady procedure: algorithms, convergence, probabilistic interpretations and novel probabilistic tensor latent variable analysis algorithms</gtr:title><gtr:parentPublicationTitle>Data Mining and Knowledge Discovery</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_55f95a95aea8c191</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1565F592-84BC-480E-92A5-2640B91ADF00</gtr:id><gtr:title>Real-time recovery of moving 3D faces for emerging applications</gtr:title><gtr:parentPublicationTitle>Computers in Industry</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25ee711d337be289e055d1e1c14c53ef"><gtr:id>25ee711d337be289e055d1e1c14c53ef</gtr:id><gtr:otherNames>Emrith K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>56cc37dcd234b2.11507950</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>966E4DE0-C66B-4D77-B808-E8D35F29F3CC</gtr:id><gtr:title>Multi-Scale Depth from Slope with Weights</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/36d154d8bf43372ae4ab36eb553b7ce6"><gtr:id>36d154d8bf43372ae4ab36eb553b7ce6</gtr:id><gtr:otherNames>n/a Saracchini</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_281784652613f37498</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3654137C-B23E-4722-BC33-1315151A0590</gtr:id><gtr:title>PTU-022&amp;acirc;? A Novel Photometric Stereo Imaging Sensor For Endoscopy Imaging: Proof Of Concept Studies On A Porcine Model</gtr:title><gtr:parentPublicationTitle>Gut</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/45817a047cd2ad3b38ff247ed4733f58"><gtr:id>45817a047cd2ad3b38ff247ed4733f58</gtr:id><gtr:otherNames>Poullis A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56cb1172221096.56669007</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3511BB0F-5869-4378-8FC6-6C27B89DBB00</gtr:id><gtr:title>BRDF of human skin in the visible spectrum</gtr:title><gtr:parentPublicationTitle>Sensor Review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f5cb9a29dbca049607c2d02d8fab7729"><gtr:id>f5cb9a29dbca049607c2d02d8fab7729</gtr:id><gtr:otherNames>Sohaib A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa7bf1cb63721.18105915</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>81CED06A-49E7-4D56-9184-C3047812D1CE</gtr:id><gtr:title>2.5D Elastic graph matching</gtr:title><gtr:parentPublicationTitle>Computer Vision and Image Understanding</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_55f95a95aeb374fe</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CC580A37-CBA8-4BD3-98B3-DF34A8937FB2</gtr:id><gtr:title>Face recognition in 2D and 2.5D using ridgelets and photometric stereo</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bbd1673045edd96815be571ae2f8c3b6"><gtr:id>bbd1673045edd96815be571ae2f8c3b6</gtr:id><gtr:otherNames>Kautkar S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>58c177585b3601.01713381</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EFAA28FA-3058-4305-9611-F49C9A57E5AE</gtr:id><gtr:title>A efficient and practical 3D face scanner using near infrared and visible photometric stereo</gtr:title><gtr:parentPublicationTitle>Procedia Computer Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cb16f71373308c205aedc24988c2ac66"><gtr:id>cb16f71373308c205aedc24988c2ac66</gtr:id><gtr:otherNames>Atkinson G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>58be82d1d5a402.64200209</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D1E31526-A237-40F0-BF01-91F67CEC5AC4</gtr:id><gtr:title>Using Photometric Stereo for Face Recognition</gtr:title><gtr:parentPublicationTitle>International Journal of Bio-Science and Bio-Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/36b355031565328b29e583c079d6f7cb"><gtr:id>36b355031565328b29e583c079d6f7cb</gtr:id><gtr:otherNames>Atkinson G A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>58c17a262be2b3.78917654</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5B5D1C6C-978A-4BCC-A8FA-5BBA0E43A22B</gtr:id><gtr:title>Eye center localization and gaze gesture recognition for human-computer interaction.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33b3a33f2507beb150e78e1e5a17353e"><gtr:id>33b3a33f2507beb150e78e1e5a17353e</gtr:id><gtr:otherNames>Zhang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>56cb12cbaf6c87.83946828</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C5F7C8A6-485B-4635-9B56-4A0CAFD72D3B</gtr:id><gtr:title>An improved photometric stereo through distance estimation and light vector optimization from diffused maxima region</gtr:title><gtr:parentPublicationTitle>Pattern Recognition Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/04941cb54772be3c323dc4c3d2c82eed"><gtr:id>04941cb54772be3c323dc4c3d2c82eed</gtr:id><gtr:otherNames>Ahmad J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>58be6f6f227979.70849984</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E79D1BD4-3A09-486D-93A8-B57F84ACF9CF</gtr:id><gtr:title>Nonlinear non-negative component analysis algorithms.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_55f951951272872f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3F61E1E0-C946-4175-B0CF-4B3A96D38701</gtr:id><gtr:title>Using nasal curves matching for expression robust 3D nose recognition</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d5c287fabbd962dbf21d5eb3a473ba3d"><gtr:id>d5c287fabbd962dbf21d5eb3a473ba3d</gtr:id><gtr:otherNames>Emambakhsh M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>58c17c69279288.39586044</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4389CB57-AA0C-4D56-AE77-7B67C6E10B30</gtr:id><gtr:title>3D reconstruction of concave surfaces using polarisation imaging</gtr:title><gtr:parentPublicationTitle>Journal of Modern Optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f5cb9a29dbca049607c2d02d8fab7729"><gtr:id>f5cb9a29dbca049607c2d02d8fab7729</gtr:id><gtr:otherNames>Sohaib A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58c17626df9403.17984965</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A6CC5F35-A9AB-424D-A6AC-D57C3F31106A</gtr:id><gtr:title>Multispectral Contactless 3D Handprint Acquisition for Identification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ef3b7a2145e7e5fa5b217b4e5375d92b"><gtr:id>ef3b7a2145e7e5fa5b217b4e5375d92b</gtr:id><gtr:otherNames>Hansen M F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c17b71307370.32767055</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5773363D-14AF-4EB8-ABF5-45C546337260</gtr:id><gtr:title>Baseline face recognition using photometric stereo data</gtr:title><gtr:parentPublicationTitle>Procedia Computer Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>58be8022d2b7d5.09109242</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>83D455F7-9D24-401E-9545-8F76C9AED74F</gtr:id><gtr:title>Gender recognition from facial images: two or three dimensions?</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33b3a33f2507beb150e78e1e5a17353e"><gtr:id>33b3a33f2507beb150e78e1e5a17353e</gtr:id><gtr:otherNames>Zhang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>56cb134b4d8df2.82435888</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>46D4A243-4AC4-4E84-B45A-01B47EB0B00A</gtr:id><gtr:title>3D face reconstructions from photometric stereo using near infrared and visible light</gtr:title><gtr:parentPublicationTitle>Computer Vision and Image Understanding</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0f4893d7db830e2454765960bdcd4e93"><gtr:id>0f4893d7db830e2454765960bdcd4e93</gtr:id><gtr:otherNames>Hansen M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53cfecfec468fa16</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>29CF2B6D-B107-4A6F-9974-5630357D815A</gtr:id><gtr:title>Using GPU Acceleration for Real-time Detection of Facial Micro-movements</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25ee711d337be289e055d1e1c14c53ef"><gtr:id>25ee711d337be289e055d1e1c14c53ef</gtr:id><gtr:otherNames>Emrith K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>58c17fc95e4060.40099506</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F3FBE99A-CB9B-495D-97B6-ADE1CE469C35</gtr:id><gtr:title>A sparse representation method for determining the optimal illumination directions in Photometric Stereo</gtr:title><gtr:parentPublicationTitle>Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9e2f72525b77b50fba8edac03560a4d0"><gtr:id>9e2f72525b77b50fba8edac03560a4d0</gtr:id><gtr:otherNames>Argyriou V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_55f95a95aebca71e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3BB5FDC0-F488-42D0-A97A-A61EF678FBBE</gtr:id><gtr:title>Gender and gaze gesture recognition for human-computer interaction</gtr:title><gtr:parentPublicationTitle>Computer Vision and Image Understanding</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33b3a33f2507beb150e78e1e5a17353e"><gtr:id>33b3a33f2507beb150e78e1e5a17353e</gtr:id><gtr:otherNames>Zhang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd975a466945.01528040</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3728CA77-3CD0-47E9-ACC1-A35293630B4C</gtr:id><gtr:title>Eye centre localisation: an unsupervised modular approach</gtr:title><gtr:parentPublicationTitle>Sensor Review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33b3a33f2507beb150e78e1e5a17353e"><gtr:id>33b3a33f2507beb150e78e1e5a17353e</gtr:id><gtr:otherNames>Zhang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd97b4a586d2.05432958</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3E34A2AA-369E-471F-A2C9-3C93989F8250</gtr:id><gtr:title>PTU-024&amp;nbsp;Photometric stereo reconstruction for surface analysis of mucosal tissue</gtr:title><gtr:parentPublicationTitle>Gut</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/45817a047cd2ad3b38ff247ed4733f58"><gtr:id>45817a047cd2ad3b38ff247ed4733f58</gtr:id><gtr:otherNames>Poullis A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cb0fc7219ad3.28722105</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A30F314A-9F72-480E-BE4E-A3E34152BE16</gtr:id><gtr:title>Face Recognition and Verification Using Photometric Stereo: The Photoface Database and a Comprehensive Evaluation</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Information Forensics and Security</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9a4fcf7065577f4f52875c6b49e4997"><gtr:id>a9a4fcf7065577f4f52875c6b49e4997</gtr:id><gtr:otherNames>Zafeiriou S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>58be7eb3737052.76994703</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E028659/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>