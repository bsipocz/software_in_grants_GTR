<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E43E4393-0A4D-4FE3-8F9A-B619B35D9B30"><gtr:id>E43E4393-0A4D-4FE3-8F9A-B619B35D9B30</gtr:id><gtr:firstName>Jinendra</gtr:firstName><gtr:surname>Ekanayake</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MC_EX_G0802357"><gtr:id>8BA5CD8D-B293-4F40-A407-7D3F2B453A4F</gtr:id><gtr:title>Control of Attention in the human brain studied with real-time fMRI</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>MC_EX_G0802357</gtr:grantReference><gtr:abstractText>We can selectively attend to particular locations or features in our environment even when our gaze is kept fixed, by moving our focus of attention. This is accompanied by changes in signals recorded from the visual brain, but whether and how they alter visual perception and processing is poorly understood. Here I will exploit a new development in functional brain imaging known as real-time functional MRI. Functional MRI allows non-invasive recording of neural processing in the human brain, but typically requires many hours of processing. With real-time fMRI I can now record and immediately feedback brain signals to the subject who is being scanned. I will use this to teach subjects to voluntarily control activity in particular regions of the visual brain. By doing this I can test whether such changes in activity in visual cortex also change perception and processing of visual information, establishing a causal relationship. Moreover, I will also investigate how such real-time decoding of attention might be used to provide information about where a subject wishes to look or act on the environment, through thought alone. Such signals could potentially be used to control a 'neural prosthesis' in patients paralysed as a result of neurological disease.</gtr:abstractText><gtr:technicalSummary>Introduction
Brain injury as a result of trauma or disease processes may result in the restriction or loss of an individual's capacity to move and to communicate. The consequent disability represents a significant burden on both the patient and the healthcare system. A number of therapeutic approaches have been adopted including attempts to reverse the primary and secondary disease processes. An exciting development has the been the emergence of invasive and non-invasive brain-machine interfaces which provide the alternative of circumventing the areas of injury by using brain signals from sensory or motor cortex to control neuroprosthetic devices. The concurrent use of functional imaging techniques in investigating the neural basis of such signals has direct biological relevance for understanding mechanisms of perception and action. 

Aims
I propose to use the new techniques of real-time functional MRI (rt-fMRI) and online neurofeedback to address two related questions:
1) Can attention be decoded in real time from human visual cortex to potentially provide control signals for a neural prosthesis?
2) Does the level of attentionally modulated activity in human visual cortex have a causal influence on perception and awareness?

Design/ Methods
rt-fMRI will be used to identify retinotopic cortex in a group of 8-10 human participants. The participants will then be taught with online neurofeedback of their brain signals to regulate their brain activity with respect to cortical representations of specific targets. Once the initial training paradigm has been established, I will test the participants in separate behavioural and conventional fMRI experiments (i.e. event-related fMRI paradigms) examining how self-regulated neurofeedback modulation of visual cortex activity affects perception (reaction times and error rates), the effect on cortical activity in response to stimuli, and whether such cortical signals can be decoded.

This method will be applied in three set of experiments:-
1) aspects of spatial attention (i.e. targets in trained specific visual quadrant)
2) non-spatial feature-based aspects of attention in single and separate functionally specialised cortical areas (i.e. overlapping dissimilar items, overlapping similar items)
3) combinations of spatial and feature-based attention

Clinical/Scientific applications
Together these experiments will provide converging evidence from behaviour and functional brain imaging on how real-time modulation of activity in visual cortex trained by neurofeedback might lead to causal effects on perception and cortical activity. Importantly the complementary focus on the decoding of cortical signals using rt-fMRI will provide practical insights into its use as a brain-computer interface for patient communication and control.</gtr:technicalSummary><gtr:fund><gtr:end>2009-07-02</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2009-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>0</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">MC_EX_G0802357</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>041997EB-CFD8-493D-B0F8-DFA35451D0BE</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Neurological</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>74DC189C-F240-42D1-84DD-85475A95ABE8</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>6.7  Physical</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>