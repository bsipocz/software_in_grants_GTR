<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/632505CF-6670-44B4-A91B-5B3726BA067E"><gtr:id>632505CF-6670-44B4-A91B-5B3726BA067E</gtr:id><gtr:firstName>Antony</gtr:firstName><gtr:otherNames>Bryan</gtr:otherNames><gtr:surname>Morland</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/0B23CA11-0793-4421-ABE1-94FE0BC36B00"><gtr:id>0B23CA11-0793-4421-ABE1-94FE0BC36B00</gtr:id><gtr:firstName>Alex</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Wade</gtr:surname><gtr:orcidId>0000-0003-4871-2747</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM002543%2F1"><gtr:id>7CD8A51A-BC71-4418-87F1-5A5E1ED065B0</gtr:id><gtr:title>Neural pathways underlying human 3D motion perception</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M002543/1</gtr:grantReference><gtr:abstractText>We use our eyes and brain to move confidently within our surroundings without bumping into things, identifying objects as dangerous or attractive and parsing subtle changes in facial expression. Vision is a hugely complex process that uses much of the brain's resources and involves a constant trade-off between energetic efficiency, speed and accuracy. How is this achieved? 

Clues to answer this question come from fundamental biology. Anatomically, it is striking that there are multiple pathways in the visual system and neurons in different visual areas and pathways appear differentially sensitive to certain types of visual information, such as colour or motion. 

It is clear that some visual brain areas and pathways have evolved at different times and for different functions. Dedicating different pathways to different functions can be a way of reducing the complexity of the processing problem - allowing the brain to compute independent properties in parallel. Here, we are interested in a specific set of pathways that seem to show strong independence of this type: those involved in the perception of motion in three dimensional space.

Whilst motion is known to be critical for the 'where' functions of the dorsal pathway, very little attention has been placed on how binocular information for motion is processed, nor what pathways carry out that processing. In this project we explore how binocular visual information about motion-in-depth (MID) is processed and carried by several different visual pathways. 

Two computational processes have been proposed for using binocular information for MID, and there is evidence for each of them being useful for human vision. Are these signals processed along different fundamental pathways in the brain? Why is it interesting to ask this question? (1) Because neither pathway is fully understood: the sites and natures of the computations involved in processing MID in two ways have not been identified. Even more intriguingly, while one pathway, has been much studied, the other is barely explored, very poorly understood and potentially ancient, in an evolutionary sense. (2) The two pathways might perform different functions, and we propose a series of studies to specifically explore what those functions might be.

Our project has very broad scope, we explore the nature of the putative pathways at the anatomical level, using functional magnetic resonance imaging (fMRI) to localize function, and source-imaged electroencephalography (EEG), which can be used to understand the temporal dynamics of visual processing. We will use psychophysical behavioural studies to study what computational processes take place during MID perception, using both a normal population to explore normal function, and a clinical group of subjects (strabismic amblyopes) that we know have compromised MID processing using one specific pathway. Additionally using Transcranial Magnetic Stimulation (TMS) to degrade information in a particular visual area we will test the causal relevance of MID-responsive regions identified with fMRI and EEG. Finally, we will also employ eye-tracking methods to understand what specific sources of MID information are useful for. Using all these techniques will allow us to get a full picture of the processes underlying MID. To achieve this we require the expertise of three institutions, and we will need to host two RA's, one with visual behavioural and eye tracking skills, the other with imaging credentials.

The work proposed in this project is primarily core visual neuroscience. However, it has implications for human health. One of our techniques will exploit the fact that a person with a squint (strabismic amblyopes) is unable to use a core source of MID information, namely binocular disparity. There are hints that this group may be able to use other sources of MID. Our group will be the first to explore this issue comprehensively.</gtr:abstractText><gtr:technicalSummary>Anatomically, it is striking that there are multiple pathways in the visual system. Physiologically, neurons in different visual areas appear specifically sensitive to different visual information, like colour, motion or objects. Why? Dedicating different pathways to different functions can be a way of reducing the complexity of the processing problem. Here, we are interested in a specific set of pathways, those involved in the perception of motion in three dimensions.

Whilst motion is known to be critical for the 'where' functions of the dorsal pathway, very little attention has been placed on how binocular information for motion is processed, nor what pathways carry out that processing. In this project we explore how specifically binocular visual information about motion-in-depth (MID) is potentially processed and carried by several different visual pathways. 

Two computational processes have been proposed for using binocular information for MID, and there is evidence for each of them being useful for human vision. One is the rate of change of binocular disparity over time (changing disparity, CD), the other is the binocular combination of monocular motion signals (inter-ocular velocity difference, IOVD). Both are known to be used in human vision. Our aim here is to determine if these signals processed along different fundamental pathways in the brain. We target the magnocellular (magno), parvocellular (parvo) and koniocellular (konio) pathways. The former two are well studied; disparity is carried by both pathways, motion predominantly by the magno. Of particular interest, is the fact that the konio pathway projects to extra-striate cortex without passing through V1, thus providing an alterative pathway to higher visual areas. We will use brain imaging (fMRI, EEG) and visual psychophysics, to explore where, how and why MID information may be separated across different pathways.</gtr:technicalSummary><gtr:potentialImpactText>Specific Users / Stakeholders
Our proposal is for core human neuroscience research with no immediate application to UK-plc. However, we have identified two groups of possible indirect stakeholders, and two groups of direct stakeholders:
(1) Technologists and display developers, using stereoscopic displays and stereoscopic content producers.
(2) Medical professions involved in diagnosing and understanding binocular vision deficits.
(3) The general public: both consumers and producers of new stereoscopic content.
(4) Project researchers, who will be trained in interdisciplinary skills and exchange subject-specific knowledge.

Plans for engagement

(1) Technologists developing 3D material
Whilst the basic neuroscientific knowledge we generate will not be of direct interest to this group, they should be interested in the our characterisation of the utility of CD and IOVD information, in other words, how important these two sources of information are for 3D display. Harris or RA1 will attend the international conference &amp;quot;Stereoscopic Displays and Applications&amp;quot;, set up by IEEE, towards the end of the project to disseminate our results in the appropriate way for this audience.

(2) Medical professionals
Our work should be of relevance to medical professionals interested in amblyopia and strabismus, conditions that are linked and thought to be due to deficits in the development of binocular vision. One of our experiments will test a population of strabismic observers. For our purposes, we use that population's differently developed vision to test hypotheses, however, our experimental results will have relevance to the understanding of the conditions, and for their potential treatment. Towards the end of the project, we plan to invite our clinical contacts to a workshop session organised under the auspices of the Bradford Institute for Health Research to discuss the clinical implications of our work.

(3) The general public
We intend to make full use of the Press Relations Offices at each of the Institutions involved to maximise our outreach. To this end both RA's will attend the BBSRC Media Training Course. 
Wade hosts public engagement websites to teach the public about colour vision, http://www.vischeck.com/ and infant visual development http://www.tinyeyes.com/ . We will build on this experience to develop a website to demonstrate the two forms of binocular motion in depth systems that can be isolated both and allow users to generate stimuli that contain mixtures of each cue for educational purposes. 
Binocular vision is also a very popular topic with the general public of all ages, due in part to the recent resurgence of 3D film. This therefore provides an excellent opportunity for public engagement, to involve people in understanding how the brain is needed for sight and how 3D technology works. We have experience and equipment to deliver public displays at Science Fairs on how the psychology and neuroscience of binocular vision link to optics and ophthalmology. We plan to attend opens days and science fairs in Scotland and Yorkshire.

(4) Project researchers
The proposal is an interdisciplinary collaboration. We will appoint experienced postdoctoral researchers in St. Andrews and York. Each individual will experience training and will be exposed to research across disciplines, allowing us to deliver genuine inter-disciplinary scientists to the UK research community, at the end of the project. This aim will be achieved via our regular (12 in total) face to face meetings between all members of the project group.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-03-15</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2015-03-16</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>340291</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of York</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Health Sciences</gtr:department><gtr:description>Project Underwood</gtr:description><gtr:id>1839F542-FF29-4286-B363-77527606E5BD</gtr:id><gtr:impact>An entire 3D stimulus generation system has been designed to facilitate the study of navigation, 3D vision, immersion and memory. This software is currently hosted on a private internal repository (GitLab) and we plan to release it to the scientific community in Q1 2018.</gtr:impact><gtr:outcomeId>58c72dcf6592f1.29439943-1</gtr:outcomeId><gtr:partnerContribution>Out partners have brought expertise in virtual world design, 3D interactive graphics and contacts with the games and entertainment industry.</gtr:partnerContribution><gtr:piContribution>As a result of our increasing expertise in the domain of 3D vision and motion processing we have embarked on an ambitious collaboration with groups in Psychology, Computer Science and Theater Film and TV to form an interdisciplinary team focused on Virtual Reality. We have generated a new, dynamic 3D environment for studying a range of issues in psychology, game design and interactive entertainment and a major project grant is planned for Q4 2017. Our contribution has been to lead this collaborative team and to provide advice on neuroimaging, stimulus generation and experimental design.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>School visit day</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>7560BC34-142E-4C30-AB45-C3205B80201E</gtr:id><gtr:impact>Lab demonstration of 3D technology, motion-in-depth stimuli. Discussion of biological principles underlying stereoscopic vision. Audience participation with mirror stereoscopes, 3D displays, VR systems.</gtr:impact><gtr:outcomeId>58c44198eb01d9.18831111</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The primary goals of the research comprised core human neuroscience research, but the results have scientific impacts beyond the specific outcomes detailed elsewhere. The project itself explores the basic visual pathways that analyse motion, a core feature of the perceptual system for a mobile animal, such as ourselves.

We outlined 4 groups of user and stakeholders in our Pathways to Impact document, technologists, medical professional, general public and project researchers. At this, point, one year into the project we have contributed to impact deliverables for the latter 3 of these.

(a) Engagement with medical professionals. We have engaged with Dr. Alison Bruce, Head Orthoptist at Bradford Teaching Hospitals NHS Foundation Trust/ NIHR Post Doctoral Research Fellow at the Bradford Institute for Health Research (BIHR). We are collaborating with her to deliver part of the project using participants with amblyopia and she will help establish a Yorkshire-based (University of York/ University of Bradford) pool of suitable study participants and at the end of the project she will help us organise a clinical workshop session, under the auspices of the BIHR http://www.bradfordresearch.nhs.uk/ to discuss and disseminate the clinical implications of our work. 

(b) Public engagement. The Harris lab have developed displays for public science festival events, so far taking part in the St. Andrews University Science Open Day, 2015. Harris has given two talks in 2015, to young adults in 6th form, as part of a Sutton Trust Summer School, and for the St. Andrews Open Association lectures. 
 
 (c) RA's Giesel and Maloney are to complete the BBSRC media training course in 2016. The whole group, including 3 PhD students working in similar areas, have met for 3 project meetings. These give the RA's the opportunity to interact with scientists trained in other areas and to learn to collaborate in an interdisciplinary fashion.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>9A65F2AB-5346-46C3-B47E-2BB7299C08E8</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d6f7185b5a93.88045745</gtr:outcomeId><gtr:sector>Education,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We are nearly 1 year into the project and are making progress on both of our original aims:

Aim 1
A paper on the chromatic tuning of motion in depth mechanisms is ready for submission. 
fMRI data for two experiments is well underway: Expt 1 examines the coding of eye-specific information within the visual cortex and asks, in addition, if regions that are not directly driven by a monocular stimulus nevertheless contain information about it's eye of origin. Expt 1 asks which regions are involved in coding the two types of motion in depth information critical to this grant. Elegant stimuli are used to ensure that both stimulus types are independent and, again, both directly driven and 'surround' regions are interrogated. Chromatic calibration for a third experiment examining the interaction between MID and colour in cortex is complete and these experiments will begin in mid April.


Aim 2
Psychophysical experiments on the nature of the IOVD cue to 3D motion. We have shown so far IOVD information can likely only be totally isolated using de-correlated rather than anti-correlated motion. The well known increase in duration thresholds with stimulus size for lateral motion is not present for motion in depth. Thus there appears to be a fundamental difference between motion in depth and lateral motion information.</gtr:description><gtr:exploitationPathways>Findings will be taken to national and international conferences over 2016-17 and published in top journals.</gtr:exploitationPathways><gtr:id>06ED2D1A-632B-419E-B42A-5C649075BBEC</gtr:id><gtr:outcomeId>56d6f6bd615006.10531870</gtr:outcomeId><gtr:sectors><gtr:sector>Education</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>D9B0D321-355E-4503-9ABC-22442BAA572B</gtr:id><gtr:title>Attentional state modulates responses to motion-in-depth stimuli across striate and extrastriate visual areas</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d96083f5fa3436c5df565701ade2d098"><gtr:id>d96083f5fa3436c5df565701ade2d098</gtr:id><gtr:otherNames>Kaestner M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa68cff680e26.93014589</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>016ABC73-BC04-4532-BD9B-704557DA7856</gtr:id><gtr:title>The effect of locomotion on early visual contrast processing in humans.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/203727acbc110c79043db8900e7e1c36"><gtr:id>203727acbc110c79043db8900e7e1c36</gtr:id><gtr:otherNames>Benjamin AV</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>5a96bd039b54b2.91694423</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>131CE957-058F-42B6-B34B-DABDA720FF44</gtr:id><gtr:title>fMRI reveals S-cone and achromatic contributions to motion-in-depth perception</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d96083f5fa3436c5df565701ade2d098"><gtr:id>d96083f5fa3436c5df565701ade2d098</gtr:id><gtr:otherNames>Kaestner M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5aa68c7ec7f1f3.90898285</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M002543/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>