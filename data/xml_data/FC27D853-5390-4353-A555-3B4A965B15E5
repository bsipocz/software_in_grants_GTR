<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1E267E0C-FC58-46FF-99CC-0AC5FDF5F588"><gtr:id>1E267E0C-FC58-46FF-99CC-0AC5FDF5F588</gtr:id><gtr:name>Silicon Graphics International Corp SGI</gtr:name><gtr:address><gtr:line1>200 Berkshire Place</gtr:line1><gtr:line2>Wharfedale Road</gtr:line2><gtr:line3>Winnersh</gtr:line3><gtr:line4>Wokingham</gtr:line4><gtr:line5>Berkshire</gtr:line5><gtr:postCode>RG41 5RD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A66281EB-0EDE-495D-AD55-D81A4E060EC6"><gtr:id>A66281EB-0EDE-495D-AD55-D81A4E060EC6</gtr:id><gtr:name>Electrosonic Ltd</gtr:name><gtr:address><gtr:line1>Hawley Mill</gtr:line1><gtr:line2>Hawley Road</gtr:line2><gtr:line4>Dartford</gtr:line4><gtr:postCode>DA2 7SY</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/77E367B6-A19C-47CB-A7C0-20F8B35D1217"><gtr:id>77E367B6-A19C-47CB-A7C0-20F8B35D1217</gtr:id><gtr:name>Avanti Communications Limited</gtr:name><gtr:address><gtr:line1>20 Blackfriars Lane</gtr:line1><gtr:postCode>EC4V 6EB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/281178AD-E637-43C4-9943-0B22423A69AF"><gtr:id>281178AD-E637-43C4-9943-0B22423A69AF</gtr:id><gtr:name>VISUAL ACUITY LIMITED</gtr:name><gtr:address><gtr:line1>8 Brighton Office Campus</gtr:line1><gtr:line2>Hunns Mere Way</gtr:line2><gtr:line4>Brighton</gtr:line4><gtr:postCode>BN2 6AH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5A5A7D90-A667-4BFC-8A2E-814AE73C1A88"><gtr:id>5A5A7D90-A667-4BFC-8A2E-814AE73C1A88</gtr:id><gtr:firstName>Anthony</gtr:firstName><gtr:surname>Steed</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE010032%2F1"><gtr:id>FC27D853-5390-4353-A555-3B4A965B15E5</gtr:id><gtr:title>Eye Catching: Supporting tele-communicational eye-gaze in Collaborative Virtual Environments</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E010032/1</gtr:grantReference><gtr:abstractText>Driven by the potentials and demands of an increasing global market and fed by advances in information and communication technology, one of the trends in the modern workplace is for more distributed team working. Distributed working has long been a major topic in computer science, but despite excellent work and the development of highly sophisticated computer-supported cooperative work (CSCW) systems, in many situations there is no substitute for a face-to-face meeting. The consequent demands for travel to meetings have immediate short term quality of life and productivity impacts on individuals. There may also be more far-reaching and profound implications of our current reliance on long distance travel. Thus it is still very relevant to try to determine why some CSCW fails and to research possible technologies for expanding the situations for which face to face meetings can be avoided. There are numerous common collaborative scenarios that require a more natural way of interacting across a distance. Specifically we have identified conscious and subconscious communication of attention and emotion as common critical elements that make many such scenarios hard to support without eye-gaze. Eye-gaze is a key interactional resource in collaboration but it is not well supported in today's communication technology. Indeed many have claimed that lack of ability to faithfully represent eye-gaze is the key failing of current CSCW systems. Within today's video based systems eye-gaze can be maintained in some limited way if the user is willing to look directly at a camera, but this is unnecessarily constraining in a social situation, especially during object or environment focussed collaboration.We propose to evaluate the role of eye-gaze in tele-communication so as to better design future communication technologies. To do this we will build the world's first tele-collaboration system that supports two and three way communicational eye-gaze without restricting the gaze direction of participants. We will integrate eye-tracking technologies into Immersive Projection Technology (IPT) displays, and develop the software necessary to build a consistent collaborative virtual environment where each participant can see the other and accurately track their eye-gaze. To prove the utility of this system we will compare it to AccessGrid technology which provides state-of-the-art video conferencing on large wall displays. Although unable to support communicational eye-gaze between moving participants, AccessGrid does offer advantages in terms of placement within working environments and realism of representation. Comparison between the two approaches will provide valuable insight into future development of each. Through a series of experiments we will establish what conditions are necessary and sufficient to support communicational eye-gaze in a tele-communication system; validate the support of eye-gaze in tele-communication by measuring its impact on collaboration; measure the impact of technology approaches and variables; establish when eye-gaze is important; and establish situations where eye-gaze is critical for successful collaboration at a distance.</gtr:abstractText><gtr:fund><gtr:end>2008-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>236868</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/E010032/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>