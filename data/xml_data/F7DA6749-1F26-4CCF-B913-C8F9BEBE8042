<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2F667752-ABE0-4914-9C97-82F42CC11C60"><gtr:id>2F667752-ABE0-4914-9C97-82F42CC11C60</gtr:id><gtr:name>University of Greenwich</gtr:name><gtr:department>Educational Development Unit</gtr:department><gtr:address><gtr:line1>Old Royal Naval College</gtr:line1><gtr:line2>Park Row</gtr:line2><gtr:line3>Greenwich</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE10 9LS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2F667752-ABE0-4914-9C97-82F42CC11C60"><gtr:id>2F667752-ABE0-4914-9C97-82F42CC11C60</gtr:id><gtr:name>University of Greenwich</gtr:name><gtr:address><gtr:line1>Old Royal Naval College</gtr:line1><gtr:line2>Park Row</gtr:line2><gtr:line3>Greenwich</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE10 9LS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E0D78456-8B1B-4532-A04A-53AD40C15CE3"><gtr:id>E0D78456-8B1B-4532-A04A-53AD40C15CE3</gtr:id><gtr:firstName>Ralph Alexander</gtr:firstName><gtr:surname>Barthel</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/843279CD-5F28-4EBA-B68E-473C1E498E1A"><gtr:id>843279CD-5F28-4EBA-B68E-473C1E498E1A</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:surname>Hudson-Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=AH%2FM002233%2F1"><gtr:id>F7DA6749-1F26-4CCF-B913-C8F9BEBE8042</gtr:id><gtr:title>Sound and Vision Scapes (SViS)</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/M002233/1</gtr:grantReference><gtr:abstractText>Sound and Vision Scapes (SViS) integrates the social Internet of Things software platform Tales of Things with the BBC media archive in order to link video and audio content to places and objects via mobile devices. Project SViS will augment a combination of 100 objects and places objects throughout the UK to enable the public to engage with the BBC archive in novel ways that increase access and provide new opportunities to participate in the replay and social recording of objects, places and spaces. For this purpose we will utilize 'broadcast beacons' to allow read/write access to the archive directly linked to the object or place. These beacons, based on Bluetooth Low Energy (BLE) technologies, will broadcast the availability of provenance information to BLE enabled devices (phones, smart watches) in the proximity (up to 25m distances). The project builds on the next generation of the Internet of Things and utilises the provenance/read write platform of Tales of Things to allow a seamless interaction with media and objects/places of cultural heritage significance as a means of gathering and displaying information. 
 
Talesofthings.com is part of the EPSRC funded Tales of Things and electronic Memory (TOTeM) project. It represents the worlds largest archive of Internet of Things connected second hand objects with over 10,000 'things' connected to stories, tales and information about their provenance. The project has received over 40 articles in the international press, was named as part of Wired's Top Technology 2011, been utilised by Oxfam as part of their ongoing Shelf Life project and won the cross research council impact award 2011. The linking of the project with the BBC archive, along with the inclusion of geographic location and use of broadcast beacons, will provide a unique roadmap to opening up a wealth of media and audio data to location. An example of this would be a broadcast beacon located on a bench in Lyme Regis on the Dorset Coast, broadcasting a 10 minute short from the BBC Series 'Coast' with information on the Jurassic Coast. The viewer would be able to contribute comments, photos or videos of their time at the location, viewable to the next person who viewed the archive from the beacon and thus adding a social network aspect to not only the archive but also the object, place and location. Another example would be the tagging of a tree in a public park, linking to media resources applicable to wide range of age groups from 'Trees and Tall Things' from the Show Me Show Me CBBC series to Gardeners World. This aim is to link information about objects, places and spaces directly to the BBC archive while also combining the crowd sourced/social network nature of Tales of Things using known systems and techniques.

It is to be expected that the proposed project will generate new types of data about interactions with cultural heritage. This data can be used for the creation of insightful visualisations, it can inform the development of new data analysis tools and methods that support research in the social sciences, arts and humanities. The project proposes the creation of a social cultural heritage platform that allows researchers to explore how people perceive cultural heritage. We aim to investigate new social practises of creating and managing social memories linked to places. Consequently our research also explores novel forms of digital citizenship that can help to democratise how cultural heritage is recorded. In order to study these new phenomena the project will create new tools and methods to study and analyse the generated heritage data.

The use of established and proven technologies enables the project partners to carefully manage risks that are inherent to projects that involve software development. By applying existing technologies the associated risks are low and software development will be restricted to customization and integration of the different backend systems.</gtr:abstractText><gtr:potentialImpactText>There are a number of impact beneficiaries of the proposed intervention. First of all SViS will increase opportunities for engagement with cultural heritage resources to the general public. This will encourage people to learn about the identity of places by broadcasting information about the provenance of a place and past events linked to it. Hence the expected impacts of the project amongst others are:

- Improved access to affordable and widely available tools and services for releasing the economic potential of cultural heritage in digital form and for adding value to cultural content in educational, scientific and leisure contexts; 

- Engagement of a wide range of users with cultural resources in diverse real and virtual contexts and considerably altered ways to experience culture heritage as a personalized and adaptive user experience

The proposed social software system that emerges as a result of integrating Tales of Things and the BBC broadcasting archive will enable people to participate in the discussion about cultural heritage and its preservation. Hence the intervention provides learning opportunities for members of the public and it also enables novel forms of participation and citizenship that inform decision-making and initiatives from local authorities. Consequently an outcome of this project will be a new type of social software system for the digital cultural heritage sector. The resulting software artifact will provide insights into possible avenues for commercialization, the design of socio-technical systems for cultural heritage and add-on services with economical viability. 

Enabling people to add their own voice also encourages the democratization of recording cultural heritage and social memory. This is important as it will help marginalised groups having their voices heard in a sector that is otherwise dominated by the cultural industry. There is then a risk that hyperlocal heritage and provenance gets forgotten due to a potential bias for settling for a mainstream perspective. Citizens are rarely involved in curating cultural heritage experiences. While the recent uptake of digital technologies has led to improved opportunities for audience feedback in general, and to a certain extent for social interpretation, these approaches tend to only reach an already interested audience. Unfortunately too often cultural minority groups and less affluent or culturally less important regions are under-represented in heritage applications. The Internet of Things-approach that we are putting forward enables new opportunities for people to connect with the culture of place in everyday activities. 

The proposed project also provides a stimulus for the economy and in particular the creative industries and tourism sectors. The project will provide pointers for new tourism applications that integrate tailored media access when interacting in-situ with places in the real world through the use of Internet of Things technologies. The use of low-cost ubiquitous mobile technologies will allow greater accessibility to informal learning in groups that may not normally visit museums or cultural sites/institutions. We also envision that our intervention will support novel forms of inquiry learning where students can probe and question their perceptions through interactions with places that have been augmented. 

The intervention also unlocks new user-generated data resources that researchers can tap into, visualise and analyse. Hence it enables researchers to work with new data sets and explore novel research questions relating to cultural heritage. Peoples' perceptions and attitudes towards cultural heritage artefacts that are currently largely hidden will be made visible and thus can be used for discussion and mediation of meaning.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2014-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>63329</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>Renderign of the final version of a prototype device</gtr:description><gtr:id>EC3D94AE-08C9-424C-A5B9-BA9B2911FB07</gtr:id><gtr:impact>Contains all the parts and details for 3D print and assembly</gtr:impact><gtr:outcomeId>56ddfaffbfe6d0.59304152</gtr:outcomeId><gtr:title>Final rendering of a prototype device</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/2jwcg7kcmr23zw0/150428_augmented%20bench_FINAL.png?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Detailed rendering of a prototype device for the augmentation of a bench on-site.</gtr:description><gtr:id>0EA5D740-2A3F-4ED3-B42E-94CF467D5C9E</gtr:id><gtr:impact>The rendering was used as a blueprint for prototyping and 3D printing of a physical prototype</gtr:impact><gtr:outcomeId>56ddfa5c8eea94.38530961</gtr:outcomeId><gtr:title>Design Concept IoT Augmented Bench</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/qh4ihfyo4ymhfmo/150826_exploded%20persp_DIAGRAM_FINAL.png?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>This was a second a map we created that shows were on site interactive IoT enabled objects could be located.</gtr:description><gtr:id>B1ED8F1B-CF00-4D07-964F-967C7ABC2096</gtr:id><gtr:impact>This map was instrumental in planning fieldwork and in exploring the logistsics of having IoT enabled interactive objects on site.</gtr:impact><gtr:outcomeId>56ddf90e60cde1.18766871</gtr:outcomeId><gtr:title>A map that shows potential locations for IoT enabled interactive objects</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/ej665dmfsm85db1/230429_map.png?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>All the sounds and voiceovers that were recorded for the project.</gtr:description><gtr:id>4B3F6F88-A81C-4733-9A1B-C9C3412DDFBA</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56deb80caf4246.40297846</gtr:outcomeId><gtr:title>All recorded audio files</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>https://www.dropbox.com/sh/9bje9m6n2tfllkt/AAAyIKfGdUYGJvAk6FgSNQfYa?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>As part of our research we created a map of the University of Greenwich Maritime campus overlayed with the location were films were shot on site and their genre. The map also shows significant historic events that took place on site.</gtr:description><gtr:id>3FFFF780-D18A-43F0-AA07-2A424E8EFD01</gtr:id><gtr:impact>The research that informed the creation of this map supported us envision how the campus could be augmented with interactive IoT-enabled on-site objects.</gtr:impact><gtr:outcomeId>56ddf6d6dd96a6.53616611</gtr:outcomeId><gtr:title>University of Greenwich Campus with film locations and locations of significant historic events</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/ax50a8zr59r4se3/150212_GreenwichCampus.jpg?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Edited version of a sound recording of an actress telling on-site stories based on a script from a researcher. We created six different stories.</gtr:description><gtr:id>524EABAD-54F8-4658-B993-B63B998A4D96</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56ddffae16b244.88801795</gtr:outcomeId><gtr:title>Audio story 1</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>https://www.dropbox.com/s/enfc3dqb185xsny/150717_story2_v3.wav?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Details of the 3d printed prototype of a bench augmentation kit</gtr:description><gtr:id>3588E3E5-E7BE-47A1-9082-0F6A55092754</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56ddfc03d81f35.88595635</gtr:outcomeId><gtr:title>First photo of the bench augmentation kit</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/ng8iyrfoncytx11/2a.jpg?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Script for the voice recordings of on site stories.</gtr:description><gtr:id>71A9B967-AF4E-4223-AC2C-911F7A22CF5D</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56ddfeabe125d2.41305808</gtr:outcomeId><gtr:title>Sound script</gtr:title><gtr:type>Creative Writing</gtr:type><gtr:url>https://www.dropbox.com/s/0tlfje7wjtb33p5/150315_SOUND%20SCRIPT.pdf?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Details of the 3D printed and assembled bench augmentation kit</gtr:description><gtr:id>9EBC1238-6575-46D0-9EAC-66AE55037279</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56ddfdba4d7a93.24412410</gtr:outcomeId><gtr:title>Third photo of the bench augmentation kit</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/wzkkie77p7o6m6r/4a.jpg?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>List of the sounds that were recorded to augment the storytelling</gtr:description><gtr:id>CBE8391B-21B3-4B12-91DB-32C532F9823B</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56deb6fc7303b3.89372440</gtr:outcomeId><gtr:title>Sound List</gtr:title><gtr:type>Creative Writing</gtr:type><gtr:url>https://www.dropbox.com/s/qza2venvdpk6amw/150514_Sound%20List.pdf?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>Details of the 3D printed prototype</gtr:description><gtr:id>B2B5290D-6C5A-4E72-B9F9-AACCB6A372C4</gtr:id><gtr:impact>Was used to elicit feedback from people that experienced the device in our research.</gtr:impact><gtr:outcomeId>56ddfc8437dc05.28969239</gtr:outcomeId><gtr:title>Second photo of the bench augmentation kit</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:url>https://www.dropbox.com/s/wmx2g38754n58rh/3a.jpg?dl=0</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>30692</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Proof of Concept fund</gtr:description><gtr:end>2016-06-02</gtr:end><gtr:fundingOrg>University of Greenwich</gtr:fundingOrg><gtr:fundingRef>HEIF-PoC-ACH-02/15</gtr:fundingRef><gtr:id>77DCB14D-A7E6-4620-ADF8-8BFBE091F669</gtr:id><gtr:outcomeId>56d8084461da98.40585247</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-12-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Outcomes from our research have been instrumental in informing a new project (information mediators) that is currently underway. The &amp;quot;Information Mediators&amp;quot; project aims to create a new half digital, half physical experiential environment on the University of Greenwich Campus through enhancing the built environment with physical, interactive IoT enabled site objects. The main goal of the project is to create an opportunity for students and visitors to explore and discover provenance information about the site in a creative and engaging way, through an interaction with physical devices that are deployed around the site. These devices will, apart from delivering information also absorb them, acting as a &amp;quot;Speakers Corner&amp;quot; for students, staff and visitors giving an opportunity to everyone to express their ideas, complaints and dreams regarding life on the university campus. 

The research supported by this award has helped to further develop the skills of the research team to explore commercialisation of IoT enabled objects in the built environment in conjunction with a industry partner in a wider context. We have been successful in securing follow-on funding for business planning and necessary additional technical development. We believe that the outcomes of the project are suitable to benefit individuals and organisations alike and they will be used in different sectors to increase public engagement and public participation in other secotors such a wellbeing.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>A330C0AE-5FFD-4F82-9ADD-D15A3DCD07EE</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56dd9e02cebfe2.82378429</gtr:outcomeId><gtr:sector>Education,Healthcare,Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Through this grant we developed a new approach with a low entry barrier to participation in digital cultural heritage through interactions with IoT (Internet of Things) enabled objects. Many IoT technologies such as Bluetooth low energy or NFC require smartphones and bespoke apps for consuming locative media and content. We found that these relatively high technical requirements restrict uptake and audiences for digital cultural heritage applications and public engagement. This led us to reconsider our approach to employing IoT in cultural heritage and urban spaces which are the primary contexts of our research. Initially we planned to emply IoT as being enabled by wearable and ubiquitous computing devices that people carry whilst interacting with hidden tags and technologies (e.g. Bluetooth Low Energy) in-situ. However, it emerged through our research that creating visible, aesthetic and evocative objects in the built environment with which people can interact without the need of sensor equipment smartphones is a much more desirable, accessible and suitable approach to engage with cultural heritage and informal learning. 

During the duration of the project the research team developed and improved skills to research this interdisciplinary space and we found design research and design fiction to be a valuable approach in this context. We developed new concepts, artefacts, performative media, visual representations and prototypes which helped to balance different perspectives and to start conversations with different potential stakeholders in employing emerging technologies such as IoT to explore cultural heritage.</gtr:description><gtr:exploitationPathways>Our research has led us to reconsider how people can access Internet of Things technologies and how participation in memory creation and social interpretation can be achieved with a low barrier to entry via using social media (e.g. Twitter) and modes of interaction (text messaging) with IoT objects in the built environment. We are currently exploring the commercialisation of new types of IoT enabled information mediators, that are informed by the research of Sound and Vision Scapes, in collaboration with a commercial partner. This project is funded through and University of Greenwich proof of concept award. This follow-on work leads to a marketable concept and a technical product that is of interest to the museum sector and we expect this work to inform similar offerings that heritage institutions might use for visitor engagement.

The research outputs and challenges are of interest to an interdisciplinary audience and our design research provides interesting insights how design fiction and traditional social science research methods can be combined to design valuable activities with Internet of Things technologies in a digital heritage context. Our prototypes and the location map of films are example artefacts of this approach.</gtr:exploitationPathways><gtr:id>86EFA16A-CA90-4EC3-A286-570AF34E1823</gtr:id><gtr:outcomeId>56dd6cbae829b7.38818318</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors><gtr:url>http://blogs.gre.ac.uk/svis/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">AH/M002233/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>12F57045-398B-4CC0-BF63-76C038A2E247</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cultural &amp; museum studies</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>8990E5FE-B44F-4A5B-8FDE-0610A5BE98C4</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cultural Geography</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0F8B7B13-F2F5-42B3-95C6-EF12D7877319</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Multimedia</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>34B6BDD6-DA02-4CA0-A969-29D50394A953</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Networks &amp; Distributed Systems</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>