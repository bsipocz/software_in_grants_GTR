<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3FC11ED4-3AC3-4E12-8508-FBBBB8E63073"><gtr:id>3FC11ED4-3AC3-4E12-8508-FBBBB8E63073</gtr:id><gtr:name>Massive Analytic Limited</gtr:name><gtr:address><gtr:line1>26 HILLFIELD PARK</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>N21 3QH</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3FC11ED4-3AC3-4E12-8508-FBBBB8E63073" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>3FC11ED4-3AC3-4E12-8508-FBBBB8E63073</gtr:id><gtr:name>Massive Analytic Limited</gtr:name><gtr:address><gtr:line1>26 HILLFIELD PARK</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>N21 3QH</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>166384.0</gtr:offerGrant><gtr:projectCost>369743.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/44F10B0E-1B60-4076-9911-59F2CA1435A5"><gtr:id>44F10B0E-1B60-4076-9911-59F2CA1435A5</gtr:id><gtr:firstName>Gary</gtr:firstName><gtr:surname>Brooks</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=720732"><gtr:id>A9E2F1AD-E80F-48D3-A3A4-B3EE6F9A0BB9</gtr:id><gtr:title>Video Precognition</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>GRD Development of Prototype</gtr:grantCategory><gtr:grantReference>720732</gtr:grantReference><gtr:abstractText>Founded in 2010, Massive Analytic is a London-based data science company, developing
innovative technologies related to artificial intelligence, big data and predictive analytics.
Holding core patents for artificial precognition, MA seek to disrupt the way we interact with
data, realised through the novel software platform Oscar AP.
This project aims to transform video analytics by making it possible to predict likely event
outcomes. Surveillance videos can be monitored automatically in real time, triggering alerts to
be sent to response teams such as emergency services as required. This allows crowd
managers and emergency services to target resources effectively.
Current video analytic solutions are limited by their capability to capture relevant information
from video streams in real time, given the increasing size of data streams. Human operators
can only monitor a limited number of screens and their reliability decreases dramatically after
20 minutes continuous monitoring. The performance of automatic video analytic solutions is
also limited, with high rates of false alarms and missed events.
Massive Analytic have applied the latest techniques in data science and, by approaching video
analytics in an entirely new way, have succeeded in demonstrating the concept of video
precognition. This demonstration system is able to predict when a fight is about to break out
in a crowd, or identify a car driving amongst the people.
To develop the system to a prototype that can be used to engage with clients, the system will
need to be scaled to be able to process thousands of hours of videos and trained to recognise a
large array of different behaviours. Massive Analytic will use their expertise in big data
solutions to deliver an innovative, robust and computationally efficient video precognition
system that can interface easily with third-party systems.</gtr:abstractText><gtr:fund><gtr:end>2017-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2015-12-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>166384</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">720732</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>