<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/772A1E12-7175-46C0-B665-CE27930D15A8"><gtr:id>772A1E12-7175-46C0-B665-CE27930D15A8</gtr:id><gtr:name>Liverpool John Moores University</gtr:name><gtr:department>General Engineering Research Institute</gtr:department><gtr:address><gtr:line1>Egerton Court</gtr:line1><gtr:line2>No 2 Rodney Street</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L3 5UX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/772A1E12-7175-46C0-B665-CE27930D15A8"><gtr:id>772A1E12-7175-46C0-B665-CE27930D15A8</gtr:id><gtr:name>Liverpool John Moores University</gtr:name><gtr:address><gtr:line1>Egerton Court</gtr:line1><gtr:line2>No 2 Rodney Street</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L3 5UX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F95E540F-BA83-4136-9913-02CB594B685B"><gtr:id>F95E540F-BA83-4136-9913-02CB594B685B</gtr:id><gtr:firstName>David</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Burton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/EADE3A35-25D8-4618-9B09-71E4215ED3CB"><gtr:id>EADE3A35-25D8-4618-9B09-71E4215ED3CB</gtr:id><gtr:firstName>M J</gtr:firstName><gtr:surname>Lalor</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD077702%2F1"><gtr:id>93D862AB-8D2F-41D7-9D7E-1931F52A0429</gtr:id><gtr:title>Metrology Guided Radiotherapy</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D077702/1</gtr:grantReference><gtr:abstractText>Radiotherapy cures local cancer by repeatedly targeting a tumour with small doses of radiation in 'fractions'. Though healthy tissues are irradiated, image assisted pre-treatment planning keeps this to a minimum. CT scans allow the body surface, tumour and critical organs to be seen to scale, so that the optimum shapes and directions of a set of radiation beams can be calculated. These are used daily in a treatment regime that may last weeks. The corresponding dose distribution is estimated and radiobiology can be used to predict the probabilities of cure and complications. How a patient will move or change during treatment itself, is unknown. Hence, an expert specifies a tolerance margin around the tumour and assumes everything else will stay as seen in the pre-treatment CT scan. On this simplified basis the patient is positioned on each day of the treatment.When treatment is in progress, and radiation is being directed at the tumour, there is no monitoring of the patient's position or internal anatomy. Hence, a precisely planned treatment is delivered in a manner that is effectively blind. This situation persists, despite complex new treatments and image guided radiotherapy (IGRT) that now includes 'cone beam' imaging (CBI), which the investigators helped to develop. IGRT radiation dose and CBI practical limitations are new causes for concern. MEGURATH introduces metrology guided radiotherapy (MGRT), where the patient is measured, imaged and modelled during treatment delivery. It researches non-invasive, radiation-free, real-time 3D patient positional monitoring based on optoelectronic sensors using structured light to map the body surface. A prototype system, with unrivalled performance, has been successfully piloted by the investigators in the treatment room. This will be developed to include radical concepts of multi-colour, adaptive sensing, where the structured light projected onto the body surface is first pre-adapted to the shape information available in patient's CT planning scan and then refined during use. The MEGURATH sensors will be synchronised with novel low radiation dose CBI based on acquiring images of the patient between treatment beams. This approach has been piloted by the investigators along with an innovative CBI collimator design that has the potential to halve patient dose, yet improve contrast in the reconstructed volume image. In a feedback loop, the CBI will then be optimally corrected for measured motion that is not necessarily periodic. Reconstructive imaging will then be combined with dynamic deformation modelling, to quantify changes in the shapes and positions of the tumour and nearby organs. Pilot work using sensor measurements to deform treatment plans has been reported by the investigators. Extending this approach across the irradiated part of the body will make it possible to describe the shape changes that occurred in the patient during irradiation. This will be the first time that a point by point model of the patient during treatment has been constructed from live measurements. In turn, this will finally make it possible to use radiobiology to calculate the probabilities of tumour cure and complications for the treatment actually delivered, and to compare this with the treatment that was planned.MEGURATH has strong, diverse theoretical components. It also has an ambitious programme for the translation of science and technology into the first purpose built IGRT research facility in the UK. It is materially supported by the manufacturers of IGRT and treatment planning equipment. Hence, it offers a unique opportunity to advance clinical practice beyond IGRT to MGRT and to use the skills of scientists, mathematicians and clinicians to address cancer treatment at some of the most significant and mobile disease sites, not least breast, lung and pelvis.</gtr:abstractText><gtr:fund><gtr:end>2009-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>362772</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>F851F29B-E687-4BDE-8F0B-D63018AC1E32</gtr:id><gtr:title>An analysis of breast motion using high-frequency, dense surface points captured by an optical sensor during radiotherapy treatment delivery.</gtr:title><gtr:parentPublicationTitle>Physics in medicine and biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e3048ab82151c061705ea19c0f51d8c3"><gtr:id>e3048ab82151c061705ea19c0f51d8c3</gtr:id><gtr:otherNames>Price GJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0031-9155</gtr:issn><gtr:outcomeId>doi_53d04004060ceb1b</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A3351417-1872-45C8-8856-3CBFD373E874</gtr:id><gtr:title>Three-dimensional phase unwrapping using the Hungarian algorithm.</gtr:title><gtr:parentPublicationTitle>Optics letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/816d007b6e4d505c2a440d9a0fa8c38e"><gtr:id>816d007b6e4d505c2a440d9a0fa8c38e</gtr:id><gtr:otherNames>Gdeisat M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0146-9592</gtr:issn><gtr:outcomeId>doi_53d07f07ff3d8269</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E055CA90-C5E5-453E-8193-B5DD16E23641</gtr:id><gtr:title>Hybrid robust and fast algorithm for three-dimensional phase unwrapping.</gtr:title><gtr:parentPublicationTitle>Applied optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/36b6d02d45df96d6bf200b03fda7371d"><gtr:id>36b6d02d45df96d6bf200b03fda7371d</gtr:id><gtr:otherNames>Arevalillo-Herr?ez M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1559-128X</gtr:issn><gtr:outcomeId>doi_53d07e07e4ad83e0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BA529608-2243-4ABE-9222-8ABD47EDEA0A</gtr:id><gtr:title>Fast and robust three-dimensional best path phase unwrapping algorithm</gtr:title><gtr:parentPublicationTitle>Applied Optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c955390ab5f9b11c9caf30a671eef9d0"><gtr:id>c955390ab5f9b11c9caf30a671eef9d0</gtr:id><gtr:otherNames>Abdul-Rahman H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>doi_53d07e07e4342092</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>019B7D80-CC75-4537-BC5F-7FFE40FA7172</gtr:id><gtr:title>Spatial fringe pattern analysis using the two-dimensional continuous wavelet transform employing a cost function</gtr:title><gtr:parentPublicationTitle>Applied Optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e3675c3cdf7b68608119fd07be3441ad"><gtr:id>e3675c3cdf7b68608119fd07be3441ad</gtr:id><gtr:otherNames>Abid A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>doi_53d07e07e42ab7df</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D077702/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>