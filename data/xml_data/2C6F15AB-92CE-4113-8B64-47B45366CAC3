<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Informatics</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B1BAEC2E-49D0-4151-B0F4-91097AE1D51A"><gtr:id>B1BAEC2E-49D0-4151-B0F4-91097AE1D51A</gtr:id><gtr:firstName>Robert</gtr:firstName><gtr:surname>Fisher</gtr:surname><gtr:orcidId>0000-0001-6860-9371</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM00189X%2F1"><gtr:id>2C6F15AB-92CE-4113-8B64-47B45366CAC3</gtr:id><gtr:title>Colour space homography</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M00189X/1</gtr:grantReference><gtr:abstractText>For commercial 'imaging' products like the digital camera in your phone, engineers seek simple and elegant solutions to hard problems. You will have noticed that newer cameras take better pictures than older ones. This is in part due to ever advancing hardware: there are faster processors and more pixels. Yet, there has been some important problem solving insights that make it possible to solve problems that were hitherto intractable. A good example of this is the problem of colour casts (one of the foci of this proposal). When you take a picture with a camera the colours that are recorded are dependent on the colour of objects in the scene and (perhaps surprisingly) on the colour of the light. Physically, your white T-shirt is yellowish and bluish when viewed in direct sunlight or when you are in the shadows (because sunlight and shadows are respectively yellowish and bluish). We do not see the colour casts as our vision system factors out the colour of the light and, likewise, digital cameras process images to (much of the time) remove colour casts. But, if you compare the outputs of cameras today with those 15 years ago, the modern era cameras are much better at removing colour casts. Why? because of clever insights that helped engineers build systems which correctly infer the colour of the prevailing light.

This research project begins with a surprising new observation which we believe will help us improve still further imaging products such as colour cameras. We make, for the first time, a deep link between the colours recorded in image - typically three R,G and B numbers that measure the redness, greenness and blueness of a pixel - and the 3D locations of points in the world and how these points correspond to pixel locations in an image. Thinking about geometry, we are all aware that train tracks appear to converge in the distance even although we know they stay the same distance apart (intrinsically, we understand how the 3D world maps to 2D pictures). In this research we begin by showing that the relationship between the colours - same colourful object viewed under different viewing conditions - is exactly the same as the relationship that links different viewpoints - say of the front of a building - in geometry. Mathematically, this relationship is called an homography.

Importantly, now that we have linked the colours you see in the camera to how the 3D world maps to images we can use this observation - we can exploit lessons learnt in the geometric domain - to help us solve some colour imaging problems. First, by exploiting colour space homography, camera manufacturers (and enthusiasts) will be able to more accurately calibrate their cameras and this will further optimize image colour fidelity. Homographies also play an important role the colour cast removal problem and in this proposal we will develop a homography-based algorithm that will advance the state of the art. Outside of photography, we are interested in problems such as colour based medical diagnosis e.g. we will be aiming to improve the automatic identification of skin lesions. We propose that homographies are also the key to solving high level vision tasks including identifying, manipulating and removing shadows from images.

More novelly, we have found that answering the question &amp;quot;how do we find a coloured filter which, when place in front of a camera makes the camera measure light in a way that is similar to the human visual system' also involves solving for a homography. Homographies have a link to problems such as image fusion - fusing 100s of images into a single colour summary - which process images in the so-called derivative domain. Here images are transformed into an edge representation and then these edges are manipulated before an output is reintegrated. Homographies hold the promise of making the reintegration process faster and less prone to introducing artifacts (a well known problem of existing techniques).</gtr:abstractText><gtr:fund><gtr:end>2019-02-27</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-02-28</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>44384</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>A method for relating the colour images captured by different cameras. A way of recolouring an image to a specified colour range.

This project is starting year 2 of 3.</gtr:description><gtr:exploitationPathways>Image and camera companies might use some of the methods. It might allow in the field colour image correction.</gtr:exploitationPathways><gtr:id>B6653A94-1C75-49AB-84CA-2897260EAD6E</gtr:id><gtr:outcomeId>56d6fe17836d70.59203139</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Environment,Healthcare,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>3003C10A-1937-46C6-9C74-AC274241969E</gtr:id><gtr:title>Color Homography</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/45883e203b86c1a711c4df9ec291bd7e"><gtr:id>45883e203b86c1a711c4df9ec291bd7e</gtr:id><gtr:otherNames>Finlayson G D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>588636d351c0f2.60906364</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6E21F37E-9A44-4EC6-A69E-7B820D638EA5</gtr:id><gtr:title>3D color homography model for photo-realistic color transfer re-coding</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7998d4ee273850d37439417c15334631"><gtr:id>7998d4ee273850d37439417c15334631</gtr:id><gtr:otherNames>Gong H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a748d623cb239.57184135</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94651FFE-BE72-4E98-A91B-52F42B53DE98</gtr:id><gtr:title>Color Homography Color Correction</gtr:title><gtr:parentPublicationTitle>Color and Imaging Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8879ef5121d8d4a4ff256c71412b8da0"><gtr:id>8879ef5121d8d4a4ff256c71412b8da0</gtr:id><gtr:otherNames>Finlayson G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a748cfe4d9af1.84941477</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D8306ACE-08B4-4B4F-9B8D-89EA31AC3A2C</gtr:id><gtr:title>Color Homography: theory and applications</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8879ef5121d8d4a4ff256c71412b8da0"><gtr:id>8879ef5121d8d4a4ff256c71412b8da0</gtr:id><gtr:otherNames>Finlayson G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8a9af71d8b65.20166699</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>076A90A2-9A40-4AB5-BC8A-72305F52404A</gtr:id><gtr:title>Recoding Color Transfer as a Color Homography</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7998d4ee273850d37439417c15334631"><gtr:id>7998d4ee273850d37439417c15334631</gtr:id><gtr:otherNames>Gong H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>588636332c7b37.03815247</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>884AB132-B7B2-483B-8E5D-8C06E12B6D9E</gtr:id><gtr:title>Color Homography Color Correction</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/45883e203b86c1a711c4df9ec291bd7e"><gtr:id>45883e203b86c1a711c4df9ec291bd7e</gtr:id><gtr:otherNames>Finlayson G D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>588635b727b634.36909761</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M00189X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>