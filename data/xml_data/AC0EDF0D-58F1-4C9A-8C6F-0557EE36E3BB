<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/A0A585E0-6B0D-4643-A3A6-47943B4CBFEF"><gtr:id>A0A585E0-6B0D-4643-A3A6-47943B4CBFEF</gtr:id><gtr:name>University of Liverpool</gtr:name><gtr:department>Electrical Engineering and Electronics</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line2>Abercromby Square</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L69 3BX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A0A585E0-6B0D-4643-A3A6-47943B4CBFEF"><gtr:id>A0A585E0-6B0D-4643-A3A6-47943B4CBFEF</gtr:id><gtr:name>University of Liverpool</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line2>Abercromby Square</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L69 3BX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/762EEFE2-22D9-4836-AEBC-B7BAE2E694F4"><gtr:id>762EEFE2-22D9-4836-AEBC-B7BAE2E694F4</gtr:id><gtr:firstName>Maxine</gtr:firstName><gtr:surname>Power</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/278D130A-8219-49DC-925B-B102070E1806"><gtr:id>278D130A-8219-49DC-925B-B102070E1806</gtr:id><gtr:firstName>John</gtr:firstName><gtr:otherNames>Yannis</gtr:otherNames><gtr:surname>Goulermas</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE004156%2F1"><gtr:id>AC0EDF0D-58F1-4C9A-8C6F-0557EE36E3BB</gtr:id><gtr:title>AN AUTOMATED IMAGE ANALYSIS AND MEASUREMENT SYSTEM FOR VIDEO-FLUOROSCOPIC EVALUATION OF SWALLOWING DYSFUNCTIONS.</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E004156/1</gtr:grantReference><gtr:abstractText>Although swallowing is a function performed effortlessly hundreds of times daily by healthy humans, it is an extremely complex process that involves the rapid and precise coordination of numerous muscles and tissues in the human body. In stroke (that affects thousands of people every year in the UK with an annual NHS cost of 2.3 billion) and many other pathologies of the nervous system, dysphagia (abnormal swallowing) frequently occurs and can lead to fatal pneumonia. Video-Fluoroscopy (VF) is the gold-standard for diagnosing dysphagia. For a VF swallowing study, the patient is seated comfortably and given barium enriched (to become opaque in the x-ray) liquid. The patient swallows while x-ray video images of the head and neck are being recorded. This video has to be manually examined by clinicians, but this task is visually demanding, extremely time consuming and error prone, since it requires the replay of the entire video frame-by-frame in slow motion and the very careful examination of the involved anatomical areas. This has direct consequences to the diagnostic accuracy.We propose to develop a system that processes the entire video sequence automatically and calculates measurements that are critical for robust diagnosis by the clinician. Specifically, instead of the clinicians examining the video data frame-by-frame in slow motion, the system will be able to do the job automatically and provide the clinicians with the required measurements. We propose to do this through the development of image processing algorithms that segment an image to its constituent regions. These regions will be the specified anatomical areas and the liquid during swallowing. By automatically tracking all these regions during time, the system will be able to calculate all measurements needed by the clinician to perform a diagnosis. After the algorithms are developed, we plan to apply the system to normal and affected subjects, and compare the automatically calculated measurements with ones estimated manually. The proposed work will have significant benefits on patients, NHS and the scientific community. It is novel as none of the previous works attempted the proposed automation, and is timely due to the current needs for improving the effectiveness of VF-based evaluation.</gtr:abstractText><gtr:fund><gtr:end>2009-10-25</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-04-26</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>188534</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>7A786009-4EEE-461D-A456-0FFD1AD35B9D</gtr:id><gtr:title>Automated anatomical demarcation using an active shape model for videofluoroscopic analysis in swallowing.</gtr:title><gtr:parentPublicationTitle>Medical engineering &amp; physics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a85c4491c06a2a98e90a5c76b3446c46"><gtr:id>a85c4491c06a2a98e90a5c76b3446c46</gtr:id><gtr:otherNames>Aung MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1350-4533</gtr:issn><gtr:outcomeId>doi_53d000000edb9fca</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C752B253-53C2-497B-9462-1DF08EB21B73</gtr:id><gtr:title>Measuring Bolus Transit Times from Videofluoroscopy Using Image Profiles and Particle Swarm Optimisation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aff0b9f9080aa0f1db5c2bf5ca4b438f"><gtr:id>aff0b9f9080aa0f1db5c2bf5ca4b438f</gtr:id><gtr:otherNames>Aung M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-5401-3</gtr:isbn><gtr:outcomeId>doi_53d0570575377497</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E004156/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>76783275-A9F8-4B4E-B314-51363124259C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Fundamentals of Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>