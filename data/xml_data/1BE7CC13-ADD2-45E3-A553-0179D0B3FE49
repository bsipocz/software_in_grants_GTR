<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3E18DACB-05AA-4C71-88FB-C909A8311BB5"><gtr:id>3E18DACB-05AA-4C71-88FB-C909A8311BB5</gtr:id><gtr:name>Birkbeck College</gtr:name><gtr:department>Psychological Sciences</gtr:department><gtr:address><gtr:line1>Malet Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 7HX</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3E18DACB-05AA-4C71-88FB-C909A8311BB5"><gtr:id>3E18DACB-05AA-4C71-88FB-C909A8311BB5</gtr:id><gtr:name>Birkbeck College</gtr:name><gtr:address><gtr:line1>Malet Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 7HX</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/EDB55F61-EF46-40F4-814A-AE2577213A94"><gtr:id>EDB55F61-EF46-40F4-814A-AE2577213A94</gtr:id><gtr:firstName>Martin</gtr:firstName><gtr:surname>Eimer</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FK006142%2F1"><gtr:id>1BE7CC13-ADD2-45E3-A553-0179D0B3FE49</gtr:id><gtr:title>Images in the mind: The control of visual object selection by attentional templates</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/K006142/1</gtr:grantReference><gtr:abstractText>&lt;p>Human visual perception is strongly affected by current expectations and intentions. What is perceived is determined by what is attended, and what is attended is determined by &amp;quot;images in the mind&amp;quot; that guide attention in line with active goals and preferences. This project uses new experimental procedures and methodological techniques (including temporally precise measures of electrical brain activity) to investigate how many things can be attended at any time, and to study the adverse consequences of having to simultaneously attend to multiple objects in perception, visual working memory, and action.&lt;/p>

&lt;p>&amp;nbsp;&lt;/p>

&lt;p>Are there systematic differences between individuals in their ability to attend to more than one thing at a time? New methods will be developed to obtain precise measures of the speed of voluntary visual attention shifts: If attention is engaged at a particular location, how fast can it be moved to a new potentially relevant object? Initial results suggest that the top-down guidance of attention is faster and more flexible than usually assumed, and the project will test whether and under which circumstances this is the case. Experimental results will have important consequences for current theoretical models of how attention operates.&lt;/p></gtr:abstractText><gtr:potentialImpactText>Attentional templates (&amp;quot;images in the mind&amp;quot;) control which objects and events we perceive and select, and which types of actions we choose at any given moment. Although the research proposed in this project is primarily basic cognitive/psychological research into the fundamental properties of these &amp;quot;images&amp;quot; and how they affect perception and action, insights from our research will also have practical implications, which we intend to disseminate to the wider public as well as to interested user groups.
 In real-world contexts, visual search for target objects and events, and its control by attentional templates, has obvious practical applications in specialist fields where professionals with high expertise and extensive training are expected to make critical decisions based on potentially ambiguous visual information, such as in security contexts (e.g., security officers searching scanned x-ray images of luggage for suspicious items) and in medical diagnostics (e.g., a radiologist examining MRI scans for abnormal tissue). A better understanding of the factors that determine successful target detection may help to improve user interfaces in such contexts. It may also have general implications for the search strategies employed by specialists involved in such tasks (e.g., feature-based search sets linked to the colour-coding of organic versus non-organic substances in airport security scanners), and thus for their training. 
 We will make all outcomes of our research available not only through the standard routes (publications in peer-reviewed top-quality journals), but also through posting of the most relevant findings on the website, as well as through directly informing the media about findings that are likely to be of interest to the general public. In addition, we will actively explore possibilities of directly communicating with experts in relevant applied fields (e.g., institutions or individuals involved in the training of specialist personnel responsible for real-life visual search tasks, as in medical or security-related contexts; visual interface designers for scanning or general monitoring devices). We will work with Birkbeck's Business Relations unit to contact institutions and individuals in these applied areas, with the longer-term aim of establishing collaborative links that could result in more formal interactions, such as a knowledge transfer partnership. The Department of Psychology is currently in the process of appointing an Impact Officer who will be specifically involved in promoting impact-related activities associated with scientific research in our department. We anticipate that the applied implications of the research proposed here will make it particularly suitable for such future impact initiatives.
 The applicant has also been active in promoting the impact-related aspects of experimental attention research to audiences beyond the narrow confines of experimental psychology. He was one of the keynote speaker at an interdisciplinary workshop on &amp;quot;The Psychology and Economics of Scarce Attention&amp;quot; at the Institut d'Economie Industrielle in Toulouse in September 2011, which brought together world-leading psychologists, neuroscientists, and economists to discuss how cognitive and neuroanatomical constraints determine how human subjects allocate attention, and the implications of this for economic decision-making. A detailed pamphlet summarizing the outcome of this meeting by Diane Coyle (www.enlightenmenteconomics.com) is available on-line (http://www.idei.fr/doc/conf/psy/2011/summary.pdf). We will maintain and extend these contacts with economists, and will seek to develop the translational aspects of our research in order to apply them to issues associated with choice and selection, as addressed by economists.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2013-12-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>297321</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The research conducted in this project was basic experimental neuroscience/cognitive psychology , with potential implications for education and ergonomics.
Our research results have been presented at numerous conferences and in a large number of peer-reviewed academic publications. Because of their nature, our insights into the time course and functional organisation of attentional control processes and its neural basis do not have any immediate and directly measurable societal and economic impacts. Our insights into some surprising limitations of these control processes (especially with respect to the limited role of object representations for attentional guidance) do however have interesting implications for general attentional management strategies in educational contexts as well as for human/computer interface designs. The PI is currently planning to prepare an article aimed at an audience interested in applied research where these implications are discussed.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>E543F847-A522-453F-BE66-C4FA11051C52</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>544908ab6b1733.57517697</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Education</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The goal of this research project was to obtain new insights into how mental representations of task-relevant features and objects guide our attention. We have developed new experimental procedures and new methodological techniques (including temporally precise measures of electrical brain activity obtained while observers are engaged in attentional selection tasks) to investigate a series of interrelated questions, described below. The research conducted in this project was exceptionally productive, and has resulted in more than 20 publications. Most of them were in leading high-impact journals in the field, and many of our recent findings have already received substantial attention from other researchers world-wide. Results have also been disseminated at national and international conferences, including the Annual Meetings of the Vision Sciences Society (VSS), of the European Society of Cognitive Psychology (ESCOP), International Meetings of the Psychonomic Society, the European Conference on Visual Perception (ECVP), as well as Meetings of the UK Experimental Psychology Society (EPS), and at national and international departmental seminars and workshops (including presentations in Australia, USA, the Netherlands, Germany, Switzerland, and Austria).

We have found new answers to some of the fundamental questions that have been debated by experimental psychologists for a long time, including the following. Can we attend to more than one feature/object simultaneously? Answer: Yes, but at some cost for the speed of attentional selectivity (e.g., Grubert &amp;amp; Eimer, 2015, JEP:HPP; Grubert &amp;amp; Eimer, 2016, JEP:HPP; Grubert, Carlisle, &amp;amp; Eimer, 2016, JOCN). Do attentional templates represent integral visual objects or separate representations of individual task-relevant features? Answer: At the most fundamental level of rapid attentional control, templates are representations of features that control attention independently and simultaneously. Integrated object representations only emerge at a subsequent stage of attentional processing (e.g., Eimer &amp;amp; Grubert, 2014; JEP:HPP). If attention is engaged at a particular location, how fast can it be moved to a new potentially relevant object? Answer: We have shown that in many situations, attention can be shifted to a new location but be simultaneously be maintained at its original location (e.g., Eimer &amp;amp; Grubert, 2014, CurrBiol; Grubert &amp;amp; Eimer, 2015, JEP:HPP). We have also demonstrated that attention can be directed independently and simultaneously to multiple task-relevant objects, as proposed by parallel models of attentional selectivity (e.g., Grubert &amp;amp; Eimer, 2016, BiolPsych; Jenkins, Grubert, &amp;amp; Eimer, 2016; JOCN). Critically, we have also developed new methods designed to impose strictly sequential movements of attention between visual objects. Such serial shifts can be triggered within 60 ms of each other, in line with what has been proposed on the basis of purely behavioural data by serial models of visual search (Grubert &amp;amp; Eimer, 2016; JOCN). Can attentional templates also represent more abstract information, such as target-defining categories? Answer: Most definitely yes - we have demonstrated remarkably efficient attentional control by categories in numerous experiments (e.g., Nako et al., 2014, JEP:HPP; Nako, Grubert, &amp;amp; Eimer, 2016, JEP:HPP; Jenkins et al., 2016, JOCN). 
One further indication of the success of this grant is that the postdoctoral RA on this grant (Dr Anna Grubert) has been successful in obtaining a permanent Lectureship position at Durham University, which started on 1 September 2016.</gtr:description><gtr:exploitationPathways>This is basic experimental neuroscience, with potential implications for education and ergonomics.</gtr:exploitationPathways><gtr:id>B05F2BC6-5FD9-4845-AB7A-AF9C75DDCDFA</gtr:id><gtr:outcomeId>54490892074228.37634312</gtr:outcomeId><gtr:sectors><gtr:sector>Education</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>59DE59EE-B449-4505-ABA7-F0E5BCB294AF</gtr:id><gtr:title>The Oxford Handbook of Attention</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0e96dab9063879f6f66ced1258177558"><gtr:id>0e96dab9063879f6f66ced1258177558</gtr:id><gtr:otherNames>Eimer, M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-0-19-967511-1</gtr:isbn><gtr:outcomeId>5448fdd9da3c52.15677381</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0702B179-3D87-4DA3-8D35-C0C896CA154B</gtr:id><gtr:title>Rapid guidance of visual search by object categories.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9f08cbc36bc515ad6e21b0c161c28d65"><gtr:id>9f08cbc36bc515ad6e21b0c161c28d65</gtr:id><gtr:otherNames>Nako R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>541fecf81c83b4.29531935</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>511E5485-B673-42A6-A57E-B40A0B287773</gtr:id><gtr:title>Searching for something familiar or novel: top-down attentional selection of specific items or object categories.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/253054702d11f52d5a51c18d9946083e"><gtr:id>253054702d11f52d5a51c18d9946083e</gtr:id><gtr:otherNames>Wu R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>541fecb04f52b8.19072392</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5E36A6B3-D7DF-447F-8894-F3220DF71D46</gtr:id><gtr:title>Rapid Parallel Attentional Selection Can Be Controlled by Shape and Alphanumerical Category.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/df5dab2d58f5d48407448135c9c4da20"><gtr:id>df5dab2d58f5d48407448135c9c4da20</gtr:id><gtr:otherNames>Jenkins M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5829d4a75901b2.41455488</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5335A0C6-3875-4952-9F21-678464F5E9EF</gtr:id><gtr:title>Spatial attention can be allocated rapidly and in parallel to new visual objects.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cae372acc1c9002d24cd87115d277a93"><gtr:id>cae372acc1c9002d24cd87115d277a93</gtr:id><gtr:otherNames>Eimer M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>5449028a7d05e4.07630782</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E1B2D051-1EFA-459C-99A3-E648A738390B</gtr:id><gtr:title>The neural basis of attentional control in visual search.</gtr:title><gtr:parentPublicationTitle>Trends in cognitive sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cae372acc1c9002d24cd87115d277a93"><gtr:id>cae372acc1c9002d24cd87115d277a93</gtr:id><gtr:otherNames>Eimer M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1364-6613</gtr:issn><gtr:outcomeId>541fedaa3d2ff7.76428750</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4F5C7A89-4EFA-4D99-A8FD-068E15462F32</gtr:id><gtr:title>Visual search is postponed during the period of the AB: An event-related potential study.</gtr:title><gtr:parentPublicationTitle>Psychophysiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/338aef5b6f242e2fd5da3279af3aab83"><gtr:id>338aef5b6f242e2fd5da3279af3aab83</gtr:id><gtr:otherNames>Lagroix HE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0048-5772</gtr:issn><gtr:outcomeId>5603caf78e6304.02280080</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>57CB8E79-5303-4C44-AFB6-7A845D14F868</gtr:id><gtr:title>A dissociation between selective attention and conscious awareness in the representation of temporal order information.</gtr:title><gtr:parentPublicationTitle>Consciousness and cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cae372acc1c9002d24cd87115d277a93"><gtr:id>cae372acc1c9002d24cd87115d277a93</gtr:id><gtr:otherNames>Eimer M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1053-8100</gtr:issn><gtr:outcomeId>5603caf730cbf5.82801189</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8B9AE349-F84F-4157-8D35-E4D769C7BF22</gtr:id><gtr:title>Rapid top-down control over template-guided attention shifts to multiple objects.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>5829d4a90e3252.23224218</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>999E3116-ED2F-4A6F-BD69-36F7850FCCA1</gtr:id><gtr:title>Item and category-based attentional control during search for real-world objects: Can you find the pants among the pans?</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9f08cbc36bc515ad6e21b0c161c28d65"><gtr:id>9f08cbc36bc515ad6e21b0c161c28d65</gtr:id><gtr:otherNames>Nako R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>541fef132b7d11.29556040</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>78D09258-FF86-4EEF-AC49-AECC0483F74B</gtr:id><gtr:title>Rapid attentional selection processes operate independently and in parallel for multiple targets.</gtr:title><gtr:parentPublicationTitle>Biological psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0301-0511</gtr:issn><gtr:outcomeId>5829d4a71e4836.38998724</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5133A16F-3B3E-429E-8742-76B48EEA373E</gtr:id><gtr:title>Target objects defined by a conjunction of colour and shape can be selected independently and in parallel.</gtr:title><gtr:parentPublicationTitle>Attention, perception &amp; psychophysics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/df5dab2d58f5d48407448135c9c4da20"><gtr:id>df5dab2d58f5d48407448135c9c4da20</gtr:id><gtr:otherNames>Jenkins M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1943-3921</gtr:issn><gtr:outcomeId>5a1d383e5e24c4.43447384</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9FF39E3C-9560-431B-AC35-EA073E467544</gtr:id><gtr:title>Qualitative differences in the guidance of attention during single-color and multiple-color visual search: behavioral and electrophysiological evidence.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>541febb878f3c7.89167279</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>57A7109D-BB60-47B7-A086-E3DA16B406A2</gtr:id><gtr:title>A unitary focus of spatial attention during attentional capture: Evidence from event-related brain potentials.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>541fec2949aa87.40114353</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FBDB1210-349F-4E5C-8192-6103386BA17C</gtr:id><gtr:title>Intermodal Attention Shifts in Multimodal Working Memory.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d1ce947e1da708714fcf7119d6ad1293"><gtr:id>d1ce947e1da708714fcf7119d6ad1293</gtr:id><gtr:otherNames>Katus T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5829d4a8e75d30.07086152</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AC6D200B-AEAB-4F53-9241-C5C127D43CB9</gtr:id><gtr:title>Lateralized delay period activity marks the focus of spatial attention in working memory: evidence from somatosensory event-related brain potentials.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d1ce947e1da708714fcf7119d6ad1293"><gtr:id>d1ce947e1da708714fcf7119d6ad1293</gtr:id><gtr:otherNames>Katus T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>5603caf7e3e784.16167518</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AF026350-4C06-4977-AFB4-1C697FAAA167</gtr:id><gtr:title>Nasotemporal ERP differences: evidence for increased inhibition of temporal distractors.</gtr:title><gtr:parentPublicationTitle>Journal of neurophysiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a2cc7bd098f1921d132717fbf8a0513b"><gtr:id>a2cc7bd098f1921d132717fbf8a0513b</gtr:id><gtr:otherNames>Huber-Huber C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0022-3077</gtr:issn><gtr:outcomeId>5603caf7047249.79251030</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3072CCBE-AF06-4BAF-AAE8-78D0E20EC1BA</gtr:id><gtr:title>The Speed of Serial Attention Shifts in Visual Search: Evidence from the N2pc Component.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>56af896127a616.10422937</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2090A94D-6B3F-4725-A232-BF39F5CF40B2</gtr:id><gtr:title>Category-based guidance of spatial attention during visual search for feature conjunctions.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9f08cbc36bc515ad6e21b0c161c28d65"><gtr:id>9f08cbc36bc515ad6e21b0c161c28d65</gtr:id><gtr:otherNames>Nako R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>5829d4a7c16216.76498663</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B60C52ED-1A1F-4C03-B206-1C81C7BE1852</gtr:id><gtr:title>The Control of Single-color and Multiple-color Visual Search by Attentional Templates in Working Memory and in Long-term Memory.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5829d4a6bd4a77.65944918</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8966D279-44E3-4249-AAD5-31D15B5C37B3</gtr:id><gtr:title>Multivariate EEG analyses support high-resolution tracking of feature-based attentional selection.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b4368d03144b5d4d5d7997f5caced15b"><gtr:id>b4368d03144b5d4d5d7997f5caced15b</gtr:id><gtr:otherNames>Fahrenfort JJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn><gtr:outcomeId>5a1d38826765a9.47384183</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D449FD84-69A7-4AD7-ABE6-F64A8434B20A</gtr:id><gtr:title>Rapid parallel attentional target selection in single-color and multiple-color visual search.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>5603caf6c35b68.48539885</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>392E468C-BC48-4C9D-949F-7C1F83312230</gtr:id><gtr:title>The speed of voluntary and priority-driven shifts of visual attention.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/df5dab2d58f5d48407448135c9c4da20"><gtr:id>df5dab2d58f5d48407448135c9c4da20</gtr:id><gtr:otherNames>Jenkins M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>5a1d38ca744c25.01809868</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8E16A157-AABD-44FE-A020-CFAEB78F9858</gtr:id><gtr:title>Activation of new attentional templates for real-world objects in visual search.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9f08cbc36bc515ad6e21b0c161c28d65"><gtr:id>9f08cbc36bc515ad6e21b0c161c28d65</gtr:id><gtr:otherNames>Nako R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>5603caf68416f6.53089331</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C6656805-5FB5-4989-A06E-EFFF450B3087</gtr:id><gtr:title>Electrophysiological Evidence for a Sensory Recruitment Model of Somatosensory Working Memory.</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d1ce947e1da708714fcf7119d6ad1293"><gtr:id>d1ce947e1da708714fcf7119d6ad1293</gtr:id><gtr:otherNames>Katus T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>541fefafcaa935.24558438</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E991D937-F3A8-4EFE-AC8C-473552BF600E</gtr:id><gtr:title>All set, indeed! N2pc components reveal simultaneous attentional control settings for multiple target colors.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>5829d4a82a67f1.77225366</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1009D7FB-F2FE-4DAD-BAB2-32828FFC48A9</gtr:id><gtr:title>Does visual working memory represent the predicted locations of future target objects? An event-related brain potential study.</gtr:title><gtr:parentPublicationTitle>Brain research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0270db24e682e72ae46b566ce7a8ad5d"><gtr:id>0270db24e682e72ae46b566ce7a8ad5d</gtr:id><gtr:otherNames>Grubert A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0006-8993</gtr:issn><gtr:outcomeId>5675dd377361d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>53CF0AC5-B89A-4AD7-93D2-B4E8CA7C1C3D</gtr:id><gtr:title>The gradual emergence of spatially selective target processing in visual search: From feature-specific to object-based attentional control.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cae372acc1c9002d24cd87115d277a93"><gtr:id>cae372acc1c9002d24cd87115d277a93</gtr:id><gtr:otherNames>Eimer M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>541fea248e8ba4.68684202</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/K006142/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>