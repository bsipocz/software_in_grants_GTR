<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/1529782F-9068-4364-888E-46E4FC4881F5"><gtr:id>1529782F-9068-4364-888E-46E4FC4881F5</gtr:id><gtr:name>Nottingham Trent University</gtr:name><gtr:department>Sch of Social Sciences</gtr:department><gtr:address><gtr:line1>Burton Street</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG1 4BU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1529782F-9068-4364-888E-46E4FC4881F5"><gtr:id>1529782F-9068-4364-888E-46E4FC4881F5</gtr:id><gtr:name>Nottingham Trent University</gtr:name><gtr:address><gtr:line1>Burton Street</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG1 4BU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3CF46228-FC4E-49BE-B553-9CE279ED7A47"><gtr:id>3CF46228-FC4E-49BE-B553-9CE279ED7A47</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:surname>Lansdale</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE006876%2F1"><gtr:id>324160BC-9DAC-4FE9-AFED-7F313BEF2AB8</gtr:id><gtr:title>Exploiting spatial cognition in picture database design</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E006876/1</gtr:grantReference><gtr:abstractText>The commercial and functional potential of picture databases is very great for a range of applications from medicine to medieval history. However, this potential is proving difficult to deliver and research activity in this area is intense. There are two principal approaches: i) extending existing methods to encode pictures by description and keywords; and ii) computational analysis of images to capture superficial aspects such as colour and texture; aiming to remove the effort of entering pictures into a database and to allow user's crude depictions to access subsets of pictures to be searched for recognition. However, current opinion suggests neither approach is likely in the medium term to deliver cost-effective solutions to the problem except in highly specialised areas.Our research proposes to innovate by considering the problem from a third, psychological, perspective: human spatial cognition is robust, and we are generally good at inspecting pictures and recalling their spatial layout later. Furthermore, the layout of most images can be described in ways that preserve elements of meaning and visual distinctiveness. Ideally therefore, databases that encode location information in pictures, and allow users to use that information in retrieval, represent a match of human skills with a method generally applicable to most task domains. To this end, this proposal links two lines of psychological research. First, we are interested in visual attention: how do people look at pictures? For the purposes of database design, we are interested in the relationship between picture content and attention; as expressed in eye movements. Although eye movements are variable, they do show elements of consistency. We will be concerned with how best to represent and evaluate this consistency as a function of factors such as: the picture content; different observers; task domain; and delay between storage and retrieval.Second, we aim to study how the spatial layout of images is remembered as a consequence of attention. Can we use our understanding of visual attention processes (and eye movements in particular) to predict spatial recall? How precise is this spatial knowledge, how could it be used, and how discriminating is it in the retrieval of images from a database? There are two issues here: (i) We know that some location knowledge is acquired very quickly in the inspection processes. This is also the stage when the viewer's eye movements are more predictable by computer because they are driven by visual analysis of the image and less upon its meaning. It follows that if we can model the relationship between early eye movements and location memory, and if that memory is useful in retrieval, then some indexing of pictures into databases can be automated. This research aims to evaluate this potential; (ii), As inspection continues, eye movements become harder to predict as the viewer's understanding of the content of the image develops. We aim to show how this meaning influences eye movements and the impact of this upon location memory beyond that gained in the early stages of viewing. Overall, these two complementary questions will tell us how much picture coding can be automated and how task- and user- specific factors will influence design.As a study of the feasibility of this innovation to the design of picture databases, this proposal also considers the adaptability and efficiency of the approach in different circumstances. Accordingly, in evaluating the cost benefits to picture databases, the project will seek to measure the contribution of: domain expertise, training, and some interface design issues. This will indicate whether the approach has general applicability in picture databases or whether it is best applied to bespoke, specialist, systems where training and expertise is required.</gtr:abstractText><gtr:fund><gtr:end>2008-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-16</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>308537</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings underpin an innovative approach to the design of picture databases; currently under development and for which patents are being filed</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>BE54994E-52D4-43A8-9F26-FAE2E5FB9DDD</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545a352a5bb571.91845501</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The grant produced three bodies of work each of which make significant contributions to the overall aims:

1) When viewing pictures, the only information of significance for the viewer's subsequent recall of them is the areas of interest visited; and critically; not the order in which they were viewed;
2) Representation of object location in memory is derived from the earliest stages of viewing in which eye movements to the next fixation are being planned and consists of vectors representing the relative direction of one object in relation to another;
3) Memory for complex images requires recall of very few such vectors to specify the recall of the spatial configuration of complex scenes accurately. In other words, human memory is employing a highly adaptive and efficient method of encoding.</gtr:description><gtr:exploitationPathways>This research is currently subject to a patent application (hence the delayed appearance of academic articles). It is reasonable to say that this work has application in the design of picture databases, but I am unable to specify further at this stage.</gtr:exploitationPathways><gtr:id>9219B390-8DB7-4C9A-BAE2-8A244BD1229D</gtr:id><gtr:outcomeId>545a34b1258402.69971933</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Culture, Heritage, Museums and Collections,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>678CD36A-DDB3-477B-B096-8A205EF65757</gtr:id><gtr:title>Something Overlooked? How experts in change detection use visual saliency</gtr:title><gtr:parentPublicationTitle>Applied Cognitive Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6516fa583e34bb2fdde2eea11dadb117"><gtr:id>6516fa583e34bb2fdde2eea11dadb117</gtr:id><gtr:otherNames>Lansdale M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53cfbffbf2fa2506</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E006876/1</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>324160BC-9DAC-4FE9-AFED-7F313BEF2AB8</gtr:id><gtr:grantRef>EP/E006876/1</gtr:grantRef><gtr:amount>308537.88</gtr:amount><gtr:start>2006-10-16</gtr:start><gtr:end>2008-04-30</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>DC3121C0-5F32-4370-9A9F-55B2B8002A55</gtr:id><gtr:grantRef>EP/E006876/2</gtr:grantRef><gtr:amount>142101.97</gtr:amount><gtr:start>2008-05-01</gtr:start><gtr:end>2009-12-31</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>