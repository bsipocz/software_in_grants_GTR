<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/536116AC-C155-4A24-A743-309BD68E50CE"><gtr:id>536116AC-C155-4A24-A743-309BD68E50CE</gtr:id><gtr:name>Defence Science &amp; Tech Lab DSTL</gtr:name><gtr:address><gtr:line1>Defence Science &amp; Tech Lab - MOD</gtr:line1><gtr:line2>Porton Down</gtr:line2><gtr:line4>Salisbury</gtr:line4><gtr:postCode>SP4 0JQ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B2F1DE67-D494-4AE0-A66F-351680253A00"><gtr:id>B2F1DE67-D494-4AE0-A66F-351680253A00</gtr:id><gtr:name>Home Office Sci Development Branch</gtr:name><gtr:address><gtr:line1>Langhurst House,</gtr:line1><gtr:line2>Langhurst Wood Road</gtr:line2><gtr:line4>Horsham</gtr:line4><gtr:line5>West Sussex</gtr:line5><gtr:postCode>RH12 4WX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/6E33201A-4224-4D4C-B496-4A8E4AF23209"><gtr:id>6E33201A-4224-4D4C-B496-4A8E4AF23209</gtr:id><gtr:name>Ultra Electronics Limited</gtr:name><gtr:address><gtr:line1>Ultra Electronics Ltd</gtr:line1><gtr:line2>419 Bridport Road</gtr:line2><gtr:line4>Greenford</gtr:line4><gtr:postCode>UB6 8UA</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/50510C52-0CF5-4095-A6E8-5A95BBC2F84B"><gtr:id>50510C52-0CF5-4095-A6E8-5A95BBC2F84B</gtr:id><gtr:name>Tyco Fire &amp; Integrated Solutions Ltd.</gtr:name><gtr:address><gtr:line1>Tyco Integrated Systems</gtr:line1><gtr:line2>Bridge House</gtr:line2><gtr:line3>Saxon Way, Bar Hill</gtr:line3><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB3 8TY</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/38006814-9130-49B7-A5D5-274211E5856A"><gtr:id>38006814-9130-49B7-A5D5-274211E5856A</gtr:id><gtr:name>Liverpool City Council</gtr:name><gtr:address><gtr:line1>Municipal Buildings</gtr:line1><gtr:line2>Dale Street</gtr:line2><gtr:postCode>L69 2DH</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DFF6A755-4D98-4A5E-B46D-B19E3F4A5F2D"><gtr:id>DFF6A755-4D98-4A5E-B46D-B19E3F4A5F2D</gtr:id><gtr:name>Smart CCTV Ltd</gtr:name><gtr:address><gtr:line1>16 The Oakwood Centre</gtr:line1><gtr:line2>Downley Road</gtr:line2><gtr:line4>Havant</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>PO9 2NP</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5F961B89-2879-410D-A939-48D8A153CB77"><gtr:id>5F961B89-2879-410D-A939-48D8A153CB77</gtr:id><gtr:name>Ministry of Defence MOD</gtr:name><gtr:address><gtr:line1>Director General</gtr:line1><gtr:line2>Research &amp; Technology</gtr:line2><gtr:line3>Mail Centre Main Building, Horse Guards</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SW1A 2HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2E60B81F-B1D4-4416-A04B-1C760D892A92"><gtr:id>2E60B81F-B1D4-4416-A04B-1C760D892A92</gtr:id><gtr:firstName>Shaogang</gtr:firstName><gtr:surname>Gong</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/7F75BAD0-CD11-40DC-BF44-43B483A316F8"><gtr:id>7F75BAD0-CD11-40DC-BF44-43B483A316F8</gtr:id><gtr:firstName>Tao</gtr:firstName><gtr:surname>Xiang</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE028594%2F1"><gtr:id>D68ECA09-7C82-4259-9F9B-7B0EFDFD0D2F</gtr:id><gtr:title>BEWARE: Behaviour based Enhancement of Wide-Area Situational Awareness in a Distributed Network of CCTV Cameras</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E028594/1</gtr:grantReference><gtr:abstractText>There are now large networks of CCTV cameras collecting colossal amounts of video data, of which many deploy not only fixed but also mobile cameras on wireless connections with an increasing number of the cameras being either PTZ controllable or embedded smart cameras. A multi-camera system has the potential for gaining better viewpoints resulting in both improved imaging quality and more relevant details being captured. However, more is not necessarily better. Such a system can also cause overflow of information and confusion if data content is not analysed in real-time to give the correct camera selection and capturing decision. Moreover, current PTZ cameras are mostly controlled manually by operators based on ad hoc criteria. There is an urgent need for the development of automated systems to monitor behaviours of people cooperatively across a distributed network of cameras and making on-the-fly decisions for more effective content selection in data capturing. Todate, there is no system capable of performing such tasks and fundamental problems need to be tackled. This project will develop novel techniques for video-based people tagging (consistent labelling) and behaviour monitoring across a distributed network of CCTV cameras for the enhancement of global situational awareness in a wide area. More specifically, we will focus on developing three critical underpinning capabilities:(a) To develop a model for robust detection and tagging of people over wide areas of different physical sites captured by a distributed network of cameras, e.g. monitoring the activities of a person travelling through a city/cities.(b) To develop a model for global situational awareness enhancement via correlating behaviours across a network of cameras located at different physical sites, and for real-time detection of abnormal behaviours in public space across camera views; The model must be able to cope with changes in visual context and on definitions of abnormality, e.g. what is abnormal needs be modelled by the time of the day, locations, and scene context.(c) To develop a model for automatic selection and controlling of Pan-Tilt-Zoom (PTZ)/embedded smart cameras (including wireless ones) in a surveillance network to 'zoom into' people based on behaviour analysis using a global situational awareness model therefore achieving active sampling of higher quality visual evidence on the fly in a global context, e.g. when a car enters a restricted zone which has also been spotted stopping unusually elsewhere, the optimally situated PTZ/embedded smart camera is to be activated to perform adaptive image content selection and capturing of higher resolution imagery of, e.g. the face of the driver.</gtr:abstractText><gtr:fund><gtr:end>2011-01-01</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-07-02</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>623617</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>12000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:department>Centre for Defence Enterprise</gtr:department><gtr:description>MOD CDE</gtr:description><gtr:end>2012-04-02</gtr:end><gtr:fundingOrg>Defence Science &amp; Technology Laboratory (DSTL)</gtr:fundingOrg><gtr:id>6E2E9232-8A9C-411A-8247-07A57036F659</gtr:id><gtr:outcomeId>56ccd334c216b9.61910909</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>546000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:department>Seventh Framework Programme (FP7)</gtr:department><gtr:description>EU FP7 Security Programme</gtr:description><gtr:end>2017-07-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:id>A0C74FB4-EDDF-4F90-899B-AC8D2F9BD5CE</gtr:id><gtr:outcomeId>56ccc10bb66a46.27934334</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>413000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:department>Seventh Framework Programme (FP7)</gtr:department><gtr:description>EU FP7 Security Programme</gtr:description><gtr:end>2016-05-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:id>13B3F060-C0CF-45A5-ABB6-A2944B667288</gtr:id><gtr:outcomeId>56ccc1dc8a1ad2.20595820</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-03-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>69500</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Ministry of Defence</gtr:description><gtr:end>2015-03-02</gtr:end><gtr:fundingOrg>Ministry of Defence (MOD)</gtr:fundingOrg><gtr:id>8C4D0E2A-B308-4213-8530-D67E00DCF226</gtr:id><gtr:outcomeId>5ec80df45ec80e08</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>120000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Ministry of Defence</gtr:description><gtr:end>2015-09-02</gtr:end><gtr:fundingOrg>Ministry of Defence (MOD)</gtr:fundingOrg><gtr:id>721AA6F0-10F6-4091-BBF3-712C0E65F13B</gtr:id><gtr:outcomeId>r-1287519364.88553806a2aa12</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>111000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Royal Society Newton Advanced Fellowship</gtr:description><gtr:end>2019-02-02</gtr:end><gtr:fundingOrg>The Royal Society</gtr:fundingOrg><gtr:id>3177E677-820B-4624-A858-AA7C92421B49</gtr:id><gtr:outcomeId>56d5bec16aeab2.86588590</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-03-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>120000</gtr:amountPounds><gtr:country>United States of America</gtr:country><gtr:currCode>USD</gtr:currCode><gtr:currCountryCode>Ecuador</gtr:currCountryCode><gtr:currLang>es_EC</gtr:currLang><gtr:description>US Army Research Lab</gtr:description><gtr:end>2010-12-02</gtr:end><gtr:fundingOrg>US Army Research Lab</gtr:fundingOrg><gtr:id>87291B08-33EF-4DB0-A933-E8CBC7AAA732</gtr:id><gtr:outcomeId>5eb9e5085eb9e51c</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2008-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>412000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>BAE Systems</gtr:description><gtr:end>2013-05-02</gtr:end><gtr:fundingOrg>BAE Systems</gtr:fundingOrg><gtr:id>B6FFE648-346C-4388-8E83-9052D6BFADEE</gtr:id><gtr:outcomeId>5eb9ef125eb9ef26</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2010-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>108000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>DSTL</gtr:description><gtr:end>2012-03-02</gtr:end><gtr:fundingOrg>Defence Science &amp; Technology Laboratory (DSTL)</gtr:fundingOrg><gtr:id>55872922-1040-449B-96CA-E469D66297DA</gtr:id><gtr:outcomeId>56ccd44a949af9.47525242</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2011-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>12000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>British Airports Authority (BAA)</gtr:description><gtr:end>2011-11-02</gtr:end><gtr:fundingOrg>Heathrow Airport Holdings</gtr:fundingOrg><gtr:id>CD3539B1-2A52-4F21-B0A7-1E8F67500548</gtr:id><gtr:outcomeId>r-6891503675.739750683c444</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2011-01-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Spin-out company Vision Semantics; DSTL and MOD development contracts; US DOD development contracts; Patents licensing;</gtr:description><gtr:id>252F2E7A-7A04-470A-9E43-70FBF4FD656F</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56bfb6d9731188.92978120</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Developed mathematical models and computer systems for automatic person re-identification in public spaces over distributed networks of cameras, global situational correlation of human behaviours observed across a camera network, and abnormal behaviour recognition in crowded public spaces.



Selected Publications:



S. Gong and T. Xiang. Visual Analysis of Behaviour: From Pixels to Semantics, 376 pages, Springer, May 2011.



W. Zheng, S. Gong and T. Xiang. Re-identification by Relative Distance Comparison. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 35, No. 3, pp. 653-668, March 2013.



J. Li, S. Gong and T. Xiang. Learning Behavioural Context. International Journal of Computer Vision, Vol. 97, No. 3, pp. 276-304, May 2012. 



T. Hospedales, J. Li, S. Gong and T. Xiang. Identifying Rare and Subtle Behaviours: A Weakly Supervised Joint Topic Model. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 33, No. 12, pp. 2451-2464, December 2011.



C.C. Loy, T. Xiang and S. Gong. Time-Delayed Correlation Analysis for Multi-Camera Activity Understanding. International Journal of Computer Vision, Vol. 90, No. 1, pp. 106-129, October 2010.</gtr:description><gtr:exploitationPathways>Public security and safety; Infrastructure protection University spin-out company</gtr:exploitationPathways><gtr:id>783169CA-9AE1-431C-9776-1C3BF970A750</gtr:id><gtr:outcomeId>r-3440026336.75935377489326</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Security and Diplomacy,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.eecs.qmul.ac.uk/~sgg/BEWARE/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>Vision Semantics Ltd</gtr:companyName><gtr:description>Vision Semantics Ltd is a spin-out company of Queen Mary University of London, developing self-configuring video analysis and dynamic scene understanding tools &amp;amp; applications that employ innovative learning and statistical methods.</gtr:description><gtr:id>14429291-3D46-4305-87C7-D51F0FB3A359</gtr:id><gtr:impact>Five patents granted and pending, a joint venture start-up in the Far East (2012), a world-wide licensing for setting up another start-up (2014).</gtr:impact><gtr:outcomeId>m-6270856062.202579513307758</gtr:outcomeId><gtr:yearCompanyFormed>2007</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>66E43823-BF1C-452D-89A4-96B847317BF2</gtr:id><gtr:title>Recognising action as clouds of space-time interest points</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f42c6c4a0cea334c49169fb4af4a1eef"><gtr:id>f42c6c4a0cea334c49169fb4af4a1eef</gtr:id><gtr:otherNames>Bregonzio M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-3992-8</gtr:isbn><gtr:outcomeId>doi_53d05705746197ee</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4D9B0667-CAC8-4D1F-A8F1-8D2A46883A10</gtr:id><gtr:title>Quantifying contextual information for object detection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4845a879f74db024ebd17f1832778255"><gtr:id>4845a879f74db024ebd17f1832778255</gtr:id><gtr:otherNames>Wei-Shi Zheng</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4420-5</gtr:isbn><gtr:outcomeId>56bfa6bad44ea6.50982296</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5CD63121-8F4B-44ED-8B53-A793FAD14693</gtr:id><gtr:title>Multi-camera activity correlation analysis</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d825a5a42cb567805d255569972d6005"><gtr:id>d825a5a42cb567805d255569972d6005</gtr:id><gtr:otherNames>Chen Change Loy</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-3992-8</gtr:isbn><gtr:outcomeId>56bfa84cc16342.83044354</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3F78D6E-8E1F-4876-8E05-331000ECA1D5</gtr:id><gtr:title>Learning multimodal latent attributes.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a327b9a2fc29d8eb935d903258b855e"><gtr:id>6a327b9a2fc29d8eb935d903258b855e</gtr:id><gtr:otherNames>Fu Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf9fbbd6a333.11460157</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C734A726-7D57-422E-9EB8-BADEF68495A2</gtr:id><gtr:title>Modelling activity global temporal dependencies using Time Delayed Probabilistic Graphical Model</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/90e7a3a71faf9859dbc2f8194dd9b6f5"><gtr:id>90e7a3a71faf9859dbc2f8194dd9b6f5</gtr:id><gtr:otherNames>Loy C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4420-5</gtr:isbn><gtr:outcomeId>56bfa74a6933d3.06664156</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8182387E-F913-40C6-B79B-29528438767C</gtr:id><gtr:title>Transfer re-identification: From person to set-based verification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4845a879f74db024ebd17f1832778255"><gtr:id>4845a879f74db024ebd17f1832778255</gtr:id><gtr:otherNames>Wei-Shi Zheng</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1226-4</gtr:isbn><gtr:outcomeId>56bfad547bcd26.81942895</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0388613E-27EE-40EA-821B-E5979E7617AB</gtr:id><gtr:title>A Markov Clustering Topic Model for mining behaviour in video</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/099aff7d107f1a3f812f6edfe83b14d0"><gtr:id>099aff7d107f1a3f812f6edfe83b14d0</gtr:id><gtr:otherNames>Hospedales T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4420-5</gtr:isbn><gtr:outcomeId>56bfa7117f35e4.55358306</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FFDA2157-FE83-450D-BCC5-AC7365A04E52</gtr:id><gtr:title>Learning from Multiple Sources for Video Summarisation</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1172f97c22d54c3bbbc974671046c557"><gtr:id>1172f97c22d54c3bbbc974671046c557</gtr:id><gtr:otherNames>Zhu X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bf9d74319a69.15802870</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1E6641AF-695F-401F-80E0-A9EBF994EF04</gtr:id><gtr:title>Video Behaviour Mining Using a Dynamic Topic Model</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/099aff7d107f1a3f812f6edfe83b14d0"><gtr:id>099aff7d107f1a3f812f6edfe83b14d0</gtr:id><gtr:otherNames>Hospedales T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>56bf9474683448.75946043</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>081709CD-AFCA-4013-AE7C-080CB9C5BEB1</gtr:id><gtr:title>Incremental activity modeling in multiple disjoint cameras.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/164ae623860b6c9e1a568fab94e4af3e"><gtr:id>164ae623860b6c9e1a568fab94e4af3e</gtr:id><gtr:otherNames>Loy CC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf94e83ab897.01895367</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>37B265EC-9948-4291-9441-66A8DB5DDDA2</gtr:id><gtr:title>Fusing appearance and distribution information of interest points for action recognition</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f42c6c4a0cea334c49169fb4af4a1eef"><gtr:id>f42c6c4a0cea334c49169fb4af4a1eef</gtr:id><gtr:otherNames>Bregonzio M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>56bf95a5ced851.34415027</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>02582B7D-9EE3-420C-8C55-C942C48D919D</gtr:id><gtr:title>Detecting and discriminating behavioural anomalies</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/90e7a3a71faf9859dbc2f8194dd9b6f5"><gtr:id>90e7a3a71faf9859dbc2f8194dd9b6f5</gtr:id><gtr:otherNames>Loy C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>56bfa289528884.07676503</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>95774579-0F5A-4FD7-9B79-99DCBA06AAFC</gtr:id><gtr:title>Towards Open-World Person Re-Identification by One-Shot Group-Based Verification.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/839f7135318d379e02ac5c586a9e26bc"><gtr:id>839f7135318d379e02ac5c586a9e26bc</gtr:id><gtr:otherNames>Zheng WS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf9d96b71d23.17469727</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7BFB39CA-D03C-47DB-A0FB-7A115FB043CE</gtr:id><gtr:title>Quantifying and transferring contextual information in object detection.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/839f7135318d379e02ac5c586a9e26bc"><gtr:id>839f7135318d379e02ac5c586a9e26bc</gtr:id><gtr:otherNames>Zheng WS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf94b15b8100.02374564</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DC4C69FC-42C5-4F5B-98E5-959F1A2E1729</gtr:id><gtr:title>Person re-identification by probabilistic relative distance comparison</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4cadbaffa8796a72e06df565b9b84278"><gtr:id>4cadbaffa8796a72e06df565b9b84278</gtr:id><gtr:otherNames>Zheng W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-0394-2</gtr:isbn><gtr:outcomeId>56bf933e1df3c7.63790420</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CFD38CA9-1DEA-4017-81C5-2823CF9C4B74</gtr:id><gtr:title>Finding Rare Classes: Active Learning with Generative and Discriminative Models</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Knowledge and Data Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/099aff7d107f1a3f812f6edfe83b14d0"><gtr:id>099aff7d107f1a3f812f6edfe83b14d0</gtr:id><gtr:otherNames>Hospedales T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>56bfa013c34171.95294737</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AB3F2AD3-3211-4AFF-A37E-F95925CF5BA9</gtr:id><gtr:title>Learning Behavioural Context</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ad7968d586527c1fd3f76aeabf35ac38"><gtr:id>ad7968d586527c1fd3f76aeabf35ac38</gtr:id><gtr:otherNames>Li J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>56bf8a34e46a44.01035988</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3D9C424F-2C4A-45C2-A334-AD5E1883EB73</gtr:id><gtr:title>Time-Delayed Correlation Analysis for Multi-Camera Activity Understanding</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/90e7a3a71faf9859dbc2f8194dd9b6f5"><gtr:id>90e7a3a71faf9859dbc2f8194dd9b6f5</gtr:id><gtr:otherNames>Loy C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53cfdefdef658a55</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4DE1D123-B606-4EEA-B503-BF1D7664563B</gtr:id><gtr:title>Identifying Rare and Subtle Behaviors: A Weakly Supervised Joint Topic Model.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c2779ccae98312994e9949f895264718"><gtr:id>c2779ccae98312994e9949f895264718</gtr:id><gtr:otherNames>Hospedales TM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>doi_53d05e05efbf14ee</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F1333D15-85BA-486C-B06D-D90DA9C46182</gtr:id><gtr:title>Stream-based joint exploration-exploitation active learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/90e7a3a71faf9859dbc2f8194dd9b6f5"><gtr:id>90e7a3a71faf9859dbc2f8194dd9b6f5</gtr:id><gtr:otherNames>Loy C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1226-4</gtr:isbn><gtr:outcomeId>56bfade0e0ef00.81249270</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>702ACA95-0BA7-4AB4-A6CD-9A56BF4DB76C</gtr:id><gtr:title>Person Re-Identification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a259e3251a4833a57263daf524498d54"><gtr:id>a259e3251a4833a57263daf524498d54</gtr:id><gtr:otherNames>Gong S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-1-4471-6295-7</gtr:isbn><gtr:outcomeId>56bf93824dcda9.75454403</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8F7B664C-CE7A-4BB2-B829-FAE45F21CEB5</gtr:id><gtr:title>Person Re-Identification by Discriminative Selection in Video Ranking.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9ee1bcb1cf299cd91d287356fafa8cc8"><gtr:id>9ee1bcb1cf299cd91d287356fafa8cc8</gtr:id><gtr:otherNames>Wang T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf9d2a86a684.35183226</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3B1DE38D-4028-44A5-B453-A14340B9044F</gtr:id><gtr:title>Visual Analysis of Humans</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a259e3251a4833a57263daf524498d54"><gtr:id>a259e3251a4833a57263daf524498d54</gtr:id><gtr:otherNames>Gong S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-0-85729-996-3</gtr:isbn><gtr:outcomeId>56bf8d98ebff19.50443112</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>30D071F7-A45B-4662-B08D-84628B8554A3</gtr:id><gtr:title>On-the-fly feature importance mining for person re-identification</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b7a1e6c1d76e70702a15effb81f63589"><gtr:id>b7a1e6c1d76e70702a15effb81f63589</gtr:id><gtr:otherNames>Liu C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56bf9f8b69f5b7.72373202</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50CC1402-211D-4F80-B909-FA0910881741</gtr:id><gtr:title>Visual Analysis of Behaviour</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a259e3251a4833a57263daf524498d54"><gtr:id>a259e3251a4833a57263daf524498d54</gtr:id><gtr:otherNames>Gong S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-0-85729-669-6</gtr:isbn><gtr:outcomeId>56bf8bde5450d4.62808619</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FAA9C50E-29AA-4F85-9A46-DBE131651F34</gtr:id><gtr:title>Reidentification by Relative Distance Comparison.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/839f7135318d379e02ac5c586a9e26bc"><gtr:id>839f7135318d379e02ac5c586a9e26bc</gtr:id><gtr:otherNames>Zheng WS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56bf9521a20940.18839425</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E028594/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>