<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Experimental Psychology</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FE32D667-DB53-4D33-A773-AD15962AF2D8"><gtr:id>FE32D667-DB53-4D33-A773-AD15962AF2D8</gtr:id><gtr:name>Vox Generation Ltd</gtr:name><gtr:address><gtr:line1>Manor House</gtr:line1><gtr:line2>21 Soho Square</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W1D 3QP</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/9C7C5B8A-F1F8-4573-BD46-D66C9D8C0986"><gtr:id>9C7C5B8A-F1F8-4573-BD46-D66C9D8C0986</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:otherNames>Maitland</gtr:otherNames><gtr:surname>Stringer</gtr:surname><gtr:roles><gtr:role><gtr:name>TRAINING_GRANT_HOLDER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FH016287%2F1"><gtr:id>93B094FF-0EF9-4371-9609-08AC4FF15B39</gtr:id><gtr:title>Computational neuroscience of natural language learning in the brain</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Training Grant</gtr:grantCategory><gtr:grantReference>BB/H016287/1</gtr:grantReference><gtr:abstractText>Understanding how information processing is done in the visual and the auditory pathways in the brain is important for understanding speech recognition. The current project will aim to create a biologically plausible model of the auditory system and, after further investigations with a biologically plausible model of the visual system, VisNet, bring the two pathways together to investigate how word learning might operate in the brain. Our approach is distinctive in that we will investigate processing across these two areas through the development of biologically accurate neuro-dynamical models of these pathways, and explore how representations develop in these areas as the models are exposed to realistic visual and auditory sensory input. Our model of the auditory system will be based on the neurophysiology of the brain by modeling it using biologically realistic neural networks with associative learning rules. Although neural networks have been used in speech recognition before, previous models have typically used supervised learning, which is not biologically plausible. We expect that the behaviour of our model will be critically dependent on the precise dynamical properties of the neurons, synapses and learning rules that constitute the network model. It is expected that the model will be able to cope with such problems as different speeds of speech and different speakers by creating representations of words, which are reasonably robust to these dimensions of variability. Another issue we will explore is the possible development of representations of word categories during learning. The development of such categories may be guided by a number of factors. For example, the statistics of where words occur in sentences (syntax) may drive representations reflecting the parts of speech. There is a lot of evidence for audio and visual information integration in the brain. For example, neurophysiological studies have shown that visual and auditory information is integrated in the superior colliculi. There is also evidence suggesting that the two pathways can affect each other. Probably the most extensively studied example of this is the McGurk effect. A biologically plausible neural network model of the ventral visual stream, VisNet, will be used to study the visual pathway. In order to model the interaction between the visual and language areas of the brain, we need to understand how visual scenes are represented in the later stages of the visual pathway. For example, how might activity within the output layer of the visual pathway represent individual objects, multiple objects, and the parts of objects? How might the identity and emotional expression of faces be represented? The way in which such information is represented in the visual system may have a fundamental effect on the nature of the interaction between vision and language during development. Following the proposed separate investigations for the visual and the auditory pathways, the two models will be combined to investigate language acquisition constraints such as the taxonomic, the whole object and the mutual exclusivity constraints. These constraints will be modelled by introducing bilateral modifiable connections between the output layers of the auditory and the visual pathways. Once the model can explain how the constraints operate, it can be used to study how further word learning happens, where these constraints are broken and children learn to associate new words with individual instances of categories, or parts of objects or have more than one label for an objects. This is expected to happen because of the statistical properties of the stimuli. Through our dual-pathway model, we aim to understand how word learning actually happens in the infant brain, and how children's vocabulary gets expanded during development. We hope this research will ultimately lead to more powerful speech recognition models than the existing engineering approaches.</gtr:abstractText><gtr:fund><gtr:end>2014-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2010-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>75281</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/H016287/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>