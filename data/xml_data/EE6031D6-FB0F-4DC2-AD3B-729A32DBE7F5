<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF"><gtr:id>CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF</gtr:id><gtr:name>Loughborough University</gtr:name><gtr:department>Ergonomics and Safety Research Institute</gtr:department><gtr:address><gtr:line1>Loughborough University</gtr:line1><gtr:line4>Loughborough</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE11 3TU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF"><gtr:id>CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF</gtr:id><gtr:name>Loughborough University</gtr:name><gtr:address><gtr:line1>Loughborough University</gtr:line1><gtr:line4>Loughborough</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE11 3TU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/DAA0A6D3-2768-4BAC-8069-0920D7D0F5E1"><gtr:id>DAA0A6D3-2768-4BAC-8069-0920D7D0F5E1</gtr:id><gtr:firstName>Alastair</gtr:firstName><gtr:otherNames>George</gtr:otherNames><gtr:surname>Gale</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FF008937%2F1"><gtr:id>EE6031D6-FB0F-4DC2-AD3B-729A32DBE7F5</gtr:id><gtr:title>Attention Responsive Technology Implementation For Independent Control of the Environment (ARTIFICE)</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F008937/1</gtr:grantReference><gtr:abstractText>ARTIFICE (Attention Responsive Technology Implementation For Independent Control of the Environment) is an innovative assistive technology which aids individuals, whose mobility is impaired as a result of disability or age, operate environmental control systems, such as door entry, lighting and multimedia devices, autonomously. The system works by monitoring the individual and the ICT devices in his/her environment. It continuously examines the individual's eye movement behaviour and uses the assessment of steady eye gaze, together with the individual's point of gaze, to determine where in the environment they are looking. Image processing algorithms then determine whether they are gazing at an ICT device and if so then to which particular ICT device they are attending. This information then initiates an interface, configured for the individual, which displays only those controls that are appropriate, both to the user and to the particular device in question. The user can then choose to operate the device via the interface, or not, thereby overcoming accidental device operations. Control information is wirelessly relayed to the device itself. ARTIFICE acts as an enabling assistive technology, with the system fully user-configurable, either by the user or their carer, and is fully able to cater for future technological developments.</gtr:abstractText><gtr:fund><gtr:end>2008-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>97259</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>A successful system was developed and built. This was demonstrated at an international EU COGAIN Network of Excellence meeting where several disabled users of assistive technology devices successfully tried it out. It was also discussed with several manufacturers of assistive technology devices and was particularly demonstrated to a potential UK assistive technology company with a view to them further developing it. 



The novelty of the research work led to several collaborative publications with other EU researchers from the COGAIN network.

Some diseases cause an individual to lose motor ability whilst still maintaining cognitive skills. Typically they have to have a carer to help them operate devices or to do even simple tasks such as opening a window. Various technological advances allow such users to operate a computer which can then control environmental devices directly. A system was successfully developed which would monitor the visual behaviour of a severely disabled individual sitting in a wheelchair and enable them to select and operate a device in their environment simply by firstly looking at it and then using their eye behaviour to control that device appropriately. This freed them from being wholly dependant upon a carer.

Beneficiaries: Severely disabled individuals

Contribution Method: This research was innovative and entirely novel. The work led to collaborations with other researchers in the EU. Various presentations at international conferences were made together with peer reviewed publications.</gtr:description><gtr:id>C24FAF95-5831-4219-8BB1-678444081642</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>m-5134250079.406658de248da0</gtr:outcomeId><gtr:sector>Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>ARTIFICE further developed and enhanced the technoogy that we developed in the foregoing ART project (RES-328-25-0003-A and 

RES-328-25-0003). This resulted in a working technology platform built around a motorised wheelchair. A disabled person sitting in the wheelchair could select and operate ICT devices simply by firstly looking directly at the device and then by looking at an interface on the wheelchair.</gtr:description><gtr:exploitationPathways>The system provides severely disabled individuals with a means of controlling ICT devices independently. The technology was exploited by demonstrating it to a major UK manufacturer of assistive technology devices. Unfortunately they ultimately felt that whilst the concept was innovative and had potential it required considerable investment to take it from our demonstrtaor to a commercial product.



The technology development led to us being involved in the EU COGAIN Network of Excellence.</gtr:exploitationPathways><gtr:id>22D4B9C2-105E-43E2-ACF5-D26E6B4DA969</gtr:id><gtr:outcomeId>r-4076862478.7003384776e91fc</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.lboro.ac.uk/research/applied-vision/projects/art/index.htm</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C86D4538-AD2A-4BE3-A927-268BAF63371D</gtr:id><gtr:title>Eye-based Direct Interaction for Environmental Control in Heterogeneous Smart Environments</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e7e8f5154cefa834523e673f8a8d6b4"><gtr:id>4e7e8f5154cefa834523e673f8a8d6b4</gtr:id><gtr:otherNames>C Corno</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_781233862513aa2c48</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>39A1FC6A-9A0B-4BCD-A9A1-21C66AC6EA61</gtr:id><gtr:title>Computers Helping People with Special Needs</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d60b5ca5282194b81067f7df3589ac6f"><gtr:id>d60b5ca5282194b81067f7df3589ac6f</gtr:id><gtr:otherNames>Shi F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:isbn>978-3-540-70539-0</gtr:isbn><gtr:outcomeId>doi_53cfccfcc8062132</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EB3AE680-FE4A-4659-B636-3DF9EF561460</gtr:id><gtr:title>Environmental control by remote eye tracking</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/51064835c3c2c2ff665d24dbeecd4ab1"><gtr:id>51064835c3c2c2ff665d24dbeecd4ab1</gtr:id><gtr:otherNames>F Shi</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_171644899513df6548</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1B7A642E-DCD4-47F3-A081-2AB0A2922EAC</gtr:id><gtr:title>Eye-Operated Assistive Technology For Environmental Control</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/51064835c3c2c2ff665d24dbeecd4ab1"><gtr:id>51064835c3c2c2ff665d24dbeecd4ab1</gtr:id><gtr:otherNames>F Shi</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_113198738713df66ce</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9B8BE972-1901-4E33-B200-A743E0E224D0</gtr:id><gtr:title>A blueprint for eye-controlled environments</gtr:title><gtr:parentPublicationTitle>Universal Access in the  Information Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aab699207164d379ae1bd72a40460362"><gtr:id>aab699207164d379ae1bd72a40460362</gtr:id><gtr:otherNames>D Bonino</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_442731986513776894</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F008937/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>85</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>CC2B62EB-22CD-45F9-A6D2-0CE29B6D90FD</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Cognitive Science Appl. in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E05CFE0B-163D-412D-A3C2-28E89B2CA336</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Software Engineering</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>