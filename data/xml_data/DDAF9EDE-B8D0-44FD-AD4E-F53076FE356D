<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/30A429E3-83B7-4E41-99C0-14A144F07DFE"><gtr:id>30A429E3-83B7-4E41-99C0-14A144F07DFE</gtr:id><gtr:name>University of Southampton</gtr:name><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Highfield</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO17 1BJ</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/769758FB-34BC-4C3C-BC42-29F8D1E4E8AF"><gtr:id>769758FB-34BC-4C3C-BC42-29F8D1E4E8AF</gtr:id><gtr:name>Birmingham Conservatoire</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/909C646F-C9A3-42E9-BB1D-579B9B63772D"><gtr:id>909C646F-C9A3-42E9-BB1D-579B9B63772D</gtr:id><gtr:name>Arup Group Ltd</gtr:name><gtr:address><gtr:line1>13 Fitzroy Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>W1T 4BQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/686D9BAA-DD97-47C0-80A0-26916C5FB515"><gtr:id>686D9BAA-DD97-47C0-80A0-26916C5FB515</gtr:id><gtr:name>Internet Archive</gtr:name><gtr:address><gtr:line1>300 Funston Avenue</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/481D8333-88B8-4BF7-9DF2-5600BC827328"><gtr:id>481D8333-88B8-4BF7-9DF2-5600BC827328</gtr:id><gtr:name>University of Northampton</gtr:name><gtr:address><gtr:line1>Boughton Green Road</gtr:line1><gtr:line4>Northampton</gtr:line4><gtr:line5>Northamptonshire</gtr:line5><gtr:postCode>NN2 7AL</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/EF390CF0-ECD3-47D8-B9A8-7602AF319BEE"><gtr:id>EF390CF0-ECD3-47D8-B9A8-7602AF319BEE</gtr:id><gtr:name>Northumbria University</gtr:name><gtr:address><gtr:line1>Ellison Place</gtr:line1><gtr:line4>Newcastle upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 8ST</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A022BD3A-2A7B-4E64-8877-A2E381C4CCB5"><gtr:id>A022BD3A-2A7B-4E64-8877-A2E381C4CCB5</gtr:id><gtr:name>Birmingham City University</gtr:name><gtr:address><gtr:line1>University House</gtr:line1><gtr:line2>15 Bartholomew Row</gtr:line2><gtr:postCode>B5 5JU</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D394BCC7-2CE9-41C0-A124-1A05C8E4FD6E"><gtr:id>D394BCC7-2CE9-41C0-A124-1A05C8E4FD6E</gtr:id><gtr:name>City, University of London</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/F7E13617-2678-475B-99E4-31479C92038D"><gtr:id>F7E13617-2678-475B-99E4-31479C92038D</gtr:id><gtr:name>University of Aberdeen</gtr:name><gtr:address><gtr:line1>University Office</gtr:line1><gtr:line2>Regent Walk</gtr:line2><gtr:line4>Aberdeen</gtr:line4><gtr:line5>Aberdeenshire</gtr:line5><gtr:postCode>AB24 3FX</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/E4B5C8C4-E04B-4D88-9B70-44BFA5AF0534"><gtr:id>E4B5C8C4-E04B-4D88-9B70-44BFA5AF0534</gtr:id><gtr:name>Spanish National Research Council (CSIC)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/0C422A2E-BE95-4551-BD39-D97589C0B7C6"><gtr:id>0C422A2E-BE95-4551-BD39-D97589C0B7C6</gtr:id><gtr:name>Autonomous University of Barcelona (UAB)</gtr:name><gtr:address><gtr:line1>Edifici CN - Campus 08193 Bellatterra</gtr:line1><gtr:line4>Barcelona</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>Spain</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3B164344-2CFD-4F68-BC3C-0E0B1A22517A"><gtr:id>3B164344-2CFD-4F68-BC3C-0E0B1A22517A</gtr:id><gtr:name>Academic Rights Press (ARP)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/30A429E3-83B7-4E41-99C0-14A144F07DFE"><gtr:id>30A429E3-83B7-4E41-99C0-14A144F07DFE</gtr:id><gtr:name>University of Southampton</gtr:name><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Highfield</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO17 1BJ</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/769758FB-34BC-4C3C-BC42-29F8D1E4E8AF"><gtr:id>769758FB-34BC-4C3C-BC42-29F8D1E4E8AF</gtr:id><gtr:name>Birmingham Conservatoire</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/909C646F-C9A3-42E9-BB1D-579B9B63772D"><gtr:id>909C646F-C9A3-42E9-BB1D-579B9B63772D</gtr:id><gtr:name>Arup Group Ltd</gtr:name><gtr:address><gtr:line1>13 Fitzroy Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>W1T 4BQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/686D9BAA-DD97-47C0-80A0-26916C5FB515"><gtr:id>686D9BAA-DD97-47C0-80A0-26916C5FB515</gtr:id><gtr:name>Internet Archive</gtr:name><gtr:address><gtr:line1>300 Funston Avenue</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/481D8333-88B8-4BF7-9DF2-5600BC827328"><gtr:id>481D8333-88B8-4BF7-9DF2-5600BC827328</gtr:id><gtr:name>University of Northampton</gtr:name><gtr:address><gtr:line1>Boughton Green Road</gtr:line1><gtr:line4>Northampton</gtr:line4><gtr:line5>Northamptonshire</gtr:line5><gtr:postCode>NN2 7AL</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A9B1866C-EE3E-4D81-A83C-118745E9433E"><gtr:id>A9B1866C-EE3E-4D81-A83C-118745E9433E</gtr:id><gtr:name>Goldsmiths College</gtr:name><gtr:address><gtr:line1>Lewisham Way</gtr:line1><gtr:line2>New Cross</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SE14 6NW</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EF390CF0-ECD3-47D8-B9A8-7602AF319BEE"><gtr:id>EF390CF0-ECD3-47D8-B9A8-7602AF319BEE</gtr:id><gtr:name>Northumbria University</gtr:name><gtr:address><gtr:line1>Ellison Place</gtr:line1><gtr:line4>Newcastle upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 8ST</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A022BD3A-2A7B-4E64-8877-A2E381C4CCB5"><gtr:id>A022BD3A-2A7B-4E64-8877-A2E381C4CCB5</gtr:id><gtr:name>Birmingham City University</gtr:name><gtr:address><gtr:line1>University House</gtr:line1><gtr:line2>15 Bartholomew Row</gtr:line2><gtr:postCode>B5 5JU</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D394BCC7-2CE9-41C0-A124-1A05C8E4FD6E"><gtr:id>D394BCC7-2CE9-41C0-A124-1A05C8E4FD6E</gtr:id><gtr:name>City, University of London</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F7E13617-2678-475B-99E4-31479C92038D"><gtr:id>F7E13617-2678-475B-99E4-31479C92038D</gtr:id><gtr:name>University of Aberdeen</gtr:name><gtr:address><gtr:line1>University Office</gtr:line1><gtr:line2>Regent Walk</gtr:line2><gtr:line4>Aberdeen</gtr:line4><gtr:line5>Aberdeenshire</gtr:line5><gtr:postCode>AB24 3FX</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E4B5C8C4-E04B-4D88-9B70-44BFA5AF0534"><gtr:id>E4B5C8C4-E04B-4D88-9B70-44BFA5AF0534</gtr:id><gtr:name>Spanish National Research Council (CSIC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0C422A2E-BE95-4551-BD39-D97589C0B7C6"><gtr:id>0C422A2E-BE95-4551-BD39-D97589C0B7C6</gtr:id><gtr:name>Autonomous University of Barcelona (UAB)</gtr:name><gtr:address><gtr:line1>Edifici CN - Campus 08193 Bellatterra</gtr:line1><gtr:line4>Barcelona</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>Spain</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3B164344-2CFD-4F68-BC3C-0E0B1A22517A"><gtr:id>3B164344-2CFD-4F68-BC3C-0E0B1A22517A</gtr:id><gtr:name>Academic Rights Press (ARP)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/BAD3780F-6F65-4292-A69C-923CAE91A7BB"><gtr:id>BAD3780F-6F65-4292-A69C-923CAE91A7BB</gtr:id><gtr:name>British Broadcasting Corporation - BBC</gtr:name><gtr:address><gtr:line1>British Broadcasting Corporation</gtr:line1><gtr:line2>Broadcasting House</gtr:line2><gtr:line3>Portland Place</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>W1A 1AA</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5A5739A5-B58F-47C1-B425-94267E91DEE1"><gtr:id>5A5739A5-B58F-47C1-B425-94267E91DEE1</gtr:id><gtr:name>Technology Strategy Board</gtr:name><gtr:address><gtr:line1>Block B, Floor 1</gtr:line1><gtr:line2>North Star House</gtr:line2><gtr:line3>North Star Avenue</gtr:line3><gtr:line4>Swindon</gtr:line4><gtr:postCode>SN2 1JF</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/A3C215EE-5645-4543-ACD7-878BFB368AC7"><gtr:id>A3C215EE-5645-4543-ACD7-878BFB368AC7</gtr:id><gtr:firstName>Panos</gtr:firstName><gtr:surname>Kudumakis</gtr:surname><gtr:orcidId>0000-0003-0518-4198</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2D1D7ADD-45F8-4B1A-89C5-9D33EAA1E795"><gtr:id>2D1D7ADD-45F8-4B1A-89C5-9D33EAA1E795</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:surname>Sandler</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ010375%2F1"><gtr:id>DDAF9EDE-B8D0-44FD-AD4E-F53076FE356D</gtr:id><gtr:title>Semantic Media: a new paradigm for navigable content for the 21st Century</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J010375/1</gtr:grantReference><gtr:abstractText>This proposal stems directly from the EPSRC Workshop held on 20 &amp;amp; 21 October 2010 &amp;quot;ICT Research - The Next Decade&amp;quot;. It seeks to address the challenge of the navigation of time-based media collections and items throughout the content life-cycle, from creation to consumption. It will achieve this by establishing an open network of researchers from across academia and industry, who engage in workshops, sandpits and, most importantly, feasibility or path-finder mini-projects. These mini-projects have the aims not only of performing leading edge, early stage research that will lead on to larger proposals, but also of building a critical mass of researchers, whose expectation is to tackle significant challenges by collaborating. Other elements of this project are to create a Landscape document for the field, develop appropriate ontologies for capturing media semantics, present results through a diverse range of channels and summarise the findings of the project, including a Roadmap.
 
The research agenda is based on five premises: 
1. Content-related metadata is an effective and scalable approach exemplified in this domain and applicable to future large scale, automated and interactive information systems;
2. The point of creation is the best time and place to collect (and compute) metadata; 
3. The best way to represent this metadata is one that is amenable to knowledge processing and management, linked data strategies and logical inference;
4. Significant challenges require a cross-disciplinary approach, ranging from fundamental theory to applied research set in the context of a real problem; and 
5. The UK is supremely placed with the world-leading skills and experience to be a world-beating authority in an area of intellectual and societal/commercial benefit.

This proposal deliberately does not address related problems of navigation through legacy content, nor of Rights Management, as these are already embedded in the research landscape. Instead, we concentrate on the production of future media items.

The issues raised and investigated by this proposal are pertinent not only to EPSRC, but also to ESRC, AHRC, JISC and TSB, and with particular relevance to the Digital Economy.

The applications of such ideas span all the different time-based media, including music, drama, documentary, film, texts and so on. In order to advance the field, this project will bring together acknowledged experts from across UK academia in a diverse range of disciplines, including Semantic Web experts, Signal Processing experts, Video experts, Performance experts and more. The project aims to form a network and a critical mass of expertise by a series of interventions that will also include industrial collaborators (assisted by the TSB Creative Industries Knowledge Transfer Network). Network activities include workshops and sandpits, as well as collaborative small scale research projects, each typically of 6 months duration with 2 or 3 participant universities.

The outcomes of the project include: Research and Impact Roadmaps; a well-connected community of researchers engineers, creatives, content producers and funders; commercial and full-fledged research proposals; research publications; and specific impact activities at world leading Broadcast and Media conventions.</gtr:abstractText><gtr:potentialImpactText>The context of this proposal is development of EPSRC ICT strategy, following the ICT Futures Workshop. Therefore this is an important pathway to impact. In addition, by conducting this strategy study in the context of the creative industries domain it will have impact in a field where application of ICT has direct and large scale societal relevance.

The primary beneficiaries of this strategy study are ICT researchers (including but not exclusively academic), and by embedding in the context of digital media it also benefits those involved in the creation, production and ultimately consumption of digital content. We believe that the best way to create a research agenda which ultimately leads to the successful application of advanced ICT research is to engage in a domain that exemplifies future ICT challenges, adopts leading edge technology, has massive user engagement, is an incubator for new ideas and new business models, and has existing engagement activities to build on. 

By conducting this ICT strategy study in the context of digital media the project will address the following impact areas: Quality of Life; Knowledge Transfer/Exchange; Business and Commercial; Policy; Communications and Engagement.

The Roadmaps are the principal deliverable and will made widely available and promoted through community channels both within ICT and Creative Industries. The other mechanisms to ensure impact are summarised below.
* Research projects: Collaborative mini-projects involving at least 2 universities and preferably at least one company
* Workshops: Four with target number of participants: 100
* Sandpits: Four with target number of participants: 30
* Conferences: Individual Research Projects report results to conferences, for example ACM Multimedia
* Trade Show: Stand at International Broadcast Convention (IBC) 2013/4
* Fact-finding Missions: Travel to research centres such as Fraunhofer Institutes in Germany, MediaX at Stanford, Media Lab at MIT, Interactive Telecommunication Program (ITP) at NYU.
* Standardization: the project will be represented at all MPEG meetings (4 per year) over its duration. The communication will be 2-way. The project will also engage with EBU and W3C
* Electronic Forums: the project will create a live website, and a social networking forum (probably over LinkedIn)

Long term, the outcomes of this project will have significant impact on how entertainment content is created, delivered, modified and consumed. The opportunity is for the UK to take a lead in this highly important generator of National Income. Those working in the entertainment content industries will be impacted by improved workflow, productivity and satisfaction in the workplace. Those consuming the content will find the entertainment needs satisfied more easily and more completely.

Finally, there will be direct impact on the RA employed on the project by exposure to the wide range of industry needs and the scientific and technological challenges and solutions that will be addressed. Similarly those employed to work on the Feasibility Study mini-projects will benefit similarly.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-04-16</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>572749</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking of BBC Radio (SLoBR) - Programme Data and Early Music</gtr:description><gtr:id>3BF482EC-1AB3-4938-AD78-6C42F9ED67AC</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e633946995.21469309-2</gtr:outcomeId><gtr:partnerContribution>Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: WhatTheySaid</gtr:description><gtr:id>28373F18-49CE-4BD0-8BFD-61436A8B173C</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e4a8791926.85934845-3</gtr:outcomeId><gtr:partnerContribution>The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Metadata Used in Semantic Indexes and Charts (MUSIC)</gtr:description><gtr:id>EEEB4303-ED8A-4D1A-AC5D-AA46474AB35F</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e44d089af8.79551912-2</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Southampton</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: SemanticNews: enriching publishing of news stories</gtr:description><gtr:id>82C1CD6A-4629-48C0-99B9-7C52662B2D6C</gtr:id><gtr:impact>Technical reports, conference publications.</gtr:impact><gtr:outcomeId>5461e3278b21c4.98701824-1</gtr:outcomeId><gtr:partnerContribution>This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking and Integration of Content, Knowledge and Metadata in Early Music</gtr:description><gtr:id>16F61FD1-ABEC-45D7-88B5-56ADFDD5C77F</gtr:id><gtr:impact>Conference publications listed separately</gtr:impact><gtr:outcomeId>5461e1b6b58cb5.84303745-1</gtr:outcomeId><gtr:partnerContribution>Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Birmingham Conservatoire</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Large-Scale capture of Producer-Defined Musical Semantics</gtr:description><gtr:id>65A1D335-DBC7-45E2-9394-6FC264C12A85</gtr:id><gtr:impact>Conference publications, open source software</gtr:impact><gtr:outcomeId>546114d5b9a6f7.63196086-3</gtr:outcomeId><gtr:partnerContribution>The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking and Integration of Content, Knowledge and Metadata in Early Music</gtr:description><gtr:id>C511B53D-ABAF-4B54-8573-DF4BD4E1DD03</gtr:id><gtr:impact>Conference publications listed separately</gtr:impact><gtr:outcomeId>5461e1b6b58cb5.84303745-3</gtr:outcomeId><gtr:partnerContribution>Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Birmingham City University</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Large-Scale capture of Producer-Defined Musical Semantics</gtr:description><gtr:id>23255944-1AB4-438C-9BAB-EC9333B65063</gtr:id><gtr:impact>Conference publications, open source software</gtr:impact><gtr:outcomeId>546114d5b9a6f7.63196086-1</gtr:outcomeId><gtr:partnerContribution>The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Manchester</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Tawny Overtone</gtr:description><gtr:id>93935F84-741B-4A46-8118-5CDE6CC9CFA6</gtr:id><gtr:impact>Open Source software:
http://homepages.cs.ncl.ac.uk/m.j.bell1/blog/?p=962
http://homepages.cs.ncl.ac.uk/m.j.bell1/blog/?p=963</gtr:impact><gtr:outcomeId>5461e286c5f4d6.26521754-2</gtr:outcomeId><gtr:partnerContribution>This is highly speculative work, and will enable us to understand whether we
can compose and orchestrate metadata alongside the music; it will push the
boundaries of integration of music and semantics.
We propose to investigate born-semantic music, where semantic annotation can
be added at any point in the production of the music. For this, we will
combine Overtone and Tawny-OWL. The former is an electronic music system that
allows the description and synthesis of music at all levels: from the quality
of the sounds, to notes and rhythm, to song or composition level. The latter
allows a generation of semantic annotation in OWL. Crucially, these use the
same underlying syntax and language. This should allow annotations at any
level to percolate; so, for example, if a musician creates a drum sound, their
role as a contributor should percolate through to any piece of music using
that sound automatically. Likewise, richer annotation such as mood, pace,
style should percolate.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

This is highly speculative work, and will enable us to understand whether we
can compose and orchestrate metadata alongside the music; it will push the
boundaries of integration of music and semantics.
We propose to investigate born-semantic music, where semantic annotation can
be added at any point in the production of the music. For this, we will
combine Overtone and Tawny-OWL. The former is an electronic music system that
allows the description and synthesis of music at all levels: from the quality
of the sounds, to notes and rhythm, to song or composition level. The latter
allows a generation of semantic annotation in OWL. Crucially, these use the
same underlying syntax and language. This should allow annotations at any
level to percolate; so, for example, if a musician creates a drum sound, their
role as a contributor should percolate through to any piece of music using
that sound automatically. Likewise, richer annotation such as mood, pace,
style should percolate.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Oxford</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Oxford E-Research Centre</gtr:department><gtr:description>Mini-Project: Semantic Linking and Integration of Content, Knowledge and Metadata in Early Music</gtr:description><gtr:id>9B6958DB-B496-48BF-84A8-21D7A8CE8289</gtr:id><gtr:impact>Conference publications listed separately</gtr:impact><gtr:outcomeId>5461e1b6b58cb5.84303745-4</gtr:outcomeId><gtr:partnerContribution>Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Aberdeen</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: POWkist - Visualising Cultural Heritage Linked Datasets</gtr:description><gtr:id>71D6DEC5-70E2-4E63-8639-6423208AA82C</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e5c955b757.87071542-1</gtr:outcomeId><gtr:partnerContribution>The POWKist project aims to use semantic technologies to support visualisation of combined linked datasets in the cultural heritage domain. This is to provide systematic and attractive visualisation of cultural heritage linked dataset and bring raw data closer to citizen-historians for more efficient exploitation. POWkist will cover the whole life-cycle of content from data collection to data consumption by citizen-historians and the general public.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The POWKist project aims to use semantic technologies to support visualisation of combined linked datasets in the cultural heritage domain. This is to provide systematic and attractive visualisation of cultural heritage linked dataset and bring raw data closer to citizen-historians for more efficient exploitation. POWkist will cover the whole life-cycle of content from data collection to data consumption by citizen-historians and the general public.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Design of a Semantic Web Ontology for the PRAISE Practice Agent Architecture</gtr:description><gtr:id>7300019D-2749-4E1E-A57F-BE86A485C55C</gtr:id><gtr:impact>Open source ontology specification</gtr:impact><gtr:outcomeId>5461e570917800.78790347-1</gtr:outcomeId><gtr:partnerContribution>In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: SemanticNews: enriching publishing of news stories</gtr:description><gtr:id>6E6C4824-565E-417D-892F-4CE06AAB36F1</gtr:id><gtr:impact>Technical reports, conference publications.</gtr:impact><gtr:outcomeId>5461e3278b21c4.98701824-3</gtr:outcomeId><gtr:partnerContribution>This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Internet Archive</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Mini-Project: Computational Analysis of the Live Music Archive (CALMA)</gtr:description><gtr:id>2A1A06AA-6F8F-4254-A5A5-8F3097EDBF27</gtr:id><gtr:impact>Conference publications, public datasets, software</gtr:impact><gtr:outcomeId>5461e3c46d88f4.15497185-4</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Spanish National Research Council (CSIC)</gtr:collaboratingOrganisation><gtr:country>Spain, Kingdom of</gtr:country><gtr:department>Artificial Intelligence Research Institute (IIIA)</gtr:department><gtr:description>Mini-Project: Design of a Semantic Web Ontology for the PRAISE Practice Agent Architecture</gtr:description><gtr:id>CBF45A7B-4611-48C0-A93C-F6175937C224</gtr:id><gtr:impact>Open source ontology specification</gtr:impact><gtr:outcomeId>5461e570917800.78790347-3</gtr:outcomeId><gtr:partnerContribution>In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Northumbria University</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: POWkist - Visualising Cultural Heritage Linked Datasets</gtr:description><gtr:id>92457AAB-7BC6-4456-A277-C24B7BDB9930</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e5c955b757.87071542-2</gtr:outcomeId><gtr:partnerContribution>The POWKist project aims to use semantic technologies to support visualisation of combined linked datasets in the cultural heritage domain. This is to provide systematic and attractive visualisation of cultural heritage linked dataset and bring raw data closer to citizen-historians for more efficient exploitation. POWkist will cover the whole life-cycle of content from data collection to data consumption by citizen-historians and the general public.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The POWKist project aims to use semantic technologies to support visualisation of combined linked datasets in the cultural heritage domain. This is to provide systematic and attractive visualisation of cultural heritage linked dataset and bring raw data closer to citizen-historians for more efficient exploitation. POWkist will cover the whole life-cycle of content from data collection to data consumption by citizen-historians and the general public.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Sheffield</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: SemanticNews: enriching publishing of news stories</gtr:description><gtr:id>308493CB-30FE-4F37-9814-9A28356784FE</gtr:id><gtr:impact>Technical reports, conference publications.</gtr:impact><gtr:outcomeId>5461e3278b21c4.98701824-2</gtr:outcomeId><gtr:partnerContribution>This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

This project aims to promote people's comprehension and assimilation of news by augmenting live broadcast news articles with information from the SW in the form of linked open data (LOD). We plan to lay foundations for a toolkit for real-time automatic provision of semantic analysis and contextualization of news, encompassing state of the art SW technologies including text mining, consolidation against LOD, and advanced visualisation. To bootstrap our work, we will use television news articles that already have transcripts. Using these we will create a workflow that will a) extract relevant entities using established named entity recognition techniques to identify the types of information to contextualise for a news article; b) provide associations with concepts from LOD resources; c) visualise the context will using maps to provide the viewers with geographical information, and graphs derived from the LOD cloud. E.g. a political party has different levels of support across the country; this can be visualised by maps and graphs. The project's outcomes will be evaluated in a user study, which will provide feedback regarding toolkit quality and usability, and direct our activities in and beyond the scope of the proposal.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Large-Scale capture of Producer-Defined Musical Semantics</gtr:description><gtr:id>FC821817-BD46-4006-9A88-B9F8432EDEDA</gtr:id><gtr:impact>Conference publications, open source software</gtr:impact><gtr:outcomeId>546114d5b9a6f7.63196086-2</gtr:outcomeId><gtr:partnerContribution>The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Oxford</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Computational Analysis of the Live Music Archive (CALMA)</gtr:description><gtr:id>07476679-CFCB-4B4D-922E-D8D2121917C3</gtr:id><gtr:impact>Conference publications, public datasets, software</gtr:impact><gtr:outcomeId>5461e3c46d88f4.15497185-3</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Arup Group</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: A 'second screen' music discovery and recommendation service based on social-cultural factors</gtr:description><gtr:id>CEA7F20A-93A3-4044-ACE8-E06C493F452D</gtr:id><gtr:impact>Open source software</gtr:impact><gtr:outcomeId>5461e5087d9d42.79617858-2</gtr:outcomeId><gtr:partnerContribution>Viewers watching TV may would like to use their tablet or smart phone as a 'second screen', firstly to identify any music playing on the TV, and then secondly to discover more information about it. Thus, the microphone of the 'second screen' device is used to listen to the music playing on the TV, whilst audio fingerprinting technology is used to identify it. Then, a dynamically webpage is generated providing rich information about the music identified, as well as related music and musical artists based on social-cultural factors. The latter is achieved by querying web services such as Youtube, The Echonest, Last.fm and MusicBrainz. Linking and making sense - knowledge inference - out of such wide range and diverse music-related data acquired across multiple sources and services on the web is achieved thanks to C4DM Music Ontology. An Android app acting as a 'second screen' is currently available for demonstration purposes.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Viewers watching TV may would like to use their tablet or smart phone as a 'second screen', firstly to identify any music playing on the TV, and then secondly to discover more information about it. Thus, the microphone of the 'second screen' device is used to listen to the music playing on the TV, whilst audio fingerprinting technology is used to identify it. Then, a dynamically webpage is generated providing rich information about the music identified, as well as related music and musical artists based on social-cultural factors. The latter is achieved by querying web services such as Youtube, The Echonest, Last.fm and MusicBrainz. Linking and making sense - knowledge inference - out of such wide range and diverse music-related data acquired across multiple sources and services on the web is achieved thanks to C4DM Music Ontology. An Android app acting as a 'second screen' is currently available for demonstration purposes.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>City, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking and Integration of Content, Knowledge and Metadata in Early Music</gtr:description><gtr:id>A4273B0B-8688-48CD-BE62-5499431AE4EC</gtr:id><gtr:impact>Conference publications listed separately</gtr:impact><gtr:outcomeId>5461e1b6b58cb5.84303745-2</gtr:outcomeId><gtr:partnerContribution>Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Linking data from various sources via metadata and/or content is a vital task in musicology and library cataloguing, where semantic annotations play an essential role. This innovative pilot project will work with data in ECOLM of two types: (a) encoded scores OCR'd from 16-c printed music; (b) expert metadata from British Library cataloguers. We'll build on existing ontologies such as the Music Ontology, introducing key concepts embedded in our historical text and music images (e.g., place- and person names, dates, music- titles and lyrics) and prepare the ground for a new ontology for melodic, harmonic and rhythmic sequences. 16-c printed texts vary a lot in quality, spelling, languages, fonts and layouts, so support for approximate matching, e.g. using the Similarity Ontology, is vital for human control and interaction in cataloguing and retrieval of historical music documents. The project will produce an online demonstrator to show the principles in action, serving as a multidisciplinary pilot application of Linked Data in the study of early music which will be widely applicable for scholarship in other musical and historical repertories.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Design of a Semantic Web Ontology for the PRAISE Practice Agent Architecture</gtr:description><gtr:id>53E611F1-F01A-4664-AE2D-AAA7E85E58BE</gtr:id><gtr:impact>Open source ontology specification</gtr:impact><gtr:outcomeId>5461e570917800.78790347-2</gtr:outcomeId><gtr:partnerContribution>In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>City, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking of BBC Radio (SLoBR) - Programme Data and Early Music</gtr:description><gtr:id>86B32BA8-D4F8-48EF-9472-B1A230E76172</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e633946995.21469309-4</gtr:outcomeId><gtr:partnerContribution>Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Goldsmiths College</gtr:description><gtr:id>E57025C0-F55C-4FD2-8AEE-3BEE1B5D009D</gtr:id><gtr:impact>The Transforming Musicology grant from AHRC is one outcome.</gtr:impact><gtr:outcomeId>b99b2bd4b99b2be8-1</gtr:outcomeId><gtr:partnerContribution>Research knowhow, co-writing papers, access to software, joint grant proposals.</gtr:partnerContribution><gtr:piContribution>Various academics from Goldsmiths have collaborated with QM over the years, including Prof T Crawford, Prof A Tanaka, Prof M D'Inverno</gtr:piContribution><gtr:sector>Academic/University</gtr:sector></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Northampton</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Metadata Used in Semantic Indexes and Charts (MUSIC)</gtr:description><gtr:id>AFA8A1C3-FDF1-4BD3-9D19-E769F5DABF7A</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e44d089af8.79551912-1</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Manchester</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Computational Analysis of the Live Music Archive (CALMA)</gtr:description><gtr:id>3B70444F-E75B-43A2-8B18-0B306A2D6A39</gtr:id><gtr:impact>Conference publications, public datasets, software</gtr:impact><gtr:outcomeId>5461e3c46d88f4.15497185-1</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University College London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: WhatTheySaid</gtr:description><gtr:id>661540F9-9B69-471F-BC32-A721739789FC</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e4a8791926.85934845-2</gtr:outcomeId><gtr:partnerContribution>The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Goldsmiths, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking of BBC Radio (SLoBR) - Programme Data and Early Music</gtr:description><gtr:id>510BEB75-6411-4991-A3FB-081F9B193992</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e633946995.21469309-3</gtr:outcomeId><gtr:partnerContribution>Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Aberdeen</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: An Argument Workbench - extracting structured arguments from social media</gtr:description><gtr:id>3B0AC519-EE2A-4704-A4CB-75F0186A32C3</gtr:id><gtr:impact>non yet</gtr:impact><gtr:outcomeId>5461e683131fb9.38578451-1</gtr:outcomeId><gtr:partnerContribution>Reader-contributed comments to a news article are a source of arguments for and against issues raised in the article, where an argument is a claim with justifications and exceptions. For example, commenting about an article on the Crimea, a reader states that Russia's behaviour is unacceptable, giving justifications; another reader criticises the justifications; and so on. It is difficult to coherently understand the overall, integrated meaning of the comments. Consequently, the &amp;quot;wisdom of crowds&amp;quot; is lost. Difficulties arise because comments are: in high volume, updated, presented in a list so distributing ideas, represented in language, not machine-readable, and miss indicators for relationships amongst comments. While argument visualisation tools help people to understand media derived arguments, the visualisations are manually reconstructed, thus expensive to produce in terms of time, money, and knowledge. Current automatic text mining techniques, e.g. sentiment analysis and named entity/relation extraction, miss the argument structure. Furthermore, arguments cannot be automatically reprocessed. To reconstruct the arguments sensibly and reusably, we propose a novel argumentation workbench, which is a semi-automated, interactive, integrated, modular tool set to extract, reconstruct, and visualise arguments. The intention is to present the arguments in a clearer, organised form, not to judge or filter out alternative viewpoints. The workbench integrates well-developed, published, state-of-the-art tools in information retrieval and extraction, visualisation, and computational approaches to abstract and instantiated argumentation. These techniques will identify the higher-level structures of meaning found in argumentation and reasoning. The workbench will be the basis for further theoretical and applied work.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Reader-contributed comments to a news article are a source of arguments for and against issues raised in the article, where an argument is a claim with justifications and exceptions. For example, commenting about an article on the Crimea, a reader states that Russia's behaviour is unacceptable, giving justifications; another reader criticises the justifications; and so on. It is difficult to coherently understand the overall, integrated meaning of the comments. Consequently, the &amp;quot;wisdom of crowds&amp;quot; is lost. Difficulties arise because comments are: in high volume, updated, presented in a list so distributing ideas, represented in language, not machine-readable, and miss indicators for relationships amongst comments. While argument visualisation tools help people to understand media derived arguments, the visualisations are manually reconstructed, thus expensive to produce in terms of time, money, and knowledge. Current automatic text mining techniques, e.g. sentiment analysis and named entity/relation extraction, miss the argument structure. Furthermore, arguments cannot be automatically reprocessed. To reconstruct the arguments sensibly and reusably, we propose a novel argumentation workbench, which is a semi-automated, interactive, integrated, modular tool set to extract, reconstruct, and visualise arguments. The intention is to present the arguments in a clearer, organised form, not to judge or filter out alternative viewpoints. The workbench integrates well-developed, published, state-of-the-art tools in information retrieval and extraction, visualisation, and computational approaches to abstract and instantiated argumentation. These techniques will identify the higher-level structures of meaning found in argumentation and reasoning. The workbench will be the basis for further theoretical and applied work.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Oxford</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Semantic Linking of BBC Radio (SLoBR) - Programme Data and Early Music</gtr:description><gtr:id>3D354B5F-96F8-4FF3-8D74-40C361DFDE9B</gtr:id><gtr:impact>none yet</gtr:impact><gtr:outcomeId>5461e633946995.21469309-1</gtr:outcomeId><gtr:partnerContribution>Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Semantic Linking of BBC Radio (SLoBR) addresses a further crucial step in applying Linked Data (LD) as an end-to-end solution for the music domain. Previous efforts, including the successful SLICKMEM project, primarily generated data and links from and between academic and commercial sources; SLoBR focuses on the use and consumption of such LD and development of tooling to support these applications.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Computational Analysis of the Live Music Archive (CALMA)</gtr:description><gtr:id>78529BAB-4A88-46A6-83D6-A9B0864963C8</gtr:id><gtr:impact>Conference publications, public datasets, software</gtr:impact><gtr:outcomeId>5461e3c46d88f4.15497185-2</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Computational Analysis of the Live Music Archive&amp;quot; (CALMA) project is to facilitate scholarship related to live music in the areas of music informatics, popular musicology and music information retrieval. The project will develop a Linked Data service exposing substantial data about live music, including core and contextual metadata linked with existing popular Semantic Web resources, as well as the output of content-based analyses (tempo, key, etc.) of audio recordings. The outcomes will be evaluated using exemplar research questions.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Autonomous University of Barcelona (UAB)</gtr:collaboratingOrganisation><gtr:country>Spain, Kingdom of</gtr:country><gtr:description>Mini-Project: Design of a Semantic Web Ontology for the PRAISE Practice Agent Architecture</gtr:description><gtr:id>E2C35E24-C01D-401E-A53C-C7E3E884E55C</gtr:id><gtr:impact>Open source ontology specification</gtr:impact><gtr:outcomeId>5461e570917800.78790347-4</gtr:outcomeId><gtr:partnerContribution>In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

In this project we designed a Semantic Web Ontology according to the PRAISE Practice Agent Architecture specification using the OWL 2 Web Ontology language. Semantic Web technologies allows for the structured representation of data that can be shared across agents, and can be queried using powerful RDF query languages such as SPARQL. The ontology covers different forms of feedback such as praise and criticism, including sub types: constructive, descriptive and evaluative. It covers arrangements of and between people and agents, such as community, peer and teacher. It defines a list of all standard tasks a user can carry out within the PRAISE platform, e.g. record, listen, annotate, share. While the PRAISE specification defines several domain-specific concepts, we also extensively reuse existing ontologies in our design, such as the Music Ontology and Audio Features Ontology.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Southampton</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: WhatTheySaid</gtr:description><gtr:id>7B8C1B8D-DD0A-45C5-83FF-FC4B783BE02A</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e4a8791926.85934845-1</gtr:outcomeId><gtr:partnerContribution>The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The TV programmes, such as new reports, politics discussion programme and interviews, produced by mass media exerts tremendous influence on the transparency of politics in the UK. Political figures need to be responsible for what they have said to public media as they will be monitored by the public. However, it is still difficult currently to automatically analyse recording archives to find the answer to questions such as: did some political figure made a promise some time ago, that he did not meet later; did someone in the government refer to a figure that was actually wrong? This project is aiming to develop a framework using natural language processing and machine learning to automatically extract key concepts from the speech statements and categorize them for searching, viewing and comparison. We will also provide data visualisation along the timeline, where the statements will be visualised together with the speaker, the audio-visual record and related context from the Linked Data Cloud, so that users can easily search, view and compare the statements the political figures have made. To bootstrap our work, we will obtain archives of politics interview programmes with transcript segmented by speakers from BBC, the most influential broadcasting company in UK. We can use natural language processing tools to analysis the transcripts, extract important concepts (semantic annotations) from statements they have made and categorize them by the key concepts, such as law, economy, foreign affairs, NHS, migration, etc. Furthermore, using linked data, each important statement and semantic concepts in the programme will be linked to a fragment of the video archive. Then users can search by speakers, categories and plain text, and watch the video fragments as the proof the statement. With the help of video metadata, we can also visualise the statements and media fragments along the real-world timeline. Similar to the demo of TimelineJS (http://timeline.verite.co/), users can easily navigate through the timeline and spot whether some government or politic figures' statements made in different times are inconsistent.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Sheffield</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: An Argument Workbench - extracting structured arguments from social media</gtr:description><gtr:id>8BAFE9FD-D4A5-4607-8878-EEE7C812D70B</gtr:id><gtr:impact>non yet</gtr:impact><gtr:outcomeId>5461e683131fb9.38578451-2</gtr:outcomeId><gtr:partnerContribution>Reader-contributed comments to a news article are a source of arguments for and against issues raised in the article, where an argument is a claim with justifications and exceptions. For example, commenting about an article on the Crimea, a reader states that Russia's behaviour is unacceptable, giving justifications; another reader criticises the justifications; and so on. It is difficult to coherently understand the overall, integrated meaning of the comments. Consequently, the &amp;quot;wisdom of crowds&amp;quot; is lost. Difficulties arise because comments are: in high volume, updated, presented in a list so distributing ideas, represented in language, not machine-readable, and miss indicators for relationships amongst comments. While argument visualisation tools help people to understand media derived arguments, the visualisations are manually reconstructed, thus expensive to produce in terms of time, money, and knowledge. Current automatic text mining techniques, e.g. sentiment analysis and named entity/relation extraction, miss the argument structure. Furthermore, arguments cannot be automatically reprocessed. To reconstruct the arguments sensibly and reusably, we propose a novel argumentation workbench, which is a semi-automated, interactive, integrated, modular tool set to extract, reconstruct, and visualise arguments. The intention is to present the arguments in a clearer, organised form, not to judge or filter out alternative viewpoints. The workbench integrates well-developed, published, state-of-the-art tools in information retrieval and extraction, visualisation, and computational approaches to abstract and instantiated argumentation. These techniques will identify the higher-level structures of meaning found in argumentation and reasoning. The workbench will be the basis for further theoretical and applied work.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Reader-contributed comments to a news article are a source of arguments for and against issues raised in the article, where an argument is a claim with justifications and exceptions. For example, commenting about an article on the Crimea, a reader states that Russia's behaviour is unacceptable, giving justifications; another reader criticises the justifications; and so on. It is difficult to coherently understand the overall, integrated meaning of the comments. Consequently, the &amp;quot;wisdom of crowds&amp;quot; is lost. Difficulties arise because comments are: in high volume, updated, presented in a list so distributing ideas, represented in language, not machine-readable, and miss indicators for relationships amongst comments. While argument visualisation tools help people to understand media derived arguments, the visualisations are manually reconstructed, thus expensive to produce in terms of time, money, and knowledge. Current automatic text mining techniques, e.g. sentiment analysis and named entity/relation extraction, miss the argument structure. Furthermore, arguments cannot be automatically reprocessed. To reconstruct the arguments sensibly and reusably, we propose a novel argumentation workbench, which is a semi-automated, interactive, integrated, modular tool set to extract, reconstruct, and visualise arguments. The intention is to present the arguments in a clearer, organised form, not to judge or filter out alternative viewpoints. The workbench integrates well-developed, published, state-of-the-art tools in information retrieval and extraction, visualisation, and computational approaches to abstract and instantiated argumentation. These techniques will identify the higher-level structures of meaning found in argumentation and reasoning. The workbench will be the basis for further theoretical and applied work.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Academic Rights Press (ARP)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Metadata Used in Semantic Indexes and Charts (MUSIC)</gtr:description><gtr:id>FD93E54B-B519-4522-90AC-779355E860FD</gtr:id><gtr:impact>Conference publications</gtr:impact><gtr:outcomeId>5461e44d089af8.79551912-3</gtr:outcomeId><gtr:partnerContribution>The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

The objective of the &amp;quot;Metadata Used in Semantic Indexes and Charts&amp;quot; (MUSIC) project is to facilitate musicological research in the area of popular music. Emerging Linked Data technologies enable the combination of several music related data sources published openly on the Semantic Web. Academic Rights Press provides an extensive database of popular music charts, already linked to academic publications: Academic Charts Online (ACO). Fusing these resources will facilitate innovative, to date unprecedented ways of navigating through the popular music space, enabling novel research to be carried out. The integration of resources and the provision of an easy to use interface present several challenges requiring disparate skills, interdisciplinary collaboration, and small scale funding difficult to obtain otherwise. These challenges include the effective fusion of Semantic Web resources with data and analytical tools provided by ACO, metadata alignment in different data repositories, testing and improving large-&amp;shy;-scale data integration technologies, and providing an interface relevant to researchers and students working in popular musicology. The project will thus rely on, and bring value to multiple disciplines including musicology, Linked Data and the Semantic Web, user interface design, software development, and the broader fields of music informatics and pedagogy.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Newcastle University</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: Tawny Overtone</gtr:description><gtr:id>937FD5F3-3785-4388-84EC-B0CD49F7F900</gtr:id><gtr:impact>Open Source software:
http://homepages.cs.ncl.ac.uk/m.j.bell1/blog/?p=962
http://homepages.cs.ncl.ac.uk/m.j.bell1/blog/?p=963</gtr:impact><gtr:outcomeId>5461e286c5f4d6.26521754-1</gtr:outcomeId><gtr:partnerContribution>This is highly speculative work, and will enable us to understand whether we
can compose and orchestrate metadata alongside the music; it will push the
boundaries of integration of music and semantics.
We propose to investigate born-semantic music, where semantic annotation can
be added at any point in the production of the music. For this, we will
combine Overtone and Tawny-OWL. The former is an electronic music system that
allows the description and synthesis of music at all levels: from the quality
of the sounds, to notes and rhythm, to song or composition level. The latter
allows a generation of semantic annotation in OWL. Crucially, these use the
same underlying syntax and language. This should allow annotations at any
level to percolate; so, for example, if a musician creates a drum sound, their
role as a contributor should percolate through to any piece of music using
that sound automatically. Likewise, richer annotation such as mood, pace,
style should percolate.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

This is highly speculative work, and will enable us to understand whether we
can compose and orchestrate metadata alongside the music; it will push the
boundaries of integration of music and semantics.
We propose to investigate born-semantic music, where semantic annotation can
be added at any point in the production of the music. For this, we will
combine Overtone and Tawny-OWL. The former is an electronic music system that
allows the description and synthesis of music at all levels: from the quality
of the sounds, to notes and rhythm, to song or composition level. The latter
allows a generation of semantic annotation in OWL. Crucially, these use the
same underlying syntax and language. This should allow annotations at any
level to percolate; so, for example, if a musician creates a drum sound, their
role as a contributor should percolate through to any piece of music using
that sound automatically. Likewise, richer annotation such as mood, pace,
style should percolate.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Queen Mary University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Mini-Project: A 'second screen' music discovery and recommendation service based on social-cultural factors</gtr:description><gtr:id>2DEA7ED0-FCE0-4B41-AE44-4F5AFB588D73</gtr:id><gtr:impact>Open source software</gtr:impact><gtr:outcomeId>5461e5087d9d42.79617858-1</gtr:outcomeId><gtr:partnerContribution>Viewers watching TV may would like to use their tablet or smart phone as a 'second screen', firstly to identify any music playing on the TV, and then secondly to discover more information about it. Thus, the microphone of the 'second screen' device is used to listen to the music playing on the TV, whilst audio fingerprinting technology is used to identify it. Then, a dynamically webpage is generated providing rich information about the music identified, as well as related music and musical artists based on social-cultural factors. The latter is achieved by querying web services such as Youtube, The Echonest, Last.fm and MusicBrainz. Linking and making sense - knowledge inference - out of such wide range and diverse music-related data acquired across multiple sources and services on the web is achieved thanks to C4DM Music Ontology. An Android app acting as a 'second screen' is currently available for demonstration purposes.</gtr:partnerContribution><gtr:piContribution>This was a mini-project funded by the Semantic Media grant:

Viewers watching TV may would like to use their tablet or smart phone as a 'second screen', firstly to identify any music playing on the TV, and then secondly to discover more information about it. Thus, the microphone of the 'second screen' device is used to listen to the music playing on the TV, whilst audio fingerprinting technology is used to identify it. Then, a dynamically webpage is generated providing rich information about the music identified, as well as related music and musical artists based on social-cultural factors. The latter is achieved by querying web services such as Youtube, The Echonest, Last.fm and MusicBrainz. Linking and making sense - knowledge inference - out of such wide range and diverse music-related data acquired across multiple sources and services on the web is achieved thanks to C4DM Music Ontology. An Android app acting as a 'second screen' is currently available for demonstration purposes.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Semantic Media @ The British Library</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>F25BE319-3818-4700-A395-27CCA25AF9B5</gtr:id><gtr:impact>We organized a workshop in conjunction with the British Library to foster relationships and promote the idea of using semantic technologies in media-related fields and combine that with signal processing and machine learning. With about 100 participants from academia, public bodies and companies the workshop was a huge success.

The Semantic Media project aims at establishing an open network uniting research efforts related to the development of novel tools and standards for organizing and navigating in digital media archives. In this context, the British Library as one of the two largest libraries in the world is of particular importance. The collection comprises more than 150 million items from many countries and in many formats (digital and print): books, newspapers, magazines, journals, and manuscripts, as well as sound and music recordings, videos, patents, databases, maps, stamps, drawings and much more. Providing access to these collections the British Library has served researchers for many years. However, with the corresponding data sets expanding exponentially over time, there is an increasing demand for new approaches to making use of these gigantic collections.
Overview

1.) British Library Collections: British Library curators will give some insight into their collections (image, audio, video, news,...), which might spark some new (research) ideas in terms of how libraries could collaborate with universities to make collections more accessible. In particular, we want to start a discussion of what technology is actually needed from a library point of view.

2.) Networking: There will be a networking session, where we try to introduce people to each other across a range of media-related disciplines (image/video/audio/music/text/multimedia/linked data). The idea is to spark ideas for interdisciplinary research and build the foundations for future collaborative grant applications.

3.) Funding: Two funding schemes will be discussed: &amp;quot;BL-Labs&amp;quot; and &amp;quot;Semantic Media&amp;quot;. Both aim at providing funding for small projects, to develop new ideas in the context of digital media collections.

Sparked additional applications to the third call for projects.</gtr:impact><gtr:outcomeId>546210c0581454.93711887</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Semantic Media @ BBC</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>819EE703-7279-4DFF-B503-531A4F4F5AF8</gtr:id><gtr:impact>We organized a workshop in conjunction with the BBC to foster relationships and promote the idea of using semantic technologies in media-related fields and combine that with signal processing and machine learning. With about 60-70 participants from academia, public bodies and companies the workshop was a huge success.

A major goal of the Semantic Media project is to establish an open network uniting industrial and academic research efforts related to the development of novel tools and standards for organizing and navigating in digital media. To this end, the project meetings bring industrialists together with theoretical and applied researchers, to foster relationships, and encourage working together to find solutions to science and technology problems that are relevant to digital media; see our website for a list of initial project partners (http://semanticmedia.org.uk).

Goals for the 'Semantic Media @ BBC' workshop include:

 To demonstrate the work of BBC R&amp;amp;D in areas relevant for the Semantic Media project, and to identify tasks on which the BBC could collaborate with academic researchers
 To present datasets that the BBC has to offer to external researchers.
 To involve the BBC production and archive departments to
 to illustrate how the production and archival process works within a large scale media corporation
 to gather ideas for new annotation and metadata technology to be developed within Semantic Media projects (or in full-scale follow-up projects)
 to identify how people involved in the archival and production process could actually benefit from new technology and how novel computational methods could be integrated into existing workflows in such a way that they would be accepted as new and useful tools.

Since academic research typically does not include the production of media seeing the &amp;quot;real world&amp;quot; is essential for the project and hence it is important to integrate production and archive experts as early as possible.

Sparked collaborations, also as part of mini-projects funded through Semantic Media.</gtr:impact><gtr:outcomeId>5461e9de66ae43.43742083</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Semantic Media Project Workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>A0783D76-1C42-4F69-AC3B-DD69D8EBB60A</gtr:id><gtr:impact>We organized a workshop at the Barbican Arts Centre to foster relationships and promote the idea of using semantic technologies in media-related fields and combining that with signal processing and machine learning. With about 100 participants from academia, public bodies and companies the workshop was a huge success.

The main goal of this first workshop was to introduce academic and industrial researchers from across the ICT landscape to each other. This way, experts in signal processing or video analysis were brought together with researchers working on linked data technology, broadcasting standards, interface design, natural text analysis, speech technology and many

The number of submissions to the first call for projects organized by the Semantic Media project was successfully raised considerably.</gtr:impact><gtr:outcomeId>r-3501095411.8343962b8537fa</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://semanticmedia.org.uk/?q=events</gtr:url><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Special Session at WIA2MIS Conference</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6CCAFDB9-E633-4BDF-98DE-041F46A146EE</gtr:id><gtr:impact>We organized a special sessions at the WIA2MIS Conference to foster relationships and promote the idea of using semantic technologies in media-related fields and combining that with signal processing and machine learning. With 6 accepted papers and more than 50 participants the session was a huge success.

Making media researchers aware of semantic technologies and sparking a dialog.</gtr:impact><gtr:outcomeId>5461eaf3b08d32.72493140</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:presentationType>paper presentation</gtr:presentationType><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>25000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>The Royal Society Wolfson Research Merit Award</gtr:description><gtr:end>2020-03-02</gtr:end><gtr:fundingOrg>The Royal Society</gtr:fundingOrg><gtr:fundingRef>to be confirmed.</gtr:fundingRef><gtr:id>539EB477-558C-424E-8B3E-4D07860E2D1E</gtr:id><gtr:outcomeId>56d455a7154a04.34930255</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-03-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The project was a community research programme following the EPSRC Workshop &amp;quot;ICT Research - The Next Decade&amp;quot;. The goal was explore and popularize the use of structured, linkable data structures using Semantic Web technology across all ICT fields and media types. We organized workshops at the BBC, the British Library and the Barbican, each with 70-120 participants from industry and academia. The opportunity to kick-start feasibility studies within the grant enabled collaborations between academic institutions as well as between industry and academia.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>2B0D8B27-0AF0-49B7-8A66-B63A5DF715D7</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545cad09581230.44473539</gtr:outcomeId><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The goal of the Semantic Media project was to establish an open network of researchers across a multitude of media and ICT related disciplines, through workshops and path-finder mini-projects. Central milestones in building up this network were the organization of three workshops, one special session, three successful call-for-projects, and 12 funded mini-projects.

* The first workshop was held at the Barbican Arts Centre and included internationally well-known keynote speakers.

* The second workshop was organized in conjunction with the BBC.

* The third workshop was organized in conjunction with the British Library.

* The special session was organized in collaboration with the International Workshop on Image and Audio Analysis for Multimedia Interactive services (WIAMIS)</gtr:description><gtr:exploitationPathways>Ideas to be explored for general media within the Semantic Media project are now being explored in more detail as part of the EPSRC funded programme grant FAST-IMPACT EP/L019981/1</gtr:exploitationPathways><gtr:id>6FB9A04A-CDDE-4043-A9EA-729717A97167</gtr:id><gtr:outcomeId>r-6458324442.1131277962370</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors><gtr:url>http://semanticmedia.org.uk</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Semantic Media Network Initiative</gtr:description><gtr:geographicReach>Europe</gtr:geographicReach><gtr:id>8AE1B289-252B-4744-9028-BD4B69C3F1B7</gtr:id><gtr:impact>The Semantic Media Network Initiative aimed at making researchers and policy makers aware of the advantages of using structures data representations and semantic web technology in media production and archival processes, which directly leads to and inspires novel business models, accessibility concepts and forms of media experience.</gtr:impact><gtr:outcomeId>56cf2becc989c7.71166934</gtr:outcomeId><gtr:type>Influenced training of practitioners or researchers</gtr:type><gtr:url>http://semanticmedia.org.uk/</gtr:url></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Outcome of mini-project 'POWkist - Visualising Cultural Heritage Linked Datasets' led by 'Chris Mellish'

The POWKist project aims to use semantic technologies to support visualisation of combined linked datasets in the cultural heritage domain. This is to provide systematic and attractive visualisation of cultural heritage linked dataset and bring raw data closer to citizen-historians for more efficient exploitation. POWkist will cover the whole life-cycle of content from data collection to data consumption by citizen-historians and the general public.</gtr:description><gtr:id>CF29AAB3-DA2D-46E5-9F8C-267539CB0D2C</gtr:id><gtr:impact>The POWkist demo highlights linked data technology in historical / archival contexts.</gtr:impact><gtr:outcomeId>56cf122d341bf0.08455944</gtr:outcomeId><gtr:title>Demo POWkist</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:url>http://powkist.abdn.ac.uk/pkdemo</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Viewers watching TV may would like to use their tablet or smart phone as a 'second screen', firstly to identify any music playing on the TV, and then secondly to discover more information about it. Thus, the microphone of the 'second screen' device is used to listen to the music playing on the TV, whilst audio fingerprinting technology is used to identify it. Then, a dynamically webpage is generated providing rich information about the music identified, as well as related music and musical artists based on social-cultural factors. The latter is achieved by querying web services such as Youtube, The Echonest, Last.fm and MusicBrainz. Linking and making sense - knowledge inference - out of such wide range and diverse music-related data acquired across multiple sources and services on the web is achieved thanks to C4DM Music Ontology. An Android app acting as a 'second screen' is currently available for demonstration purposes.</gtr:description><gtr:id>A64C018F-D6A4-4C7E-806E-1C958AA6D6BE</gtr:id><gtr:impact>The corresponding demo has been discussed within the MPEG consortium.</gtr:impact><gtr:outcomeId>56cefd3bc315b8.95345709</gtr:outcomeId><gtr:title>Demo Second Screen</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:url>https://code.soundsoftware.ac.uk/projects/screen2</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Outcome of mini-project 'Large-Scale capture of Producer-Defined Musical Semantics.' led by Ryan Stables.

The study is motivated by the lack of transferable semantic descriptors in music production and the requirement for more intuitive control of low-level parameters, thus providing musicians with easier access to technology. We aim to overcome this problem by evaluating large amounts of labelled data taken from within the digital audio workstation. The main novelty that will be introduced by the project is a model for the estimation of perceptually accurate descriptors based on a large corpus of semantically annotated music production data. The outcome of the mini-project will be the identification of an appropriate methodology for the capture of this semantic data.</gtr:description><gtr:id>09B5CC5D-BBC8-410E-89F3-7F7E7224C6F4</gtr:id><gtr:impact>A conference paper listed separately and ongoing work as part of the EPSRC programme grant FAST-IMPACT.</gtr:impact><gtr:outcomeId>54611206793c81.56695736</gtr:outcomeId><gtr:title>Demo SAFE Plugins</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/semanticaudio/SAFE</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>34C0395A-D7FD-4E33-8D26-829B51CC5B9F</gtr:id><gtr:title>Automatic transcription of pitched and unpitched sounds from polyphonic music</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d720457c66f1666042ea2bbbcbcf349e"><gtr:id>d720457c66f1666042ea2bbbcbcf349e</gtr:id><gtr:otherNames>Benetos E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460fcc451d3b1.59917247</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D77B9544-8B31-43C4-8802-6A6189B80CFE</gtr:id><gtr:title>Explorations in Linked Data practice for early music corpora</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ad0f98a3dce355be83ca461c37241640"><gtr:id>ad0f98a3dce355be83ca461c37241640</gtr:id><gtr:otherNames>Crawford T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54610157736c92.98916390</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1FB45BDA-FA44-4470-8217-C0EB208ED500</gtr:id><gtr:title>On providing semantic alignment and unified access to music library metadata</gtr:title><gtr:parentPublicationTitle>International Journal on Digital Libraries</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cfae4e8d7eb5b7ff60bb066b7ed435b4"><gtr:id>cfae4e8d7eb5b7ff60bb066b7ed435b4</gtr:id><gtr:otherNames>Weigl D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fe5768e3239.31339187</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>960004B5-4A4F-49DE-AAD9-2A01152A68C1</gtr:id><gtr:title>WhatTheySaid: Enriching UK Parliament Debates with Semantic Web</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b7686a770f7028f6cfae81af4ad35e64"><gtr:id>b7686a770f7028f6cfae81af4ad35e64</gtr:id><gtr:otherNames>Li, Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546105c910a9d5.02587350</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B4D90A81-83D1-481A-963D-2D47B1A33E9C</gtr:id><gtr:title>Notentext-Informierte Quellentrennung fuer Musiksignale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/22c0d138888e0f358b677bbc7d721999"><gtr:id>22c0d138888e0f358b677bbc7d721999</gtr:id><gtr:otherNames>Mueller, M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5460ff2db2fd34.85541696</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>82962464-B1F1-4CB5-B0AE-2B3BE35D5ADC</gtr:id><gtr:title>Expert-Guided Semantic Linking of Music-Library Metadata for Study and Reuse</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a72525e075193cc8f08e3e37e20a6b49"><gtr:id>a72525e075193cc8f08e3e37e20a6b49</gtr:id><gtr:otherNames>Weigl, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf24592d26d0.93992143</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C057F840-4586-4790-835B-2BC5BC5B17D9</gtr:id><gtr:title>Spatially Rendering Decomposed Recordings Integrating Score-Informed Source Separation and Semantic Playback technologies</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6bafffdb724574f4651e04351bc25e1d"><gtr:id>6bafffdb724574f4651e04351bc25e1d</gtr:id><gtr:otherNames>Thalman, F.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf183f668344.88567277</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4BC950F4-8031-41C3-834E-1A022B24B788</gtr:id><gtr:title>Score-Informed Source Separation for Musical Audio Recordings: An overview</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecbadd3514247d9dd2617ec865425671"><gtr:id>ecbadd3514247d9dd2617ec865425671</gtr:id><gtr:otherNames>Ewert S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460fc08aaa3f9.42563801</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AC9EF53B-B908-48BE-BF08-9D1FD0B451E8</gtr:id><gtr:title>A Unified Access to Media Industry and Academic Datasets: A Case Study in Early Music</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a72525e075193cc8f08e3e37e20a6b49"><gtr:id>a72525e075193cc8f08e3e37e20a6b49</gtr:id><gtr:otherNames>Weigl, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf1d26e3aab2.65257865</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A67B592C-AE82-4FCA-92FC-FDD839EB2EF5</gtr:id><gtr:title>Efficient data adaption for musical source separation methods based on parametric models</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecbadd3514247d9dd2617ec865425671"><gtr:id>ecbadd3514247d9dd2617ec865425671</gtr:id><gtr:otherNames>Ewert S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5460ff4bd57b52.35706936</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A871FE13-8AB8-4EC9-B675-36BF2741A05A</gtr:id><gtr:title>Accounting for phase cancellations in non-negative matrix factorization using weighted distances</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecbadd3514247d9dd2617ec865425671"><gtr:id>ecbadd3514247d9dd2617ec865425671</gtr:id><gtr:otherNames>Ewert S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460fcaa27e8b1.44817204</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F3BD174A-E039-4E1E-94F4-E4B02B9D978F</gtr:id><gtr:title>Non-negative matrix factorisation incorporating greedy hellinger sparse coding applied to polyphonic music transcription</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56ddd59ba69645.19139884</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4412B60C-C2FB-4C7E-B34A-D22C3B3159F4</gtr:id><gtr:title>Towards High Level Feature Extraction from Large Live Music Recording Archives</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bbff6264937a8cc4dc66e7c1a5bf271c"><gtr:id>bbff6264937a8cc4dc66e7c1a5bf271c</gtr:id><gtr:otherNames>Thomas Wilmering</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56ddc8dfc93f17.10404093</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9DAEAB7C-C6E8-45D9-B272-907F0C24F079</gtr:id><gtr:title>Improving Time-Scale Modification of Music Signals Using Harmonic-Percussive Separation</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c828cd33d2cc826aee11466967750bb6"><gtr:id>c828cd33d2cc826aee11466967750bb6</gtr:id><gtr:otherNames>Driedger J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460fc49c50d94.97224599</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CB4DA3F2-1CCE-49F1-83D6-716A67E2B9E6</gtr:id><gtr:title>Sparse NMF approaches applied to Music Transcription</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/75d759300f6e23cbc1fc5d1eda7b49b6"><gtr:id>75d759300f6e23cbc1fc5d1eda7b49b6</gtr:id><gtr:otherNames>K O'Hanlon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56e039581e59f6.50033652</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>105D6091-AF73-46B7-8DC6-EAEBF3E2B4DC</gtr:id><gtr:title>Challenges of finding aesthetically pleasing images</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0e044700d5c90cc2b5f6106ec69a8b24"><gtr:id>0e044700d5c90cc2b5f6106ec69a8b24</gtr:id><gtr:otherNames>Faria J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546212cec4b855.58321012</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>985D98F2-EFF8-41D9-BB21-A9E65E6EABD0</gtr:id><gtr:title>Hello cleveland! Linked data publication of live music archives</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2eb4f439cbab291121cb1f4342c03c5e"><gtr:id>2eb4f439cbab291121cb1f4342c03c5e</gtr:id><gtr:otherNames>Bechhofer S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5462129859dcb7.83295385</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>93FE3344-9BE1-49DF-A16D-90BCB3083AAA</gtr:id><gtr:title>Robust Joint Alignment of Multiple Versions of a Piece of Music</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/57fcb015a363298d25f9ca1ab6f9fb5f"><gtr:id>57fcb015a363298d25f9ca1ab6f9fb5f</gtr:id><gtr:otherNames>Wang, S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460fe992a7799.62597103</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DBAFBD4D-2643-4962-924F-B4DCBD6840C8</gtr:id><gtr:title>Non-Negative Group Sparsity with Subspace Note Modelling for Polyphonic Transcription</gtr:title><gtr:parentPublicationTitle>IEEE/ACM Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56ddd531ceef31.53891935</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>25D0F3C7-FD85-4BE5-A8DB-BEA731F8502B</gtr:id><gtr:title>Describing audio production workflows on the semantic web</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2fd53c70d717490415b8aa5cf9c39f79"><gtr:id>2fd53c70d717490415b8aa5cf9c39f79</gtr:id><gtr:otherNames>Fazekas G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546212f7467de5.58850970</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6C687850-BF6D-4ABC-90A2-AE8C5F0DF062</gtr:id><gtr:title>Recent advances in affective and semantic media applications at the BBC</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cbad43ae17514022aa5a9cb8a13f7f6a"><gtr:id>cbad43ae17514022aa5a9cb8a13f7f6a</gtr:id><gtr:otherNames>Eggink J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>54621269629123.40411957</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>89A8D5BB-DFF7-41C3-80BE-0ADB6A8E5FFE</gtr:id><gtr:title>Assisted Parameter Modulation in Music Production using Large-Scale Producer-Defined Semantics</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab5fb499133c1b58d618e30ffa6c74fa"><gtr:id>ab5fb499133c1b58d618e30ffa6c74fa</gtr:id><gtr:otherNames>Stables, R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546100f89e9804.53394677</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1FEF9B02-853E-46CC-A7B6-F878F9EB4199</gtr:id><gtr:title>Creating Semantic Links between Research Articles and Music Artists</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/49c159227e4f17178bdddb09ebc4d8aa"><gtr:id>49c159227e4f17178bdddb09ebc4d8aa</gtr:id><gtr:otherNames>Mora-McGinity, M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56cf152242ed37.13173227</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C558D68D-99DD-4A21-9F6E-439331C9AB74</gtr:id><gtr:title>Shared Open Vocabularies and Semantic Media</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1d5b92ee61bf449396d3c888875c0f71"><gtr:id>1d5b92ee61bf449396d3c888875c0f71</gtr:id><gtr:otherNames>Fazekas, G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>5460ffe6cd7bb2.84974204</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C1F94AFB-ECAC-45BF-86B0-146E14B15568</gtr:id><gtr:title>SemanticNews: Enriching publishing of news stories</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b0911de0b7939cd446a251fd60968243"><gtr:id>b0911de0b7939cd446a251fd60968243</gtr:id><gtr:otherNames>Hare, J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5461032e1e03f5.97249958</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>07239CDA-A503-4E23-B053-B3F8C1752D40</gtr:id><gtr:title>SAFE: A System For The Extraction And Retrieval Of Semantic Audio Descriptors</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab5fb499133c1b58d618e30ffa6c74fa"><gtr:id>ab5fb499133c1b58d618e30ffa6c74fa</gtr:id><gtr:otherNames>Stables, R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546113b1acd193.38301406</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>21129814-DFF6-4A90-B97A-92D7C4C1B728</gtr:id><gtr:title>The Audio Degradation Toolbox And Its Application To Robustness Evaluation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/355bea3af3d47f112fa8505fd4ca0be7"><gtr:id>355bea3af3d47f112fa8505fd4ca0be7</gtr:id><gtr:otherNames>Mauch, M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5460fd803788c4.26059069</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F90E0312-715A-4A48-A461-405084AC9728</gtr:id><gtr:title>Automating Annotation of Media using Linked Data Workflows</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bbff6264937a8cc4dc66e7c1a5bf271c"><gtr:id>bbff6264937a8cc4dc66e7c1a5bf271c</gtr:id><gtr:otherNames>Thomas Wilmering</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56ddc87dde9147.04001466</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2DDB900A-DE38-4548-AF7C-2B86EF59C082</gtr:id><gtr:title>Identifying Missing and Extra Notes in Piano Recordings Using Score-Informed Dictionary Learning</gtr:title><gtr:parentPublicationTitle>IEEE/ACM Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fe2b6467250.06254109</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0FDF6F95-EDED-4BBD-B1A9-12EEFC1E1A85</gtr:id><gtr:title>Computational Analysis Of The Live Music Archive</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c69bfe2dcaa2a7a3e88bd016ee6224c1"><gtr:id>c69bfe2dcaa2a7a3e88bd016ee6224c1</gtr:id><gtr:otherNames>Bechhofer, S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546103fbf10839.80287713</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1F724D43-87B0-41C3-9B67-6032F95DB1A7</gtr:id><gtr:title>Event-driven retrieval in collaborative photo collections</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/21e8c2763915ee32279ba20594d33d9b"><gtr:id>21e8c2763915ee32279ba20594d33d9b</gtr:id><gtr:otherNames>Brenner M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>54621240e3aa17.16126133</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>55FEC90E-253E-48A8-8540-D61D1876D2BB</gtr:id><gtr:title>Semi-automated video logging by incremental and transfer learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/777f83df34e1859c83cdf51578caf9d5"><gtr:id>777f83df34e1859c83cdf51578caf9d5</gtr:id><gtr:otherNames>Kim J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546212bd425518.87255452</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B2714934-D178-4F6D-A4F7-8350FA7B44FC</gtr:id><gtr:title>An iterative hard thresholding approach to \ell_0 sparse Hellinger NMF</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4f23a5e7c186f3f78d19ef8670860c30"><gtr:id>4f23a5e7c186f3f78d19ef8670860c30</gtr:id><gtr:otherNames>K. O'Hanlon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56ddd5f8cfbf22.88757890</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A569F542-24A3-45CA-9001-A94755D63127</gtr:id><gtr:title>Computational Analysis of the Live Music Archive</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2eb4f439cbab291121cb1f4342c03c5e"><gtr:id>2eb4f439cbab291121cb1f4342c03c5e</gtr:id><gtr:otherNames>Bechhofer S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460b6f0b26321.41233617</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D08BBE89-98D8-44C1-A60B-03C62D0A22B7</gtr:id><gtr:title>Robust and Efficient Joint Alignment of Multiple Musical Performances</gtr:title><gtr:parentPublicationTitle>IEEE/ACM Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d40219ab358.47698634</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50360442-3950-48D8-911B-BAF9FAB52AD0</gtr:id><gtr:title>POWKist: Visualising Cultural Heritage Linked Datasets</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/97b5e54c6178149dc0a535724ee736e8"><gtr:id>97b5e54c6178149dc0a535724ee736e8</gtr:id><gtr:otherNames>Kay, A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf24e7e6d619.81364705</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0F3AF0E7-4DB5-4841-90DF-EAAE761BA0E5</gtr:id><gtr:title>Compensating for Asychronies Between Musical Voices in Score-Performance Alignment</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d04f3972f5a6fa5e85e015596bce9f30"><gtr:id>d04f3972f5a6fa5e85e015596bce9f30</gtr:id><gtr:otherNames>Wang, S.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cf1c5caab1b2.41299559</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E5A68EAC-94AB-40D9-8E9E-F80966A09A11</gtr:id><gtr:title>Semantically Linking Humanities Research Articles and Music Artists</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c1c67bb5f6951e49af8bfe583f65e3dc"><gtr:id>c1c67bb5f6951e49af8bfe583f65e3dc</gtr:id><gtr:otherNames>Mora-McGinity, Mariano</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56cf15aebd9cd2.86955762</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0A9A1B5B-A813-49D5-BB29-6F7DAF3BEFEA</gtr:id><gtr:title>A Dynamic Programming Variant of Non-Negative Matrix Deconvolution for the Transcription of Struck String Documents</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e4162b34f41e36022fc1f3e1a467c1e3"><gtr:id>e4162b34f41e36022fc1f3e1a467c1e3</gtr:id><gtr:otherNames>Ewert, S.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56cedee9daad50.51279534</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J010375/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0A982A4A-12CF-4734-AFCA-A5DC61F667F3</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Information &amp; Knowledge Mgmt</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>