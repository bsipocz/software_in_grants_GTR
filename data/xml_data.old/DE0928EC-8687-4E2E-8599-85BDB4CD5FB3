<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D5DF5258-6FC1-4F92-928B-2E970FF914D4"><gtr:id>D5DF5258-6FC1-4F92-928B-2E970FF914D4</gtr:id><gtr:name>The University of Iowa</gtr:name><gtr:address><gtr:line1>203 Van Allen Hall</gtr:line1><gtr:line4>Iowa City</gtr:line4><gtr:line5>IA 52242-1479</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:department>Institute of Neuroscience</gtr:department><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5E2B04DD-4A03-45ED-9892-61C5CCB8AC68"><gtr:id>5E2B04DD-4A03-45ED-9892-61C5CCB8AC68</gtr:id><gtr:name>Newcastle University</gtr:name><gtr:address><gtr:line1>1 Park Terrace</gtr:line1><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:line5>Tyne and Wear</gtr:line5><gtr:postCode>NE1 7RU</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5DF5258-6FC1-4F92-928B-2E970FF914D4"><gtr:id>D5DF5258-6FC1-4F92-928B-2E970FF914D4</gtr:id><gtr:name>The University of Iowa</gtr:name><gtr:address><gtr:line1>203 Van Allen Hall</gtr:line1><gtr:line4>Iowa City</gtr:line4><gtr:line5>IA 52242-1479</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/269744D0-0C34-49B3-A012-045D336FD77B"><gtr:id>269744D0-0C34-49B3-A012-045D336FD77B</gtr:id><gtr:firstName>Christopher</gtr:firstName><gtr:surname>Petkov</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2CE12B14-E198-4CF5-9EB9-E2BA443459D5"><gtr:id>2CE12B14-E198-4CF5-9EB9-E2BA443459D5</gtr:id><gtr:firstName>Quoc</gtr:firstName><gtr:otherNames>Chi</gtr:otherNames><gtr:surname>Vuong</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FJ009849%2F1"><gtr:id>DE0928EC-8687-4E2E-8599-85BDB4CD5FB3</gtr:id><gtr:title>The impact of attention on the neuronal mechanisms of adaptation in humans and animals</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/J009849/1</gtr:grantReference><gtr:abstractText>Brain neurons adapt or change their responsiveness following the repetition of an environmental event, such as the voice or face of an individual. Neuronal adaptation/repetition effects are thought to be important because a reduced response could indicate familiarity with an individual that we have just met and help cognitive processes to recognize and remember the individual. The neuronal mechanisms of adaptation are of great interest but remain controversial.

Human functional magnetic resonance imaging (fMRI) is a non-invasive technique that is increasingly being harnessed to make inferences about neuronal responses during adaptation. Neuronal level study in animal models is required to clarify the neuronal mechanisms. However, although a number of animal neuronal studies of adaptation have shown that neurons generally reduce their firing rates to all stimuli (what is called the ?response-fatigue? model of adaptation), the latest human fMRI adaptation studies suggest that this perspective is incomplete. The human results indicate that certain brain regions might contain neurons that can become more selective to specific stimuli or their features after adaptation (what is called the ?sharpened selectivity? model). In any case, several scientific issues appear to have complicated the interpretation of the fMRI adaptation response. Namely, the impact of attention has not been studied in the same way in both species, inconsistent experimental paradigms have been used to obtain the human and animal adaptation results, and it is not clear whether the mechanisms of adaptation (which have primarily been studied in the visual system) would be comparable to those in another sensory system, such as the auditory. Therefore, despite the importance of the popular fMRI adaptation phenomenon, the neuronal mechanisms that support it remain highly controversial.

This project is designed to address this controversy by implementing a human and animal fMRI project based ame attentionally-controlled experiment, combined with precisely targeted neuronal recordings in the animals. Specifically, we aim to: 1) evaluate whether fMRI adaptation responses are comparable in humans and animals by conducting the same attentional experiment with both species; 2) extend the latest human fMRI adaptation paradigms to the work with animals, especially the new paradigms that appear to be able to reveal regional changes in neuronal selectivity; and 3) precisely target for neuronal recordings regions showing changes in selectivity and/or those consistent with the response-fatigue model in the animals. Moreover, we aim to conduct the experiment in the visual and auditory modalities (using, respectively, faces or voices as stimuli) to address the correspondence of fMRI adaptation responses across different sensory modalities. This is an important secondary objective because electrophysiological studies have obtained auditory adaptation results in various animals that may or may not be comparable to adaptation in the visual modality of animals. Lastly, although it is not critical for the success of the project, we have the opportunity here to combine fMRI and electrophysiology in animals to be able to more directly associate the fMRI signal and neuronal responses. If successful, our UK institution would be only the second institution in the world to achieve this in conscious behaving animals.

In summary, it has become crucial to test the link between human and animal adaptation results by using the same experiment (and stimuli) based on an attentionally controlled task. Our project has the potential to greatly advance our understanding of the neuronal mechanisms of fMRI adaptation and how they might be influenced by or interact with cognitive processes such as those of attention. The results are likely to guide future efforts that employ fMRI adaptation to influence mental processes, including memory and expectancy.</gtr:abstractText><gtr:technicalSummary>Neurons change or adapt their responsiveness to the repetition of the same or similar events. However, how repetition affects neuronal responses, although of tremendous interest, still remains unclear. To date, animal electrophysiology and human imaging studies (using the popular fMRI adaptation or ?repetition suppression? effects) have given rise to conflicting perspectives on the neuronal mechanisms of fMRI adaptation, and whether and how attention may have affected adaptation. We propose to address this uncertainty by using the same attentionally-controlled adaptation experiment with fMRI in humans and animals, and with electrophysiological recordings in the animals. The fMRI study will allow us to test for any cross-species correspondences in regionally-specific fMRI adaptation responses. Most outcomes will be important and are needed to reconcile the controversy surrounding the interpretation of animal and human adaptation-related results. To determine whether similar mechanisms operate in auditory and visual cortices, we aim to conduct the experiment separately in the auditory and visual modalities using parametrically morphed voices or faces. The animal fMRI results will be used to target at least two brain regions for electrophysiology. The neurophysiological data (based on response measurements from single and multiple neurons, and local-field potentials) will be related to the fMRI adaptation response and quantified in relation to the theoretical models of these to clarify the neurophysiological bases that subserve regional fMRI adaptation responses. We are confident that this ambitious project is feasible given the proven experience of the co-applicants with all aspects of the project that will be needed and the research environment at the host institution.</gtr:technicalSummary><gtr:potentialImpactText>How the brain adapts to the environment serves as an important basis for many cognitive brain functions, such as perception, attention, memory and learning. Adaptation appears to be a ubiquitous general property of many neurons across many animal species. We propose to investigate adaptation effects at multiple neurobiological levels, from single neurons to the activity of brain regions, and in humans and another species of animals. Thus, in addition to the scientific impact, our results combined with our experience with impact activities are likely to have an influence on medical research, commercial applications, and the public. Furthermore, our proposed comparative work will advance the UK priorities to reduce, refine, or replace invasive animal research, as follows.

This project will expand the UK neurobiological-research base, particularly for the staff that are presented with the unique opportunity to combine brain neuroimaging and electrophysiological techniques in behaving models. This combination is critical for detailed neuronal modelling of human brain function for medical research. Our focus on the neuronal mechanisms underlying face and voice selectivity opens up the opportunity to exploit our data for commercial applications for automated face and voice recognition. Lastly, in the short term, the research staff, technicians and students who engage in the project will develop a unique set of skills and vocational training that will help them to be competitive in medically related commercial or academic settings.

The lay public sector is another key potential beneficiary in that lay individuals will have a better understanding of how the brain supports repetition effects and their evolutionary basis. This project will also bring attention to neuronal adaptation as a prominent process in the brain, and presumably peak people?s interest on how sub-conscious processes such as this one interact with conscious processes like those that support perceptl awareness and attention.

Finally, our project will help to reduce the reliance on invasive electrophysiology in animal models and advance the use of non-invasive fMRI techniques with animals, which is an important objective of the BBSRC and the National Centre for the 3Rs (NC3Rs) with regards to refinement, reduction and replacement of animal experiments. This human and animal project highlights the ethical issues that are at the forefront of scientific research and is likely to be exemplary for other international institutions aiming to better relate human and animal research.

In sum, this multidisciplinary project will help maintain the UK?s competitive edge on the international research scene, contribute experimental brain data for systems approaches to biological research, and potentially stimulate collaboration between interdisciplinary scientists during dissemination of results at international meetings and conferences.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-02-29</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2013-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>575921</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>Recordings of human and macaque voices/faces for project allows us not only stimuli to use for the project but content for a planned methods publication.</gtr:description><gtr:id>02A07B54-8275-4604-915F-018D26DB0FAA</gtr:id><gtr:impact>no actual impacts realised to date</gtr:impact><gtr:outcomeId>m-1369628311.479118a71945d0</gtr:outcomeId><gtr:title>Recordings of human and macaque voices/faces for project</gtr:title><gtr:type>Film/Video/Animation</gtr:type><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with MRC - Centre for Macaques</gtr:description><gtr:id>702D521B-6DFA-4FCA-A6E4-AF2B41951276</gtr:id><gtr:impact>Experiments created with materials from CFM.</gtr:impact><gtr:outcomeId>b95f8c64b95f8c78-1</gtr:outcomeId><gtr:partnerContribution>Exchange of stimulus materials. Exchange of ideas.</gtr:partnerContribution><gtr:piContribution>Collaboration established with MRC - Centre for Macaques in Porton Down for exchange of materials and information.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of York</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>York Dept. Psychology (Dr. Nick Barraclough)</gtr:description><gtr:id>00B2EDE6-AA35-4C9D-BC30-289624BF38B7</gtr:id><gtr:impact>Intellectual exchange. Student co-supervision.</gtr:impact><gtr:outcomeId>b95f8886b95f889a-1</gtr:outcomeId><gtr:partnerContribution>Intellectual exchange. Studentship co-supporting.</gtr:partnerContribution><gtr:piContribution>Project helped to establish a Newcastle - York Collaboration</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Iowa</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:department>Department of Neurosurgery</gtr:department><gtr:description>Direct recordings from human brain</gtr:description><gtr:id>B1E689B8-724B-4FA5-872A-88B577F2F3AA</gtr:id><gtr:impact>Paper submitted on first comparative direct recordings from the human and monkey brain.</gtr:impact><gtr:outcomeId>56c8318829f460.02691969-1</gtr:outcomeId><gtr:partnerContribution>Provide access to these rare recordings.</gtr:partnerContribution><gtr:piContribution>Collaboration to collect human intracranial recording data.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Brain Awareness Public Engagement 2014</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>E1AB1E1D-74B1-4840-839C-29667833DC6B</gtr:id><gtr:impact>CP used elements form this project to engage young audiences during Brain Awareness Week (10-12/3/2014). Demonstrations of brain neuroimaging technology was made in front of several school and church groups passing along the message of replacing animals in research procedures. Brain imaging demos. Mock scanner demo. Chocolate brain demo. Visual illusions demo.

The impact was on helping community children to appreciate that animal welfare can be advanced along with new technologies for imaging the brain.</gtr:impact><gtr:outcomeId>r-1326582274.7038510ce3103a</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>10 prominent presentations by CP this year 2015</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>61F87CFB-60CC-4CF0-B171-A0F61A2BDF86</gtr:id><gtr:impact>I have given 10 oral presentations in 2014, 4 of which have been Keynote lectures. The organizations include UCL, universities in the USA, FENS.
 In 2015 I gave 10 presentations. New ones for 2016 include important talks at Gordon Research Conference, and UC San Diego winter school in neuroscience.</gtr:impact><gtr:outcomeId>56c83488b52c00.98050191</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>175000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Wellcome Trust Enhancement Grant</gtr:description><gtr:end>2020-03-02</gtr:end><gtr:fundingOrg>Wellcome Trust</gtr:fundingOrg><gtr:id>17ED95C6-C830-4DD8-B912-2C6D197A703A</gtr:id><gtr:outcomeId>56c831f0436026.05285851</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2015-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>3800000</gtr:amountPounds><gtr:country>United States of America</gtr:country><gtr:currCode>USD</gtr:currCode><gtr:currCountryCode>Ecuador</gtr:currCountryCode><gtr:currLang>es_EC</gtr:currLang><gtr:description>NIH R01</gtr:description><gtr:end>2020-06-02</gtr:end><gtr:fundingOrg>National Institutes of Health (NIH)</gtr:fundingOrg><gtr:id>0C09DD54-6043-43F9-B076-52B75D1C30D8</gtr:id><gtr:outcomeId>56c8323b131468.26418169</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1249966</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Wellcome Trust New Investigator Award</gtr:description><gtr:end>2020-02-02</gtr:end><gtr:fundingOrg>Wellcome Trust</gtr:fundingOrg><gtr:fundingRef>102961/Z/13/Z</gtr:fundingRef><gtr:id>F8831447-DCEF-4FC3-B11A-FC029D8E0D67</gtr:id><gtr:outcomeId>5ee172585ee1726c</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2014-03-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1995000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>Consolidator Grant</gtr:description><gtr:end>2022-04-02</gtr:end><gtr:fundingOrg>European Research Council (ERC)</gtr:fundingOrg><gtr:fundingRef>MECHIDENT</gtr:fundingRef><gtr:id>EE7D0FDB-77BA-42D3-9B58-809BA066CD77</gtr:id><gtr:outcomeId>58a48351db84e6.99907283</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2017-05-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We are presenting our findings in humans at two meetings; one presentation was selected for an oral presentation. We have also published papers under this grant. There is a paper on the comparative neuroimaging of audio-visual selective attention in secondary review at Cerebral Cortex. Moreover, work on the neuropsysiology is in secondary review at PLoS Biology.

The non-academic impact is several Brain Awareness Activities arising from the work, including BBC3 Radio involvement. The work has also resulted in additional funding to pursue the new research directions that have been generated by the BBSRC grant. Additionally the work has generated new materials for morphing faces and voices, including discussions at Google with one of the founders of the voice morphing software from Japan. New work involving neurosurgery groups has also materialized highlighting the interest from the community the basis for which was established by this grant.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>B23AF34D-2C34-458E-BFE5-0BCC5B71DA06</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>546536229ae6f3.20373823</gtr:outcomeId><gtr:sector>Education,Healthcare,Manufacturing, including Industrial Biotechology,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have discovered that attention modulates voice and face sensitive cortex comparably across the sensory modalities. We have also discovered the mode by which attention influences the brain adaptation response: by increasing the gain of the brain response. 

We have also studied the how attention influences the human and monkey brain with neuroimaging. The findings are surprising in that they show that monkey attention effects are more labile than those in humans. We also identify how attention effects are 'lost' which is likely to of tremendous importance for the scientific community.</gtr:description><gtr:exploitationPathways>We are well poised to publish the remaining findings from this grant. The comparative fMRI paper and the monkey neurophysiology paper are in secondary review so are likely to be published soon.</gtr:exploitationPathways><gtr:id>4B687AE8-BB0F-4CC4-B560-CE83AE57C828</gtr:id><gtr:outcomeId>546534d3ebda20.44827538</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Healthcare,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Advisory Group</gtr:description><gtr:geographicReach>Multiple continents/international</gtr:geographicReach><gtr:id>0162DC4F-4F23-481A-9353-9AFD390809F4</gtr:id><gtr:impact>I have helped to co-found a UK NHP group of primary investigators to coordinate as a group that can inform funders, regulators, politicians and the public on when NHP work is important. We've already had key meetings. We have also invited local MEPs and MPs.</gtr:impact><gtr:outcomeId>56c833d5a7ce13.59231886</gtr:outcomeId><gtr:type>Participation in a national consultation</gtr:type></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>12113968-D9B5-4613-AA3A-9B1707BC39CF</gtr:id><gtr:title>Auditory motion-specific mechanisms in the primate brain.</gtr:title><gtr:parentPublicationTitle>PLoS biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/74dc964851dbb72ec6353dc6076236bb"><gtr:id>74dc964851dbb72ec6353dc6076236bb</gtr:id><gtr:otherNames>Poirier C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1544-9173</gtr:issn><gtr:outcomeId>5a35f73d14b3c4.77608010</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BB9F1A20-4C6C-4F9E-922A-ABD24BC1418B</gtr:id><gtr:title>Who is That? Brain Networks and Mechanisms for Identifying Individuals.</gtr:title><gtr:parentPublicationTitle>Trends in cognitive sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1df8b9415cb39e61351f2f77b90f99ea"><gtr:id>1df8b9415cb39e61351f2f77b90f99ea</gtr:id><gtr:otherNames>Perrodin C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1364-6613</gtr:issn><gtr:outcomeId>56c830968016b8.48074189</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D4BADB04-55E0-43A0-AA5F-F3FBA2E9367F</gtr:id><gtr:title>Mental structures and hierarchical brain processing. Comment on &amp;quot;Toward a computational framework for cognitive biology: unifying approaches from cognitive neuroscience and comparative cognition&amp;quot; by W. Tecumseh Fitch.</gtr:title><gtr:parentPublicationTitle>Physics of life reviews</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93dc3be766adc458d5695d04189246b7"><gtr:id>93dc3be766adc458d5695d04189246b7</gtr:id><gtr:otherNames>Petkov CI</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1571-0645</gtr:issn><gtr:outcomeId>585d3680bc5330.79553739</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CAF8DBD7-4C0D-4F24-B6F2-FC6E125E2295</gtr:id><gtr:title>Searching for the origins of musicality across species.</gtr:title><gtr:parentPublicationTitle>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9dcbc9cc1ee45213b6d86af0e4a6721a"><gtr:id>9dcbc9cc1ee45213b6d86af0e4a6721a</gtr:id><gtr:otherNames>Hoeschele M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0962-8436</gtr:issn><gtr:outcomeId>5675df542c7c8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B995F65-5A17-4CAC-9FF3-0E3F22406D96</gtr:id><gtr:title>Individually customisable non-invasive head immobilisation system for non-human primates with an option for voluntary engagement.</gtr:title><gtr:parentPublicationTitle>Journal of neuroscience methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/760024c8382e917c9c7b09d2e5306a64"><gtr:id>760024c8382e917c9c7b09d2e5306a64</gtr:id><gtr:otherNames>Slater H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0165-0270</gtr:issn><gtr:outcomeId>585d3ff48c76e4.21973973</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7481013E-74E4-41D9-9C68-F75CEEFC68FC</gtr:id><gtr:title>Neuronal coding: the value in having an average voice.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93dc3be766adc458d5695d04189246b7"><gtr:id>93dc3be766adc458d5695d04189246b7</gtr:id><gtr:otherNames>Petkov CI</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>56c83096b46618.63259265</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B6E6F36-03E3-4373-A214-DC716000CC84</gtr:id><gtr:title>Functional Imaging of Audio-Visual Selective Attention in Monkeys and Humans: How do Lapses in Monkey Performance Affect Cross-Species Correspondences?</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5e7d685bea896063510e28590f96224"><gtr:id>b5e7d685bea896063510e28590f96224</gtr:id><gtr:otherNames>Rinne T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>5a35f6b7dd8b56.01685531</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/J009849/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>4A2A69ED-37ED-4980-91A7-E54B4F6A9BC6</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal organisms</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>3493671D-A4CF-4197-90A7-3CCFBE1C0627</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools for the biosciences</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>