<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/26490210-C8AA-4AF8-AA71-0EA739BE1B91"><gtr:id>26490210-C8AA-4AF8-AA71-0EA739BE1B91</gtr:id><gtr:name>Metail Limited</gtr:name><gtr:address><gtr:line1>New Loom House,101 Back Church Lane</gtr:line1><gtr:city>London</gtr:city><gtr:postCode>E1 1LU</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/26490210-C8AA-4AF8-AA71-0EA739BE1B91" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>26490210-C8AA-4AF8-AA71-0EA739BE1B91</gtr:id><gtr:name>Metail Limited</gtr:name><gtr:address><gtr:line1>New Loom House,101 Back Church Lane</gtr:line1><gtr:city>London</gtr:city><gtr:postCode>E1 1LU</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>99444.0</gtr:offerGrant><gtr:projectCost>179762.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/FBF409E5-0407-4CCF-9BF2-889442EEA530"><gtr:id>FBF409E5-0407-4CCF-9BF2-889442EEA530</gtr:id><gtr:firstName>Yu</gtr:firstName><gtr:surname>Chen</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=710654"><gtr:id>826358AC-0FCA-4F33-BA6A-8B9F3333DD9E</gtr:id><gtr:title>Wotou</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>GRD Proof of Concept</gtr:grantCategory><gtr:grantReference>710654</gtr:grantReference><gtr:abstractText>Metail is the leading provider of body shape and garment visualisation technology for online
retailers. Our system allows an e-shopper to create her MeModel, i.e. a 3D avatar representing
her own shape, and interactively dress the MeModel to provide a photo-realistic visualisation
of how clothes will look and fit on her. The product is in use by a number of retailers in the
UK, Singapore, and Brazil, and has been proved to add values by mean of increasing
conversion rates (% of customers who buy) and engagement (time spent on site).
In Project Wotou we will explore using computer vision techniques and mobile devices to
significantly improve the quality of 3D head and hair models and the ease with which they
can be created, in particular allowing our user to add her face to the MeModel. User testing
over the last 18 months shows that personalisation is a key factor to increase adoption and
habitual use of the product. The more closely the MeModel resembles the user, the more
compelling she finds it and the more she trusts it. Unsurprisingly, the face and hair are the
most important features in this.
Project Wotou involves several key innovations in applying state-of-the-art computer vision
and image processing technology: 1) robust and accurate reconstruction of personalised 3D
head model from mobile device photography; 2) customisation of user?s head model to
support various hairstyles; 3) creating photo-realistic visualisation of user?s 3D avatar
synthesised with her personalised head model. The project will create proof-of-concept
demonstrators to enable evaluation and usability assessment of this novel head model creation
technique.
The innovation will give consumers a better experience and more confidence when shopping
online, and significantly increase the proportion of shoppers on a site using Metail?s fitting
room technology. It will extend Metail?s lead in garment visualisation and create a UK
powerhouse in this important area of online retail technology.</gtr:abstractText><gtr:fund><gtr:end>2016-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2015-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>99444</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">710654</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>