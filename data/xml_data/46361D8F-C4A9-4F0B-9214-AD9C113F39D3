<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/0554A434-CA32-47FF-A036-F9DB8C1589F8"><gtr:id>0554A434-CA32-47FF-A036-F9DB8C1589F8</gtr:id><gtr:name>Open Knowledge Foundation</gtr:name><gtr:address><gtr:line1>37 Panton Street</gtr:line1><gtr:postCode>CB2 1HL</gtr:postCode><gtr:region>East of England</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:department>Applied Maths and Theoretical Physics</gtr:department><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0554A434-CA32-47FF-A036-F9DB8C1589F8"><gtr:id>0554A434-CA32-47FF-A036-F9DB8C1589F8</gtr:id><gtr:name>Open Knowledge Foundation</gtr:name><gtr:address><gtr:line1>37 Panton Street</gtr:line1><gtr:postCode>CB2 1HL</gtr:postCode><gtr:region>East of England</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/D420E93D-1ED3-4924-9828-1DAF84D000D3"><gtr:id>D420E93D-1ED3-4924-9828-1DAF84D000D3</gtr:id><gtr:firstName>Stephen</gtr:firstName><gtr:surname>Eglen</gtr:surname><gtr:orcidId>0000-0001-8607-8025</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FH023577%2F1"><gtr:id>46361D8F-C4A9-4F0B-9214-AD9C113F39D3</gtr:id><gtr:title>Novel analytical and datasharing tools for rich neuronal activity datasets obtained with a 4096 electrodes array</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/H023577/1</gtr:grantReference><gtr:abstractText>The functional intricacy of the central nervous system (CNS) arises from the complex anatomical and dynamic interactions between different types of neurones involved in specific networks. Hence, the encoding of information in neural circuits occurs as a result of interactions between individual neurones as well as through the interplay within both microcircuits (made of few neurones) and large scale networks involving thousands to millions of cells. One of the great challenges of neuroscience nowadays is to understand how these neural networks are formed and how they operate. Such challenge can be resolved only through simultaneous recording from thousands of neurones that become active during specific neuronal tasks. One of the experimental approaches to fulfil this goal is to use multielectrode arrays (MEAs) that consist of several channels (electrodes) that can each record (and/or stimulate) from few adjacent neurones within a particular area of the CNS. MEAs can be used in vitro to record from dissociated neuronal cultures or from brain slices or isolated retinas. These MEAs consist of assemblies of electrodes embedded in planar substrates. Typical commercial MEAs consist of 60-128 electrodes with a spacing of 100-200 um. Considering that a generic neurone in the mammalian CNS has a diameter of about 10 um, it is obvious that such MEAs cannot convey information on the activity of all neurones involved in a specific network, but rather just from a sample of these cells. To overcome this activity under-sampling, in this project, we will use the Active Pixel Sensor (APS) MEA, a novel type of MEA platform developed in a NEST-EU Project by our collaborator Luca Berdondini (Italian Institute of Technology, Genova). This MEA consists of 4,096 electrodes with near cellular resolution (21x21 um, 42 um centre-to-centre separation, covering an active area of 2.5 mm x 2.5 mm), where recording is possible from all channels at the same time. We will use the APS MEA to record spontaneous waves of activity that are present in the neonatal vertebrate retina. These waves occur during a short period of development during perinatal weeks and they are known to play an important role in guiding the precise wiring of neural connections in the visual system, both at the retinal and extra-retinal levels. The APS-MEA, thanks to its unmet size and resolution, will enable us to reach new insights into the precise dynamics of these waves as never achieved before. Recordings from such large scale networks at near cellular resolution generate extremely rich datasets with the drawback that these datasets are very large and difficult to handle, thus necessitating the development of new powerful analytical tools enabling to decode in a fast, efficient and user-friendly way how cellular elements interact in the network. The development of such computational tools is the central goal of this project, while the experimental work on the retina defines a challenging and unique scientific context. The tools we plan to develop will yield parameters that will help us reach better understanding of network function, from the temporal firing patterns of individual neurones to how activity precisely propagates within the network. We will also develop novel tools for easier visualisation of the dynamical behaviour of the activity within the network. These tools will be developed in a language that could be easily utilized by other investigators using the same recording system or other platforms of their choice. Finally, to ensure that these tools are accessible to the wide neurophysiology community, they will be deployed on CARMEN (Code Analysis, Repository and Modelling for e-Neuroscience), a new internet-based neurophysiology sharing resource designed for facilitating worldwide communication between collaborating neurophysiologists.</gtr:abstractText><gtr:technicalSummary>publicly available if the proposal is funded. [up to 2000 characters] The complexity of neuronal communication arises from the exquisite precision of anatomical and functional connectivity within neuronal assemblies. To understand how neural connectivity is formed and operates, it is crucial to record simultaneously at high spatiotemporal precision from large scale neuronal networks. Multielectrode array (MEA) recordings have become one of the best experimental approaches for this purpose. Although MEAs offer excellent temporal resolution, their spatial resolution is poor, with typical commercial MEAs consisting of 60-128 electrodes with 30 um diameter and 200 um spacing, which is insufficient to study fine-grain spatiotemporal cellular interactions. In this project we will use the novel APS MEA platform developed by L. Berdondini and collaborators. The APS MEA is unique in terms of spatiotemporal resolution. It consists of 4,096 channels with near cellular resolution (21 um electrode diameter and separation) that can record simultaneously at a full frame rate of 7.8 kHz, which is high enough to reliably discriminate single spikes. We will use the APS MEA to record neonatal mouse retinal waves. Retinal waves undergo substantial changes in their spatiotemporal properties as the retina develops and the APS MEA will enable us to investigate these properties with a precision never been achieved before. The generation of such large and rich datasets necessitates the development of new powerful computational analytical tools, and this will be the central goal of this project. We will develop user-friendly new statistical approaches to decode large neuronal networks and new computational and visualization tools to quantify fine-grain spatiotemporal properties in neural networks. To allow community-wide access to these novel tools, they will be deployed on CARMEN, a new UK-based neurophysiology code development and data sharing facility developed in the past 3 years.</gtr:technicalSummary><gtr:potentialImpactText>Although our project will be the first one using the APS MEA to study an intact neural network (e.g. the retina) rather than interactions between dissociated neurones, we have no doubt that the APS MEA (or other similar developments) will soon become sought after by many neuroscientists seeking deeper understanding of precise interactions within large neuronal assemblies. From that point of view, this project will bring a strong proof of concept for the development and use of large scale MEAs. An entire session on MEAs at the last Society for Neuroscience meeting in Chicago (October 17-21 2009, ~30,000 participants) has revealed the fast growing interest of the neuroscience community in these large arrays that are becoming increasingly sophisticated thanks to new developments in nanotechnology and microfabrication. At the same time it is obvious that the APS MEA is the best performing platform available nowadays (in terms of the number of channels that can be used at any single time at high acquisition rate). The system was highly praised at the Chicago meeting, and we are in the very fortunate position of being at the forefront of research and development of the APS MEA through our collaboration with Luca Berdondini. We believe that we will be able to generate data of superior quality that will generate strong interest amongst neurophysiologists and computational neuroscientists. Because recordings with the APS MEA generate data that has no precedents in terms of spatiotemporal resolution, our results will undoubtedly shed new light on how to analyse, visualise and quantify neural network function, and this will be of great interest for the development of new software resources that will be used by systems neuroscientists. Because our experimental data and new analytical tools will be deployed on an open access data sharing facility, the impact of our research will be of much wider extent and will facilitate the dissemination of important scientific knowledge. All aspects of our research fall within the remit of research supported by the BBSRC, with special emphasis on the Tools and Resources Development Fund.</gtr:potentialImpactText><gtr:fund><gtr:end>2012-06-13</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2010-12-14</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>11930</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Open Knowledge Foundation</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with OKFN</gtr:description><gtr:id>60C7BBD8-F5B3-4898-9BD0-83119738F179</gtr:id><gtr:impact>None yet.</gtr:impact><gtr:outcomeId>56d832b7e8c475.60105006-1</gtr:outcomeId><gtr:partnerContribution>They are providing R packages.</gtr:partnerContribution><gtr:piContribution>I am now working with the Open Knowledge Foundation (OKFN) on a case study of using our data to highlight their tools for data sharing.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The basic research findings first appeared in 2014 in our Journal of Physiology paper. To my knowledge these results have not been applied out of our scientific area.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>CD7E5291-8A71-4868-8EAB-413395402BF9</gtr:id><gtr:impactTypes/><gtr:outcomeId>545ba318dd3176.79318535</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have developed computational tools for the analysis of large-scale multielectrode array recordings. We then applied them to studying the development of spontaneous activity in the developing retina.</gtr:description><gtr:exploitationPathways>The software that we wrote is freely available (https://github.com/sje30/sjemea) and the corresponding research article is open access.</gtr:exploitationPathways><gtr:id>339DBEDE-5E2C-4F6B-957F-765836E7275C</gtr:id><gtr:outcomeId>545ba23ed75675.63340945</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>68FAC5BD-1C66-4A4F-A6C2-A1A9370E6ECB</gtr:id><gtr:title>Supporting material for &amp;quot;A data repository and analysis framework for spontaneous neural activity recordings in developing retina&amp;quot;</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8afe1312ad87351397448a43bfbb8442"><gtr:id>8afe1312ad87351397448a43bfbb8442</gtr:id><gtr:otherNames>Eglen E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56d83167f03163.77093575</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>634D6806-379E-4F9A-B05A-A94FA93F17BB</gtr:id><gtr:title>Following the ontogeny of retinal waves: pan-retinal recordings of population dynamics in the neonatal mouse.</gtr:title><gtr:parentPublicationTitle>The Journal of physiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f323e1c149a9423f85c468c360282fb2"><gtr:id>f323e1c149a9423f85c468c360282fb2</gtr:id><gtr:otherNames>Maccione A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0022-3751</gtr:issn><gtr:outcomeId>585d76f07a7294.79371795</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7D299C7F-7A82-44E7-833F-BE0640C9EB4E</gtr:id><gtr:title>A data repository and analysis framework for spontaneous neural activity recordings in developing retina.</gtr:title><gtr:parentPublicationTitle>GigaScience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d0de9e4ac8784eeaffd8ac3d334109e"><gtr:id>5d0de9e4ac8784eeaffd8ac3d334109e</gtr:id><gtr:otherNames>Eglen SJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>2047-217X</gtr:issn><gtr:outcomeId>56d83168a4e300.26547343</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/H023577/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>