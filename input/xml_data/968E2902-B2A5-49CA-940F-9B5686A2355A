<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Electrical and Electronic Engineering</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/ED82DD59-59D7-4BB0-98E3-3F0855524F98"><gtr:id>ED82DD59-59D7-4BB0-98E3-3F0855524F98</gtr:id><gtr:firstName>Melvyn</gtr:firstName><gtr:surname>Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/E65A2A05-D0B1-4A4A-A575-066E01B85D5F"><gtr:id>E65A2A05-D0B1-4A4A-A575-066E01B85D5F</gtr:id><gtr:firstName>Emma</gtr:firstName><gtr:otherNames>Mary</gtr:otherNames><gtr:surname>Baxter</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F5B9C242-8EDB-4AE7-B78C-D1ED0B331C7F"><gtr:id>F5B9C242-8EDB-4AE7-B78C-D1ED0B331C7F</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Ross</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F2945463-F3B2-4046-A992-A0EC193F384B"><gtr:id>F2945463-F3B2-4046-A992-A0EC193F384B</gtr:id><gtr:firstName>John</gtr:firstName><gtr:surname>Vaughan</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/A14DCB1A-2638-4A03-98EF-AEE39C08C14C"><gtr:id>A14DCB1A-2638-4A03-98EF-AEE39C08C14C</gtr:id><gtr:firstName>Bruce</gtr:firstName><gtr:otherNames>Donaldson</gtr:otherNames><gtr:surname>Grieve</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/20195D2B-CFD8-470A-9FBE-55A372D9EC3A"><gtr:id>20195D2B-CFD8-470A-9FBE-55A372D9EC3A</gtr:id><gtr:firstName>Krikor</gtr:firstName><gtr:surname>Ozanyan</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=NE%2FP007945%2F1"><gtr:id>968E2902-B2A5-49CA-940F-9B5686A2355A</gtr:id><gtr:title>Low-cost fibre optic matting for direct live-mapping of livestock weight to improve feed efficiency. Development, demonstration &amp;amp; imaging integration.</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>NE/P007945/1</gtr:grantReference><gtr:abstractText>This project exploits prior art and know-how in sensor systems design at the University of Manchester (UoM), which has previously been utilised for mapping human gait and tested for the ability to estimate weight. This will be translated into a reference pig unit, at SRUC, to prove that the technology can be made suitably robust for weighing pigs on a mat and that the subsequent data may then be integrated with commercial and prototype pig imaging hardware, as developed by SRUC and commercial partners, including estimation of pig weight. The Bristol Robotics Laboratory (BRL) contributes the capability to determine if vision-based biometrics, combined with the tomographic footfall 'signatures' or imaging system, could feasibly be developed to autonomously identify individual pigs and assign weights to each of them, without using Radio Frequency Identification (RFID) tags, which requires a separate scanner unit. Furthermore, surface tags are prone to damage by the animals, whereas subcutaneous tags are not viable due to migration under the skin, rendering them both unreadable and acting as a source of meat contamination.
We aim to demonstrate the feasibility of one or more pig weighing methods suitable for the pig farm environment. To achieve that, we'll design and test for robustness a smart mat system enclosure and electronics; we'll deploy and test an optical weighing system; we'll also demonstrate non-contact technology to identify and assign the estimated weight to individual pigs.</gtr:abstractText><gtr:potentialImpactText>In line with the original challenge documentation the proposed smart-matting system, from the UoM, will allow nutrient use efficiency to be monitored non-intrusively and in real-time for multiple animals within a pen environment. The mass-distribution 'images' produced from the matting will monitor real time body weight within a tightly managed group of animals, as well as individuals, allowing the balance of protein-to-energy nutrients to be decreased continuously. This in turn will reduce protein wastage and energy utilisation for surplus protein breakdown leading to marked improvements in nutrient utilisation and identification of optimum time of slaughter. As a consequence for pig farmers, and potentially cattle and poultry farmer, livestock throughput will be maximised, throughout the growth cycle, by tailoring the nutritional requirements to the needs of each animal, and similarly this will have an additional effect of minimising inefficient usage of higher-value, i.e. cost, feeds. In addition to addressing the AB-Agri challenge area, the research team have verified the wider implications of the technology through sharing the concepts with the Agriculture &amp;amp; Horticulture Development Board (www.ahdb.org.uk):

- &amp;quot;This is a really interesting proposal. As you say in the attached, it is becoming more and more critical that we monitor individual pig growth curves.&amp;quot; ... &amp;quot;I don't know if you aware but there have been some progress with visual weighing systems for finishing pigs. For example, Fancom has just produced their eyenamic system and I believe Harbro will be installing their system on farm over the summer as part of the Agri-Epi project.&amp;quot; ... &amp;quot;There have not been any progress with visual weighing for sows though, as far as I am aware. I can see that a mat would be very helpful for farrowing sows, especially if it could distinguish between weights of sows and piglets. At the moment sows are not being weighed in and out of crates and it is very difficult to optimise their feeding strategies accordingly. Piglet weight gain could also be useful to better select replacement sows in a farms' breeding plan. Perhaps sows would also be at less risk of chewing the mat?!&amp;quot; ... &amp;quot;From a data point of view, we are also very interested in standardised data transfer so that information from different sensors can be easily transferred and actioned, so anything that looks at this is also really valuable. In the future, it would be brilliant to think we could link something like facial recognition into cough monitors (fancom); weight estimations; water intake information; visual imaging of abnormal/unusual behaviour or posture, etc! I hope that helps. I am more than happy to discuss at any time.&amp;quot;

Pre-emptive of this feedback the, UoM-led, activity was integrated with the Agri-EPI's strategy on pig imaging, through including the SRUC (lead member of Agri-EPI) alongside BRL, to assess the viability of fusing the data from the smart-matting with that from stereo imaging cameras, so as to deliver an equivalent of an Electronic Identification Device (EID) through biometric identification of individual pigs (including sows and piglets) without the need for RFID-tagging. In pig production the latter is extremely unreliable as ear-tags tend to be ripped-off or consumed by neighbouring animals whereas subcutaneous tags migrate within the pig tissue as they cannot be located in stable tissue without becoming a potential source of meat contamination. It should be noted that this project can only test the feasibility of amalgamating imaging and smart-matting data to deliver a virtual EID, as the resources available would not be adequate to deliver such a system. However, it will provide the necessary evidence to support delivery of a virtual EID within a subsequent phase of the development programme.

Further details may be found in the 'Pathways to Impact' document in the appendices.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-10-01</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/8A03ED41-E67D-4F4A-B5DD-AAFB272B6471"><gtr:id>8A03ED41-E67D-4F4A-B5DD-AAFB272B6471</gtr:id><gtr:name>NERC</gtr:name></gtr:funder><gtr:start>2016-10-02</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>202003</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">NE/P007945/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6BF947B0-8E6E-48DB-AB68-7130938F2DF2</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Instrument. sensor &amp; detectors</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>B76F0E6B-0363-4D1F-9F5F-353AFD4E9DB0</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Livestock production</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>189E1F60-BF95-405D-A6F0-62BBD78E2DD5</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Survey &amp; Monitoring</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>