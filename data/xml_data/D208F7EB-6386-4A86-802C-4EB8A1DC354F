<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/DB86C1FA-B62E-432F-A69D-B156E3FA8CC9"><gtr:id>DB86C1FA-B62E-432F-A69D-B156E3FA8CC9</gtr:id><gtr:name>Medaphor Limited</gtr:name><gtr:address><gtr:line1>Suite 16 , Cardiff Medicentre, Heath Park</gtr:line1><gtr:city>Cardiff</gtr:city><gtr:postCode>CF14 4UJ</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DB86C1FA-B62E-432F-A69D-B156E3FA8CC9" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>DB86C1FA-B62E-432F-A69D-B156E3FA8CC9</gtr:id><gtr:name>Medaphor Limited</gtr:name><gtr:address><gtr:line1>Suite 16 , Cardiff Medicentre, Heath Park</gtr:line1><gtr:city>Cardiff</gtr:city><gtr:postCode>CF14 4UJ</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>444413.0</gtr:offerGrant><gtr:projectCost>634876.0</gtr:projectCost></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>21530.0</gtr:offerGrant><gtr:projectCost>21530.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/4EC9DC10-75EE-4C53-926B-DFFA8B25B1D2"><gtr:id>4EC9DC10-75EE-4C53-926B-DFFA8B25B1D2</gtr:id><gtr:firstName>Steve</gtr:firstName><gtr:surname>Margetts</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=104186"><gtr:id>D208F7EB-6386-4A86-802C-4EB8A1DC354F</gtr:id><gtr:title>Virtual reality aid for ultrasound-guided needling</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Collaborative R&amp;D</gtr:grantCategory><gtr:grantReference>104186</gtr:grantReference><gtr:abstractText>&amp;quot;We aim to revolutionise interventional ultrasound needling using augmented-reality and an artificial intelligence technique known as deep-learning.

During this project, we will develop and test an ultrasound needling assistant that:

1. Automatically locates the needle-tip using deep-learning (ie by using computer vision to find the needle-tip in the ultrasound image)
2. Uses an augmented reality headset worn by the clinician to project a holographic ultrasound view over the patient's anatomy highlighting the needle track and important anatomical structures in the correct position &amp;quot;&amp;quot;within&amp;quot;&amp;quot; the patient.

Doctors use interventional needling in a variety of medical procedures: for example, to biopsy tissues, to drain fluid, to insert cannulas, and to administer regional anaesthesia in a procedure known as a peripheral nerve block. Particularly when guiding the needle to deep structures, it is important that they do not damage other tissue. Clincians therefore need to be able to see the needle-tip. They often use ultrasound to do this since it is a safe imaging technique and the equipment can be brought to the bedside.

For many needling procedures, NICE recommends that ultrasound guidance always be used.

Ultrasound uses sound to visualise tissues. The ultrasound transducer emits a narrow beam of sound (rather like sonar on a submarine). Reflected sound is received by the machine and used to image the tissue it is reflected from.

Ultrasound needling is a difficult technique to master: the clinician must manipulate the needle and ultrasound transducer whilst looking at the ultrasound machine's screen (away from the patient) rather than at the patient themselves. They must manually keep the needle-tip within the ultrasound beam whilst advancing it towards its target. If the tip moves out of plane, it can become confused with the needle-shaft on the ultrasound image with potentially serious consequences.

Using augmented reality allows the ultrasound to be placed over the patient so the physical needle can simultaneously be seen, additionally highlighting the needle and important anatomical structures in the ultrasound view.

This will help the patient (by the clinician not missing the biopsy target and avoiding damage to adjacent structures), the health service (by reducing procedure time and cost) and the clinician (by reducing repetitive strain injury as the procedure will be more ergonomic).

These will give significant benefits to the NHS (both for patients and in improving the healthcare economics of ultrasound-guided needling) as well as significant export potential for a world-leading new digital health technology.&amp;quot;</gtr:abstractText><gtr:fund><gtr:end>2019-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2018-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>465943</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">104186</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>