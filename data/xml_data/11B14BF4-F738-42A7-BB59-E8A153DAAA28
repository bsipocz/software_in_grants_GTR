<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Informatics</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/66B20C24-740C-4155-8D3D-9749B0409CFA"><gtr:id>66B20C24-740C-4155-8D3D-9749B0409CFA</gtr:id><gtr:firstName>Michael</gtr:firstName><gtr:surname>O'Boyle</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/082EED8A-45D0-430B-8316-6D9601C7ED8E"><gtr:id>082EED8A-45D0-430B-8316-6D9601C7ED8E</gtr:id><gtr:firstName>Stratis</gtr:firstName><gtr:surname>Viglas</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F84EC4B0-993F-4414-8966-2EA7E2020B86"><gtr:id>F84EC4B0-993F-4414-8966-2EA7E2020B86</gtr:id><gtr:firstName>Hugh</gtr:firstName><gtr:surname>Leather</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/48ED7FDA-0571-430F-AB6B-5B8515B94A9D"><gtr:id>48ED7FDA-0571-430F-AB6B-5B8515B94A9D</gtr:id><gtr:firstName>Boris</gtr:firstName><gtr:surname>Grot</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM015823%2F1"><gtr:id>11B14BF4-F738-42A7-BB59-E8A153DAAA28</gtr:id><gtr:title>Distributed Heterogeneous Vertically IntegrateD ENergy Efficient Data centres</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M015823/1</gtr:grantReference><gtr:abstractText>Our world is in the midst of a &amp;quot;big data&amp;quot; revolution, driven by the ubiquitous ability to gather, analyse, and query datasets of unprecedented variety and size. The sheer storage volume and processing capacity required to manage these datasets has resulted in a transition away from desktop processing and toward warehouse-scale computing inside data centres. State-of-the-art data centres, employed by the likes of Google and Facebook, draw 20-30 MW of power, equivalent to 20,000 homes, with these companies needing many data centres each. The global data centre energy footprint is estimated at around 2% of the world's energy consumption and doubles every five years [33, 34]. Contemporary data centres have an average overhead of 90% [32], meaning that they consume up to 1.9 MW to deliver 1 MW of IT support; this is not cost-effective or environmentally sound. If the exponential data growth and processing capacity are to scale in the way that both the public and industry have come to rely upon, we must tackle the data centre energy crisis or face the reality of stagnated progress. With the semiconductor industry's inability to further lower operating voltages in processor and memory chips, the challenge is in developing technologies for large-scale data-centric computation with energy as a first-order design constraint.
The DIVIDEND project attacks the data centre energy efficiency bottleneck through vertical integration, specialisation, and cross-layer optimisation. Our vision is to present heterogeneous data centres, combining CPUs, GPUs, and task-specific accelerators, as a unified entity to the application developer and let the runtime optimise the utilisation of the system resources during task execution. DIVIDEND embraces heterogeneity to dramatically lower the energy per task through extensive hardware specialisation while maintaining the ease of programmability of a homogeneous architecture. To lower communication latency and energy, DIVIDEND leverages SoC integration and prefers a lean point-to-point messaging fabric over complex connection-oriented network protocols. DIVIDEND addresses the programmability challenge by adapting and extending the industry-led heterogeneous systems architecture programming language and runtime initiative to account for energy awareness and data movement. DIVIDEND provides for a cross-layer energy optimisation framework via a set of APIs for energy accounting and feedback between hardware, compilation, runtime, and application layers. The DIVIDEND project will usher in a new class of vertically integrated data centres and will take a first stab at resolving the energy crisis by improving the power usage effectiveness of data centres by at least 50%.</gtr:abstractText><gtr:potentialImpactText>DIVIDEND aims at a paradigm shift from throughput-oriented to energy-oriented parallel computing. The performance of computing systems is already defined by the available power, yet most layers of the HW/SW stack of modern systems are optimised without power considerations. DIVIDEND will develop methods and tools for energy-aware optimisation throughout the HW and SW stack.
Parallel programming already faces major challenges in dealing with the increasing diversity and heterogeneity of parallel architectures. These challenges will only grow larger as energy will become the main limitation in future architectures. DIVIDEND involves the programmer in energy management, through the HSA programming language that assist in energy conservation by parallel pro- grams. At the same time, DIVIDEND implements a high-productivity system software tool-chain which effectively supports heterogeneous data centre environments.
DIVIDEND makes energy a first-class citizen in computing systems, by developing a HW/SW environment that manages energy as a resource that is equally critical as other resources, such as processor time and memory space. DIVIDEND also advocates a fundamental departure from the current fragmented models of energy management in computing systems. The DIVIDEND HW/SW environment develops holistic energy optimisation by controlling a multitude of tuneable HW and SW parameters and leveraging dynamic workload properties.
All academic partners of DIVIDEND are active and prolific members of the HiPEAC European Network of Excellence. One of the project's principal investigators is also a contributor of the 2013 HiPEAC Roadmap (http://www.hipeac.net/system/files/hipeac_roadmap1_0.pdf). DIVIDEND responds to the three major future challenges identified by the HiPEAC Roadmap: (a) Data Center Computing, &amp;quot;we must develop the capabilities to process 'big data' without increasing cost or energy&amp;quot;; (b) Energy efficiency,&amp;quot;to enable power efficient systems we must address the challenges of program- ming parallel heterogeneous processors and optimizing data movement&amp;quot;; and (c)System Complexity, &amp;quot;we need to develop tools and techniques to optimize for performance and ensure correct operation, while operating 'at-scale'&amp;quot;. DIVIDEND also responds to the societal challenges of environmental protection and productivity: Computing systems are a part of the growing energy problem, consuming hundreds of GigaJoules of energy annually (about as much as civil aviation). Computing systems are also an essential ingredient of productivity in all aspects of human economic activity.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-12-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-12-31</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>143136</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Smart compiler technology can reduce power consumption in mobile and data centre settings</gtr:description><gtr:exploitationPathways>Larger scale investigation in cloud</gtr:exploitationPathways><gtr:id>AC577A7B-B9D6-4664-B4C6-CFCD71BFD4CF</gtr:id><gtr:outcomeId>56ded21e5a20c3.82891199</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors><gtr:url>http://dividend.gforge.inria.fr/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>E39FD896-2A5A-4A46-84C3-3BB26038EB13</gtr:id><gtr:title>Synthesizing Benchmarks for Predictive Modeling</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0318367168ea706164bb2ffb333fce67"><gtr:id>0318367168ea706164bb2ffb333fce67</gtr:id><gtr:otherNames>Cummins C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58ac68f3782e14.82381987</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>63452EFB-33C1-4924-9080-34A238AAF719</gtr:id><gtr:title>Iterative Compilation on Mobile Devices</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/026da9418b411f55a06558351e03c2b1"><gtr:id>026da9418b411f55a06558351e03c2b1</gtr:id><gtr:otherNames>Mpeis P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58ac6ad0896008.00168201</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6DB830D6-E24E-4A20-B920-2ED43D48C952</gtr:id><gtr:title>ALEA</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Architecture and Code Optimization</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/404372024c6783e815b577891556dbe4"><gtr:id>404372024c6783e815b577891556dbe4</gtr:id><gtr:otherNames>Mukhanov L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58ac69f54b6888.78232609</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CC161207-CAA8-4007-BC5F-30B7CC494AB6</gtr:id><gtr:title>Towards Collaborative Performance Tuning of Algorithmic Skeletons</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0318367168ea706164bb2ffb333fce67"><gtr:id>0318367168ea706164bb2ffb333fce67</gtr:id><gtr:otherNames>Cummins C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58ac6a887929f5.19630649</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F3AF98F9-1649-44DA-BF16-34A665844FC5</gtr:id><gtr:title>Power Capping: What Works, What Does Not</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2bde899fb68fecadc9ae020db7074893"><gtr:id>2bde899fb68fecadc9ae020db7074893</gtr:id><gtr:otherNames>Petoumenos P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56ded008e40390.27366288</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4F8709BE-D578-4890-BE6D-8F6B49766BD8</gtr:id><gtr:title>Minimizing the cost of iterative compilation with active learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b7197bb51478e2d4660dff1eb153e900"><gtr:id>b7197bb51478e2d4660dff1eb153e900</gtr:id><gtr:otherNames>Ogilvie W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58ac697a1557b2.76957449</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E0D2CB63-763A-44BD-A0F1-F04F0D6471E1</gtr:id><gtr:title>Autotuning OpenCL Workgroup Size for Stencil Patterns</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0318367168ea706164bb2ffb333fce67"><gtr:id>0318367168ea706164bb2ffb333fce67</gtr:id><gtr:otherNames>Cummins C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58ac6b67466417.88827051</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M015823/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>D7BA1404-E001-4782-929E-E96E28B01201</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Sys. &amp; Architecture</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>