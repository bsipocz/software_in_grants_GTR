<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:department>Sch of Engineering</gtr:department><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B42833A1-ABC4-4108-8369-A39C427D8689"><gtr:id>B42833A1-ABC4-4108-8369-A39C427D8689</gtr:id><gtr:firstName>Yulia</gtr:firstName><gtr:otherNames>Alexandrovna</gtr:otherNames><gtr:surname>Hicks</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE017576%2F1"><gtr:id>498482C0-1167-454F-BC1D-DF45CB568AB1</gtr:id><gtr:title>Adaptive Models of Human Motion</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E017576/1</gtr:grantReference><gtr:abstractText>Tracking and interpreting human motion is currently one of the main active research areas in computer vision. In particular, tracking 3D articulated motion finds applications in numerous areas including sports training, computer games and computer animation. The problem of tracking 3D articulated motion is a very challenging one, considering the complexity and variety of the geometry of a human body, high level of self-occlusions present in the motion and a large number of degrees of freedom of the motion. Using models of geometry and valid poses of the human body helps to deal with these problems by imposing constraints on the interpretation of image data. Automatic motion capture systems make it possible to collect a large amount of real motion data, which can be used to automatically learn statistical models of motion. Among the popular statistical models to represent human motion are hidden Markov models (HMM). In our previous work, we developed a framework for tracking 3D articulated human motion in monocular video sequences utilising HMMs.However, currently such models tend to record averages and are static in time, so cannot easily respond to outlying individuals or changes over time in individual characteristics. We believe that to progress further the fields of modelling and tracking human motion we need to make the models adaptive to changes in the properties of motion over time. Our research will address this problem by developing machine learning algorithms to support adaptive models of human motion.The novelty of this proposal is the development of the adaptive models of human motion, which can be tuned to reflect the dynamics of motion of a particular person in a short period of time, or even to learn the dynamics of new type of motion. The adaptive models of human motion will be based on HMMs and thus will be easy to integrate within the current motion tracking algorithms relying in HMMs. I envisage that the use if the adaptive models will improve the accuracy and robustness of tracking results. As a part of this research, I will integrate the adaptive models into a framework for tracking articulated human motion and test the newly developed methods on real world video footage.However, the use of such adaptive models is not limited to tracking applications or even the computer vision area. The developed algorithms will benefit other research areas, such as speech recognition, where HMMs have been used for a long time and the adaptive models would be useful for modelling changes in speech properties over time.</gtr:abstractText><gtr:fund><gtr:end>2010-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>206291</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings of this grant were used to obtain further funds from EPSRC in a cross-disciplinary study involving neuroscience and computer science, grant number EP/I01487X/1, and are currently being used in another EPSRC/Dstl grant number EP/K014307/1, which involves a number of defense sector companies. At the moment, there is no impact outside of academy yet, the impact is likely to materialise in the next one or two years from these companies.</gtr:description><gtr:id>594BEC38-77DF-43BB-8AE9-4E3D99106559</gtr:id><gtr:impactTypes><gtr:impactType>Policy &amp; public services</gtr:impactType></gtr:impactTypes><gtr:outcomeId>54609c76934d78.63040658</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We developed adaptive statistical models which can be used for modelling static data or dynamic processes which change over time. Our methods allows us to update existing statistical models with the new data as it becomes available, which makes them particularly suitable for incremental learning of large data sets when all data is not available at once or cannot be accommodated in the memory of one computer due to its large volume. 
We applied these models to a number of real life problems, for example, image and video segmentation, and dynamic face modelling, which are important in the areas of automatic image and video understanding and computer graphics.</gtr:description><gtr:exploitationPathways>The findings of this grant were used to obtain further funds from EPSRC in a cross-disciplinary study involving neuroscience and computer science, grant number EP/I01487X/1, and are currently being used in another EPSRC/Dstl grant number EP/K014307/1, which involves a number of defense sector companies. At the moment, there is no impact outside of academy yet, the impact is likely to materialise in the next one or two years from these companies.</gtr:exploitationPathways><gtr:id>96FBCDD2-D039-4EAD-88EA-AB6BDF479274</gtr:id><gtr:outcomeId>54609fcfe3b4e3.26601374</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Healthcare,Leisure Activities, including Sports, Recreation and Tourism</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>D170942B-7C1C-4A6C-AF31-C5BB9E5E5850</gtr:id><gtr:title>Incremental Learning of Dynamical Models of Faces</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d4af600d7f85b18cd5193e87e46ab2ba"><gtr:id>d4af600d7f85b18cd5193e87e46ab2ba</gtr:id><gtr:otherNames>YA Hicks</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_6823392745140b397a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>87558601-7625-4678-8B2A-559757FD8194</gtr:id><gtr:title>An evolving MoG for online image sequence segmentation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2585487a691bd180a03f5803c715cdda"><gtr:id>2585487a691bd180a03f5803c715cdda</gtr:id><gtr:otherNames>Charron C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-7992-4</gtr:isbn><gtr:outcomeId>doi_53d058058b6f0838</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3BFBC86-6506-4361-A02A-9157CE5AEEE8</gtr:id><gtr:title>Applying incremental learning to parallel image segmentation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2585487a691bd180a03f5803c715cdda"><gtr:id>2585487a691bd180a03f5803c715cdda</gtr:id><gtr:otherNames>Charron C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4442-7</gtr:isbn><gtr:outcomeId>doi_53d0580586dac9c0</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E017576/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>