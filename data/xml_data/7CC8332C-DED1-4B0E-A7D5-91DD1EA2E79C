<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D6480614-BFEA-4BE8-BF95-0DA9AED70BA3"><gtr:id>D6480614-BFEA-4BE8-BF95-0DA9AED70BA3</gtr:id><gtr:name>Numerion Software Limited</gtr:name><gtr:address><gtr:line1>Mark Beech Rake Lane
Milford</gtr:line1><gtr:city>Godalming</gtr:city><gtr:postCode>GU8 5AB</gtr:postCode><gtr:region>South East</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:department>Vision Speech and Signal Proc CVSSP</gtr:department><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D6480614-BFEA-4BE8-BF95-0DA9AED70BA3"><gtr:id>D6480614-BFEA-4BE8-BF95-0DA9AED70BA3</gtr:id><gtr:name>Numerion Software Limited</gtr:name><gtr:address><gtr:line1>Mark Beech Rake Lane
Milford</gtr:line1><gtr:city>Godalming</gtr:city><gtr:postCode>GU8 5AB</gtr:postCode><gtr:region>South East</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2D0F82D5-F19E-4EA8-A0C7-C7F120102A69"><gtr:id>2D0F82D5-F19E-4EA8-A0C7-C7F120102A69</gtr:id><gtr:firstName>Adrian</gtr:firstName><gtr:surname>Hilton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6A9E5617-D8D4-4AF7-B9A3-68360A2C0BDA"><gtr:id>6A9E5617-D8D4-4AF7-B9A3-68360A2C0BDA</gtr:id><gtr:firstName>Jean-Yves</gtr:firstName><gtr:surname>Guillemaut</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM506801%2F1"><gtr:id>7CC8332C-DED1-4B0E-A7D5-91DD1EA2E79C</gtr:id><gtr:title>Fashion garment design, e-tailing and manufacturing with zero prototyping.</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M506801/1</gtr:grantReference><gtr:abstractText>This project will carry out research to acquire the knowledge and skills required to simulate the behaviour of, and render
photorealistic fabric/garment, in real-time, to enable the design, e-tailing (electronic retailing on-line and in store) and
manufacturing of fashion clothing with zero physical prototypes. The innovation here is that no one today, anywhere in the
world, is delivering high quality, real-time fabric/garment behaviour simulation and photorealistic rendering matched to real
fabric. This UK project team brings together the experience in simulation, photorealistic rendering, fashion and computer
vision to make this a reality. This technology would enable new business models in the fashion industry, such that
garments could be offered to consumers prior to manufacture for interaction e.g. try-on and outfit mixing, and
personalisation e.g. fabrics, colours etc. before purchase. It would also encourage localised manufacture-on-demand to
meet shorter delivery times and support a revitalised UK fashion manufacturing economy. There are also applications for
this technology beyond the fashion industry, such as video games, movie production and advertising.
Over the past decade the University of Surrey, Centre for Vision, Speech and Signal Processing has pioneered the
development of video-based surface motion capture to allow the acquisition of complex non-rigid motion of real surface
dynamics from multiple view video. Research has primarily focused on the use of surface motion capture to capture actor
performance to support video-realistic content production for film and interactive entertainment. Video-based
reconstruction of surface motion allows the acquisition of highly non-rigid surfaces such as the loose dress of a dancing
actor.
The goal of the proposed research is to exploit recent advances in surface motion capture to enable high-accuracy dense
reconstruction of garment motion. This is not possible with existing motion capture technologies which require the
placement of markers as tracking fiducials on the cloth surface affecting the natural cloth motion and only allowing motion
capture at sparse locations. A critical advance in this research will be verfication of the accuracy of video-based surface
motion capture for measurement of dense non-rigid cloth motion. This will open-up the potential exploitation of surface
motion capture in both the immediate application of garment design and wider application as a tool for video-based measurement of human soft-body surface motion in clinical applications ranging from biomechanics to non-invasive
monitoring of movement during medical imaging.
Application of surface motion capture to verification of physics-based cloth simulation will allow validation of methods
beyond their qualitative use as artistic tools for computer generated imagery in film production. Research will introduce
quantitative metrics for both direct evaluation of simple cloth motion under controlled conditions and full garment motion
capture where it is not possible to accurately measure the contact constraints driving the motion. This research will bridge
the gap between the real-world and physics-based simulation of complex dynamic scenes. Quantitative evaluation will
validate the use of cloth simulation in garment design enabling an end-to-end zero-prototyping process from design to
manufacture for the fashion industry.</gtr:abstractText><gtr:potentialImpactText>The proposed research in video-based cloth surface motion capture will contribute to a TSB Collaborative R&amp;amp;D project
under the 'Towards Zero Prototyping' call. This project will engage computer vision research at the University of Surrey with
three UK SMEs bringing together the expertise to achieve zero prototyping in fashion garment design: Change of Paradigm
is an SME with expertise in the fashion industry focused on the business opportunity of providing a platform for virtual
garment design through e-tailing and consumer customization to manufacturing with zero physical prototyping; Numerion
Software are leading experts in real-time physics based cloth simulation for the film industry; and Lightworks is a world
leader in real-time ray tracing for photo-realistic rendering. University of Surrey will provide the computer vision expertise
required to validate physics-based cloth simulation against real cloth motion through the introduction of video-based
surface motion capture. This research will build on previous work in 4D actor performance capture to introduce a new noninvasive
approach for accurate acquisition on complex non-rigid surface motion as a new measurement tool. Importantly
the proposed research will for the first time validate video-based surface motion capture against gold-standard ground-truth
fiducial marker based motion capture to quantify the absolute measurement accuracy in terms of both shape and motion.
Video-based surface motion capture has two significant advantages over existing measurement technologies: video-based
capture is non-invasive and does not require the placement of fiducials or other markers on the object surface; dense
surface motion can be captured rather than sparse fiducial points enabling analysis of the complete surface motion. The
project will exploit this technology for immediate use in verifying the accuracy of real-time physics-based cloth simulation
which is vital to designers in providing high-confidence visualisation of garments in motion. This is not possible with existing
motion capture technologies as the placement of markers affects the garment motion and only sparse points can be
captured.
Beyond the project video-based surface motion capture has significant potential for widespread application as a
measurement technology: clinical biomechanics enabling the analysis of human motion without the placement of markers
and allowing assessment of movement for instance for obese patients where accurate marker placement is not possible;
sports performance analysis allowing analysis of movement for training and competition from passive video capture with
out requiring attachments of fiducial markers or tracking devices; veterinary science allowing analysis of animal motion to
monitor welfare and assess biomechanics; and robot vision for autonomous systems that can interact safely with people in
domestic and workplace environments. Exploitation of surface motion capture in these applications will be explored in
subsequent and parallel projects to maximise the impact of this technology. The University of Surrey is already actively
engaged in the use of video-based surface motion capture in the creative industries to support highly realistic content
production and in veterinary science to enable non-invasive biomechanical analysis of animals in situations where marker
placement is impossible or undesirable. The research which will be underaken in this project to validate the accuracy of the
technology as a tool for surface measurement is a critical step to enabling application as a measurement tool across a range of domains.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-04-19</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-10-20</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>150917</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Numerion Software Limited</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Numerion</gtr:description><gtr:id>6302F4E1-0AF3-4116-8539-E90AE27E1AA6</gtr:id><gtr:impact>Physically validated cloth simulation tools</gtr:impact><gtr:outcomeId>58c2c7a539a504.05405285-1</gtr:outcomeId><gtr:partnerContribution>Physics based cloth simulation expertise</gtr:partnerContribution><gtr:piContribution>Validation of physics based cloth simulation against real cloth measurements</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Research has introduced methods for accurate non-contact measurement of cloth motion from video. This has been used to verify the accuracy of physics-based cloth simulation models for use in clothing design. Verified cloth simulation will allow the complete end-to-end design of garments without intermediate production of physical prototypes. The overall of impact is to reduce the time and cost of garment design and the waste created in retail production.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>8E76B22F-B933-492A-AAAC-78DE1CB28BB1</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56e0a2e871cbe8.00804693</gtr:outcomeId><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Environment,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Manufacturing, including Industrial Biotechology,Retail</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>- novel technology for non-contact video-based capture of cloth movement 
- verification of physics-based cloth simulation accuracy against ground-truth cloth measurement
- estimation of cloth physics parameters from measurement of real-cloth and garment samples</gtr:description><gtr:exploitationPathways>- Commercialisation of technology for non-contact cloth measurement
- commercialisation of technology for estimation of physical parameters of cloth from video
- follow on collaborative R&amp;amp;D transferring this technology in video-based capture for real-time use in content production
- application of video-based non-contact measurement to other domains including healthcare for monitoring of people and animals</gtr:exploitationPathways><gtr:id>E8CE696C-7EA9-4FA7-AB1D-1503958698AA</gtr:id><gtr:outcomeId>56e0a512ad8176.45382892</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Manufacturing, including Industrial Biotechology,Culture, Heritage, Museums and Collections,Retail</gtr:sector></gtr:sectors><gtr:url>http://cvssp.org/Personal/AdrianHilton</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>Multiple view video datasets and reconstructed 4D models</gtr:description><gtr:id>B66DA396-F9B3-4A69-BD6D-70BA4F06FFCF</gtr:id><gtr:impact>Data available is used by over 300 research groups worldwide. It is considered the benchmark dataset for research in this field.</gtr:impact><gtr:outcomeId>56e13d3a66d971.88681288</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Multiview and 4D Video</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://cvssp.org/data/cvssp3d/</gtr:url></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C6C0CBD5-C00F-4436-BC6F-B3A84BE20BE6</gtr:id><gtr:title>A Layered Model of Human Body and Garment Deformation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/17927ebcf630994340aee4eee61401d1"><gtr:id>17927ebcf630994340aee4eee61401d1</gtr:id><gtr:otherNames>Neophytou A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56e0b3bfce6fc1.17096940</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M506801/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>