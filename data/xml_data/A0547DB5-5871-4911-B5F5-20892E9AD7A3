<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A86D0163-6EF2-42EB-B1EC-EBE11755375E"><gtr:id>A86D0163-6EF2-42EB-B1EC-EBE11755375E</gtr:id><gtr:name>Amazon.com</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/0CD1844B-0AB5-4F25-A477-D4FD8584CAFC"><gtr:id>0CD1844B-0AB5-4F25-A477-D4FD8584CAFC</gtr:id><gtr:name>Emotech Ltd</gtr:name><gtr:address><gtr:line1>4-5 Bonhill Street</gtr:line1><gtr:postCode>EC2A 4BX</gtr:postCode><gtr:region>London</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/E5A82D2C-5AD4-488A-ACFF-566345A5D6DA"><gtr:id>E5A82D2C-5AD4-488A-ACFF-566345A5D6DA</gtr:id><gtr:name>Heriot-Watt University</gtr:name><gtr:department>S of Mathematical and Computer Sciences</gtr:department><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Riccarton</gtr:line2><gtr:line3>Ricarton</gtr:line3><gtr:line4>Currie</gtr:line4><gtr:postCode>EH14 4AS</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E5A82D2C-5AD4-488A-ACFF-566345A5D6DA"><gtr:id>E5A82D2C-5AD4-488A-ACFF-566345A5D6DA</gtr:id><gtr:name>Heriot-Watt University</gtr:name><gtr:address><gtr:line1>Administration Building</gtr:line1><gtr:line2>Riccarton</gtr:line2><gtr:line3>Ricarton</gtr:line3><gtr:line4>Currie</gtr:line4><gtr:postCode>EH14 4AS</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A86D0163-6EF2-42EB-B1EC-EBE11755375E"><gtr:id>A86D0163-6EF2-42EB-B1EC-EBE11755375E</gtr:id><gtr:name>Amazon.com</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0CD1844B-0AB5-4F25-A477-D4FD8584CAFC"><gtr:id>0CD1844B-0AB5-4F25-A477-D4FD8584CAFC</gtr:id><gtr:name>Emotech Ltd</gtr:name><gtr:address><gtr:line1>4-5 Bonhill Street</gtr:line1><gtr:postCode>EC2A 4BX</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/874A4E99-A7FB-41D2-B06B-9BDC9B577474"><gtr:id>874A4E99-A7FB-41D2-B06B-9BDC9B577474</gtr:id><gtr:name>Tilburg University</gtr:name><gtr:address><gtr:line1>P.O Box 90153</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E5CAF1A7-5493-4D51-927C-CAC26C0EE756"><gtr:id>E5CAF1A7-5493-4D51-927C-CAC26C0EE756</gtr:id><gtr:name>SemVox GmbH</gtr:name><gtr:address><gtr:line1>Mainzer Stra?e 120</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/96433D78-8C23-4E7E-A59B-20E4ADA54E0D"><gtr:id>96433D78-8C23-4E7E-A59B-20E4ADA54E0D</gtr:id><gtr:firstName>Verena Teresa</gtr:firstName><gtr:surname>Rieser</gtr:surname><gtr:orcidId>0000-0001-6117-4395</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D1113684-C428-4420-8C5B-9E09A5D5BF41"><gtr:id>D1113684-C428-4420-8C5B-9E09A5D5BF41</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:surname>Keizer</gtr:surname><gtr:orcidId>0000-0003-0173-8966</gtr:orcidId><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN017536%2F1"><gtr:id>A0547DB5-5871-4911-B5F5-20892E9AD7A3</gtr:id><gtr:title>MaDrIgAL: MultiDimensional Interaction management and Adaptive Learning</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N017536/1</gtr:grantReference><gtr:abstractText>As tech giants like Google, Facebook, Apple and Microsoft continue to invest in speech technology, the global voice recognition market is projected to reach a value of $133 billion by 2017 (companiesandmarkets.com, 2015). Speech-enabled interactive systems in particular, such as Apple's Siri and Microsoft's Cortana, are starting to show significant economic impact, with the virtual personal assistant (VPA) market estimated to grow from $352 million in 2012 to over $3 billion in 2020 (Grand View Research, 2014).

Although such commercial systems allow consumers to use their voice in interacting with their devices and services, the user experience is still limited due to the lack of naturalness of the conversations and limited social intelligence of the VPA. Moreover, the quality of these user interfaces relies on large, carefully crafted rule sets, making development labour-intensive and not scalable to new application domains. With the emergence of the Internet of Things and voice control in the smart home, there is a huge demand for scalable development of natural conversational interfaces across task domains.

MaDrIgAL will develop a radically new approach to building interactive spoken language interfaces by exploiting the multi-dimensional nature of natural language conversation: in addition to carrying out the underlying task or activity, participants in a dialogue simultaneously address several other aspects of communication, such as giving and eliciting feedback and adhering to social conventions. In analogy to the singing voices in a madrigal, simultaneous processes for each dimension operate in harmony to produce multifunctional, natural utterances. Consider the two alternative responses S2a and S2b in the following example:

U1: Hello, I would like to book a flight to London.
S2a: Which date did you have in mind?
S2b: Ok, flying to London on what date?

Whereas S2a only asks for the next piece of information to book the flight (uni-dimensional), S2b also gives feedback about the arrival city, allowing the user to correct any recognition errors (multi-dimensional). We aim to develop a principled multidimensional modelling and learning framework that covers a wide range of different phenomena, including the implicit confirmation in S2b.

This multi-dimensional approach will not only allow us to build systems that support more natural and effective interactions with users, but also enables cost-effective development of such interfaces for a variety of domains by learning transferable conversational skills (e.g., selecting actions in domain independent dimensions). We will therefore demonstrate our approach by building interactive spoken language interfaces for multiple application domains in a home automation scenario, allowing users to interact with for example their Smart TV or heating control system. We will closely collaborate with the industrial partner SemVox to explore this scenario.

The project will bring together expertise in statistical machine learning approaches to state-of-the-art spoken dialogue systems and natural language generation, as well as linguistic theories of multi-dimensional dialogue modelling (collaborating in particular with academic partner Prof. Bunt). MaDrIgAL will develop Next Generation Interaction Technologies relevant to Health Technology and Assisted Living, as well as tackle the question of a common user interface to the Internet of Things and Big Data.</gtr:abstractText><gtr:potentialImpactText>From an end-user importance point of view, this work will be of interest to a wide range of businesses and companies in the UK, operating in areas such as speech technology, AI, home automation, etcetera. Specifically, we will develop and release a new spoken dialogue system (SDS) architecture compliant with the recently developed ISO standard for dialogue act annotation. This will promote interoperability, enabling the developer community to collaborate and reuse each other's components more easily, and ultimately help industry in developing products with spoken language interfaces more efficiently. The proposed research will also help to strengthen the impact of statistical SDS. Development costs for statistical techniques seem currently too high for manufacturers, due to the requirement of sufficient domain-specific data. The proposed new modular architecture indirectly addresses the economic feasibility of developing products with interactive interfaces for a variety of application domains.

This will ultimately help the UK to push past the US, which is still the main competitor in this area, despite the emergence of new language technology companies such as VocalIQ and Arria. For example, a senior speech scientist at Apple has said publicly that statistical methods will form the algorithmic basis for Siri in the near future. These increased capabilities will also enable us to tackle more complex interaction scenarios, such as social robotics, situated multimodal dialogue with smart devices, and eventually controlling and managing the Internet of Things.

From a societal importance point of view, this project will create a unified user interface which allows every-day users to access and control the Internet of Things in an intuitive way using natural language, and as such lowers the barrier to access and benefit from new technology. This is especially relevant for elderly and/or disabled users in a home automation scenario for example.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-05-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>520418</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>EmoTech Ltd</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>EmoTech North Industry Knowledge Exchange</gtr:description><gtr:id>F9D2DFE9-38B7-4879-91C3-86DC4087B1C0</gtr:id><gtr:impact>Robotics hardware, neuroscience, human-computer interaction</gtr:impact><gtr:outcomeId>58b2e82e4f1a73.54808938-1</gtr:outcomeId><gtr:partnerContribution>Cash contribution of &amp;pound;58k to support RA. Invited research visit to London (1 week) fully supported.</gtr:partnerContribution><gtr:piContribution>we collaborate on designing and implementing a conversational interface for Olly the Robot - a product developed by Emotech Ltd, an in-home robot with conversational capabilities.

The Olly robot recently won 4 awards for Innovation at the CES showcase. (The CES Innovation Awards is an annual competition honoring outstanding design and engineering in consumer technology products over the world.)
Recently showcased at CES '17 http://www.bbc.com/news/technology-38504512

The project outcome will directly contribute the Olly product of Emotech. Emotech will release 1000-1500 units in June/July via a Kickstarter program to gauge early adopter feedback. Full commercial release is expected in Q3/4 2017 at a retail price of $600-800 per unit.

The revenue of Emotech LTD in 2017 is estimated to be &amp;pound;2m, and is expected to grow to &amp;pound;20-40m in 2018. Emotech North Ltd will be a NLP(Natural Language Processing) hub for Emotech. Its growth will create more employment positions, more collaborations with other industry partners and universities in Scotland.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Amazon.com</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Amazon Alexa Challenge</gtr:description><gtr:id>9AE76ECE-D10A-4E07-81CF-BDA8C5362E27</gtr:id><gtr:impact>Increased recognition and visibility of my research group and department.</gtr:impact><gtr:outcomeId>58b347073e8975.53916761-1</gtr:outcomeId><gtr:partnerContribution>We received a generous gift of $100k and various in-kind contributions, e.g. free training and access to Amazon Web services, Alexa-enabled devices, weekly class with one of Amazon senior researchers, free travel to Amazon HQ in Seattle for the team etc.</gtr:partnerContribution><gtr:piContribution>My team was selected to participate in the Amazon Alexa Challenge. The aim of this challenge is to build a social chat bot that can converse coherently and engagingly with humans on popular topics for 20 minutes.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Diversity and inclusion in academic ICT research</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1BA3091D-857F-4D96-BC3E-9B16F55022E6</gtr:id><gtr:impact>I am taking part in the focus group Diversity and inclusion in academic ICT research run by the EPSRC and organised by Edinburgh Napier University.</gtr:impact><gtr:outcomeId>58bfe1f511b7e4.99076765</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>https://www.epsrc.ac.uk/newsevents/news/ictdiversityinclusionresearch/</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Conversational Agents course (HWU)</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>25645DCD-FC35-44EC-90B9-AF237BE8E742</gtr:id><gtr:impact>Contributed to the course 'Conversational Agents', attended by approximately 18 undergraduate students. The contribution included in particular the supervision of 5 of the students carrying out a project as part of their coursework. The project involved working with the dialogue system code developed so far in the Madrigal project and adapting it to a new domain (domain adaptation being one of the key aspects of Madrigal). This activity has enabled knowledge transfer to students and given them an opportunity to get both theoretical and practical experience with developing dialogue systems. Moreover, the interaction with the students and their feedback has triggered major improvements and further development of the Madrigal software.</gtr:impact><gtr:outcomeId>58beb2336a2297.87229782</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>https://sites.google.com/site/olemon/conversational-agents</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Native Scientist German School Outreach</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>ACF0DF56-1186-436C-B329-FF81F274A971</gtr:id><gtr:impact>Verena Rieser engaged school children in her research. The half-day event was organised by Alleman Fun (German Saturday School) and Native Scientist. The engagement activity was held in German.</gtr:impact><gtr:outcomeId>58bfe313891401.32683044</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.macs.hw.ac.uk/RoboticsLab/news/german-native-scientist-volunteers-reaching-out-to-children-from-the-allemannfun-german-saturday-school</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Women@CS</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>DD8A2E65-B829-4ACB-81A7-2BFB20A8500B</gtr:id><gtr:impact>Verena Rieser organises a local support group for female students studying Computer Science, inspired by the &amp;quot;Sisters Clubs&amp;quot; in American universities. The goal is to attract and retain female UG students to study CS.</gtr:impact><gtr:outcomeId>58bfe0e1eff4c9.50521963</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Undergraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited seminar talk at the University of Pennsylvania, US.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>127C7DC8-B27B-4D8A-9FA3-A3B8037208FC</gtr:id><gtr:impact>Verena Rieser gave an invited seminar talk at the University of Pennsylvania on: &amp;quot;From Dialogue Systems to Social Chatbots: Reinforcement Learning, Seq2Seq, and back again&amp;quot;</gtr:impact><gtr:outcomeId>58b98f8dae2877.04780951</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>https://pricelab.sas.upenn.edu/clunch16-17</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>ECML-PKDD conference (Riva del Garda, Italy)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A532B262-773A-4E34-BE86-EBF517781AB3</gtr:id><gtr:impact>Attended the ECML-PKDD 2016 conference and gave a talk in one of its workshops, introducing the Madrigal project to peer researchers from both academia and industry. This conference visit also enabled many discussions with specialists in the field of machine learning, which was the topic of the overall conference, and an important aspect of the Madrigal project. The trip also included discussion with project collaborator Prof. Harry Bunt, who gave an invited talk at the workshop. The discussion included the planning of mutual research visits in 2017.</gtr:impact><gtr:outcomeId>58beabeedeb227.68520920</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.ecmlpkdd2016.org</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited industry talk at Thomson Reuters</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>84DA454F-9909-4BDB-84B7-6160987294B0</gtr:id><gtr:impact>Verena Rieser was invited to present her research to Thomson Reuters via an online seminar. This seminar will be broadcasted to all research employees of Thomson Reuters worldwide.</gtr:impact><gtr:outcomeId>58bfdfc58159b9.73543294</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Heriot-Watt University is currently involved in a couple of knowledge transfer collaborations with industry, including EmoTech LTD and Amazon.com, where we co-create and develop the methods proposed in this grant. For example, we were selected to participate in the prestigious Amazon Alexa challenge, which gives us a great test bed for our methods. 

Furthermore,Heriot-Watt University has also created a new MSc programme in AI with Speech and Multimodal Interaction, where methods and techniques developed as part of this proposal are taught to students in new courses, such as F20/21CA Conversational Agents.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>362045A1-5B20-4236-BBE0-C35D68DAC9BF</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58c01942b81824.26929469</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Education</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>New MSc Programme in Speech and Multimodal Interaction</gtr:description><gtr:geographicReach>National</gtr:geographicReach><gtr:id>A585C9A5-A852-47E5-B34E-EC75D35AAC83</gtr:id><gtr:impact>Verena Rieser created a new postgraduate MSc programme at Heriot-Watt, which aims to educate highly employable experts in creating conversational multimodal interfaces. The programme recently received 6 fully funded studentships by the DataLab/ Scottish funding council.</gtr:impact><gtr:outcomeId>58bfe497d95aa1.70251001</gtr:outcomeId><gtr:type>Influenced training of practitioners or researchers</gtr:type><gtr:url>http://www.macs.hw.ac.uk/cs/pgcourses/aiws.htm</gtr:url></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>7E9949C3-6848-4543-9506-C87760FBA7BC</gtr:id><gtr:title>Data-to-Text Generation Improves Decision-Making Under Uncertainty</gtr:title><gtr:parentPublicationTitle>IEEE Computational Intelligence Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/88ff04fc6f58d1fbec11cf9983b8f40e"><gtr:id>88ff04fc6f58d1fbec11cf9983b8f40e</gtr:id><gtr:otherNames>Gkatzia D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8ae79e016608.51210826</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7D275583-5F89-4DE5-B06D-E7B14500DC43</gtr:id><gtr:title>The MaDrIgAL project: Multi-Dimensional Interaction Management and Adaptive Learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f7402b3b00270544656d2e7cb6437764"><gtr:id>f7402b3b00270544656d2e7cb6437764</gtr:id><gtr:otherNames>Keizer S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58be8a7a76b609.35315397</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5BE937C9-5C89-49E7-89DA-A2C6EA40E896</gtr:id><gtr:title>A Subjective Evaluation of Chatbot Engines</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/231d6ed58f502dd6289688a1a0f381b5"><gtr:id>231d6ed58f502dd6289688a1a0f381b5</gtr:id><gtr:otherNames>Curry A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58be89afa72483.44726387</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C9988649-6A92-4A01-A750-B9A006F26C9B</gtr:id><gtr:title>Why We Need New Evaluation Metrics for NLG</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2615422ffc27fea0d39088a298a6d4f5"><gtr:id>2615422ffc27fea0d39088a298a6d4f5</gtr:id><gtr:otherNames>Novikova J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a723aaf471646.34675567</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8F28203E-FA11-4688-9E1F-51A348452E88</gtr:id><gtr:title>Special issue on spatial reasoning and interaction for real-world robotics</gtr:title><gtr:parentPublicationTitle>Advanced Robotics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6ed8915c4f7fbd63030ebe07f5e97060"><gtr:id>6ed8915c4f7fbd63030ebe07f5e97060</gtr:id><gtr:otherNames>Rieser V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58be8d14cad504.98081507</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>991AD1D6-A5F9-45E6-9609-E83194FD69E9</gtr:id><gtr:title>The E2E Dataset: New Challenges For End-to-End Generation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2615422ffc27fea0d39088a298a6d4f5"><gtr:id>2615422ffc27fea0d39088a298a6d4f5</gtr:id><gtr:otherNames>Novikova J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a723aaf1f6ea0.87794443</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CB4655A2-C9D7-45E3-812D-9E6C60497D44</gtr:id><gtr:title>A review of evaluation techniques for social dialogue systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/231d6ed58f502dd6289688a1a0f381b5"><gtr:id>231d6ed58f502dd6289688a1a0f381b5</gtr:id><gtr:otherNames>Curry A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8ae4d9e00bb0.57541363</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9EC92CC7-F5B4-4D41-81E4-840C522CB1FC</gtr:id><gtr:title>A review of spatial reasoning and interaction for real-world robotics</gtr:title><gtr:parentPublicationTitle>Advanced Robotics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2679560b93b53bf216ead353a4cd93a1"><gtr:id>2679560b93b53bf216ead353a4cd93a1</gtr:id><gtr:otherNames>Landsiedel C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58be8c49294d27.33040609</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>852375A2-3E6A-4B91-9556-62536EEFE36D</gtr:id><gtr:title>Proceedings of the 9th International Conference on Natural Language Generation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/493bfa9c82ff8614224f0f584bccf1bc"><gtr:id>493bfa9c82ff8614224f0f584bccf1bc</gtr:id><gtr:otherNames>Isard A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b4321d184088.60882055</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N017536/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>