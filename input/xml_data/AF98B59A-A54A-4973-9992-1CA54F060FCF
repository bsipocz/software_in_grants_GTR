<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Engineering</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3DEBA010-3ED5-45C2-B658-6FD44DFBA777"><gtr:id>3DEBA010-3ED5-45C2-B658-6FD44DFBA777</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Murray</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D831A1C6-3B74-45B8-9BA5-E17D177C59BD"><gtr:id>D831A1C6-3B74-45B8-9BA5-E17D177C59BD</gtr:id><gtr:firstName>Barbara</gtr:firstName><gtr:surname>Webb</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/433A71D9-8E6F-4487-8A18-F87E92C05276"><gtr:id>433A71D9-8E6F-4487-8A18-F87E92C05276</gtr:id><gtr:firstName>H</gtr:firstName><gtr:otherNames>Martin</gtr:otherNames><gtr:surname>Reekie</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/803477DE-F01F-48D4-90E0-C1E7DABC80FE"><gtr:id>803477DE-F01F-48D4-90E0-C1E7DABC80FE</gtr:id><gtr:firstName>Zhijun</gtr:firstName><gtr:surname>Yang</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5F394B54-009B-479E-933F-BE16F3E50722"><gtr:id>5F394B54-009B-479E-933F-BE16F3E50722</gtr:id><gtr:firstName>Robert</gtr:firstName><gtr:otherNames>Kerr</gtr:otherNames><gtr:surname>Henderson</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE063322%2F1"><gtr:id>AF98B59A-A54A-4973-9992-1CA54F060FCF</gtr:id><gtr:title>Neuromorphic Sensorimotor Integration for Legged Locomotion (NSILL)</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E063322/1</gtr:grantReference><gtr:abstractText>During walking, a robot must use several senses to guide its movements. For example, it may need to avoid obstacles, to lift its legs over bumps, or to take a longer stride to avoid a gap. Basic reflexes respond to direct contact (or lack of contact) with uneven ground, but walking would be aided by sensing the ground surface variation or obstacles in advance. It would help to literally see what is ahead . In living animals, walking patterns often depend on a Central Pattern Generator (CPG) to generate a regular gait. The CPG output must, however, learn to control walking on complex and unfamiliar terrain - it must use the animal's senses to adjust walking patterns. Alternatively, the patterns might emerge from distributed control in which each leg influences its neighbours. This approach might be advantageous when the 'pattern' becomes very irregular due to complex terrain.These biological solutions to the problem of walking suggest engineering solutions for walking robots. We will design and build biologically inspired systems using analogue/digital silicon chips, controlling a 6-legged robot. There are three research strands. 1) A CPG chip that learns to generate adaptive walking patterns. Biological CPGs are extremely flexible for producing different rhythms. Neuromodulators, central commands and input signals all influence the pattern produced by a CPG. They do so by altering both the electrical and chemical properties of individual neurons and the coupling between different groups of neurons. For example, visual inputs can cause an animal to break into a gallop. We have previously developed a CPG circuit capable of producing a wide range of animal gaits. We will now build this novel CPG in silicon and test it on a 6-legged insect-like robot, designed and built during the project. We will then evaluate its ability to produce sufficiently flexible output to deal with complex terrain, and compare it to a more distributed control system, or to a suitable hybrid of these two forms of walking control.2) A vision chip that estimates the distance to objects in an image. Neuromorphic vision sensors have been built for edge detection, velocity- and depth-sensing. These are, however, isolated case studies that do not integrate vision with other senses for robotic applications. We will design a silicon chip that implements a novel vision depth sensing method, developed under a previous grant and based on a spiking neuronal model. This stylised early vision model will consist of a 2-D array of light-sensitive transistors with the ability to perform both edge sensing and depth detection. 3) A biologically-inspired chip that integrates senses to make decisions. This chip will combine the output of the visual processor (detected objects and their depth) with additional senses (touch and joint angle sensors) to adjust the walking patterns to achieve smooth, stable movement across rough ground. In particular it will learn to use the visual depth information to anticipate movements required to avoid collisions and maintain stable footing. We will test the methods in simulation, then use software on microprocessors to test the results on real robots. We will then create a chip which will translate the sensors' view of the world into appropriate modulation of the walking controller. The final stage of the project will be the integration of all three chips on to the 6-legged robot to produce a new walking robot with explicit biological antecedents. The project will thus advance research in neuromorphic VLSI and sensor-motor integration, with direct applications in mobile robots for domestic applications and work in hazardous, difficult and unknown environments. It will also help to identify some of the basic computing and control principles in the nervous system.</gtr:abstractText><gtr:fund><gtr:end>2011-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>856351</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>They have not yet been used, as the robot system was not completed during the time of the p[project.</gtr:description><gtr:id>2AA14660-240A-44FD-9E50-D0A7BEDF578A</gtr:id><gtr:impactTypes/><gtr:outcomeId>54575a5987f2d0.55999983</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The key finding was that it is possible to control leg movement in an insect-like robot using a neurally-inspired algorithm implemented as a neuromorphic silicon chip.</gtr:description><gtr:exploitationPathways>Further development work would put the entire robot system together and thus create a flexible, robust system for locomotion in hazardous and unpredictable environments (eg defence or industrial decontamination).</gtr:exploitationPathways><gtr:id>96D18DB7-3AA6-4E9E-964F-36CA5354CB5D</gtr:id><gtr:outcomeId>54575a21199a30.03949061</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Construction</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>A0BBF067-E085-4567-908E-DA56E7E9E434</gtr:id><gtr:title>Bioinspired Real Time Sensory Map Realignment in a Robotic Barn Owl</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71e6fe0da60b1951fcbae068a68797b5"><gtr:id>71e6fe0da60b1951fcbae068a68797b5</gtr:id><gtr:otherNames>Alan Murray (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_911516106964282bee</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>69118A8A-2411-4EE0-B88C-0F8FFEB8D455</gtr:id><gtr:title>A hexapod robot modeled on the stick insect, Carausius morosus</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/23d858b11305c83f95d94d2ff28bdfa3"><gtr:id>23d858b11305c83f95d94d2ff28bdfa3</gtr:id><gtr:otherNames>Lewinger W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-1158-9</gtr:isbn><gtr:outcomeId>doi_53d05805823575d0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9F8D9B18-441B-464B-8F75-95EDAE422968</gtr:id><gtr:title>Self-organisation of gait pattern transition</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71e6fe0da60b1951fcbae068a68797b5"><gtr:id>71e6fe0da60b1951fcbae068a68797b5</gtr:id><gtr:otherNames>Alan Murray (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_655549742964282acc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>051A65D7-5BCA-4629-AD8C-F630158773C3</gtr:id><gtr:title>The adaptation of visual and auditory integration in the barn owl superior colliculus with Spike Timing Dependent Plasticity.</gtr:title><gtr:parentPublicationTitle>Neural networks : the official journal of the International Neural Network Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fcf860bf6081f6564a3caef42e2ee197"><gtr:id>fcf860bf6081f6564a3caef42e2ee197</gtr:id><gtr:otherNames>Huo J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0893-6080</gtr:issn><gtr:outcomeId>doi_53d0020023b9c7e0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3BC27C19-7BB5-4C84-89F6-227B94F67A11</gtr:id><gtr:title>Adaptation of Barn Owl Localization System with Spike Timing Dependent Plasticity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71e6fe0da60b1951fcbae068a68797b5"><gtr:id>71e6fe0da60b1951fcbae068a68797b5</gtr:id><gtr:otherNames>Alan Murray (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_52681010316428272a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>59FBC4CF-F8C7-4905-8D92-D74A1905126D</gtr:id><gtr:title>Neuromorphic control of stepping pattern generation: a dynamic model with analog circuit implementation.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on neural networks and learning systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf9c2d3260e115f51a5ebf8d4d07d149"><gtr:id>bf9c2d3260e115f51a5ebf8d4d07d149</gtr:id><gtr:otherNames>Yang Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>2162-237X</gtr:issn><gtr:outcomeId>doi_53d05e05edde0f8b</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>57BDA53A-336B-4E84-BA2C-47CBD4D05F8B</gtr:id><gtr:title>Modeling Visual and Auditory Integration of Barn Owl Superior Colliculus with STDP</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71e6fe0da60b1951fcbae068a68797b5"><gtr:id>71e6fe0da60b1951fcbae068a68797b5</gtr:id><gtr:otherNames>Alan Murray (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_207168237764282860</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E38CD196-F7CD-496A-A8FF-20B8AD183F61</gtr:id><gtr:title>Animals Versus Animats: Or Why Not Model the Real Iguana?</gtr:title><gtr:parentPublicationTitle>Adaptive Behavior</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/aa44d5355dd7da9822557b5a9233ed59"><gtr:id>aa44d5355dd7da9822557b5a9233ed59</gtr:id><gtr:otherNames>Webb B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d07a07a2eb9cb7</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CCF42479-F801-41E2-8983-676846F4BB5E</gtr:id><gtr:title>Silicon Superior Colliculus for the Integration of Visual and Auditory Information with Adaptive Axon Connection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71e6fe0da60b1951fcbae068a68797b5"><gtr:id>71e6fe0da60b1951fcbae068a68797b5</gtr:id><gtr:otherNames>Alan Murray (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_4554108843642829a0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>80E33567-13D7-4AFD-8BAD-CA3AE9AC4B81</gtr:id><gtr:title>Prescription of rhythmic patterns for legged locomotion</gtr:title><gtr:parentPublicationTitle>Neural Computing and Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf9c2d3260e115f51a5ebf8d4d07d149"><gtr:id>bf9c2d3260e115f51a5ebf8d4d07d149</gtr:id><gtr:otherNames>Yang Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d5e9d9868c3.20018092</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AB0D373D-88F0-42E3-B4BD-9B9DA60E9085</gtr:id><gtr:title>Minimizing the effect of process mismatch in a neuromorphic system using spike-timing-dependent adaptation.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on neural networks</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a58d69ad4f17dd544ce82aba3158212b"><gtr:id>a58d69ad4f17dd544ce82aba3158212b</gtr:id><gtr:otherNames>Cameron K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1045-9227</gtr:issn><gtr:outcomeId>doi_53d05e05ed4651ed</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ACFD410C-5EF7-47AE-A29C-861EE5DCC873</gtr:id><gtr:title>An implementation of a spike-response model with escape noise using an avalanche diode.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on biomedical circuits and systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/54277cd80b38cce0bef72cea8f9393d0"><gtr:id>54277cd80b38cce0bef72cea8f9393d0</gtr:id><gtr:otherNames>Clayton T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1932-4545</gtr:issn><gtr:outcomeId>doi_53d05c05cfaa0efd</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2ABBFF5E-B203-48AD-A955-7138B60B9166</gtr:id><gtr:title>Artificial Neural Networks - ICANN 2008</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf9c2d3260e115f51a5ebf8d4d07d149"><gtr:id>bf9c2d3260e115f51a5ebf8d4d07d149</gtr:id><gtr:otherNames>Yang Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:isbn>978-3-540-87558-1</gtr:isbn><gtr:outcomeId>doi_53cfcdfcd18ee80e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>36986BA2-2916-4D27-8B46-D3D391538BF3</gtr:id><gtr:title>Neuromorphic Circuit Implementation of Isotropic Sequence Order Learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf9c2d3260e115f51a5ebf8d4d07d149"><gtr:id>bf9c2d3260e115f51a5ebf8d4d07d149</gtr:id><gtr:otherNames>Yang Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-8432-4</gtr:isbn><gtr:outcomeId>543b9fbd613bc4.23278980</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E063322/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>18CCD01F-CBEC-46CF-B316-5A50A2CFF82D</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>New &amp; Emerging Comp. Paradigms</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>1E31C833-3A35-4F54-A499-31D0C245B5D5</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>System on Chip</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>2770EFE0-D127-47F1-9FC0-AABDCE301DD3</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>VLSI Design</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>