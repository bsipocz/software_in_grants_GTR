<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Experimental Psychology</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/9E1E0B3C-8459-4367-B9F6-C6B4E911AC83"><gtr:id>9E1E0B3C-8459-4367-B9F6-C6B4E911AC83</gtr:id><gtr:firstName>Marcus</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Munafo</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/C50EE9C0-A0E3-4EB0-9EFD-C424F4204D12"><gtr:id>C50EE9C0-A0E3-4EB0-9EFD-C424F4204D12</gtr:id><gtr:firstName>Catherine</gtr:firstName><gtr:surname>Harmer</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/42904E16-8A6E-4A00-9309-3E69B5F58593"><gtr:id>42904E16-8A6E-4A00-9309-3E69B5F58593</gtr:id><gtr:firstName>Ian</gtr:firstName><gtr:otherNames>Scott</gtr:otherNames><gtr:surname>Penton-Voak</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DE3D6859-6D8A-48E9-9A4C-7CB8AE12A689"><gtr:id>DE3D6859-6D8A-48E9-9A4C-7CB8AE12A689</gtr:id><gtr:firstName>Emily</gtr:firstName><gtr:surname>Holmes</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MR%2FJ011819%2F1"><gtr:id>3E7F5919-642A-4328-846B-2F28672FEDD0</gtr:id><gtr:title>Facing up to Faces: Changing biases in face perception to improve emotional processing in mental health</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>MR/J011819/1</gtr:grantReference><gtr:abstractText>The ability to accurately detect and recognize emotion in other people is extremely important in everyday life. Even slight differences in the ability to do this, such as a relative insensitivity to some emotions, or heightened sensitivity to other emotions, can cause problems. For example, people with depression tend to be less sensitive to expressions of happiness, and more sensitive to expressions of sadness. This may actually contribute to the onset or maintenance of their depression, by causing distortions in how they perceive the world, and in particular other people. If someone is less sensitive to happiness in others, for example, he or she may not notice when someone is responding positively to them, and fail to reciprocate this, thereby missing out on the opportunity for a positive social interaction.

We have developed a technique which allows us to subtly modify these emotion recognition biases. Faces which are ambiguous, and consist of a blend of happiness and sadness, can be used to determine when a person stops seeing one emotion and starts seeing another. Using this information, that individual can then be &amp;quot;trained&amp;quot; to be more inclined to see happiness in those ambiguous faces rather than sadness. This training procedure takes only about 20 minutes, and can be done on a laptop or, in principle, via a website or on a tablet computer or smartphone. Repeated training over a few days can produce a marked change in emotion recognition, so that the individual becomes more inclined to see happiness over sadness in other people's faces. Here we are proposing a study to answer two questions: Does this procedure improve people's mood, and what brain regions are involved in this process?

Our pilot work is very promising. In a group of people selected for high levels of depressive symptoms, four days of training resulted in a noticeable improvement in positive mood two weeks later. We would like to recruit a larger sample, to provide more definitive results, and collect mood data at a longer follow-up period of six weeks, to establish the longevity of these effects. This would allow us make the critical next step in the development of this intervention, which is to move from proof of concept to clinical translation. In parallel, we would like to run a smaller study which will use the same training procedure but will then use brain scanning technology to identify which brain regions are influenced by this training procedure. Finally, we will run a small focus group of people who have experienced depression, in order to find out whether they feel that an automated training procedure such as ours would be an acceptable treatment for depression.

The results of our study have the potential to give rise to a new type of treatment for depression, which could be used in conjunction with existing treatments such as cognitive behavioural therapy or medication. It has the advantage of being relatively simple and non-invasive, and in principle can be delivered remotely via the internet or a smartphone. In addition, the techniques we will be using can in principle be applied to other mental health problems where emotion recognition appears to play a role, such as conduct disorder, schizophrenia and addiction.</gtr:abstractText><gtr:technicalSummary>Mood disorders are highly prevalent in the general population, dominated by major depression, and constitute a substantial burden of disease - in Europe 7.2% can be attributed to depression. There is therefore a pressing need for interventions to address this. Here we propose a study to investigate the potential of a novel cognitive bias modification technique for reducing negative mood and improving positive mood in an analogue population of those with high levels of depressive symptoms. This targets biases in emotional processing characteristic of depression.

We have developed a new paradigm which targets the recognition of emotions by assessing the threshold for detecting emotion in an ambiguous expression (e.g., a blend of happiness and sadness), and then providing feedback to modify this (e.g., to favour identification of happiness). Preliminary results show that this manipulation, designed to promote the perception of positive emotion over negative emotion, results in improved positive mood at two-week follow-up. We propose two workstreams to develop these initial findings. The first will establish the effects of this training on a larger sample of individuals with high levels of depressive symptoms over six-week follow-up. The second will identify the neural substrates targeted by this procedure.

This research will allow us make the critical next step in the development of this intervention, moving from proof of concept to clinical translation. It has the potential to inform the development of a novel treatment for depression which could be used alongside existing treatments. In principle this could be delivered automatically via computer, internet or smartphone. It therefore has exciting potential to be a valuable cost-effective adjunctive treatment for depression. In addition, the technique can be adapted for use in other psychopathologies where emotion recognition biases or deficits have been implicated, such as schizophrenia, autism and addiction.</gtr:technicalSummary><gtr:potentialImpactText>Impact activities will proceed along three parallel strands: academic engagement, patient and public involvement, and scientific exploitation, including progression to clinical trials. Taken together, these activities have the potential to provide the academic community with an exciting and novel technique for exploring the causal role of emotion processing biases in psychopathology, engaging the public and service users with the developing evidence base so that they can contribute to intervention development, and providing a firm evidence base for the clinical efficacy of this intervention in depression and, in principle, other psychopathologies.

Academic impact will be achieved through publications and presentations at scientific meetings, and will constitute the broader application of the techniques described here across a range of psychopathologies where biases and deficits in emotion recognition have been implicated. It provides a novel experimental tool for exploring the causal basis of these biases in a range of psychopathologies, and can in principle be adapted for therapeutic use.

Patient and public involvement impact activities will be achieved through a service user focus group and public engagement activities, supported by our industry partner, the Mental Health Foundation. This will allow us to incorporate the view of the general public and service users into the further development of our technique, and in particular contribute to the further development of the technique and design of future applications to MRC DCS and NIHR EME mechanisms (see below).

Scientific exploitation impact activities will be achieved through applications for subsequent funding through MRC DCS and NIHR EME mechanisms. In addition, the technique described here can in principle be applied to other psychopathologies, and can be implemented via smartphone, tablet computer and internet. Future research will investigate the implementation of this technique on these platforms.

These impacts will be achieved across three timescales: short-term (during the lifetime of the grant), medium-term (immediately following completion of the grant) and long-term.

Short-term impact will be achieved through the service user focus group proposed, the dissemination of the results of workstream 2 through publication and attendance at two scientific meetings, and public engagement activities conducted with the support of the Mental Health Foundation.

Medium-term impact will be achieved through the dissemination of the results of workstream 2 through further publication and attendance at scientific meetings, further public engagement activities, and the integration of the results of the service user focus group into applications for further funding to develop the clinical evidence base for this intervention.

Long-term impact will be achieved through the translation of these findings into novel treatments for depression and other psychopathologies, the development of novel delivery platforms such as internet website and smartphone and tablet computer apps, and the uptake of this technique by the wider scientific community.

Finally, mood disorders are highly prevalent in the general population, dominated by major depression, and constitute a substantial burden of disease - in Europe 7.2% can be attributed to depression. The economic benefits of a novel treatment for depression, such as that described here, will therefore be high.</gtr:potentialImpactText><gtr:fund><gtr:end>2014-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2012-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>256129</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Google UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>B001099C-72DA-45F3-9BE8-10300FC540CC</gtr:id><gtr:impact>40 employees of Google UK attended a presentation on the role of emotion recognition biases in mental health.

YouTube clip of presentation has been viewed &amp;gt; 2000 times as of 26/11/12.

http://www.youtube.com/watch?v=oghXHN9X-FY</gtr:impact><gtr:outcomeId>VgYRBZRqmBW</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:presentationType>Keynote/Invited Speaker</gtr:presentationType><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Data Collection Activity at At-Bristol</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>C5D497F1-344E-4448-A857-DD1AFEB83FF0</gtr:id><gtr:impact>We collected photos of children making six different facial expressions. The photos collected will be used to create stimuli for research about emotion recognition in children. For example, we hope to use these images in a training programme to increase children with autism's ability to recognise the expressions of other children.

Development of novel stimulus set for use in research.</gtr:impact><gtr:outcomeId>jdsLNFjuhfp</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Twilight Talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>EDE9E3CC-9EA5-4F0D-A681-96F877DEAF5D</gtr:id><gtr:impact>100 members of the public attended a talk on the role of emotion recognition biases in mental health.

None.</gtr:impact><gtr:outcomeId>Qy4kgmYD3xx</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:presentationType>Keynote/Invited Speaker</gtr:presentationType><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs><gtr:productOutput><gtr:clinicalTrial>true</gtr:clinicalTrial><gtr:description>We have developed a new paradigm which targets the recognition of facial expression of emotions by initially assessing the threshold for detecting one emotion over another in an ambiguous expression (e.g., a blend of happiness and sadness), and then providing feedback to shift this threshold (e.g., to favour identification of happiness over sadness). Training consists of feedback to shift the participant's balance point, estimated by presenting exemplar faces from a 15-frame morphed face image continuum using a two-alternative forced choice procedure. In the training condition, the 'correct' classification shifted two morph steps towards 'happy'; the two images nearest the balance point that the participant would have previously classified as 'angry' at baseline were considered 'happy' in terms of providing feedback.</gtr:description><gtr:id>04889C3E-14CE-4349-A355-12167A079D40</gtr:id><gtr:impact>None yet.</gtr:impact><gtr:outcomeId>biWCrVwCrEa</gtr:outcomeId><gtr:stage>Refinement.  Non-clinical</gtr:stage><gtr:status>Under active development_distribution</gtr:status><gtr:title>Emotion Recognition Training and Mood</gtr:title><gtr:type>Therapeutic Intervention - Psychological_Behavioural</gtr:type><gtr:yearDevCompleted>2012</gtr:yearDevCompleted></gtr:productOutput><gtr:productOutput><gtr:clinicalTrial>true</gtr:clinicalTrial><gtr:description>Emotion Recognition Training (ERT) vs. Control 

Session 1: The first session will involve a screening assessment to ensure that participants fit the requirements of the study and are in general good physical and psychological health. During this session participants will also complete questionnaire measures and will be required a computer-based emotion perception task. Participants will be randomised to one of 2 groups: treatment or control. This session would last approximately 60 minutes. 

Sessions 2-5: We will ask participants to attend four sessions on consecutive days (or as close as possible) to complete the computer-based emotion perception task and a series of questionnaires rating mood. These sessions should last approximately 25 minutes. 

Session 5: We will ask participants to undergo a MRI scan consisting of two parts. Participants will first undergo an anatomical MRI scan; this will last approximately 5 minutes and participants will just lie still. In the second part of the MRI scan participants will view images projected on a screen above their head. This session would last approximately 60 minutes.</gtr:description><gtr:id>82AE7FC8-E593-4687-A117-2187EC1D2438</gtr:id><gtr:impact>None yet.</gtr:impact><gtr:outcomeId>LwAwp6AoUcS</gtr:outcomeId><gtr:stage>Initial development</gtr:stage><gtr:status>Under active development_distribution</gtr:status><gtr:title>Emotion Recognition Training and Brain Response</gtr:title><gtr:type>Therapeutic Intervention - Psychological_Behavioural</gtr:type><gtr:yearDevCompleted>2013</gtr:yearDevCompleted></gtr:productOutput></gtr:productOutputs><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>026DC459-601A-4E51-8EDE-B6B159DEDA73</gtr:id><gtr:title>Effects of emotion recognition training on mood among individuals with high levels of depressive symptoms: study protocol for a randomised controlled trial.</gtr:title><gtr:parentPublicationTitle>Trials</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1d5ca3e7fb4665839f6fab3cfc3300b2"><gtr:id>1d5ca3e7fb4665839f6fab3cfc3300b2</gtr:id><gtr:otherNames>Adams S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1745-6215</gtr:issn><gtr:outcomeId>pm_13547_27_23725208</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7D52C26A-21FB-41BD-BD9B-3D2648BE4E74</gtr:id><gtr:title>Meta-analysis of emotion recognition deficits in major depressive disorder.</gtr:title><gtr:parentPublicationTitle>Psychological medicine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ccfb540b94bb03d8f480d44a76b43858"><gtr:id>ccfb540b94bb03d8f480d44a76b43858</gtr:id><gtr:otherNames>Dalili MN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0033-2917</gtr:issn><gtr:outcomeId>5675dccc161c0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FADF8E06-3DD6-4A0F-A548-C8B38E73CED8</gtr:id><gtr:title>Emotion recognition training using composite faces generalises across identities but not all emotions.</gtr:title><gtr:parentPublicationTitle>Cognition &amp; emotion</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ccfb540b94bb03d8f480d44a76b43858"><gtr:id>ccfb540b94bb03d8f480d44a76b43858</gtr:id><gtr:otherNames>Dalili MN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0269-9931</gtr:issn><gtr:outcomeId>585d4c9d02ad05.21723274</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7EE8B39C-3999-4821-8209-8E808484F4B9</gtr:id><gtr:title>Biased Facial-Emotion Perception in Mental Health Disorders: A Possible Target for Psychological Intervention?</gtr:title><gtr:parentPublicationTitle>Current Directions in Psychological Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d060eceb7fb12ad42f04ab5e4c30909c"><gtr:id>d060eceb7fb12ad42f04ab5e4c30909c</gtr:id><gtr:otherNames>Penton-Voak I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fd8ba290133.02459402</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">MR/J011819/1</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>3C193D18-12BD-4B15-8347-037BA623E0FF</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Mental Health</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>CA7C1014-EC90-43EB-B9F2-C12CD9DD1A1C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>5.6  Psychological and behavioural</gtr:text></gtr:researchActivity><gtr:researchActivity><gtr:id>AAFE74BF-2594-40A4-9487-23A469C7A3C4</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>6.6  Psychological and behavioural</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>