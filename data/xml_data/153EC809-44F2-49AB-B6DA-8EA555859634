<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2ACDBC0B-E2F3-487D-8D5B-2B9A51A0E6BC"><gtr:id>2ACDBC0B-E2F3-487D-8D5B-2B9A51A0E6BC</gtr:id><gtr:name>Eye Tracking Analysts Ltd</gtr:name><gtr:address><gtr:line1>BUSINESS INNOVATION CENTRE GATES COURT , STAFFORDSHIRE TECHNOLOGY PARK</gtr:line1><gtr:city>STAFFORD</gtr:city><gtr:postCode>ST18 0AR</gtr:postCode><gtr:region>West Midlands</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2ACDBC0B-E2F3-487D-8D5B-2B9A51A0E6BC" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>2ACDBC0B-E2F3-487D-8D5B-2B9A51A0E6BC</gtr:id><gtr:name>Eye Tracking Analysts Ltd</gtr:name><gtr:address><gtr:line1>BUSINESS INNOVATION CENTRE GATES COURT , STAFFORDSHIRE TECHNOLOGY PARK</gtr:line1><gtr:city>STAFFORD</gtr:city><gtr:postCode>ST18 0AR</gtr:postCode><gtr:region>West Midlands</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>43429.0</gtr:offerGrant><gtr:projectCost>96509.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/1D5A65A6-AEB9-4204-85F0-9A0045A3FD92"><gtr:id>1D5A65A6-AEB9-4204-85F0-9A0045A3FD92</gtr:id><gtr:firstName>John</gtr:firstName><gtr:surname>Cox</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=720440"><gtr:id>153EC809-44F2-49AB-B6DA-8EA555859634</gtr:id><gtr:title>Calibration Free Eye-Tracking</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>GRD Development of Prototype</gtr:grantCategory><gtr:grantReference>720440</gtr:grantReference><gtr:abstractText>The aim of the Calibration Free Eye-Tracker project is to produce video camera based
applications that track a user?s eye-gaze as she interacts with a computerised display. The
system involves the use of a small video camera mounted below the display. The system will
then detect the user?s face in the video image and track her eye-gaze trajectory over time. The
eye gaze trajectory is then intersected with the extents of the display screen to determine the
user?s point of regard on the display. Point of regard determinations allows eye-gaze to be
used as an input mechanism for computer systems and gives insights into what the user is
looking at and not looking at on the display. Existing eye tracking systems suffer from serious
usability problems. The main usability problem is that current commercial eye-tracking
systems that offer precision eye-tracking require users to undergo a system calibration
procedure. Calibration is used to map the 2D coordinates of the user?s eyes within the video
image to the extents of the display and allows the eye tracking system to determine the user?s
point of regard on the display. A typical calibration procedure lasts for 30 seconds and
involves the user following a moving token with her eyes as it traverses the display. Once the
eye-tracker is calibrated, the user must remain virtually still when using the system.
Movement beyond a limited tolerance level will result in the loss of the eye-gaze to screen
mapping and necessitate a repeat of the calibration process.
Eye Tracking Analysts Ltd has developed a calibration free eye tracking system for precision
eye-tracking. With our system, there is no need for a calibration process and users can move
as freely as they like; they can even leave the computer display and return later without
adversely affecting eye-tracking performance. In this way, our eye-tracking system overcomes
the major usability obstacle to the adoption of eye-tracking as a natural user interface method.</gtr:abstractText><gtr:fund><gtr:end>2015-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2014-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>43429</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">720440</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>