<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/1056A257-E423-45BE-B166-A5649A672938"><gtr:id>1056A257-E423-45BE-B166-A5649A672938</gtr:id><gtr:name>Tokyo Metropolitan University</gtr:name><gtr:address><gtr:line1>1-1 Minami-Ohsawa</gtr:line1><gtr:line2>Hachioji-shi</gtr:line2><gtr:line4>Tokyo</gtr:line4><gtr:line5>192-0397</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Japan</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/B711AB39-A8D5-4894-A0A7-23C4BC8AF157"><gtr:id>B711AB39-A8D5-4894-A0A7-23C4BC8AF157</gtr:id><gtr:name>Shanghai Jiao Tong University</gtr:name><gtr:address><gtr:line1>1954 Huashan Road</gtr:line1><gtr:line4>Shanghai</gtr:line4><gtr:line5>200030</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>China</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/955C55E8-783E-4842-BB2C-2D275A3CAF82"><gtr:id>955C55E8-783E-4842-BB2C-2D275A3CAF82</gtr:id><gtr:name>University of Portsmouth</gtr:name><gtr:department>Inst of Industrial Research</gtr:department><gtr:address><gtr:line1>University House</gtr:line1><gtr:line2>Winston Churchill Avenue</gtr:line2><gtr:line4>Portsmouth</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>PO1 2UP</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/955C55E8-783E-4842-BB2C-2D275A3CAF82"><gtr:id>955C55E8-783E-4842-BB2C-2D275A3CAF82</gtr:id><gtr:name>University of Portsmouth</gtr:name><gtr:address><gtr:line1>University House</gtr:line1><gtr:line2>Winston Churchill Avenue</gtr:line2><gtr:line4>Portsmouth</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>PO1 2UP</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1056A257-E423-45BE-B166-A5649A672938"><gtr:id>1056A257-E423-45BE-B166-A5649A672938</gtr:id><gtr:name>Tokyo Metropolitan University</gtr:name><gtr:address><gtr:line1>1-1 Minami-Ohsawa</gtr:line1><gtr:line2>Hachioji-shi</gtr:line2><gtr:line4>Tokyo</gtr:line4><gtr:line5>192-0397</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Japan</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B711AB39-A8D5-4894-A0A7-23C4BC8AF157"><gtr:id>B711AB39-A8D5-4894-A0A7-23C4BC8AF157</gtr:id><gtr:name>Shanghai Jiao Tong University</gtr:name><gtr:address><gtr:line1>1954 Huashan Road</gtr:line1><gtr:line4>Shanghai</gtr:line4><gtr:line5>200030</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>China</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/31307EF8-61D2-4869-8FC9-988F04D26660"><gtr:id>31307EF8-61D2-4869-8FC9-988F04D26660</gtr:id><gtr:name>Bristol Robotics Laboratory</gtr:name><gtr:address><gtr:line1>DuPont Building</gtr:line1><gtr:line2>Bristol Business Park</gtr:line2><gtr:line3>Coldharbour Lane, Frenchay</gtr:line3><gtr:postCode>BS16 1QY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/7B6B64C6-9D49-4D5D-B682-98A0EF21AE89"><gtr:id>7B6B64C6-9D49-4D5D-B682-98A0EF21AE89</gtr:id><gtr:firstName>Honghai</gtr:firstName><gtr:surname>Liu</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG041377%2F1"><gtr:id>F876459A-D25C-4833-8F71-7368EBF7BC3F</gtr:id><gtr:title>Exploring Human Hand Capabilities into Multifingered Robot Manipulation</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G041377/1</gtr:grantReference><gtr:abstractText>It is evident that service robotics has the potential to improve people's quality of life and it holds the key to a number of unmet applications related to health care and rehabilitation. According to the prediction of International Federation of Robotics, the global market for intelligent service robots is forecast to reach 24.3 billion USD worldwide by 2010. A multi-fingered robotic hand is the most complex and dexterous robotic system, whose development represents frontiers in service robotics research. Recent innovations in motor technology and robotics have achieved impressive results in the hardware of robotic hands such as Robonaut hand. However, the manipulation systems of robotic hands are hardcoded to handle specific objects in specific ways, which significantly limits their transfer to a range of different situations and applications. The control and optimisation problems involved in robot hand manipulation are very difficult to solve in mathematical terms, however humans solve their hand manipulation related tasks easily using skill and experience. Object manipulation algorithms are required to meet the market requirement that robot hand systems should have human-like manipulation capabilities and be independent of robot hand hardware. Hence, the main challenge that researchers now face is how to enable robot hands to use what can be learned from human hands, to manipulate objects, with the same degree of skill and delicacy as human hands. The proposed work aims to investigate artificial intelligence (AI) methodologies and practical solutions which will allow robotic hands to automatically adapt to human environments and thus to enable them to autonomously perform useful manipulation tasks involved in daily living, pontentially for health care and rehabilitation applications. The investigation will focus on the following areas. 1) To generate a series of responsive human-like finger gaits for a robotic hand given an object to manipulate. This will have the capability to iteratively build a knowledge base representing the features of human hand manipulation behaviour and to efficiently provide corresponding robot hand gaits and manipulation strategies for a given manipulation task in a human environment.2) To develop feasible friction models for the interaction of objects and a robot/human hand. This will enable the application of existing mathematical research findings in multifingered robot manipulation to realworld applications in human environments and will integrate related methods in engineering and AI domains. 3) To develop an AI-based control architecture to ensure robust object manipulation of multifingered robots in terms of manipulation feasibility and efficiency. This will allow robot hands to perform stable human-like object grasping and manipulation and will also provide an open architecture which has the potential to introduce human brain (EEG/MRI signals) and human muscles (EMG signals) information into robotic hand systems.4) To validate the proposed algorithms by implementing these into a set of defined scenarios with a set of simulated multifingered robot hands and three different types of physical robot hands.</gtr:abstractText><gtr:fund><gtr:end>2013-09-14</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-03-15</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>284221</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Tokyo Metropolitan University</gtr:collaboratingOrganisation><gtr:country>Japan</gtr:country><gtr:description>Collaboration with Prof. Naoyuki Kubota</gtr:description><gtr:id>EBF0988C-8A23-4EB5-8BB0-931B1CA4A42B</gtr:id><gtr:impact>The outcomes include papers published in conferences and journals, co-organised special sessions in international conferences and co-authored books.</gtr:impact><gtr:outcomeId>56d9b424ecee79.80942672-1</gtr:outcomeId><gtr:partnerContribution>Contributed a robotic hand to this research to evaluate and test the developed software package.</gtr:partnerContribution><gtr:piContribution>Provided a software package to control the robotic hand using learned human hand manipulation skills.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Shanghai Jiao Tong University</gtr:collaboratingOrganisation><gtr:country>China, People's Republic of</gtr:country><gtr:description>Collaboration with Prof. Xiangyang Zhu</gtr:description><gtr:id>EF463D35-D7A9-406A-8DA7-D760B477166A</gtr:id><gtr:impact>The outcomes include papers published in conferences and journals, co-organised special sessions in international conferences and co-authored books.</gtr:impact><gtr:outcomeId>56d9b294000e58.66738162-1</gtr:outcomeId><gtr:partnerContribution>Contributed a prosthetic hand (SJTU hand) to this research to evaluate the developed software package.</gtr:partnerContribution><gtr:piContribution>Provided a software package to control the prosthetic hand using learned human hand manipulation skills.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>IEEE Transaction on Industrial Electronics Journal Issue on Intelligent Systems</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>1A78D118-7E89-4444-9002-F6AA304762B4</gtr:id><gtr:impact>This special journal issue is to overview the state of the art in intelligent systems, it disseminates the EPSRC grant outcomes significantly.

During the journal issue preparation and review, details on call for papers, etc. have been well published in research communities and networks.

After the special issue, the latest research findings were identified and used to plan future research directions.</gtr:impact><gtr:outcomeId>r-7575379859.2606370bceeaca</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://www.eng.auburn.edu/tie/ss09/Inteligent%20systems.pdf</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Organising HSI2015</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>580BBD22-2DE2-4170-B221-3417A7B88489</gtr:id><gtr:impact>The grant holder organized 8TH INTERNATIONAL CONFERENCE ON HUMAN SYSTEM INTERACTION 2015 in Poland as one of general chairs. HSI is one of leading conference on human system interaction, which effectively improves this project impact and strengthens the outputs.</gtr:impact><gtr:outcomeId>56d9bcf8afc636.79398870</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.ieeesmc.org/conferences/calendar/event/232-8th-international-conference-on-intelligent-robots-and-applications-ic</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Organizing ICIRA2015 in Portsmouth</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C5492A00-5DF8-41DD-8E46-1ED776B08C56</gtr:id><gtr:impact>The grant holder organized 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND APPLICATIONS 2015 in Portsmouth as a general chair. ICIRA is one of leading conference on intelligent robotic systems and applications, which effectively improves this project impact and strengthens the outputs.</gtr:impact><gtr:outcomeId>56d9bb95560991.98773903</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.ieeesmc.org/conferences/calendar/event/232-8th-international-conference-on-intelligent-robots-and-applications-ic</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Special Session in ROMAN 2015</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>7EE4A06E-15E8-4E01-8CAC-817AD38C1368</gtr:id><gtr:impact>The grant holder organised a Special Session on Cognitive Robotics at the 24th International Symposium on Robot and Human Interactive Communication, which is a significant contribution of the grant holder to disseminate/communicate this grant outcomes.</gtr:impact><gtr:outcomeId>56d9b964d3aba6.64283124</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=43931</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Special Session in SMC2015</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>DBF998B5-9A1C-4AB5-98D5-C594B8FB2AAA</gtr:id><gtr:impact>The grant holder has been invited to give a conference special session in the annual conference of IEEE SMC society. This is a significant contribution of the grant holder to disseminate/communicate this grant outcomes.

IEEE-SMC is the leading conference in human machine systems, it's one of best venues to effectively deliver this project outcome and communication.</gtr:impact><gtr:outcomeId>56d9b8bb21c149.16536322</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.smc2015.org/sites/default/files/B20_cfp.pdf</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>IEEE Transactions on Industrial Informatics Speical Issue on Intelligent Video Systems</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A262720D-CC75-4FEC-88A3-CC6AD4AF26E3</gtr:id><gtr:impact>This journal issue overviews the state of the art in intelligent video systems, it has significant impact in terms of disseminating the EPSRC grant outcomes.

During the special journal issue preparation and review process, lots of call for papers and communications have been delivered to our research communities.

The state-of-the-art and future challenges of the Intelligent Video Systems have been identified and highlighted, on which future related research plan will be based.</gtr:impact><gtr:outcomeId>r-4395420825.477150bca3318</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133476</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We have developed a multi-modal system integrating pressure, position, haptics sensors for hand motion analysis. This system outcome has demonstrate the research outcome is significant, it has been used to capture standard datasets.

This system integrates pressure, position and haptics sensors, it provide a unified platform for analyzing hand motion. It's been used to capture standard datasets for hand related algorithms development.

Beneficiaries: Academic, industrial practitioners and algorithm developer.

Contribution Method: This multi-modal system integrating pressure, position, haptics sensors for hand motion analysis, providing standard datasets for algorithms development in the world.

We have developed a portable 16-Channell EMG system. This system has integrated our developed Gaussian mixture models, it provide many advantages including portability, high accuracy and flexibility.

This device can be used for measuring EMG-based hand manipulation gestures and tasks. Unlike existing devices, this equipment can capture EMG-based hand gestures at a higher accuracy.

Beneficiaries: Academic, amputees, stroke patients, and the elderly people

Contribution Method: To our best knowledge, this device is the first one which can measure EMG-based hand gestures and manipulation at such a high accuracy. The hardware design and integrated algorithms will have a significant impact on related research.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>46FC59BB-CD67-46BD-BAA3-A98E80F540A5</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>m-957228877.5418222de251388</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Electronics,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The investigation has achieved significant outcomes, which are provided according to the grant's objectives. 1) Fuzzy Gaussian Mixture Models have been provided to generate a series of responsive human-like finger gaits for a robotic hand given an object to manipulate. This enables a robotic hand the capability to iteratively build a knowledge base representing the features of human hand manipulation behaviour and to efficiently provide corresponding robot hand gaits and manipulation strategies for a given manipulation task in a human environment.2) Gaussian mixture models are employed to develop feasible friction models for the interaction of objects and a robot/human hand. This enables the application of existing mathematical research findings in multifingered robot manipulation to realworld applications in human environments and will integrate related methods in engineering and AI domains. 3) An AI-based control architecture is developed to ensure robust object manipulation of multifingered robots in terms of manipulation feasibility and efficiency. This allows robot hands to perform stable human-like object grasping and manipulation and will also provide an open architecture which has the potential to introduce human brain (EEG/MRI signals) and human muscles (EMG signals) information into robotic hand systems.4) the proposed algorithms are partially validated by implementing these into a set of defined scenarios with a set of simulated multifingered robot hands and three different types of physical robot hands.</gtr:description><gtr:exploitationPathways>There are two ways: a) through commercial prosthetic hand companies, they transfer our technology to products or integrate to their existing products. There are two companies interested in this, they are Touch Bionics Ltd., UK, and Danyang Prosthesis Ltd. China; and there are two Universities who plan to employ our algorithms and approaches into their multi-fingered robotic hand systems, they are Shanghai Jiao Tong University, China, and Tokyo Metropolitan University, Japan. b) We currently discuss with Portsmouth University to set up a spin-out company to sell our technology/product. We have employed four ways to exploit the project outcomes: a) publish the project outcomes in peer-reviewed leading journals; b) organise international conferences or workshop to disseminate our project outcomes; c) organise leading journal special issues to overview the state of the art to attract more related researchers to our project outcomes; d) work closely with our collaborators so that they will maximise our project outcomes; e)work with potential industrial partners to seek for opportunity of transferring our technology to commercial products.</gtr:exploitationPathways><gtr:id>49047565-66A2-460F-9E1B-2A11A41F3A59</gtr:id><gtr:outcomeId>r-8277671940.8833177764adf4</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Electronics,Healthcare</gtr:sector></gtr:sectors><gtr:url>https://liuh.myweb.port.ac.uk/Projects.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>In order to study and analyse human hand motions which contain multimodal information, a generalised framework integrating multiple sensors is proposed and consists of modules of sensor integration, signal preprocessing, correlation study of sensory information and motion intention identification. Three types of sensors are integrated to simultaneously capture the finger angle trajectories, the hand contact forces and the forearm electromyography (EMG) signals.</gtr:description><gtr:id>127538DD-4F01-4C8A-BCD7-3BF68B97F995</gtr:id><gtr:impact>The proposed framework integrating the state- of-the-art sensor technology with the developed algorithms provides researchers a versatile and adaptable platform for human hand motion analysis and has potential applications especially in robotic hand or prosthetic hand control and Human Computer Interaction (HCI).</gtr:impact><gtr:outcomeId>546e26556fc649.50059655</gtr:outcomeId><gtr:title>A Multi-Modal System for Human Hand Motion Analysis</gtr:title><gtr:type>Systems, Materials &amp; Instrumental Engineering</gtr:type><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>A custom-made sEMG sleeve system omitting the stage of muscle positioning is utilised to capture the sEMG signal on the forearm. A mathematic model for muscle activation extraction is established to describe the relationship between finger pinch forces and sEMG signal, where the genetic algorithm is employed to optimise the coefficients.</gtr:description><gtr:id>BE71981E-F01F-4925-9D1E-EF64BB9F7B76</gtr:id><gtr:impact>Based on this system, experimental results demonstrates that: 1) There is a systematical relationship between muscle activations and the pinch finger forces. 2) To estimate the finger force, muscle precise positioning for electrodes placement is not inevitable. 3) In a multi-channel EMG system, selecting specific combinations of several channels can improve the estimation accuracy for specific gestures.</gtr:impact><gtr:outcomeId>546e275f623c73.33210338</gtr:outcomeId><gtr:title>Portable Multi-Channel EMG Capture System</gtr:title><gtr:type>Systems, Materials &amp; Instrumental Engineering</gtr:type><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>2340EF6C-A2DD-4763-A3B1-35755D02F13C</gtr:id><gtr:title>Surface EMG signals determinism analysis based on recurrence plot for hand grasps</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6c3022949a7cf59e73c04f9544f03467"><gtr:id>6c3022949a7cf59e73c04f9544f03467</gtr:id><gtr:otherNames>Ouyang G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1488-6</gtr:isbn><gtr:outcomeId>doi_53d0590597261aa3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3523F7E0-889C-4C3E-B7B2-9476718770C5</gtr:id><gtr:title>A Multichannel Surface EMG System for Hand Motion Recognition</gtr:title><gtr:parentPublicationTitle>International Journal of Humanoid Robotics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a2f0b29e2f955d2b9297e508053e8bff"><gtr:id>a2f0b29e2f955d2b9297e508053e8bff</gtr:id><gtr:otherNames>Fang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d9874b3b0f13.62192097</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0586DA9E-00E3-4421-8AAE-8C29C843FFD2</gtr:id><gtr:title>A Unified Fuzzy Framework for Human-Hand Motion Recognition</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Fuzzy Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a35983e4e98023370f9717e3f34cfc67"><gtr:id>a35983e4e98023370f9717e3f34cfc67</gtr:id><gtr:otherNames>Zhaojie Ju</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d05d05dd60cfb0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>41B9A85B-A963-41D1-8BE5-0C5789D0C136</gtr:id><gtr:title>Advances in View-Invariant Human Motion Analysis: A Review</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/daaaad62c1c8dffa1a5a5e15a558ba46"><gtr:id>daaaad62c1c8dffa1a5a5e15a558ba46</gtr:id><gtr:otherNames>Xiaofei Ji</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d05f05f847324c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94B54057-ED41-4856-ABF3-34A61B326B5D</gtr:id><gtr:title>Human action categorization using Conditional Random Field</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8db5e45b76ddc3e40438e2c04b30cb1a"><gtr:id>8db5e45b76ddc3e40438e2c04b30cb1a</gtr:id><gtr:otherNames>Wang J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4244-9885-7</gtr:isbn><gtr:outcomeId>doi_53d05c05c39c78c6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A43FC4DB-D0BE-4C2C-8E55-8406A97FB99C</gtr:id><gtr:title>Multiple classifier system with sensitivity based dynamic weighting fusion for hand gesture recognition</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e65d7667a209da5370c0162bc79874f"><gtr:id>1e65d7667a209da5370c0162bc79874f</gtr:id><gtr:otherNames>Huang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b7fa78304547.23542180</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>95F3E756-941B-4EBA-8F78-6B5DE28805F9</gtr:id><gtr:title>Human Hand Motion Analysis With Multisensory Information</gtr:title><gtr:parentPublicationTitle>IEEE/ASME Transactions on Mechatronics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546e146e989cf7.77698331</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DD589A78-F09A-42CF-8918-9AB4F8A5DCDE</gtr:id><gtr:title>A novel approach to extract hand gesture feature in depth images</gtr:title><gtr:parentPublicationTitle>Multimedia Tools and Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d988f7b71d25.37423478</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B9E96AF7-220B-4A28-9ABF-2DC2AC8DFD5E</gtr:id><gtr:title>Hand motion recognition via fuzzy active curve axis Gaussian mixture models: A comparative study</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4244-7315-1</gtr:isbn><gtr:outcomeId>546e146ebdffd6.18950083</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CD364E88-FAF8-4A9E-AEC6-87C155521045</gtr:id><gtr:title>Multimodal Human Hand Motion Sensing and Analysis -A Review</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Cognitive and Developmental Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d8b0a4cb089c62296d5fae9df471f36d"><gtr:id>d8b0a4cb089c62296d5fae9df471f36d</gtr:id><gtr:otherNames>Xue Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a796f8f3b0166.57671693</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>58B41E44-D341-420E-B979-B99FEF1F48B4</gtr:id><gtr:title>Intelligent control model and its simulation of flue temperature in coke oven</gtr:title><gtr:parentPublicationTitle>Discrete and Continuous Dynamical Systems - Series S</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b9b8f6134f2dda035c13e759d60eac1e"><gtr:id>b9b8f6134f2dda035c13e759d60eac1e</gtr:id><gtr:otherNames>Liu H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58b7fafe788550.60990683</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8E000F31-C535-4B41-9EA1-DB902E8C9382</gtr:id><gtr:title>Multiple Sensors Based Hand Motion Recognition Using Adaptive Directed Acyclic Graph</gtr:title><gtr:parentPublicationTitle>Applied Sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d8b0a4cb089c62296d5fae9df471f36d"><gtr:id>d8b0a4cb089c62296d5fae9df471f36d</gtr:id><gtr:otherNames>Xue Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a7970787b7705.90923738</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8701A0B6-5229-4149-AB4B-36DF197B1371</gtr:id><gtr:title>An Interactive Image Segmentation Method in Hand Gesture Recognition.</gtr:title><gtr:parentPublicationTitle>Sensors (Basel, Switzerland)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2ef91a6d242b3418b3065118aa4f2f60"><gtr:id>2ef91a6d242b3418b3065118aa4f2f60</gtr:id><gtr:otherNames>Chen D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1424-8220</gtr:issn><gtr:outcomeId>58b7f9a911c707.06262182</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2E6E77E9-7546-47DF-BC9B-DFB6D8CC612F</gtr:id><gtr:title>Time series modeling of surface EMG based hand manipulation identification via expectation maximization algorithm</gtr:title><gtr:parentPublicationTitle>Neurocomputing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0d79b292e8eb56ca2326c9e5e6cf91fc"><gtr:id>0d79b292e8eb56ca2326c9e5e6cf91fc</gtr:id><gtr:otherNames>Lu Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d9874b5cfc70.12062264</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3F0024CC-9899-4D60-8CE6-034AB1A48E99</gtr:id><gtr:title>Interface Prostheses With Classifier-Feedback-Based User Training.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on bio-medical engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a2f0b29e2f955d2b9297e508053e8bff"><gtr:id>a2f0b29e2f955d2b9297e508053e8bff</gtr:id><gtr:otherNames>Fang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0018-9294</gtr:issn><gtr:outcomeId>58b7fa77efbd67.16381503</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>18366A9F-2A51-444E-9CB2-59C575E9F4F7</gtr:id><gtr:title>Intelligent Computation in Grasping Control of Dexterous Robot Hand</gtr:title><gtr:parentPublicationTitle>Journal of Computational and Theoretical Nanoscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2669dc7e43b510cfb466af86c9a9f215"><gtr:id>2669dc7e43b510cfb466af86c9a9f215</gtr:id><gtr:otherNames>Ding W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58b7fafe43d136.10824266</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1FC1F9AC-BE59-4F8B-A715-E4279E427A3C</gtr:id><gtr:title>Featurefusion based object tracking for robot platforms</gtr:title><gtr:parentPublicationTitle>Industrial Robot: An International Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f0d10ae0b5fee7f7d7a790e1b961f1e4"><gtr:id>f0d10ae0b5fee7f7d7a790e1b961f1e4</gtr:id><gtr:otherNames>Zhang X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d055055e0eb273</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0F27010D-3188-4802-8E57-07ECAC4E42A3</gtr:id><gtr:title>Simultaneous Calibration: A Joint Optimization Approach for Multiple Kinect and External Cameras.</gtr:title><gtr:parentPublicationTitle>Sensors (Basel, Switzerland)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/924c851720af66fcbd29d896cd5c916a"><gtr:id>924c851720af66fcbd29d896cd5c916a</gtr:id><gtr:otherNames>Liao Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1424-8220</gtr:issn><gtr:outcomeId>5a797078d2d570.89383712</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>243B45AB-3BA9-459E-9E7C-6D77D7FCB80A</gtr:id><gtr:title>Frontiers of Intelligent Control and Information Processing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:isbn>978-981-4616-87-4</gtr:isbn><gtr:outcomeId>546e15b34fd190.07744312</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8D05470F-94E2-4BEA-9780-BDAC092D70CC</gtr:id><gtr:title>A New Wearable Ultrasound Muscle Activity Sensing System for Dexterous Prosthetic Control</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/79566a7f0cfa1db3f5bbd86349ee6b41"><gtr:id>79566a7f0cfa1db3f5bbd86349ee6b41</gtr:id><gtr:otherNames>Hettiarachchi N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d9874b831919.27173369</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>98CDD0C2-283C-43DF-B366-E03CF2AC05B6</gtr:id><gtr:title>FUZZY QUALITATIVE REASONING ABOUT DYNAMIC SYSTEMS CONTAINING TRIGONOMETRIC RELATIONSHIPS</gtr:title><gtr:parentPublicationTitle>International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b55dc821c2f80f754209ea4431008c8e"><gtr:id>b55dc821c2f80f754209ea4431008c8e</gtr:id><gtr:otherNames>COGHILL G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d072072e4679ea</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B298A616-A892-4740-8062-B14B86774A7D</gtr:id><gtr:title>Robot Intelligence</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/beac902e4bd22baec7fb17cc01343caa"><gtr:id>beac902e4bd22baec7fb17cc01343caa</gtr:id><gtr:otherNames>Liu, Honghai</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-84996-329-9</gtr:isbn><gtr:outcomeId>i_31603947833c081f6a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>203D14A2-2165-4FC4-8AD6-3D21D1130DFE</gtr:id><gtr:title>Human action recognition based on 3D SIFT and LDA model</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/234433c6a216c65c09fbc2a598bb3a8d"><gtr:id>234433c6a216c65c09fbc2a598bb3a8d</gtr:id><gtr:otherNames>Liu P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4244-9885-7</gtr:isbn><gtr:outcomeId>doi_53d05c05c39001be</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3ADFB5DD-DA26-4582-A8A1-896A6B9C0A82</gtr:id><gtr:title>Non-Invasive Stimulation-Based Tactile Sensation for Upper-Extremity Prosthesis: A Review</gtr:title><gtr:parentPublicationTitle>IEEE Sensors Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8ef586f0ee752b9a48fb0607626bbadf"><gtr:id>8ef586f0ee752b9a48fb0607626bbadf</gtr:id><gtr:otherNames>Li K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a79707849b538.41690952</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>16BFAF47-9465-49C7-875C-33F0F69993E0</gtr:id><gtr:title>Computational Analysis of Sparse Datasets for Fault Diagnosis in Large Tribological Mechanisms</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e4aad15969bf497e34d58ff6305e19c0"><gtr:id>e4aad15969bf497e34d58ff6305e19c0</gtr:id><gtr:otherNames>Morgan I</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_55f95d95d5b68288</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6D7DA335-53D9-4625-912E-A0248C9B8BDF</gtr:id><gtr:title>Surface EMG Based Hand Manipulation Identification Via Nonlinear Feature Extraction and Classification</gtr:title><gtr:parentPublicationTitle>IEEE Sensors Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546e146e706256.76487056</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A269125A-0A37-4075-ABA1-742DEE46A35C</gtr:id><gtr:title>Fuzzy Gaussian Mixture Models</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d0040045163dc9</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>392225A3-BCB7-4A54-8D5A-E9553EEF647B</gtr:id><gtr:title>A generalised framework for analysing human hand motions based on multisensor information</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1507-4</gtr:isbn><gtr:outcomeId>doi_53d057057d39c816</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>97128863-9DFD-4B62-AE08-8EEA92B42A88</gtr:id><gtr:title>EMPIRICAL COPULA-BASED TEMPLATES TO RECOGNIZE SURFACE EMG SIGNALS OF HAND MOTIONS</gtr:title><gtr:parentPublicationTitle>International Journal of Humanoid Robotics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7e377add07a20a5e0303a07249941566"><gtr:id>7e377add07a20a5e0303a07249941566</gtr:id><gtr:otherNames>JU Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d072072fd3cb86</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1AEFBB75-8468-455F-AE73-B84D2F81F096</gtr:id><gtr:title>An Integrative Framework of Human Hand Gesture Segmentation for Human-Robot Interaction</gtr:title><gtr:parentPublicationTitle>IEEE Systems Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3789758e4aed9cc3d4028e0df892ad9d"><gtr:id>3789758e4aed9cc3d4028e0df892ad9d</gtr:id><gtr:otherNames>Ju Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>56d988f7d88187.60615401</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9B73731C-DA80-4708-9A2A-C6B539685CE7</gtr:id><gtr:title>Exploring Human Hand Capabilities Into Embedded Multifingered Object Manipulation</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Industrial Informatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b9b8f6134f2dda035c13e759d60eac1e"><gtr:id>b9b8f6134f2dda035c13e759d60eac1e</gtr:id><gtr:otherNames>Liu H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d05e05e267b7fd</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G041377/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>55</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>53F27348-198B-4AEF-A34B-8307067F507C</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Systems engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>21CE2EA6-E7A2-4406-A045-0DA7CA19B695</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Control Engineering</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>55</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>