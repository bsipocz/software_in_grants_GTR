<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C842A34F-18F7-454D-A259-FED802368496"><gtr:id>C842A34F-18F7-454D-A259-FED802368496</gtr:id><gtr:name>University of Leicester</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Leicester</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE1 7RH</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C842A34F-18F7-454D-A259-FED802368496"><gtr:id>C842A34F-18F7-454D-A259-FED802368496</gtr:id><gtr:name>University of Leicester</gtr:name><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Leicester</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE1 7RH</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/559FDBD3-5EE9-4309-AED9-8D65439A0700"><gtr:id>559FDBD3-5EE9-4309-AED9-8D65439A0700</gtr:id><gtr:firstName>Rodrigo</gtr:firstName><gtr:surname>Quian Quiroga</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD052254%2F1"><gtr:id>285E4E44-C1FF-4AAE-89BC-7646989BE0A3</gtr:id><gtr:title>Neural coding of visual inputs in the human medial temporal lobe</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D052254/1</gtr:grantReference><gtr:abstractText>Images captured by the retina are transmitted by neurons to primary visual areas in the occipital lobe. After several processing stages, this information is transmitted to the inferior temporal cortex and from there it projects to the medial temporal lobe (MTL). It is from here that the PI has been recording individual neurons responding to visual stimuli in collaboration with the laboratory of Itzhak Fried at the UCLA medical center. These recordings are from human patients suffering from epilepsy, which are implanted with intracranial electrodes in order to determine the seizure focus for possible surgical resection. Very recently it has been shown that a large proportion of MTL neurons respond to pictures of celebrities, familiar individuals, landmarks, and animals (Quian Quiroga et al., Nature 435: 1102-1107; 2005). Such responses were highly selective in the sense that each of these neurons responded only to very few pictures. In contrast to distributed codes in which information is represented implicitly by the specific distribution of firing activity in large populations of cells, these data are in agreement with the existence of an explicit representation in MTL. In other words, the identity of individuals or objects is represented by a small number of neurons and each of these neurons is 'explicitly' telling the identity of what is being seen.How much information is represented by a population of neurons can be quantified in an objective manner by reconstructing the stimulus from the patterns of responses of the neurons in question. Such reconstruction, or decoding, offers a valuable approach to understand how the brain extracts features and deciphers information encoded in the activity of population of neurons. Given the explicit representation found in MTL neurons, in order to get further insights on how percepts are represented in MTL, we plan to study whether it is possible to predict in each trial which picture was shown from the activity of simultaneously recorded MTL neurons. Such a study addresses directly the more general issue of how neurons in the brain represent visual information in humans. Besides performing conventional analysis, it is proposed to develop new methods to analyze this data. The activity of neurons in the vicinity of the implanted electrodes is reflected in spikes. Each electrode detects the spikes of all neurons in its surroundings and each neuron fires spikes of a given shape. In order to understand how these units encode information in the brain, it is mandatory to have a reliable way of detecting and sorting the spikes (i.e. separating the spikes from the different neurons based on their shapes). An automatic method has been developed by the PI for detection and sorting of spikes (Quian Quiroga et al, Neural Computation, 16: 1661-1687; 2004) and it is planned to further improve this algorithm. In particular, with finer tuning of parameters it may be possible to obtain more neurons in an automatic way. Moreover, further optimization of the algorithm can make it run faster and even on-line. It is expected that these improvements will be useful to other animal neurophysiology laboratories. In particular, this is important for other applications were automatic sorting is mandatory, such as the development of Brain Machine Interfaces and Neural Prosthesis (i.e. prosthetic devices guided directly by neural signals). The possibility of predicting visual inputs from the activity of neurons also depends on the algorithm used for decoding and what type of information is read-out by these algorithms for doing the predictions. In this respect, it is important to study the performance of different decoding algorithms and also to study what features of the neuronal responses are the most important for decoding.</gtr:abstractText><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>130160</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>51DE2128-642E-4A94-88C2-5A9A2BDE61F6</gtr:id><gtr:title>Postscript: About grandmother cells and Jennifer Aniston neurons.</gtr:title><gtr:parentPublicationTitle>Psychological Review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5f609bf8203db2ebe1f98da7632603c3"><gtr:id>5f609bf8203db2ebe1f98da7632603c3</gtr:id><gtr:otherNames>Quian Quiroga R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545a1bd6c3d605.61264377</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6DB8DD3D-C467-4AE7-B8A5-FF05EF86C3F0</gtr:id><gtr:title>Extracting information from neuronal populations: information theory and decoding approaches.</gtr:title><gtr:parentPublicationTitle>Nature reviews. Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5f609bf8203db2ebe1f98da7632603c3"><gtr:id>5f609bf8203db2ebe1f98da7632603c3</gtr:id><gtr:otherNames>Quian Quiroga R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1471-003X</gtr:issn><gtr:outcomeId>doi_53d028028ebc7c0f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B60E4BBE-0E78-4342-9228-F8911CEA989A</gtr:id><gtr:title>Human single-neuron responses at the threshold of conscious recognition.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e039b79af8723de3e7848cf914dd60e1"><gtr:id>e039b79af8723de3e7848cf914dd60e1</gtr:id><gtr:otherNames>Quiroga RQ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>doi_53d039039c618163</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>13C97697-0B39-41AE-A805-755AE0D80BB1</gtr:id><gtr:title>Sparse but not 'grandmother-cell' coding in the medial temporal lobe.</gtr:title><gtr:parentPublicationTitle>Trends in cognitive sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e039b79af8723de3e7848cf914dd60e1"><gtr:id>e039b79af8723de3e7848cf914dd60e1</gtr:id><gtr:otherNames>Quiroga RQ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1364-6613</gtr:issn><gtr:outcomeId>doi_53d00d00d553aa04</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6C7C2950-D699-4B9D-A8A0-96B64E4C811B</gtr:id><gtr:title>Latency and selectivity of single neurons indicate hierarchical processing in the human medial temporal lobe.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7b201accac019ff07c3346cf5a918da7"><gtr:id>7b201accac019ff07c3346cf5a918da7</gtr:id><gtr:otherNames>Mormann F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>doi_53d0820827f9b280</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A1AF03D5-AD38-4250-956B-C53DEAEED6E6</gtr:id><gtr:title>Explicit encoding of multimodal percepts by single neurons in the human brain.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5f609bf8203db2ebe1f98da7632603c3"><gtr:id>5f609bf8203db2ebe1f98da7632603c3</gtr:id><gtr:otherNames>Quian Quiroga R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>doi_53cfecfec09ceb3d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F469239E-C07E-40C0-87FD-03BDB5D3A2DB</gtr:id><gtr:title>Human medial temporal lobe neurons respond preferentially to personally relevant images.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cf679214c8592e47db778dfb51ac2e0c"><gtr:id>cf679214c8592e47db778dfb51ac2e0c</gtr:id><gtr:otherNames>Viskontas IV</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>096856C5B9E</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>345D7C13-5C8B-4FF2-814E-0710456AB395</gtr:id><gtr:title>Object selectivity of local field potentials and spikes in the macaque inferior temporal cortex.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/af6db53abedc8b546deb49aa4e6a79f5"><gtr:id>af6db53abedc8b546deb49aa4e6a79f5</gtr:id><gtr:otherNames>Kreiman G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn><gtr:outcomeId>doi_53d002002851bfac</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>959DC24E-9365-4D86-A621-AC5AFBE3EAFA</gtr:id><gtr:title>Decoding visual inputs from multiple neurons in the human temporal lobe.</gtr:title><gtr:parentPublicationTitle>Journal of neurophysiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e039b79af8723de3e7848cf914dd60e1"><gtr:id>e039b79af8723de3e7848cf914dd60e1</gtr:id><gtr:otherNames>Quiroga RQ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0022-3077</gtr:issn><gtr:outcomeId>doi_53d07607661b7d5f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BAD9DC13-B4CE-4924-AE46-0BEB195187DE</gtr:id><gtr:title>Realistic simulation of extracellular recordings.</gtr:title><gtr:parentPublicationTitle>Journal of neuroscience methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f1e799e493bfd0b79ade9ee78722c2ae"><gtr:id>f1e799e493bfd0b79ade9ee78722c2ae</gtr:id><gtr:otherNames>Martinez J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0165-0270</gtr:issn><gtr:outcomeId>doi_55f94f94f3b7de70</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>67A7AC87-57A4-4B1B-B1F7-F0A270F809B8</gtr:id><gtr:title>Selectivity and invariance for visual object perception</gtr:title><gtr:parentPublicationTitle>Frontiers in Bioscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3a2a8eef8e5bf78d3fca2ec83012eb69"><gtr:id>3a2a8eef8e5bf78d3fca2ec83012eb69</gtr:id><gtr:otherNames>Ison M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53d0850859086037</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>47FCDD9C-4315-4222-A2FD-2AC0475AD99B</gtr:id><gtr:title>Measuring sparseness in the brain: comment on Bowers (2009).</gtr:title><gtr:parentPublicationTitle>Psychological review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5f609bf8203db2ebe1f98da7632603c3"><gtr:id>5f609bf8203db2ebe1f98da7632603c3</gtr:id><gtr:otherNames>Quian Quiroga R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0033-295X</gtr:issn><gtr:outcomeId>545a1b84f15963.53719458</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>38D9B627-C3C8-42CE-B824-4A5F7E56409A</gtr:id><gtr:title>Single-neuron recordings in epileptic patients</gtr:title><gtr:parentPublicationTitle>Advances in Clinical Neuroscience and Rehabilitation.</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/48f1d6ee671e06a388c1468e6f755704"><gtr:id>48f1d6ee671e06a388c1468e6f755704</gtr:id><gtr:otherNames>Quian Quiroga, R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545a1e886d27e3.42977364</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D052254/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>