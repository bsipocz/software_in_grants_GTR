<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/215C8CB9-38B2-495F-89F4-21D4414B80C6"><gtr:id>215C8CB9-38B2-495F-89F4-21D4414B80C6</gtr:id><gtr:name>University of California, Berkeley</gtr:name><gtr:address><gtr:line1>University of California, Berkeley</gtr:line1><gtr:line2>191 University Hall</gtr:line2><gtr:postCode>CA 94720</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/092E63B3-B179-4B94-956F-1896588D7FF4"><gtr:id>092E63B3-B179-4B94-956F-1896588D7FF4</gtr:id><gtr:name>SRI International (inc)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8"><gtr:id>3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8</gtr:id><gtr:name>Stanford University</gtr:name><gtr:address><gtr:line1>450 Serra Mall</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/FC4B6823-4D70-494B-BEB4-B5BA76925C4C"><gtr:id>FC4B6823-4D70-494B-BEB4-B5BA76925C4C</gtr:id><gtr:name>59 Productions</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/E1C92180-A246-4DF9-9B1F-ECAD1F776205"><gtr:id>E1C92180-A246-4DF9-9B1F-ECAD1F776205</gtr:id><gtr:name>Fidelio Arts Ltd</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/F8DB4C15-7BB8-4ABC-8871-2FA2DA40FAB2"><gtr:id>F8DB4C15-7BB8-4ABC-8871-2FA2DA40FAB2</gtr:id><gtr:name>Middle East Technical University</gtr:name><gtr:address><gtr:line1>Middle East Technical University</gtr:line1><gtr:postCode>06800</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:department>Institute of Telecommunications</gtr:department><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/215C8CB9-38B2-495F-89F4-21D4414B80C6"><gtr:id>215C8CB9-38B2-495F-89F4-21D4414B80C6</gtr:id><gtr:name>University of California, Berkeley</gtr:name><gtr:address><gtr:line1>University of California, Berkeley</gtr:line1><gtr:line2>191 University Hall</gtr:line2><gtr:postCode>CA 94720</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/092E63B3-B179-4B94-956F-1896588D7FF4"><gtr:id>092E63B3-B179-4B94-956F-1896588D7FF4</gtr:id><gtr:name>SRI International (inc)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8"><gtr:id>3DF2F8DD-33A5-44A1-81D7-347A6C2FBDC8</gtr:id><gtr:name>Stanford University</gtr:name><gtr:address><gtr:line1>450 Serra Mall</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FC4B6823-4D70-494B-BEB4-B5BA76925C4C"><gtr:id>FC4B6823-4D70-494B-BEB4-B5BA76925C4C</gtr:id><gtr:name>59 Productions</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E1C92180-A246-4DF9-9B1F-ECAD1F776205"><gtr:id>E1C92180-A246-4DF9-9B1F-ECAD1F776205</gtr:id><gtr:name>Fidelio Arts Ltd</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F8DB4C15-7BB8-4ABC-8871-2FA2DA40FAB2"><gtr:id>F8DB4C15-7BB8-4ABC-8871-2FA2DA40FAB2</gtr:id><gtr:name>Middle East Technical University</gtr:name><gtr:address><gtr:line1>Middle East Technical University</gtr:line1><gtr:postCode>06800</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/00500CF2-BC27-44BF-B441-5E5A6308F5D6"><gtr:id>00500CF2-BC27-44BF-B441-5E5A6308F5D6</gtr:id><gtr:firstName>Zoran</gtr:firstName><gtr:surname>Cvetkovic</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FK034626%2F1"><gtr:id>7E7927CC-7A40-4D2F-A8F6-FF7B0BE385D9</gtr:id><gtr:title>Visits to University of California, Berkeley, Stanford University, and SRI International</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K034626/1</gtr:grantReference><gtr:abstractText>During his visit to the Department of Statistics, University of California, Berkeley, Prof. Cvetkovic will be hosted by Prof. Yu, in the Statistical Machine Learning group. He will be focusing on topics of the current activity of Prof. Yu's group, that can be broadly described as statistical machine learning theory, methodologies, and algorithms for solving high-dimensional data problems. Particular problems covered include sparse modelling (e.g. Lasso, compressed sensing), structured sparsity, analysis and methods for spectral clustering, and applications to data which come from a diverse range of interdisciplinary areas, ranging from neuroscience to social networks. During this visit, Prof. Cvetkovic and Prof. Yu will set forth directions for collaboration on problems in learning in high-dimensions, leading to a research grant proposal.

During his previous EPSRC project, EP/D053005/1, Prof. Cvetkovic in collaboration with Prof. Sollich, Department of Mathematics, King's College London, and Prof. Yu developed an unorthodox approach to robust speech recognition in high-dimensional spaces of acoustic waveforms of speech. Dr. Horacio Franco, Director of Speech Technology and Research Laboratory of SRI International, who in 2010 won a major DARPA award for solving the problem of the sensitivity of automatic speech recognition systems to additive noise, finds this approach groundbreaking and expresses a strong interest in exploring venues for collaboration.
The purpose of this visit would be to investigate ways in which the approach developed by Prof. Cvetkovic and his collaborators can be brought closer to practice and based on that investigate the directions of long-term collaboration and possible joint grant proposals between SRI International, King's College London, and UC Berkeley.

At King's College, Prof. Cvetkovic has commenced work on a new multichannel audio technology, supported by EPSRC grant EP/F001142/1. The project produced a considerable publication volume and patent portfolio. A visit to one of world leading centres for music and acoustics technologies, such as CCRMA, would be very beneficial for taking advantage of this gained momentum to penetrate the field, which is still a new application area for Prof. Cvetkovic, at a deeper level, expand its scope, establish collaborations, and inform future grant proposals. At CCRMA, Prof. Cvetkovic will be interacting primarily with Prof. Julius Smith, working on multichannel audio technologies, and other signal processing problems in audio and acoustics. A recent work of Prof. Cvetkovic complements a large volume of work of Prof. Smith on ultra fast rendition of multichannel audio using digital waveguide networks (DWNs). This is an area which is of a significant academic interest, requiring interdisciplinary approaches at the interface of signal processing, acoustics, psychoacoustic, and computer science, as well of a great relevance to virtual reality and gaming applications. While this would be the area of initial focus, at CCRMA there are several other ongoing projects which are closely related to Prof. Cvetkovic's research or research in the Institute of Telecommunications at King's (Mobile Phone Orchestra, Sound in Space, Music in Virtual Worlds), as well as projects which could provide valuable inspiration for possible collaborative projects between the Department of Music and the Institute of Telecommunications at King's and CCRMA (Sound Waves on the Internet for Real-time Echoes, and the Historical Recordings). Finally, most of the largest companies which are potential licensees of Prof. Cvetkovic'c audio technology, such as DTS, Dolby, Microsoft, are based on the west coast of the US. The presence of Prof. Cvetkovic at CCRMA would accelerate the exploration of licensing opportunities, as these and other relevant companies frequently visit CCRMA, and are situated in the Bay Area or not too far from it.</gtr:abstractText><gtr:potentialImpactText>Visit to the Department of Statistics, University of California, Berkeley

The main purpose of the visit of Prof. Cvetkovic to the Department of Statistics, University of California, Berkeley, is to study emerging information sciences techniques and thus facilitate his engagement in cutting edge research in this field. His subsequent research in this field is meant to have a significant theoretical component, and immediate beneficiaries of this work would be other researchers in signal processing, and statistics and applied probability -- two areas which EPSRC intends to increase its investments in.
 
The techniques for statistical inference and kernel methods which Prof. Cvetkovic will be focusing on at Berkeley are applicable to a broad and diverse types of data, from social networks to neuroscience, so many segments of science, industry and society would benefit from this work. One particular application which will be considered is cardiac arrhythmia detection and classification. The ultimate benefit of this work would be improved healthcare and societal well being, as ventricular fibrillation (VF) is a leading cause of death in the western world and existing methods for VF detection are not sufficiently reliable. Other beneficiaries include pharmaceutical companies which develop medications for treating different forms of arrhythmias, then biomedical equipment companies which manufacture defibrillators, and finally other researchers in biomedical signal processing, and pharmacology.

Another application which will be considered is automatic speech recognition. The approach developed by Prof. Cvetkovic and Prof. Sollich in collaboration with Prof. Yu is still very novel and original, so results of this work will be of interest to the research community working on speech recognition. Beneficiaries of practical speech recognition systems built around these ideas are discussed in the following.

Visit to Speech Technology and Research (STAR) Laboratory, SRI International

Automatic speech recognition plays an important role in a wide variety of applications, ranging from collecting military intelligence, through assisted living and medical record transcription, to various customer service systems. Beneficiaries therefore include the military, healthcare, and service industries. Reliable and accurate automatic speech recognition systems contribute towards improving national security, providing better healthcare and reducing its cost, and making the IT infrastructure function seamlessly while appearing invisible. This work therefore addresses several important challenges within Digital Economy, Healthcare, and Global Uncertainties themes, as defined by EPSRC. 

Visit to the Center for Computer Research in Music and Acoustics (CCRMA), Stanford University

The first and immediate line of beneficiaries of the work done during the visit to CCRMA are researches the fields of signal processing, music and acoustics technologies. Then companies producing systems for multichannel audio, including home stereo systems, game devices, and sound mixing consoles, make another line of direct beneficiaries. Through their products, people working in creative industries which involve sound recording, production and reproduction, will also benefit from this work. Finally, the ultimate beneficiary is the general public which will be able to enjoy superior audio quality at a lower price. Thus, the proposed activity will advance relevant science, it will lead to technological developments, which would have a positive impact on industry and commerce, and it will contribute towards enhancing the quality of life of general public.</gtr:potentialImpactText><gtr:fund><gtr:end>2014-03-03</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-03-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>21058</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>An immersive 3D audio-visual installation</gtr:description><gtr:id>71C16E99-1BC2-4B91-9D8A-C145F1202B4E</gtr:id><gtr:impact>Demonstration and first public display of the audio technology created on the projects funded by the associated awards.</gtr:impact><gtr:outcomeId>58c442cee7d608.33003887</gtr:outcomeId><gtr:title>Ouroboros</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://pantar.com/portfolio/ouroboros/</gtr:url><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Edinburgh</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Edinburgh</gtr:description><gtr:id>CA163158-FAD9-49C2-93B4-D7B7E6D52A7B</gtr:id><gtr:impact>Preparation of a joint grant proposal.</gtr:impact><gtr:outcomeId>58c43c2a8528f9.01505809-1</gtr:outcomeId><gtr:partnerContribution>Intellectual input.</gtr:partnerContribution><gtr:piContribution>Intellectual input.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>59 Productions</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>59 Productions</gtr:description><gtr:id>5D5C3CF7-DDC9-466C-88BC-82A444F883AC</gtr:id><gtr:impact>A multimedia art installation centred around a performance of pianist Yuja Wang.</gtr:impact><gtr:outcomeId>58c437c1e30635.62521559-1</gtr:outcomeId><gtr:partnerContribution>Design and production of a multimedia art installation centred around a performance of pianist Yuja Wang.</gtr:partnerContribution><gtr:piContribution>Soundscape design for a multimedia art installation centred around a performance of pianist Yuja Wang.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Surrey</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Institute of Sound Recording, University of Surrey</gtr:description><gtr:id>0A6BE780-0227-4915-84B2-CAEACA7BC2BB</gtr:id><gtr:impact>Joint publications, grant proposal, and further development and deployment of the audio technology developed with the relevant EPSRC project in art projects and installations.</gtr:impact><gtr:outcomeId>58b555bacc4450.99480605-1</gtr:outcomeId><gtr:partnerContribution>Expertise, intellectual input.</gtr:partnerContribution><gtr:piContribution>Expertise, intellectual input.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Fidelio Arts Ltd</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Fidelio Arts</gtr:description><gtr:id>D93FCC35-0CEB-4869-B5CC-D4D698244340</gtr:id><gtr:impact>A multimedia art installation centred around performance of Yuja Wang, a pianist represented by Fidelio Arts, presently one of leading classical pianists.</gtr:impact><gtr:outcomeId>58c436717118c6.94012466-1</gtr:outcomeId><gtr:partnerContribution>Organisation and management of the project, multimedia art installation centred around a performance of pianist Yuja Wang, including time of the pianist.</gtr:partnerContribution><gtr:piContribution>Soundscape design for a multimedia art installation centred around a performance of pianist Yuja Wang.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Middle East Technical University</gtr:collaboratingOrganisation><gtr:country>Turkey, Republic of</gtr:country><gtr:department>Institute of Marine Sciences</gtr:department><gtr:description>METU</gtr:description><gtr:id>01E31AA3-4CE8-4333-AB2B-7D9C71A37D30</gtr:id><gtr:impact>Joint publications. Development of the audio technology developed on the relevant EPSRC project and its deployment in art projects and installations.</gtr:impact><gtr:outcomeId>58b55715e9f0e2.97601595-1</gtr:outcomeId><gtr:partnerContribution>Expertise, intellectual.</gtr:partnerContribution><gtr:piContribution>Expertise, intellectual.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of California, Berkeley</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>UC Berkeley</gtr:description><gtr:id>2E07124E-B3CD-4FE9-A3A5-210152D6CA6E</gtr:id><gtr:impact>Two conference papers, and one journal paper.
A grant proposal on robust speech recognition is formulated jointly, in which UC Berkeley appears as a formal partner.
It is a collaborative project at the interface between signal processing, statistics, and machine learning, addressing a problem in speech technologies.</gtr:impact><gtr:outcomeId>545ce9f35a5544.88655193-1</gtr:outcomeId><gtr:partnerContribution>Collaboration on several joint publications, and on formulating a grant proposal to continue collaboration on robust speech recognition.
They also co-sponsored a visit of Prof. Cvetkovic in 2012, and were hosting him for 7 months in 2013.</gtr:partnerContribution><gtr:piContribution>Collaboration on several joint publications, and on formulating a grant proposal to continue collaboration on robust speech recognition.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2007-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Stanford University</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Stanford</gtr:description><gtr:id>BA218731-706F-4343-9109-183F7E0E2A24</gtr:id><gtr:impact>A joint tutorial on multichannel surround systems, to be presented at ICASSP 2015.
A joint paper to be submitted to AT&amp;amp;T Transactions on Audio, Speech, and Language Processing.</gtr:impact><gtr:outcomeId>545cf681164155.18924398-1</gtr:outcomeId><gtr:partnerContribution>Collaborative research.</gtr:partnerContribution><gtr:piContribution>Collaborative research.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>SRI International (inc)</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>SRI</gtr:description><gtr:id>F334D8DB-3B66-41D4-97E5-B40FCF682309</gtr:id><gtr:impact>We formulated a grant proposal, submitted to EPSRC, with SRI as a formal partner.
It is a multidisciplinary project involving signal processing, statistics, and machine learning, applied to a problem in speech technologies.</gtr:impact><gtr:outcomeId>545cec2196b142.67015921-1</gtr:outcomeId><gtr:partnerContribution>Exchange of ideas and technical discussions.
They were co-sponsoring one visit of Prof Cvetkovic in 2012,
and they were hosting him for 4 months (full or part time) at the lab in 2014.</gtr:partnerContribution><gtr:piContribution>Exchange of ideas and technical discussions.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>2015 Summer Science Exhibition of the Royal Society.</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0EA70C9F-F139-41B7-B54D-9D70D9A71E75</gtr:id><gtr:impact>Our scattering delay network (SDN) technology was showcased during the 2015 Summer Science Exhibition, the flagship event of the Royal Society for science communication to the public. The event, lasting a week, had an attendance of about 15,000 people, in addition to two gala nights with the fellows of the Royal Society. The demonstration was part of the stand &amp;quot;Sound Scape Interaction in a 3D World&amp;quot; organised by a consortium of european universities led by Imperial College London. The demonstration consisted of a rotating platform called &amp;quot;Sound Hunter&amp;quot;.
Visitors wore headphones while standing on the rotating platform and their task was to rotate the platform until a sound source auralised through the headphones was perceived to be in front of them. The SDN was used in cases where users choose to locate the sound source while in a reverberant room.</gtr:impact><gtr:outcomeId>56ddf84b8bb6e8.10131856</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://sse.royalsociety.org/2015</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>25800</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Cultural Institute Award</gtr:description><gtr:end>2017-06-02</gtr:end><gtr:fundingOrg>King's College London</gtr:fundingOrg><gtr:id>8C9F64E1-FA30-4ADA-A5F7-90D81BC619FF</gtr:id><gtr:outcomeId>58c440d95e4158.28132326</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>6000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Impact Acceleration Award</gtr:description><gtr:end>2016-06-02</gtr:end><gtr:fundingOrg>King's College London</gtr:fundingOrg><gtr:id>699AC34C-7E5C-4C0C-A749-E77BD7DE073F</gtr:id><gtr:outcomeId>58c4401acbdbd7.04824267</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-11-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This award was an Overseas Travel Grant. It's aim was to 
support visits of the PI to:
? Department of Statistics, University of California, Berkeley, for six months.
? Speech Technology &amp;amp; Research Laboratory, SRI International, for one month.
? Center for Computer Research in Music and Acoustics, Stanford University, for three months.
The objectives of these visits were to enable the PI to:
? establish and develop long-term collaborations with internationally leading centres of excellence,
?have a concentrated activity on studying new techniques at the interface of signal processing, statistical inference and machine learning,
? broaden the scope of his current research developed with recent EPSRC support and bring its results closer to practice,
? accelerate commercial exploitation of the intellectual property generated during EPSRC supported projects.
Each of the individual visits is intended to accomplish two or more of these objectives.

Considering the nature of the project, there are no key scientific findings, but all objectives have been met. An account of specific accomplishments is provided under section: RCUK Key Findings.</gtr:description><gtr:id>BC23C873-3B4B-488F-B013-958EDE7D2E3F</gtr:id><gtr:impactTypes/><gtr:outcomeId>545cc9ef65cb90.65040034</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>During his visit to UC Berkeley, the PI was hosted by Prof. Yu, in the Statistical Machine Learning group. He was focusing on the topics of the current activity of Prof. Yu's group, that can be broadly described as statistical machine learning theory, methodologies, and algorithms for solving high-dimensional data problems. Simultaneously, the PI was visiting weekly the speech group at ICSI, to keep abreast with developments in speech recognition; he and Prof. Yu had had a previous collaboration on speech recognition which they planned to continue and expand. 

At SRI, the PI was investigating ways in which the approach to robust automatic speech recognition, which he and his CoI developed within the project funded through EPSRC award EP/D053005/1, could be brought closer to practice, and based on that set forth the directions of long-term collaboration and possible joint grant proposals between SRI, King's College London, and UC Berkeley.

At CCRMA, the PI was working on multichannel audio technologies, and signal processing problems in audio and acoustics. The particular problem of initial focus were digital waveguide networks (DWN) for ultra fast real time rendition of multichannel audio. At CCRMA there are also several other ongoing projects which are closely related to PI's research, and these provided inspiration for collaborative research at the interface of (audio) signal processing and the humanities (e.g. reconstruction of acoustic spaces of historical venues), or music (composition with 3D sound effects), or even neuroscience (understanding neural mechanisms governing music perception).

The visit to UC Berkeley was very beneficial in terms of enabling the PI to gain a wider perspective, and where needed
in-depth knowledge, of state-of-the-art developments in statistical machine learning relevant to his work. The visit to UC Berkeley, including ICSI, and the visit to SRI, enabled setting forth directions of collaborative research on robust speech recognition. A grant proposal in this domain, with UC Berkeley and SRI as project partners, committing considerable resources, has been submitted to EPSRC.

Tangible outputs of the visit to Stanford, include a collaborative journal paper which will be submitted to IEEE Transactions on Audio, Speech, and Language Processing by the end of 2014, and a joint tutorial on multichannel surround sound systems, to be presented at ICASSP 2015.</gtr:description><gtr:exploitationPathways>The purpose of this award was to support PI's visits to UC Berkeley, SRI, and Stanford. The project is not expected to produce any findings, but rather aims to enable the PI to learn new techniques, and facilitate collaborations with international centres of excellence. These aims have been accomplished, and the collaborative research facilitated by this grant is likely to have impact several sectors, as indicated below.</gtr:exploitationPathways><gtr:id>FA62F50B-FBE4-499D-B8E9-6985BBDB8A8C</gtr:id><gtr:outcomeId>545cc6b492e8b0.79328356</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Creative Economy,Digital/Communication/Information Technologies (including Software),Electronics,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections,Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The iPhone app aims at delivering the auditory illusion of being in the middle of a virtual rectangular room. This is achieved by means of the scattering delay network (SDN) technology, together with binaural reproduction technique. The app is capable of simulating the acoustics of the room in real time thanks to the extremely low computational complexity of the SDN method, while at the same time delivering important perceptual cues in an accurate manner. The app uses the iPhone gyroscope in order to track the movement of the listener's head and adjusts the simulation accordingly.</gtr:description><gtr:id>2CCDBB0C-5D3E-4EC0-92AA-6E11D9D62D5E</gtr:id><gtr:impact>The app was sent to several companies to spur their interest in commercial exploitation of the intellectual property arising from relevant EPSRC projects. Dolby has made several visit to King's College and is presently evaluating our technology.</gtr:impact><gtr:outcomeId>56ddf9b4b10ec0.29290886</gtr:outcomeId><gtr:title>SDN iPhone app</gtr:title><gtr:type>Webtool/Application</gtr:type><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>80EF7ACA-D75D-4761-81A5-6FE5D0CDAE9C</gtr:id><gtr:title>Efficient Synthesis of Room Acoustics via Scattering Delay Networks</gtr:title><gtr:parentPublicationTitle>IEEE/ACM Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25a83866e70c5df5959c53997f0305da"><gtr:id>25a83866e70c5df5959c53997f0305da</gtr:id><gtr:otherNames>De Sena E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5675f5943600a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D954979A-7395-4FC1-9B99-EA3E10985B68</gtr:id><gtr:title>Perceptual Spatial Audio Recording, Simulation, and Rendering: An overview of spatial-audio techniques based on psychoacoustics</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b38284caf63d9387c109565e1f134718"><gtr:id>b38284caf63d9387c109565e1f134718</gtr:id><gtr:otherNames>Hacihabiboglu H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58b553069d4493.69196963</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K034626/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>