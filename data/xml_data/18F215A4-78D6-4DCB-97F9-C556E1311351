<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A673E710-CDD7-4BE2-B179-F00C522C38DF"><gtr:id>A673E710-CDD7-4BE2-B179-F00C522C38DF</gtr:id><gtr:name>National Key Laboratory of Cognitive Neuroscience and Learning, Beijing, China</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:department>Biomedical Science</gtr:department><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A673E710-CDD7-4BE2-B179-F00C522C38DF"><gtr:id>A673E710-CDD7-4BE2-B179-F00C522C38DF</gtr:id><gtr:name>National Key Laboratory of Cognitive Neuroscience and Learning, Beijing, China</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/398FA6C6-97BE-4912-9629-9497A0786A26"><gtr:id>398FA6C6-97BE-4912-9629-9497A0786A26</gtr:id><gtr:name>Cairn Research Ltd</gtr:name><gtr:address><gtr:line1>Graveney Road</gtr:line1><gtr:line4>Faversham</gtr:line4><gtr:line5>Kent</gtr:line5><gtr:postCode>ME13 8UP</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/A6FBA80C-02DC-450D-9DD7-35D4298D34BF"><gtr:id>A6FBA80C-02DC-450D-9DD7-35D4298D34BF</gtr:id><gtr:firstName>Mikko Ilmari</gtr:firstName><gtr:surname>Juusola</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM009564%2F1"><gtr:id>18F215A4-78D6-4DCB-97F9-C556E1311351</gtr:id><gtr:title>How early eye circuits process and present visual features</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M009564/1</gtr:grantReference><gtr:abstractText>From humans to fruit flies, the ability of resolve individual objects by their features and to link these features to a coherent precept of the world is crucial for visual behaviours and fitness of seeing animals. But it remains a mystery how information processing within the networks of nerve cells in the eyes make object recognition possible.

Eye circuits process and represent visual information as patterns. Some of these patterns are complex and allow the brain, for example, to recognize objects from different perspectives. It is not understood how the eyes/brains represent visual information as patterns, recognises those patterns, and then solves problems. However, it is likely that the underlying processes occur at the level of circuits, where neurons and their connections interact dynamically. 

These important questions have direct implications for how we understand neural mechanisms for object/pattern recognition, with obvious links to artificial visual systems, machine-learning and robotics. Yet remarkably, they can be particularly well studied in the simple eyes and brain of fruit fly, Drosophila. While fly and human eyes have a very different architecture, both eyes must somehow extract object features from visual scenes, and to link these neural representations to some form of internal activity &amp;quot;maps&amp;quot; to execute goal-oriented behaviours. Importantly, Drosophila has a hard-wired circuitry of known layout, genetic toolboxes for modifying connectivity, and allows monitoring of neural activity with scalable resolution during visual stimulation/behaviour. This would not be possible in human eyes/brain. 

We now wish to utilise new wiring diagrams, genetic, electrophysiological and optical imaging tools available for Drosophila and state of the art mathematical analysis to study neural mechanisms of object representation at the level of its eye microcircuits. Specifically, we are interested in uncovering what kind of processing strategies early visual circuits use to extract object features; how and why eye circuits separate and integrate the representations of object colour and shape ('what' information) from that of its location and motion ('where' information), and how these representations adapt when the same object is seen in different lighting conditions/backgrounds. This research plan aims to start identifying and quantifying the fundamental early neural mechanisms for object perception that are probably used in the nervous systems of seeing animals across the animal kingdom. 

The knowledge we gain from these studies will not only advance our understanding of how animals see but, because the basic underlying neural connectivity and synaptic mechanisms are so widely found in other sensory systems and in our brain, will provide new insight into many other, often clinically important processes in the nervous system. Thus, our results should be off great interest to academics and industry, seeking to understand biologically-inspired design for machine sensing; principles which are usually more robust, cheaper, smaller and more energy-efficient than conventional engineering concepts. In long term, the new knowledge from our experiments and modelling may even help to manufacture novel adaptive biochips and test their performance as sensory implants.</gtr:abstractText><gtr:technicalSummary>We wish to identify, analyse and model early synaptic mechanisms for processing and representing object features in the lamina/medulla circuits in the Drosophila eye. We shall use new wiring diagrams, electrophysiology, 2-photon imaging, modern genetics and mathematical analysis to quantify how: object 'what' (colour/texture/shape) and 'where' features (position/motion) are processed and represented by the lamina output neurones (L1-L5); analyse/model the neural/biophysical mechanisms responsible encoding these object features; elucidate the neural coding rules for early object feature representations.

This research will provide the experimental framework for building general theories about how visual information is sampled, processed, integrated and routed in the eye circuits. Such visual processes underpin many aspects of perception and behaviour of seeing animals, having obvious links to machine learning and robotics. Specifically, it is expected to advance neurosciences in three important ways: (i) Its results will provide new understanding to neural computations and circuit architecture behind early representation of visual objects and neural control of visual behaviours. (ii) It will generate new mathematical models and theories about how interactions between visual inputs and neural representations of object/event features, proving new insight to perception and ultimately to cognitive phenomena. (iii) it will generate new genetic fly models for monitoring and manipulating in vivo visual information processing in eye/brain circuits, and quantitative methods for analysing the recorded neural activity. These new results/methods/models/theories are expected to be very useful for hypothesis testing also in other neural systems, and could be of vital importance when designing the brain-machine interfaces of biomimetic prosthesis, such as artificial retinae.</gtr:technicalSummary><gtr:potentialImpactText>Ph.D. students/staff: the project participants will obtain broad training in systems neuroscience research, including: live-imaging, electrophysiology, animal behaviour, genetics, signal analysis, modelling and basic lab skills; improving their employability in academia/high-tech industry. We have successfully trained students/post-docs both for academia and industry: senior academics/research fellows, a senior EU patent officer, a project engineer in BMW, etc. in both UK and abroad. We also train biomedical science undergraduate/masters students in lab-based projects, and provide lab tours for new students entering the university - these experiences inspire students. The postdocs will further participate in specialist courses to learn generic research skills, and will have an opportunity to gain teaching experience. I also have given research skill workshops in my laboratory for advanced international students (EMBO-summer courses) and, by invitation lectured on several international graduate schools and specialist courses.

Pharmaceutical industry and health practitioners: Neural computations and organisations underpinning information processing are similar across species - from flies to humans, involving similar logical operations, produced by comparable parallelism, connectivity and neurotransmitters. Furthermore, the retina is extension of the brain proper, having stratified organisation for massively parallel processing. So the circuit computations that we aim to elucidate will have their counter-functions in the human nervous system. The generic characteristic of any nervous system is its robustness to resist alterations and damage. E.g., the first clear symptoms of Parkinson's disease appear only when over 90% dopaminergic neurones in substantia nigra have died. Until then, the nervous system could sufficiently reroute information using homeostatic gain changes and parallel pathways. The genetic silencing experiments that we shall perform in the fly eye parallel networks, combined with direct live-imaging of the neural activity changes that so result, will give us unprecedented window to quantify how circuits overcome damage by redistributing their processing between neural neighbours though reinforcement/regeneration of connections. The fly preparation refined for this study, thus, has potential future use for testing the impact of therapeutic drugs on circuits, affected by neurodegeneration/trauma, to improve the nation's health.

Engineers and system biologists: Our (BBSRC funded) seminal assumption-free method for extrapolating the rate of information transfer of any signalling system from finite data continues to have increasing impact on how neural information processing is understood and quantified. Using that method, we were also the first to demonstrate that in cortical circuits action potential waveforms carry information. In the current study, we shall expand its use to spatiotemporal neural information processing to gain insight on one central question in biological systems: how object recognition emerges from feedback and feedforward neural interactions. The results we will obtain could have potentially profound impacts on algorithm design in many bioengineering application, including robotics, pattern recognition, machine-vision and design of retinal implants/artificial visual systems.

General Public: We expect the public to be keen to learn about different aspects of our research, including: (1) the perceptual world of insects, which is very different from our own (flies can see much faster movements than us and detect polarised and UV images). (2) The contributions Drosophila, as a model organism, can make to our understanding of brain functions. At a more advanced level, our research is deemed to provide the most comprehensive explanation for information processing at early circuits of the compound eyes: it is taught at 2nd year level at our University/in international University courses.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-03-01</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2015-03-02</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>909913</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>National Key Laboratory of Cognitive Neuroscience and Learning, Beijing, China</gtr:collaboratingOrganisation><gtr:country>China, People's Republic of</gtr:country><gtr:description>PI of a new research laboratory in National Key Laboratory of Cognitive Neuroscience and Learning, Beijing, China</gtr:description><gtr:id>FBD3012A-65AD-4FC2-942A-9A5EDCB3CBCB</gtr:id><gtr:outcomeId>b95fdea8b95fdec6-1</gtr:outcomeId><gtr:piContribution>Minimum of 2 months/year to work on information processing in Drosophila visual system and in mammalian cortex in BNU, China. National Key Laboratory of Cognitive Neuroscience and Learning has provided me with a fully-equipped research laboratory, including fly facilities; three experimental rooms, two of which are electrically shielded for behavioural and electrophysiological studies; and office rooms for workers (currently funding 2 full-time technicians). Their total investment into my BNU laboratory already amounts to ~&amp;pound;100,000</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Organising &quot;Phototransduction 2016&quot; workshop in Sheffield</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>BF75CADD-98F5-4442-AC4A-1CA2ABF0F9E8</gtr:id><gtr:impact>~30 international leading researchers and ~30 post-doctoral scientists and Ph.D. students attended this 3-day workshop to present their latest results and discuss on future research challenges.</gtr:impact><gtr:outcomeId>586b7d57e5de29.04501145</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited research talk in Complex, University College London, UK.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>2438572D-27EC-4C38-A69E-DF9A3436F547</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards

Reinforcing excising research collaborations</gtr:impact><gtr:outcomeId>568e5cb3297a18.22717060</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>https://www.ucl.ac.uk/complex/events</gtr:url><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited research talk in University of Helsinki, Finland</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D61B7183-2DA1-4695-B7BC-110C3021B8D2</gtr:id><gtr:impact>talk sparked questions and discussion afterwards

Forming new international research collaborations</gtr:impact><gtr:outcomeId>568e59f97c6422.50245130</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>https://tuhat.halvi.helsinki.fi/portal/en/activities/hosted-academic-vis(6dc4101d-5d14-44a0-874c-f1f356ee4dbc).html</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited presentation in JFRC Conference: Insect Vision, Cells, Computation, and Behavior. Howard Hughes Medical Research Institute, Janelia Farm, USA</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>17608C3F-DF59-4DD0-8D3F-4837347E5DC5</gtr:id><gtr:impact>My presentation sparked many questions and lively discussion afterwards

Reinforcing international collaborations between my research group and Janelia farm scientists</gtr:impact><gtr:outcomeId>568e56f814c164.54765406</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>https://www.janelia.org/you-janelia/conferences/insect-vision-cells-computation-and-behavior-0</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk in a research symposium &quot;Information Processing in Sensory Systems&quot;. Organisation for Computational Neurosciences (CNS), Prague, Czech Republic.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>090BD9D1-D271-4C83-827A-570689077A54</gtr:id><gtr:impact>Talks sparked active discussion afterwards

Reinforcing excising international research collaborations</gtr:impact><gtr:outcomeId>568e5814c51640.51927328</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://www.bionet.ee.columbia.edu/workshops/cns/methods/2015/identification</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Foreign High-End Foreign Expert Talk; National Key Laboratory of Cognitive Neuroscience and Learning. Beijing Normal University (BNU), Beijing, China.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>810AE655-944E-44C2-A92C-BBE957E94B33</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards

Reinforcing my research collaboration in Beijing Normal University, China</gtr:impact><gtr:outcomeId>568e5b0e266f32.63268400</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://brain.bnu.edu.cn/cn/news/2015/0629/435.html</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>100000</gtr:amountPounds><gtr:country>Finland, Republic of</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>Research project grant/fellowship</gtr:description><gtr:end>2016-12-02</gtr:end><gtr:fundingOrg>Jane &amp; Aatos Erkko Foundation</gtr:fundingOrg><gtr:id>3DA4D1B3-5A79-4402-B979-1DC287EF9EA1</gtr:id><gtr:outcomeId>568e547e04de64.76361809</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>800000</gtr:amountPounds><gtr:country>China, People's Republic of</gtr:country><gtr:currCode>CNY</gtr:currCode><gtr:currCountryCode>China</gtr:currCountryCode><gtr:currLang>zh_CN</gtr:currLang><gtr:description>High End Foreign Expert Grant</gtr:description><gtr:end>2018-06-02</gtr:end><gtr:fundingOrg>State Administration of Foreign Experts Affairs</gtr:fundingOrg><gtr:id>0AD808A1-F65D-4F47-8CCE-A6FB9D5320C4</gtr:id><gtr:outcomeId>568e4e9a6cb434.79389762</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>900000</gtr:amountPounds><gtr:country>China, People's Republic of</gtr:country><gtr:currCode>CNY</gtr:currCode><gtr:currCountryCode>China</gtr:currCountryCode><gtr:currLang>zh_CN</gtr:currLang><gtr:description>Project research grant with international collaboration</gtr:description><gtr:end>2012-12-02</gtr:end><gtr:fundingOrg>National Science Foundation China</gtr:fundingOrg><gtr:id>D998DC0D-9BCD-4A40-9E2F-7F60733C1EC1</gtr:id><gtr:outcomeId>5420c5dd02a165.89709095</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2009-01-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Our recent findings (data and simulations) about neural mechanisms of visual information processing in the Drosophila eyes are now used in a new open source platform (NeuroKernel) for emulating the fruit fly brain (Columbia University, New York, USA):
http://neurokernel.github.io/

In General, discoveries from my laboratory are taught in relevant University courses worldwide; integrated into undergraduate lectures in Sheffield and likely in other institutions internationally.

Working with Cairn Research Ltd, I produced a Drosophila track-ball system with virtual reality displays. This commercial product is now operational in my Sheffield and Beijing laboratories, with units already sold to research institutes in Israel, China and USA (2013-15). [initial funding from my BBSRC Sparking Impact Award; BB/F012071/1]</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>4C08F689-E6EB-4058-AC1D-6A0942A54474</gtr:id><gtr:impactTypes><gtr:impactType>Cultural</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56b1cb9ee6b3a2.17726332</gtr:outcomeId><gtr:sector>Education,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We discovered and explained the neural mechanisms that provide the insect compound eyes hyperacute vision.

From humans to insects, animals with good vision, irrespective of their eye designs, view the world through saccadic/microsaccadic eye movements and gaze fixation. But why did evolution settle upon this general viewing strategy, and how does it affect the eyes' visual information sampling over space and in time?

It is known for long that fast visual adaptation causes perceptual fading during fixation and to see the world requires motion or self-motion: body, head and eye movements, which remove adaptation. On the other hand, fast eye movements should blur vision. Thus, it has remained an enigma whether or how information sampling by phototransduction biophysics is tuned to saccadic/microsaccadic visual behaviours to see the world better.

To study this, we devised new in vivo recording and stimulation methods for intracellular electrophysiology and high-speed video microscopy, which allowed us to present precisely controlled moving light stimuli to individual photoreceptors and to monitor how this shapes their receptive fields spatiotemporally. This approach was further complemented with fly genetics, extensive biophysical modelling, electron microscopy and fly behaviour.

Firstly, we found that the photoreceptors' information transfer is maximised for the sort of high-frequency saccadic light bursts, which would be experienced during normal eye/head/body movements. We worked out the details how this can be explained mechanistically using a biophysically-realistic mathematical model based on the stochastic phototransduction reactions inside 30,000 microvilli (sampling units), which form the photoreceptor's light-sensor - the rhabdomere.

Secondly, we found that photoreceptors resolve point-objects moving at saccadic speeds far better than what is predicted by the classic motion-blur models (of the compound eye optics). By using high-speed video-microscopy of photoreceptor rhabdomeres, intracellular recordings and mathematical modelling, we reveal the mechanisms relying this remarkable hyperacuity. We show that light changes evoke microsaccadic photoreceptor contractions - too fast to see with a naked eye - so that as moving point-objects enter a photoreceptor's field of view, the photoreceptor's receptive field is dynamically shifted and narrowed. 

We then demonstrated that this hyperacuity is exploited behaviourally in optomotor behaviour performance in a flight simulator system. Our results disprove the 100-year old dogma that visual acuity of compound eyes is optically limited by the photoreceptor spacing in neighbouring ommatidia. The results will change our understanding of how vision operates in insects and suggest that similar microsaccadic information sampling could assist vision in vertebrate retinae, delivering much-needed benchmark quantifications for future theoretical and experimental studies.</gtr:description><gtr:exploitationPathways>These discoveries could be used when designing and building high-resolution optical systems from low-resolution parts.</gtr:exploitationPathways><gtr:id>2E59106D-2AC0-425C-96BA-758C6D7CC31D</gtr:id><gtr:outcomeId>56b1cbb8641bf4.46963501</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Manufacturing, including Industrial Biotechology,Other</gtr:sector></gtr:sectors><gtr:url>http://biorxiv.org/content/early/2016/10/26/083691</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>I initiated a project and worked with Cairn Research Ltd UK to produce a Drosophila track-ball system with virtual reality displays (funded by BBSRC). This project was supported by: BBSRC Sparking Impact Award, UK (2013-2014), Mikko Juusola (PI), Cairn research UK (Industrial Partner), Industrial Collaborative project grant: Production of a Drosophila track-ball system with virtual reality displays, &amp;pound;20,000 (+ &amp;pound;20,000 in-kind contribution from Cairn Research Limited).</gtr:description><gtr:id>D7B28881-AB6A-4A97-8749-0B58819CA499</gtr:id><gtr:impact>This commercial product is ready and operational in my Sheffield and Beijing laboratories, with units (currently priced at &amp;pound;17,500) already been sold to leading research institutes in Europe, China and USA. After selling four units, my laboratory will receive a free track-ball system form Cairn Research.</gtr:impact><gtr:outcomeId>568e534be612e2.79248051</gtr:outcomeId><gtr:title>Drosophila trackball system with virtual reality displays</gtr:title><gtr:type>Physical Model/Kit</gtr:type><gtr:url>http://cognition.group.shef.ac.uk/research/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B605EBE5-CC56-4F0D-AF66-ADE59153B1CA</gtr:id><gtr:title>Random Photon Absorption Model Elucidates How Early Gain Control in Fly Photoreceptors Arises from Quantal Sampling.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/779e6157d0d4e9f5475bdb158e38eccf"><gtr:id>779e6157d0d4e9f5475bdb158e38eccf</gtr:id><gtr:otherNames>Song Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn><gtr:outcomeId>585d3d6dc9b6c2.56151004</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CD09CCB9-0643-4DB2-BA0F-5D8C6CEB6DF8</gtr:id><gtr:title>Microsaccadic sampling of moving image information provideshyperacute vision.</gtr:title><gtr:parentPublicationTitle>eLife</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/03207a5a2e36f1a388821fb6a1226fb8"><gtr:id>03207a5a2e36f1a388821fb6a1226fb8</gtr:id><gtr:otherNames>Juusola M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2050-084X</gtr:issn><gtr:outcomeId>5a2fce575ae240.09369596</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2DFF9D85-D26A-4FD6-AF57-CBBE5E846E3C</gtr:id><gtr:title>Electrophysiological Method for Recording Intracellular Voltage Responses of Drosophila Photoreceptors and Interneurons to Light Stimuli In Vivo.</gtr:title><gtr:parentPublicationTitle>Journal of visualized experiments : JoVE</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/03207a5a2e36f1a388821fb6a1226fb8"><gtr:id>03207a5a2e36f1a388821fb6a1226fb8</gtr:id><gtr:otherNames>Juusola M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1940-087X</gtr:issn><gtr:outcomeId>585d43446a9291.41497972</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>86103997-F1A5-4CD6-A8F1-8D34B95261F8</gtr:id><gtr:title>How a fly photoreceptor samples light information in time.</gtr:title><gtr:parentPublicationTitle>The Journal of physiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/03207a5a2e36f1a388821fb6a1226fb8"><gtr:id>03207a5a2e36f1a388821fb6a1226fb8</gtr:id><gtr:otherNames>Juusola M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0022-3751</gtr:issn><gtr:outcomeId>5a2fcdc5097534.31780268</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B5D885C6-F64B-4E46-BFD3-0AD20339267E</gtr:id><gtr:title>Modeling elucidates how refractory period can provide profound nonlinear gain control to graded potential neurons.</gtr:title><gtr:parentPublicationTitle>Physiological reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/779e6157d0d4e9f5475bdb158e38eccf"><gtr:id>779e6157d0d4e9f5475bdb158e38eccf</gtr:id><gtr:otherNames>Song Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2051-817X</gtr:issn><gtr:outcomeId>5a2fcc1c507b24.49485549</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4D0A7567-E838-4C38-A426-8C4D044A1A77</gtr:id><gtr:title>Phototransduction in Drosophila.</gtr:title><gtr:parentPublicationTitle>Current opinion in neurobiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e994e57eeba7fd24bf87b9c571b7c843"><gtr:id>e994e57eeba7fd24bf87b9c571b7c843</gtr:id><gtr:otherNames>Hardie RC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0959-4388</gtr:issn><gtr:outcomeId>568e4d0d951538.09063013</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B40FA965-B13D-4560-88C9-8AE433686FA6</gtr:id><gtr:title>Speed and sensitivity of phototransduction in Drosophila depend on degree of saturation of membrane phospholipids.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/92c46755c68b60f8615b50de3f75247b"><gtr:id>92c46755c68b60f8615b50de3f75247b</gtr:id><gtr:otherNames>Randall AS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>568e4d0d4d61f6.90506682</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CC737876-1D0F-4DAB-AD1F-62D29DEF024A</gtr:id><gtr:title>Fly Photoreceptors Encode Phase Congruency.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7a6c2f010321ace1378ad0308ba61baf"><gtr:id>7a6c2f010321ace1378ad0308ba61baf</gtr:id><gtr:otherNames>Friederich U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>585d3d571862e2.82831728</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EF6D7F91-FFCF-485F-A209-B4B2CD67B7FF</gtr:id><gtr:title>Evidence for Dynamic Network Regulation of Drosophila Photoreceptor Function from Mutants Lacking the Neurotransmitter Histamine.</gtr:title><gtr:parentPublicationTitle>Frontiers in neural circuits</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c993fa7477f7df81adcf8be24c8032fa"><gtr:id>c993fa7477f7df81adcf8be24c8032fa</gtr:id><gtr:otherNames>Dau A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1662-5110</gtr:issn><gtr:outcomeId>585d70bda157a3.13012788</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2A911955-ADA6-4C8D-ADC1-A8DEA3311931</gtr:id><gtr:title>Shining new light into the workings of photoreceptors and visual interneurons.</gtr:title><gtr:parentPublicationTitle>The Journal of physiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/779e6157d0d4e9f5475bdb158e38eccf"><gtr:id>779e6157d0d4e9f5475bdb158e38eccf</gtr:id><gtr:otherNames>Song Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0022-3751</gtr:issn><gtr:outcomeId>5a2fccb099ef26.52078855</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CC7C9531-0719-4439-8DB4-20ECDECF1634</gtr:id><gtr:title>A biomimetic fly photoreceptor model elucidates how stochastic adaptive quantal sampling provides a large dynamic range.</gtr:title><gtr:parentPublicationTitle>The Journal of physiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/779e6157d0d4e9f5475bdb158e38eccf"><gtr:id>779e6157d0d4e9f5475bdb158e38eccf</gtr:id><gtr:otherNames>Song Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0022-3751</gtr:issn><gtr:outcomeId>5a2fcd7635a900.97594946</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M009564/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>DEA11FBC-BEED-4EDD-890B-97D728462D26</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Mathematical sciences</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>FA8953A0-71F7-49B0-AC17-5CC7AECA6A83</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>3Rs</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E793F7FE-614C-4A45-83A0-BE79B172092C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal &amp; human physiology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>62309876-5C71-411C-B1A7-1B2907AFB5A8</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Statistics &amp; Appl. Probability</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>