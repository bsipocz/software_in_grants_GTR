<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:department>Physiology</gtr:department><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8B68569B-A669-48AF-9FF8-D2A2CDFCAD97"><gtr:id>8B68569B-A669-48AF-9FF8-D2A2CDFCAD97</gtr:id><gtr:firstName>Roy</gtr:firstName><gtr:otherNames>Dunbar</gtr:otherNames><gtr:surname>Patterson</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=G0500221"><gtr:id>186B814C-7BEE-4FCF-B0C8-50D97F37716C</gtr:id><gtr:title>Temporal processing in the auditory system: Separating the message from the carrier</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>G0500221</gtr:grantReference><gtr:abstractText>Professor Patterson has participated in the development of about 10 auditory warning systems which have provided the basis for national and international standards in aircraft, hospitals, and the railways. Four of the systems have been implemented and installed for use in civil helicopters, military helicopters, London?s fire stations and the safety handsets of railway maintenance staff. Prof. Patterson continues to give radio interviews on auditory warnings and he has served as the ?scientific authority? in videos prepared to promote acceptance of the new warning systems by railway maintenance crews and London?s fire crews. This year we are also hosting a special session on ?Size information in speech and animal calls? at a major international meeting to bring the implications of time-scale analysis to the attention of the larger scientific community. 
Our web site has become an increasingly important vehicle for contact with the wider community and for attracting students and staff. We provide a variety of educational materials including three software packages for auditory modeling. Over the past two years, the site has handled about 2500 successful requests per month.</gtr:abstractText><gtr:technicalSummary>When a child and an adult say the same word, it is only the message that is the same. The child has a smaller mouth and smaller vocal cords which vibrate faster and produce a higher pitch. As a result, the waveform carrying the message is quite different for the child. The fact that we hear the same message shows that the auditory system has mechanisms in the brain to adjust, or normalize, speech sounds for mouth size and pitch. These normalization mechanisms are crucial for extracting the message from the sound that carries it from speaker to listener. Moreover, the information that they extract about the size of the speaker and the pitch of the voice can be used in noisy environments to help the brain focus on the person you are trying to listen to and ignore other sources. Current speech recognition systems have spectrographic preprocessors that ignore the internal structure of speech, and make it impossible to perform normalization in the way the auditory system does. This is one of the main reasons why speech recognition systems and cochlear implants are so much less robust than human speech recognition in multi-source environments.
This new perspective on auditory processing arose when we discovered that physicists working in quantum mechanics had mathematical tools for describing the size information in natural sounds (time-scale analysis), and that the mathematics could be used to explain how the auditory system normalizes speech sounds and extracts the message from the carrier. The research in this proposal is designed to determine the algorithms that the auditory system uses to normalize everyday sounds like speech and music, and where the different stages of processing occur in the brain.</gtr:technicalSummary><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2005-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>457130</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>MRC Institute of Hearing Research</gtr:department><gtr:description>Brain imaging of auditory perception (MEG)</gtr:description><gtr:id>8386D924-87FE-447E-A38D-33A7A0D91506</gtr:id><gtr:impact>The collaboration led to a succession of papers, the latest of which are MPID 16464550, 16814971 and 17563235</gtr:impact><gtr:outcomeId>3FDF2ACBD2E-1</gtr:outcomeId><gtr:partnerContribution>They provided the brain imaging machine and technicians and participated fully in the design and running of the experiments.</gtr:partnerContribution><gtr:piContribution>We provided threoretical support and acoustic stimuli for brain imaging studies conducted at the University Hospital in Meunster Germany.</gtr:piContribution><gtr:sector>Public</gtr:sector></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>MRC Cognition and Brain Sciences Unit</gtr:department><gtr:description>Brain imaging of auditory perception (fMRI)</gtr:description><gtr:id>9D3A49DD-1C59-4A37-A33B-9B5E7182C481</gtr:id><gtr:impact>The most notable output was published papers, namely PMID 16504540, 19055501 and 19596043</gtr:impact><gtr:outcomeId>8A622AEDEE2-1</gtr:outcomeId><gtr:partnerContribution>They provided the brain imaging facilities, technical support and they participated fully in the design, execution and writing up of the papers.</gtr:partnerContribution><gtr:piContribution>We provided stimuli and theoretical support for brain imaging experiments on pitch perception and speech perception.</gtr:piContribution><gtr:sector>Public</gtr:sector></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C4C234FB-BB33-4771-A9DB-6CBEE08AFEBE</gtr:id><gtr:title>Comparison of the roex and gammachirp filters as representations of the auditory filter.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b2f6b04a1f1ac55b0db4316474efed8f"><gtr:id>b2f6b04a1f1ac55b0db4316474efed8f</gtr:id><gtr:otherNames>Unoki M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>585d4f02358cb7.81140684</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>02D18721-3A5A-4197-9AC9-69EDBB9F072E</gtr:id><gtr:title>Location and acoustic scale cues in concurrent speech recognition.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e39dbba487b07f45192952421d7c5f4"><gtr:id>4e39dbba487b07f45192952421d7c5f4</gtr:id><gtr:otherNames>Ives DT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>85EEEBA4_485EEEBA4_4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DD1C8EE1-89A0-47A4-9426-BE688841708F</gtr:id><gtr:title>Locating the initial stages of speech-sound processing in human temporal cortex.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/595a013be6a6b2b907d8b743ddc6e68c"><gtr:id>595a013be6a6b2b907d8b743ddc6e68c</gtr:id><gtr:otherNames>Uppenkamp S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>07A66DC3F13</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>917C6271-227B-4AE0-B638-5CF4B691E136</gtr:id><gtr:title>Progressive associative phonagnosia: a neuropsychological analysis.</gtr:title><gtr:parentPublicationTitle>Neuropsychologia</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da71aacde649c79908766aada3e56e48"><gtr:id>da71aacde649c79908766aada3e56e48</gtr:id><gtr:otherNames>Hailstone JC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0028-3932</gtr:issn><gtr:outcomeId>861A92AF705</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F53004FD-FB7D-4FEB-A741-189C4649A52A</gtr:id><gtr:title>The mutual roles of temporal glimpsing and vocal characteristics in cocktail-party listening.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e1887aaef069a2124e892824117bcb1"><gtr:id>1e1887aaef069a2124e892824117bcb1</gtr:id><gtr:otherNames>Vestergaard MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>pm_540e13fe13fc3adb8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>295773E0-DC50-4ACB-9A6C-209F0B294850</gtr:id><gtr:title>Auditory size-deviant detection in adults and newborn infants.</gtr:title><gtr:parentPublicationTitle>Biological psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e1887aaef069a2124e892824117bcb1"><gtr:id>1e1887aaef069a2124e892824117bcb1</gtr:id><gtr:otherNames>Vestergaard MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0301-0511</gtr:issn><gtr:outcomeId>248E7F5993E</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3D49660B-A0B8-4A78-B9CF-5A5474BFFBB7</gtr:id><gtr:title>The interaction of vocal characteristics and audibility in the recognition of concurrent syllables.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e1887aaef069a2124e892824117bcb1"><gtr:id>1e1887aaef069a2124e892824117bcb1</gtr:id><gtr:otherNames>Vestergaard MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>13AE6E9E218</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A02DED5D-EBC8-4BD4-89B1-9D86DF46782E</gtr:id><gtr:title>The processing and perception of size information in speech sounds.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/244f1088d52fa72e45bd5defda488335"><gtr:id>244f1088d52fa72e45bd5defda488335</gtr:id><gtr:otherNames>Smith DR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2005-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>585d4f503f3b34.95346608</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E863A365-AB6E-41F7-9DD3-44CB4B444A25</gtr:id><gtr:title>A Dynamic Compressive Gammachirp Auditory Filterbank.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on audio, speech, and language processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fb9108c6e32af72175b46536fb609f79"><gtr:id>fb9108c6e32af72175b46536fb609f79</gtr:id><gtr:otherNames>Irino T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1558-7916</gtr:issn><gtr:outcomeId>7CE388FEAAB</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BDC97D02-6FFD-430B-AA53-A19304EF361E</gtr:id><gtr:title>Discrimination of speaker size from syllable phrases.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e39dbba487b07f45192952421d7c5f4"><gtr:id>4e39dbba487b07f45192952421d7c5f4</gtr:id><gtr:otherNames>Ives DT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2005-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>585d4f4a8cdc12.28645368</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>89C9D2AB-377C-43FB-9DE0-AFFC5EAE07AB</gtr:id><gtr:title>Effects of voicing in the recognition of concurrent syllables.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e1887aaef069a2124e892824117bcb1"><gtr:id>1e1887aaef069a2124e892824117bcb1</gtr:id><gtr:otherNames>Vestergaard MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>702B0E88FAF</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>401D8B97-AE0E-4699-A35D-5FCC33AE115F</gtr:id><gtr:title>Discrimination of speaker sex and size when glottal-pulse rate and vocal-tract length are controlled.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/244f1088d52fa72e45bd5defda488335"><gtr:id>244f1088d52fa72e45bd5defda488335</gtr:id><gtr:otherNames>Smith DR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>47E23F34D76</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9683D88E-D245-48B2-B65E-444FB62EAA74</gtr:id><gtr:title>Evidence for early specialized processing of speech formant information in anterior and posterior human auditory cortex.</gtr:title><gtr:parentPublicationTitle>The European journal of neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0e577fa8d205be1d39ce885c7bff49bd"><gtr:id>0e577fa8d205be1d39ce885c7bff49bd</gtr:id><gtr:otherNames>Edmonds BA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0953-816X</gtr:issn><gtr:outcomeId>pm_540e13fe13fb41334</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FE341715-D508-4D25-BED2-2840E985AB5C</gtr:id><gtr:title>Tone sequences with conflicting fundamental pitch and timbre changes are heard differently by musicians and nonmusicians.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7868e7b9080251f86800f38349371de"><gtr:id>e7868e7b9080251f86800f38349371de</gtr:id><gtr:otherNames>Seither-Preisler A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>DD2C5979D64</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D2EE105C-2FD8-49DE-8456-17F41D475C50</gtr:id><gtr:title>Functional imaging of the auditory processing applied to speech sounds.</gtr:title><gtr:parentPublicationTitle>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7bd9fca9ec544e42f045b53293e27bd1"><gtr:id>7bd9fca9ec544e42f045b53293e27bd1</gtr:id><gtr:otherNames>Patterson RD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0962-8436</gtr:issn><gtr:outcomeId>CDCE8FBA285</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>57108B19-93D4-4028-8646-15C4D928B454</gtr:id><gtr:title>The interaction of glottal-pulse rate and vocal-tract length in judgements of speaker size, sex, and age.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/244f1088d52fa72e45bd5defda488335"><gtr:id>244f1088d52fa72e45bd5defda488335</gtr:id><gtr:otherNames>Smith DR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2005-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>585d4f4d784fb3.84951109</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>31DEA4EF-B10B-479A-AD90-6DFF27876A31</gtr:id><gtr:title>From noise to pitch: transient and sustained responses of the auditory evoked field.</gtr:title><gtr:parentPublicationTitle>Hearing research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7868e7b9080251f86800f38349371de"><gtr:id>e7868e7b9080251f86800f38349371de</gtr:id><gtr:otherNames>Seither-Preisler A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0378-5955</gtr:issn><gtr:outcomeId>F27CBBF895F</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>240B1E5D-888F-4585-927D-598C9FDB191F</gtr:id><gtr:title>A statistical, formant-pattern model for segregating vowel type and vocal-tract length in developmental formant data.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4ea7266b9d98424a687605344fb5c68c"><gtr:id>4ea7266b9d98424a687605344fb5c68c</gtr:id><gtr:otherNames>Turner RE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>C94E4AEE886</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2C27A11A-B62C-4826-96C7-6AAB60F821EE</gtr:id><gtr:title>Self-report outcome in new hearing-aid users: Longitudinal trends and relationships between subjective measures of benefit and satisfaction.</gtr:title><gtr:parentPublicationTitle>International journal of audiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e1887aaef069a2124e892824117bcb1"><gtr:id>1e1887aaef069a2124e892824117bcb1</gtr:id><gtr:otherNames>Vestergaard MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1499-2027</gtr:issn><gtr:outcomeId>63E99AD0AC8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11251E7A-5B3F-40CA-96D6-5A3A022CD2C2</gtr:id><gtr:title>Timbre-independent extraction of pitch in newborn infants.</gtr:title><gtr:parentPublicationTitle>Psychophysiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e25f60991d56ccba724e906b22220ce3"><gtr:id>e25f60991d56ccba724e906b22220ce3</gtr:id><gtr:otherNames>H?den GP</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0048-5772</gtr:issn><gtr:outcomeId>695F1E7A060</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>876A84CA-BB79-4EC1-BAD0-A00C528E87F7</gtr:id><gtr:title>Vocal-tract resonances as indexical cues in rhesus monkeys.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1cff62ebca82def42df79c982f765cd4"><gtr:id>1cff62ebca82def42df79c982f765cd4</gtr:id><gtr:otherNames>Ghazanfar AA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>1CF1CF8A21A</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AF0A0591-919A-49EF-90F5-D680DAB3665A</gtr:id><gtr:title>Neural representation of auditory size in the human voice and in sounds from other resonant sources.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e33cec1226c56bd4536afc176b195faa"><gtr:id>e33cec1226c56bd4536afc176b195faa</gtr:id><gtr:otherNames>von Kriegstein K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>E8F48538958</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FF8DA722-A41F-482A-8655-0016FF04DE65</gtr:id><gtr:title>The effect of temporal context on the sustained pitch response in human auditory cortex.</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/71fb969834470b9c2ddf9b7b5b10d4e0"><gtr:id>71fb969834470b9c2ddf9b7b5b10d4e0</gtr:id><gtr:otherNames>Gutschalk A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>B7F0B03AADF</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>507F36DB-189F-4333-AA74-DF30AB4C21C1</gtr:id><gtr:title>How the human brain recognizes speech in the context of changing speakers.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e33cec1226c56bd4536afc176b195faa"><gtr:id>e33cec1226c56bd4536afc176b195faa</gtr:id><gtr:otherNames>von Kriegstein K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn><gtr:outcomeId>DF66BE497EF</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D63ED42F-DA9B-46DF-B2F6-EAC98BFE6BDF</gtr:id><gtr:title>Evidence of pitch processing in the N100m component of the auditory evoked field.</gtr:title><gtr:parentPublicationTitle>Hearing research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7868e7b9080251f86800f38349371de"><gtr:id>e7868e7b9080251f86800f38349371de</gtr:id><gtr:otherNames>Seither-Preisler A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0378-5955</gtr:issn><gtr:outcomeId>9B8FC40FF79</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>72B28197-C31D-4A9E-9572-725FE8FDAA29</gtr:id><gtr:title>Pitch strength decreases as F0 and harmonic resolution increase in complex tones composed exclusively of high harmonics.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e39dbba487b07f45192952421d7c5f4"><gtr:id>4e39dbba487b07f45192952421d7c5f4</gtr:id><gtr:otherNames>Ives DT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>2947E98B412</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5DCC8381-4A9C-45B9-BC7A-B756DA7FC7E6</gtr:id><gtr:title>Processing the acoustic effect of size in speech sounds.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e33cec1226c56bd4536afc176b195faa"><gtr:id>e33cec1226c56bd4536afc176b195faa</gtr:id><gtr:otherNames>von Kriegstein K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>pm_540e13fe13f923143</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>93A850F9-DA7F-4451-864D-F34B106D0D74</gtr:id><gtr:title>Perception of acoustic scale and size in musical instrument sounds.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed5e918fce3ee31f1fb8c0bbf5be5f91"><gtr:id>ed5e918fce3ee31f1fb8c0bbf5be5f91</gtr:id><gtr:otherNames>van Dinther R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>585d4f1044dad5.21770856</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11F3943A-DAEC-468E-AB0A-6DB80551F742</gtr:id><gtr:title>Age-related difference in melodic pitch perception is probably mediated by temporal processing: empirical and computational evidence.</gtr:title><gtr:parentPublicationTitle>Ear and hearing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1383eb6a8575ba491a424a8afac42d34"><gtr:id>1383eb6a8575ba491a424a8afac42d34</gtr:id><gtr:otherNames>Russo FA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0196-0202</gtr:issn><gtr:outcomeId>pm_540e13fe13fd200d9</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E20ECDB2-5144-42C0-9190-A1F6D936CE75</gtr:id><gtr:title>Speech Segregation Using an Auditory Vocoder With Event-Synchronous Enhancements.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on audio, speech, and language processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fb9108c6e32af72175b46536fb609f79"><gtr:id>fb9108c6e32af72175b46536fb609f79</gtr:id><gtr:otherNames>Irino T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1558-7916</gtr:issn><gtr:outcomeId>2664EBF39DE</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>92ADE9D1-D4F6-4DB8-A070-CA9A5BDA8486</gtr:id><gtr:title>A neural mechanism for recognizing speech spoken by different speakers.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0fda45e43b8ece96a7ae5ed31a62595d"><gtr:id>0fda45e43b8ece96a7ae5ed31a62595d</gtr:id><gtr:otherNames>Kreitewolf J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>pm_540e140e1400e18f2</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">G0500221</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>5585DDA6-FCF6-4B64-8332-1BDFE62CE94E</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Ear</gtr:text></gtr:healthCategory><gtr:healthCategory><gtr:id>041997EB-CFD8-493D-B0F8-DFA35451D0BE</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Neurological</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>CF950C9A-DB16-4E23-8AEB-94548777BCA1</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>1.1  Normal biological development and functioning</gtr:text></gtr:researchActivity><gtr:researchActivity><gtr:id>12A0B409-0C29-4056-9092-2D86E44017F3</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>1.4  Methodologies and measurements</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>