<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Centre for Speech Tech Research-PPLS</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/BED7E282-7C13-4113-95C0-D4EDF526F0AF"><gtr:id>BED7E282-7C13-4113-95C0-D4EDF526F0AF</gtr:id><gtr:firstName>Matthew</gtr:firstName><gtr:otherNames>Peter</gtr:otherNames><gtr:surname>Aylett</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6E9EAE62-9ADC-4E84-B950-56966D646A8F"><gtr:id>6E9EAE62-9ADC-4E84-B950-56966D646A8F</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:surname>King</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD058139%2F1"><gtr:id>C6B9A8F1-3C11-4ECA-9E50-30A2A95DB7FB</gtr:id><gtr:title>Automatically-determined Unit Inventories for Unit Selection Text-to-Speech Synthesis</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D058139/1</gtr:grantReference><gtr:abstractText>Speech synthesis - the generation of speech by computer - is a key technology for mobile computing and telephone-based services. A recent development, called Unit selection speech synthesis has now improved the quality of the speech so much that it is often indistinguishable from natural speech.Unfortunately, the creation of new voices for this unit selection technology is very expensive because it is labour intensive and must be done by experts. This is preventing the use of the technology in many applications, such as the production of high quality speech synthesisers for languages spoken in less developed countries.We are proposing to develop methods that will make it much quicker and cheaper to create new voices for speech synthesisers and also allow non-experts to carry out this work.</gtr:abstractText><gtr:fund><gtr:end>2009-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>238470</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>The future of Languages - more than just words</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>326E363E-88CD-41BB-AD62-91A088FFB046</gtr:id><gtr:impact>A public lecture at the Public Library in Amsterdam, followed by a debate with an audience.

Interactions with the audience.</gtr:impact><gtr:outcomeId>545f6dbf8a2f28.04664057</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.clubofamsterdam.com/event.asp?contentid=854</gtr:url><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited public lecture: A survey of speech technology</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>301832C9-ADFD-49E0-946A-A80E2CEEEFA8</gtr:id><gtr:impact>Discussions with the audience


Follow up emails from members of the audience</gtr:impact><gtr:outcomeId>545f6e82a15719.69114559</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2009</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project succeeded in producing both statistical parametric and unit selection &amp;quot;emergent phone&amp;quot; systems. In addition we also created orthographic unit-based systems. These systems were evaluated against classical phone systems. A large number of techniques were evaluated for generating these systems and applied to the two main underlying problems that needed tobe solved namely:* Segmenting and categorising units of speech. * Generalising the expected units in unseen words from a database of s</gtr:description><gtr:id>2609A06D-17CD-4FC3-B5E3-F9E04E7702C7</gtr:id><gtr:outcomeId>r-3695073401.27143477970aa6</gtr:outcomeId><gtr:sectors/></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>A7846879-917F-4465-B26A-26446096F248</gtr:id><gtr:title>Unsupervised adaptation for HMM-based speech synthesis</gtr:title><gtr:parentPublicationTitle>Proc. Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/22ce4b2506b6f3bf65e487e3ca7ebf90"><gtr:id>22ce4b2506b6f3bf65e487e3ca7ebf90</gtr:id><gtr:otherNames> S King, K Tokuda, H Zen, J Tamagishi</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_47289995981404f196</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3A5BBD32-1190-4AC2-BBBD-396BCC230B04</gtr:id><gtr:title>Speech synthesis without a phone inventory</gtr:title><gtr:parentPublicationTitle>Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5408f0cfbda4d97e12bad46673fea0e8"><gtr:id>5408f0cfbda4d97e12bad46673fea0e8</gtr:id><gtr:otherNames> M Aylett</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_396048539713edb94a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5312AEBD-12E0-45EE-BBCF-A9A78A73CA9F</gtr:id><gtr:title>Combining Statistical Parameteric Speech Synthesis and Unit-Selection for Automatic Voice Cloning</gtr:title><gtr:parentPublicationTitle>Proc. LangTech 2008</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d5373b269a1d1a71090294bdf33ef2ed"><gtr:id>d5373b269a1d1a71090294bdf33ef2ed</gtr:id><gtr:otherNames> M Aylett and J Yamagishi</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_144175792813edb666</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E02FD9CE-4656-498D-A1F5-0027FE1470DA</gtr:id><gtr:title>Single Speaker Segmentation and Inventory Selection Using Dynamic Time Warping Self Organization and Joint Multigram Mapping</gtr:title><gtr:parentPublicationTitle>SSW06</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a761931577975437fb1cf159912d7488"><gtr:id>a761931577975437fb1cf159912d7488</gtr:id><gtr:otherNames> M Aylett and S KIng</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_707212972313edb710</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D058139/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>