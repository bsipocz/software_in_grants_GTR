<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/1085A47A-566B-423D-B2BB-41ECD918125A"><gtr:id>1085A47A-566B-423D-B2BB-41ECD918125A</gtr:id><gtr:name>South China University of Technology</gtr:name><gtr:address><gtr:line1>Guangzhou H.E. Mega Centre</gtr:line1><gtr:line2>Panyu District</gtr:line2><gtr:line4>Guangzhou</gtr:line4><gtr:line5>510006</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>China</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1085A47A-566B-423D-B2BB-41ECD918125A"><gtr:id>1085A47A-566B-423D-B2BB-41ECD918125A</gtr:id><gtr:name>South China University of Technology</gtr:name><gtr:address><gtr:line1>Guangzhou H.E. Mega Centre</gtr:line1><gtr:line2>Panyu District</gtr:line2><gtr:line4>Guangzhou</gtr:line4><gtr:line5>510006</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>China</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DDCA16B5-1844-4825-AF8F-D18E387891A7"><gtr:id>DDCA16B5-1844-4825-AF8F-D18E387891A7</gtr:id><gtr:name>Delcam International plc</gtr:name><gtr:address><gtr:line1>Talbot Way</gtr:line1><gtr:line2>Small Heath Business Park</gtr:line2><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B10 0HJ</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/74BFF899-2EA9-4F9F-87F0-710C4A58F8AE"><gtr:id>74BFF899-2EA9-4F9F-87F0-710C4A58F8AE</gtr:id><gtr:firstName>Xianfang</gtr:firstName><gtr:surname>Sun</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DDD13EB6-E292-413B-8892-3CEF4CFDFED6"><gtr:id>DDD13EB6-E292-413B-8892-3CEF4CFDFED6</gtr:id><gtr:firstName>Paul</gtr:firstName><gtr:surname>Rosin</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/CCFA3B48-16D1-482A-A2A0-368E4528C384"><gtr:id>CCFA3B48-16D1-482A-A2A0-368E4528C384</gtr:id><gtr:firstName>Ralph</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Martin</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ02211X%2F1"><gtr:id>37AA7551-93BF-46AE-9EA9-1B703AAE4E97</gtr:id><gtr:title>Robust and Sensitive Methods for Non-rigid and Partial 3D model Retrieval</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J02211X/1</gtr:grantReference><gtr:abstractText>3D models have a broad range of applications in many different areas such as engineering, biology, chemistry, medicine, entertainment and cultural heritage. Many 3D models are available from the Internet and other sources, resulting in a problem of how to effectively and efficiently find required 3D models (i.e., 3D model retrieval). Current research on 3D model retrieval mainly focuses on global rigid 3D model retrieval, and algorithms for solving this problem are not effective for non-rigid and partial 3D model retrieval. Because many 3D models of interest are non-rigid (such as humans, and mechanisms), and because it is often important to consider just parts of a 3D model (e.g. find a model with a particular connector), finding an efficient way to retrieve non-rigid and partial 3D models is a pressing and challenging problem. This project intends to develop robust and sensitive algorithms for non-rigid and partial 3D model retrieval.

A typical shape-based 3D model retrieval algorithm consists of three main steps: model preprocessing, feature/shape descriptor extraction, and feature/shape indexing and matching. This project will investigate all three steps and develop new non-rigid and partial 3D model retrieval algorithms based on novel techniques from other research areas. Set-membership estimation from control theory will be introduced into model preprocessing and feature/shape descriptor extraction. New machine learning methods, such as affinity propagation, manifold learning and ranking, will be explored for extracting features/shape descriptors, and for feature/shape indexing and matching. The N-gram model from natural language processing will be adapted to feature/shape indexing and matching. Other new techniques from image processing and computer vision will be investigated regarding their effectiveness for non-rigid and partial 3D model retrieval.

This project will also consider potential applications of the newly developed techniques. The 3D model retrieval algorithms will be evaluated jointly with Delcam plc with a view to commercial exploitation. A practical non-rigid and partial 3D model search engine will be developed and deployed on the Internet for public use.</gtr:abstractText><gtr:potentialImpactText>3D geometric models are widely used in many different areas, such as engineering, chemistry, biology, medicine, cultural heritage, and entertainment. The broad availability of 3D models from the Internet and other sources has stimulated interest in the development of effective 3D model search/retrieval techniques. This project aims to develop robust and sensitive algorithms for non-rigid and partial 3D model retrieval. It will be of benefit to both academia and business. In addition, it is also expected to be beneficial to the advance in medical science and cultural heritage protection.

In engineering, computer-aided design (CAD) uses digital models of 3D objects for design. When many models are available, it is inefficient to manually search for required 3D models. This project will develop effective 3D model retrieval algorithms which can help CAD designers to find CAD models quickly. The algorithms can also be combined into existing CAD software packages to enhance their functionality. The project is potentially beneficial to both CAD end users and CAD software developers. We will cooperate with Delcam, one of the world's leading CAD software suppliers, to explore potential applications of our algorithms in their CAD software.
 
In chemistry and molecular biology, molecules and proteins are modelled as 3D objects, for structural classification and drug design, etc. Currently, structure classification is largely manual work. Given that protein databases are usually large, automatic classification using protein geometric features becomes very important. In classifying different proteins, there is a need for deformable (non-rigid) or partial shape matching. The local feature extraction and matching methods developed in this project are thus potentially usable for protein structure classification. In drug design, it is necessary to search for and compare deformable 3D models within molecular reference databases, so that suitable drug molecular structures can be designed to cure specific diseases. The 3D model search engine developed in this project has the potential to be used for this purpose. 

In medical imaging applications, 3D volume data obtained by CT and MRI scans are currently used for diagnosis of organ deformations by matching actual images with medical databases of known deformations. Non-rigid 3D model retrieval algorithms are required since deformations are the prominent feature in these applications. 

Many cultural heritage objects, such as old buildings, statues, pottery, and ceramics are digitized as 3D models in order to preserve cultural heritage, and also to make it available to a wider public. 3D model matching can be used to find similar artefacts for research purposes, or to compare classes of objects. For example, given pots from an archaeological site, they can be compared to known examples in a database as a basis for determing their the age or origin. 

One of the most important application areas of non-rigid and partial 3D model retrieval is the field of entertainment. Animations in films or computer games need many non-rigid or part models of 3D characters for rendering. These models can be obtained from the Internet and 3D model manufacturers. However, 3D model databases are usually very large, and it is not easy to find specific 3D models from large databases. Our 3D search engines have the potential to save time for entertainment media production. 

Besides the above-mentioned applications, 3D model retrieval also has potential applications in virtual geography environments (VGE), 3D spatial terrain, and robotics.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-08-21</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-04-22</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>309946</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>South China University of Technology</gtr:collaboratingOrganisation><gtr:country>China, People's Republic of</gtr:country><gtr:description>Collaboration with SCUT</gtr:description><gtr:id>9FC459AC-E089-4B1A-9775-035A119786BC</gtr:id><gtr:impact>Joint proposal</gtr:impact><gtr:outcomeId>56b4cb7d0c9479.58166271-1</gtr:outcomeId><gtr:partnerContribution>We submitted a joint proposal to NSFC-RS Exchange Scheme</gtr:partnerContribution><gtr:piContribution>We submitted a joint proposal to NSFC-RS Exchange Scheme</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Royal Holloway, University of London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Computer Science</gtr:department><gtr:description>Collaboration with Hangzhou Dianzi University</gtr:description><gtr:id>41E0C55A-F863-4007-BCB3-426A1FD05B8F</gtr:id><gtr:impact>Z. Ji, W. Ma, and X. Sun (2014), Bas-Relief Modeling from Normal Images with Intuitive Styles, IEEE Transactions on Visualization and Computer Graphics, 20(5): 675-685.
Z. Ji, X. Sun, S. Li, and Y. Wang and (2014), Real-time Bas-Relief Generation from Depth-and-Normal Maps on GPU, Computer Graphics Forum, 33(5): 75-83</gtr:impact><gtr:outcomeId>56b4cccd9982f9.59839696-1</gtr:outcomeId><gtr:partnerContribution>Our research resulted in two Joint papers.</gtr:partnerContribution><gtr:piContribution>Our research resulted in two Joint papers.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>1) We created a benchmarking dataset for testing non-rigid 3D shape retrieval algorithms, one that is much more challenging than existing datasets. 
2) We presented a new benchmark for testing algorithms that create canonical forms for use in non-rigid 3D shape retrieval. 
3) We proposed a linear time complexity method for computing a canonical form of non-rigid 3D shape, using Euclidean distances between pairs of a small subset of vertices. 
4) We proposed some skeleton-based canonical forms for non-rigid 3D shape retrieval, which lead to computational speed-up, and reduced distortion of local shape detail.
5) We proposed a view-based feature matching method for partial Partial 3D shape retrieval.
6) We suggested that analogies can be an effective query method for searching for specific content in multimedia databases, including 3D shape retrieval.</gtr:description><gtr:exploitationPathways>The researchers in the area of non-rigid 3D shape retrieval can use our benchmark datasets to test their algorithms, and further develop new algorithms that are robust to noise and distortion, and sensitive to tiny feature changes. Researchers in multimedia retrieval area will find new ways of retrieval, i.e., using analogies. In general applications of non-rigid 3D shape retrieval, the proposed linear time complexity method for computing a canonical form of non-rigid 3D shape will help to speed up retrieval.</gtr:exploitationPathways><gtr:id>93B0830C-4079-4F51-9977-F02C8963A455</gtr:id><gtr:outcomeId>56d47ef468df59.79561437</gtr:outcomeId><gtr:sectors><gtr:sector>Chemicals,Creative Economy,Digital/Communication/Information Technologies (including Software),Manufacturing, including Industrial Biotechology,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>We have created a new benchmarking dataset for testing non-rigid 3D shape retrieval algorithms, one that is much more challenging than existing datasets. Our dataset features exclusively human models, in a variety of body shapes and poses.</gtr:description><gtr:id>D8C6DF37-B25A-43EA-8E7A-338AF46EEECE</gtr:id><gtr:impact>3D models of humans are commonly used within computer graphics and vision, and so the ability to distinguish between body shapes is an important shape retrieval problem. This dataset was submitted and accepted as a track of SHREC'14 - 3D Shape Retrieval Contest 2014. Nine groups from all over the world have submitted the results of a total of 22 different methods which have been tested on our new dataset. We published the testing results at EUROGRAPHICS 2014 - Workshop on 3D Object Retrieval.</gtr:impact><gtr:outcomeId>546091e136b459.16820335</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Non-Rigid 3D Human Models</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.cs.cf.ac.uk/shaperetrieval/shrec14/</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>This dataset was made by combining a selection of models from two existing databases. The two datasets are the SHREC'11 non-rigid dataset and the SHREC'14 non-rigid humans dataset.</gtr:description><gtr:id>86392452-CF38-4AAA-B259-CAF78C19866B</gtr:id><gtr:impact>This dataset was submitted and accepted as a track of SHREC'15 - 3D Shape Retrieval Contest 2015. Two groups attended the contest and tested on this dataset. We published the testing results at EUROGRAPHICS 2015 - Workshop on 3D Object Retrieval. We have invited more groups from all over the world to test this dataset and submit their results. We are expecting to publish the extended test results to International Journal of Computer Vision or Pattern Recognition.</gtr:impact><gtr:outcomeId>56b4c86c3a7e93.29365829</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Non-Rigid 3D Models for Canonical Form Contest</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.cs.cf.ac.uk/shaperetrieval/shrec15/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>009B837A-1280-4316-8F66-1581AC7282E6</gtr:id><gtr:title>Non-rigid 3D Shape Retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8ebb59a8f7cce0c19e45b21e53d39a72"><gtr:id>8ebb59a8f7cce0c19e45b21e53d39a72</gtr:id><gtr:otherNames>Lian Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>978-3-905674-78-1</gtr:isbn><gtr:outcomeId>56b4c39f0d0739.69734184</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E13A1762-1AA4-48B9-9074-4B142074D169</gtr:id><gtr:title>Real-time Bas-Relief Generation from Depth-and-Normal Maps on GPU</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7e168572fe61d95bdfdf8b3b03202e2d"><gtr:id>7e168572fe61d95bdfdf8b3b03202e2d</gtr:id><gtr:otherNames>Ji Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>541867b871bd23.33744971</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1E7B7465-147F-4FFD-B3C6-22D948D3290F</gtr:id><gtr:title>Euclidean-distance-based canonical forms for non-rigid 3D shape retrieval</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6739e11790d28c93d55c5eca3921fbd9"><gtr:id>6739e11790d28c93d55c5eca3921fbd9</gtr:id><gtr:otherNames>Pickup D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>585d54639a05d7.18176534</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>324A32E6-F468-4967-A8DD-42CDB70FED97</gtr:id><gtr:title>Shape Retrieval of Non-rigid 3D Human Models</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6739e11790d28c93d55c5eca3921fbd9"><gtr:id>6739e11790d28c93d55c5eca3921fbd9</gtr:id><gtr:otherNames>Pickup D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d5fb0aa3d72.72299427</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9498D7DC-9CC0-441D-AB0D-F1A80E09B648</gtr:id><gtr:title>Bas-Relief Modeling from Normal Images with Intuitive Styles.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7e168572fe61d95bdfdf8b3b03202e2d"><gtr:id>7e168572fe61d95bdfdf8b3b03202e2d</gtr:id><gtr:otherNames>Ji Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_55f97597507558a3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C33521D9-5D57-495F-8EBE-535491E82D31</gtr:id><gtr:title>Skeleton-based canonical forms for non-rigid 3D shape retrieval</gtr:title><gtr:parentPublicationTitle>Computational Visual Media</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6739e11790d28c93d55c5eca3921fbd9"><gtr:id>6739e11790d28c93d55c5eca3921fbd9</gtr:id><gtr:otherNames>Pickup D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd86d88cbfb1.43541814</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>559A20FF-5138-489F-B96A-D68D5F5AA59F</gtr:id><gtr:title>An Evaluation of Canonical Forms for Non-Rigid 3D Shape Retrieval</gtr:title><gtr:parentPublicationTitle>Graphical Models</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6739e11790d28c93d55c5eca3921fbd9"><gtr:id>6739e11790d28c93d55c5eca3921fbd9</gtr:id><gtr:otherNames>Pickup D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa0fb355d57b7.84111010</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BC89BBF3-5062-4A78-95BA-6C8A09CE1AF0</gtr:id><gtr:title>Canonical Forms for Non-Rigid 3D Shape Retrieval</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6739e11790d28c93d55c5eca3921fbd9"><gtr:id>6739e11790d28c93d55c5eca3921fbd9</gtr:id><gtr:otherNames>Pickup D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>978-3-905674-78-1</gtr:isbn><gtr:outcomeId>56b4c139a87005.10198236</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J02211X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>