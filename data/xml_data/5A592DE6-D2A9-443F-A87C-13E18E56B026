<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Engineering Science</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/536116AC-C155-4A24-A743-309BD68E50CE"><gtr:id>536116AC-C155-4A24-A743-309BD68E50CE</gtr:id><gtr:name>Defence Science &amp; Tech Lab DSTL</gtr:name><gtr:address><gtr:line1>Defence Science &amp; Tech Lab - MOD</gtr:line1><gtr:line2>Porton Down</gtr:line2><gtr:line4>Salisbury</gtr:line4><gtr:postCode>SP4 0JQ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6D419C9B-1ACA-435A-B8B1-36FA3461BF52"><gtr:id>6D419C9B-1ACA-435A-B8B1-36FA3461BF52</gtr:id><gtr:firstName>Philip</gtr:firstName><gtr:otherNames>Hilaire</gtr:otherNames><gtr:surname>Torr</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN019474%2F1"><gtr:id>5A592DE6-D2A9-443F-A87C-13E18E56B026</gtr:id><gtr:title>Understanding scenes and events through joint parsing, cognitive reasoning and lifelong learning</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N019474/1</gtr:grantReference><gtr:abstractText>The goal of this MURI team is to develop machines that have the following capabilities:
i) Represent visual knowledge in probabilistic compositional models in spatial, temporal, and causal hierarchies augmented with rich attributes and relations, use task-oriented representations for efficient task-dependent inference from an agent's perspective, and preserve uncertainties;
ii) Acquire massive visual commonsense via web scale continuous lifelong learning from large and small data in weakly supervised HCI, and maintain consistence via dialogue with humans;
iii) Achieve deep understanding of scenes and events through joint parsing and cognitive reasoning about appearance, geometry, functions, physics, causality, intents and belief of agents, and use joint and long-range reasoning to fill the performance gap with human vision;
iv) Understand human needs and values, interact with humans effectively, and answer human queries about what, who, where, when, why and how in storylines through Turing tests.

Collaboration with US:
Principal Investigator: Dr. Song-Chun Zhu
Tel. 310-206-8693, Fax. 310-206-5658, email: sczhu@stat.ucla.edu
Institution: University of California, Los Angeles
Statistics and Computer Science
8125 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095
Institution proposal no. 20153924

Other universities in the US
CMU: Martial Hebert Computer Vision, Robotics &amp;amp; AI
Abhinav Gupta Computer Vision, Lifelong Learning
MIT: Joshua Tenenbaum Cognitive Modeling and Learning
Nancy Kanwisher Cognitive Neuroscience
Stanford: Fei-Fei Li Computer Vision, Psychology &amp;amp; AI
UIUC Derek Hoiem Computer Vision, Machine Learning
Yale Brian Scholl Psychology, Cognitive Science</gtr:abstractText><gtr:potentialImpactText>Not required</gtr:potentialImpactText><gtr:fund><gtr:end>2018-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>668728</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>oxsight</gtr:companyName><gtr:description>xSight is a University of Oxford venture that uses the latest smart glasses to improve sight for blind and partially sighted people. OxSight's aim is to develop sight enhancing technologies to improve the quality of life for blind and partially sighted people around the world. Our current commercial products can enhance vision for people affected by conditions like glaucoma, diabetes and retinitis pigmentosa as well as some other degenerative eye diseases.</gtr:description><gtr:id>923F8A46-F84E-46FF-907F-2A353E24654E</gtr:id><gtr:impact>see http://smartspecs.co/</gtr:impact><gtr:outcomeId>58c293e39b39c9.26611300</gtr:outcomeId><gtr:url>http://smartspecs.co/</gtr:url><gtr:yearCompanyFormed>2016</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>F9E20816-392B-4F39-A1FD-6405B787DD46</gtr:id><gtr:title>Efficient minimization of higher order submodular functions using monotonic Boolean functions</gtr:title><gtr:parentPublicationTitle>Discrete Applied Mathematics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eb36c3cd67f98536e9819f1d6798f7e9"><gtr:id>eb36c3cd67f98536e9819f1d6798f7e9</gtr:id><gtr:otherNames>Ramalingam S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58b57d82deb384.02357040</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E579A457-0C6D-4E47-9E02-2D803E9FFE5E</gtr:id><gtr:title>Efficient Semidefinite Branch-and-Cut for MAP-MRF Inference</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d744b37eab5d54815ab8dca6c36aae5"><gtr:id>5d744b37eab5d54815ab8dca6c36aae5</gtr:id><gtr:otherNames>Wang P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58b57e021530b5.35769681</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>950FB9A9-8B4D-40B7-99D7-6B90BD2169B7</gtr:id><gtr:title>Knowing who to listen to: Prioritizing experts from a diverse ensemble for attribute personalization</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dfadccca725ce8eac1aeaed9dac300b8"><gtr:id>dfadccca725ce8eac1aeaed9dac300b8</gtr:id><gtr:otherNames>Lad S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b57d8276af23.10479088</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>38D6FF90-8D6E-412B-B201-D70E1C8EED7B</gtr:id><gtr:title>Sequential Optimization for Efficient High-Quality Object Proposal Generation.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0355658aee7a567caa922e6adbda88b6"><gtr:id>0355658aee7a567caa922e6adbda88b6</gtr:id><gtr:otherNames>Zhang Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>5a6f2ecf07f595.22441323</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>62488466-8115-41D2-B71E-16D61B702E0A</gtr:id><gtr:title>Pixelwise Instance Segmentation with a Dynamically Instantiated Network</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/61b237ff91af5edbc996fbd131b77526"><gtr:id>61b237ff91af5edbc996fbd131b77526</gtr:id><gtr:otherNames>Arnab A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708db0138202.21672701</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>978D5DC3-C7A3-4A06-A7E1-835C6F1BFBF9</gtr:id><gtr:title>Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a7aef32c0301a9c801e8c7a949edd916"><gtr:id>a7aef32c0301a9c801e8c7a949edd916</gtr:id><gtr:otherNames>Singh G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708d34e34427.00849983</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9E32FA36-7853-4640-9547-6EC682BC1376</gtr:id><gtr:title>Efficient Linear Programming for Dense CRFs</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7fb8430d762831f250e7384eaba99f70"><gtr:id>7fb8430d762831f250e7384eaba99f70</gtr:id><gtr:otherNames>Ajanthan T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2eccd86d18.34655697</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D378A6E0-4D7F-494F-99E3-BDE0B0468AF2</gtr:id><gtr:title>On-the-Fly Adaptation of Regression Forests for Online Camera Relocalisation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d99287a8e2ea8c46f67ac264ea3abaa1"><gtr:id>d99287a8e2ea8c46f67ac264ea3abaa1</gtr:id><gtr:otherNames>Cavallari T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2ef1c5bc52.87806244</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DB6919DD-AF7A-4F5C-8947-CB578D626CA4</gtr:id><gtr:title>Staple: Complementary Learners for Real-Time Tracking</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/74c187c793077cf4ecad1345363499f3"><gtr:id>74c187c793077cf4ecad1345363499f3</gtr:id><gtr:otherNames>Bertinetto L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b57d82985618.28618392</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>589C4211-597C-476C-8082-CA9FEB173379</gtr:id><gtr:title>CODE: Coherence Based Decision Boundaries for Feature Correspondence.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c9171dfd3ad325c124344be97147ef5"><gtr:id>2c9171dfd3ad325c124344be97147ef5</gtr:id><gtr:otherNames>Lin WY</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>58b57d830d8381.30808716</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>99CD73F8-13B0-4F35-A872-3B19058F7A11</gtr:id><gtr:title>End-to-End Saliency Mapping via Probability Distribution Prediction</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/68ab3dc4a4bc0738c6eeec4819cdcfc4"><gtr:id>68ab3dc4a4bc0738c6eeec4819cdcfc4</gtr:id><gtr:otherNames>Jetley S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a708d71b2e492.92728367</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7045D2A0-0090-459C-A85B-92C1B164DD9B</gtr:id><gtr:title>End-to-End Representation Learning for Correlation Filter Based Tracking</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c591b0a09c267ee0ab709063ae27f97d"><gtr:id>c591b0a09c267ee0ab709063ae27f97d</gtr:id><gtr:otherNames>Valmadre J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a6f2eb417a9e4.64527883</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>390330FB-A2B7-4846-ADCF-D978DA479840</gtr:id><gtr:title>Heterogeneous wireless system testbed for remote image processing in automated vehicles</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/52239df11b51b8e664f3f204186a05ab"><gtr:id>52239df11b51b8e664f3f204186a05ab</gtr:id><gtr:otherNames>Roman C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b57d8259b8a0.44922118</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E368FA72-EC51-43E0-AA52-1FC94C9AB363</gtr:id><gtr:title>Learning to Navigate the Energy Landscape</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bc59f5fb736c3da3ed9d0d9ee91dddab"><gtr:id>bc59f5fb736c3da3ed9d0d9ee91dddab</gtr:id><gtr:otherNames>Valentin J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b57d82bba094.51373037</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5C48A128-E0B9-49EC-B1A8-74359A2B1B49</gtr:id><gtr:title>ROAM: A Rich Object Appearance Model with Application to Rotoscoping</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a49a21d77d9dee3ab76e089088f5b100"><gtr:id>a49a21d77d9dee3ab76e089088f5b100</gtr:id><gtr:otherNames>Miksik O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708d727819f8.53554351</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D49F61A3-B257-42EB-B0A5-2F2CFBB151AB</gtr:id><gtr:title>Large-Scale Binary Quadratic Optimization Using Semidefinite Relaxation and Applications.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5d744b37eab5d54815ab8dca6c36aae5"><gtr:id>5d744b37eab5d54815ab8dca6c36aae5</gtr:id><gtr:otherNames>Wang P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>58b57d832fc910.58809629</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D49F615A-8D60-430B-9149-150EA16EAE10</gtr:id><gtr:title>Deeply Supervised Salient Object Detection with Short Connections</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/41a849d7897e0f1a73e9efb613c0df4c"><gtr:id>41a849d7897e0f1a73e9efb613c0df4c</gtr:id><gtr:otherNames>Hou Q</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a708c7d813758.94037960</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N019474/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>