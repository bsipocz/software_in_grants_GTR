<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Informatics</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5BCE7F74-9DAD-47E4-B636-89BB451B2806"><gtr:id>5BCE7F74-9DAD-47E4-B636-89BB451B2806</gtr:id><gtr:firstName>Vaishak</gtr:firstName><gtr:surname>Belle</gtr:surname><gtr:orcidId>0000-0001-5573-8465</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FR021317%2F1"><gtr:id>FEE932FD-1B7F-49A3-91FE-D70E4C293250</gtr:id><gtr:title>Towards Explainable and Robust Statistical AI: A Symbolic Approach</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/R021317/1</gtr:grantReference><gtr:abstractText>Data science provides many opportunities to improve private and public life, and it has enjoyed significant investment in the UK, EU and elsewhere. Discovering patterns and structures in large troves of data in an automated manner - that is, machine learning - is a core component of data science. Machine learning currently drives applications in computational biology, natural language processing and robotics. However, such a highly positive impact is coupled to a significant challenge: when can we convincingly deploy these methods in our workplace? For example: 

(a) how can we elicit intuitive and reasonable responses from these methods?

(b) would these responses be amenable to suggestions/preferences/constraints from non-expert users? 

(c) do these methods come with worst-case guarantees?

Such questions are clearly vital for appreciating its benefits in human-machine collectives. 

This project is broadly positioned in the context of establishing a general computational framework to aid explainable and robust machine learning. This framework unifies probabilistic graphical models, which forms the statistical basis for many machine learning methods, and relational logic, the language of classes, objects and composition. The framework allows us to effectively codify complex domain knowledge for big uncertain data. 

Concretely, the project aims to learn a model that best summarises the observed data in a completely automated fashion, thereby accounting of both observable and hidden factors in that data. To provide guarantees, two distinct algorithms are considered:

(a) an algorithm that learns simple models with exact computations; 

(b) an algorithm that learns complex models but rests on approximations with certificates. 

To evaluate the explainable, interactive nature of the learned models, the project considers the application of dialogue management with spatial primitives (e.g., &amp;quot;turn south after the supermarket&amp;quot;). We will study the scalability of these algorithms, and then evaluate the closeness of the learned models to actual suggestions from humans. 

Computationally efficient and explainable algorithms will significantly expand the range of applications to which the probabilistic machine learning framework can be applied in society and contribute to the &amp;quot;democratisation of data.&amp;quot;</gtr:abstractText><gtr:potentialImpactText>The work in this proposal has the potential for substantial economic benefits, because better modelling languages, faster and robust inference algorithms will enable the graphical modelling framework to be applied with less effort and more confidence to a broader variety of problems. Graphical models provide a principled reasoning framework that has proven successful for problems in which there is noisy data and unknown hidden variables. Naturally, this applies to many applications and domains, both in academia and industry. Indeed, graphical models have supercharged the use of statistical methods in robotics, vision, and medical diagnosis, as well as core technologies thereof, such as deep generative neural networks. Despite this success, actually specifying these models is very challenging, especially for non-experts, and in that regard, probabilistic relational models have helped enormously. Our project directly builds on these successes, and will allow these models to finally reason about continuous data, which are very common in real-world applications (e.g., measurement errors, temporally-indexed values such as stock price fluctuations).

The following will benefit from the direction of this research: 

- The general public: If users do not understand the inner workings of machine learning models and also cannot extract meaningful behaviour from them, their applicability is likely to be limited to the select few who are technologically-gifted; this is likely to deepen social inequality. Explainable algorithms would help realise machine learning systems as an enabling technology, especially in human-machine collectives, to achieve goals collaboratively. 

- Private sector: Smart services and intelligent programs are becoming increasingly ubiquitous, and are often situated in larger smart environments. By identifying the foundations for compositionality in machine learning, technology-oriented companies can capitalise on these techniques to engineer their systems. Moreover, robustness can help such companies understand the risks of deploying a probabilistic machine learning method in a social context, in the sense of avoiding catastrophic outcomes. Finally, regulations on explainability in algorithms will certainly affect the packaging of AI technologies in products. 

- Research community: They will gain insights on expressive modelling languages and robust machine learning techniques. The problem is that graphical models can be difficult to apply for non-experts, especially if they have to design their own custom inference technique. Our outcomes will contribute to alleviating these challenges. 

To reach out to these beneficiaries on the project's outputs, we will: 

(a) publish the results in the top venues for AI, and engage with industry labs; 

(b) engage with non-experts (via discussion forums such as the Edinburgh International Development Society); 

(c) make benchmarks and software open access and publicise them on, e.g., beyondnp.org, which is a software repository for solvers of problem domains beyond the NP complexity class; 

(d) deliver seminars, lectures, and enhance teaching modules based on the outcomes of this project; and 

(e) organise a research workshop on symbolic methods for explainable AI, to which we will invite industry thought leaders invested in statistical relational learning and human-machine interaction, such as IBM, Microsoft and Google.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2018-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>100739</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/R021317/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>76783275-A9F8-4B4E-B314-51363124259C</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Fundamentals of Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>