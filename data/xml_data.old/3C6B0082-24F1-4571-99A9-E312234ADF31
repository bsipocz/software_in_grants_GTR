<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5CF71613-7461-4FB7-9F30-CE68D58063D1"><gtr:id>5CF71613-7461-4FB7-9F30-CE68D58063D1</gtr:id><gtr:firstName>Mounia</gtr:firstName><gtr:surname>Lalmas</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/ADB0D91F-D751-451F-BEA8-E17EE763D25A"><gtr:id>ADB0D91F-D751-451F-BEA8-E17EE763D25A</gtr:id><gtr:firstName>Fabrizio</gtr:firstName><gtr:surname>Smeraldi</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FF015984%2F1"><gtr:id>3C6B0082-24F1-4571-99A9-E312234ADF31</gtr:id><gtr:title>Towards Context-sensitive Information Retrieval Based on Quantum Theory: With Applications to Cross-media Search and Structured Document Access</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F015984/1</gtr:grantReference><gtr:abstractText>Consider the following search scenario: I am looking for information about children activities around Cambridge; this information is usually listed at the top of documents. I also want to see images of the listed places, and here is an example image of what sort of activities I am looking for. The weather for this weekend is predicted to be rain, so I prefer indoor activities . This information need contains contextual components: local search, weather. It also contains multimodal components: it specifies where the relevant information can be found in the document structure; it requests text and non-text results; and it requires a mixture of image-, text- and structure-based querying. This type of common and realistic information needs cannot be satisfied with today's search technologies. Context-sensitive search and multimodal search are two major challenges to developing new search technologies that will allow information access systems to be truly usable and valuable and make a fully satisfying impact on today's everyday life. Current IR research cannot deal with these challenges sufficiently because of its traditionally ad-hoc and incremental nature and the lack of a unified theoretical framework and mechanisms to seamlessly integrate context and multimodal search. To address these new challenges, it is essential that a radically new IR theory is developed, leading to a revolutionary shift of the IR paradigm. The growth of context-sensitive information access systems and the proliferation of multimedia and structured information sources, where multimodal access is essential for the efficient and effective e.g. learning and teaching through well-structured multimedia learning resources, searching and browsing of web repositories, cultural heritage collections and multimedia digital libraries, etc., make this revolutionary shift increasingly urgent. This proposal aims to make such a revolutionary shift of the IR paradigm by developing a novel and unified information retrieval (IR) theory based on the Quantum Theory (QT) framework to address the emerging challenges of context-sensitive and multimodal search. The proposed theory will be applied, evaluated, validated and refined in two important scenarios: multimedia and structured document retrieval. It has been shown that there exist peculiar relationships between formal methods in IR and QT, suggesting that a non-classical approach based on quantum theory can potentially resolve the aforesaid challenges. The hypothesis that this project builds on is that the QT theory provides innovation and inspiration into circumventing the emerging context and multimodality issues that current IR and search technologies cannot deal with. It will bring new light into IR research and force us to think about the problem from a different but more revolutionary way. This offers tantalizing possibilities and out of the ordinary implications, some of which, if realized, can lead to genuine breakthroughs and frontier technologies. The project is also innovative in the sense that we will conduct pioneering research in not simply building a generic QT-based IR theory but also applying and evaluating the proposed theory in the practical settings.This is a highly adventurous investigation into a largely unexplored area based on the intriguing connections between QT and IR. The success of this research will make significant and far-reaching impact on both information retrieval and quantum information processing: a completely new paradigm and underlying theory of IR for developing context-sensitive and multimodal search technologies that previously could not be brought about by incrementally extending classical IR models; and an expansion of the territory of quantum information processing.</gtr:abstractText><gtr:fund><gtr:end>2008-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-04-30</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>300274</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/F015984/1</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>3C6B0082-24F1-4571-99A9-E312234ADF31</gtr:id><gtr:grantRef>EP/F015984/1</gtr:grantRef><gtr:amount>300274.86</gtr:amount><gtr:start>2008-04-30</gtr:start><gtr:end>2008-08-31</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>C634F8CE-BD40-41B6-A6C3-DABA0A1D21BC</gtr:id><gtr:grantRef>EP/F015984/2</gtr:grantRef><gtr:amount>269014.7</gtr:amount><gtr:start>2008-09-01</gtr:start><gtr:end>2011-04-30</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0A982A4A-12CF-4734-AFCA-A5DC61F667F3</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Information &amp; Knowledge Mgmt</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>