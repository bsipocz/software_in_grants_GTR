<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/0FFF0D86-B44A-489C-95DB-F98FE3D400AB"><gtr:id>0FFF0D86-B44A-489C-95DB-F98FE3D400AB</gtr:id><gtr:name>Manufacturing Technology Centre (MTC)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/277D241B-DC33-47D0-9AC3-1A11FEFE6618"><gtr:id>277D241B-DC33-47D0-9AC3-1A11FEFE6618</gtr:id><gtr:name>Global Robots</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/119C5534-C0BC-4310-8481-C7E06B395A08"><gtr:id>119C5534-C0BC-4310-8481-C7E06B395A08</gtr:id><gtr:name>General Electric (GE)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/AE2AAE91-F3E0-4643-AB17-F49D7C2791E2"><gtr:id>AE2AAE91-F3E0-4643-AB17-F49D7C2791E2</gtr:id><gtr:name>Alstom</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/F45A4578-F962-4EFA-9CC1-9F2FF4F760AE"><gtr:id>F45A4578-F962-4EFA-9CC1-9F2FF4F760AE</gtr:id><gtr:name>Cranfield University</gtr:name><gtr:department>School of Water, Energy and Environment</gtr:department><gtr:address><gtr:line1>Cranfield</gtr:line1><gtr:line4>Bedford</gtr:line4><gtr:line5>Bedfordshire</gtr:line5><gtr:postCode>MK43 0AL</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F45A4578-F962-4EFA-9CC1-9F2FF4F760AE"><gtr:id>F45A4578-F962-4EFA-9CC1-9F2FF4F760AE</gtr:id><gtr:name>Cranfield University</gtr:name><gtr:address><gtr:line1>Cranfield</gtr:line1><gtr:line4>Bedford</gtr:line4><gtr:line5>Bedfordshire</gtr:line5><gtr:postCode>MK43 0AL</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5A5739A5-B58F-47C1-B425-94267E91DEE1"><gtr:id>5A5739A5-B58F-47C1-B425-94267E91DEE1</gtr:id><gtr:name>Technology Strategy Board</gtr:name><gtr:address><gtr:line1>Block B, Floor 1</gtr:line1><gtr:line2>North Star House</gtr:line2><gtr:line3>North Star Avenue</gtr:line3><gtr:line4>Swindon</gtr:line4><gtr:postCode>SN2 1JF</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0FFF0D86-B44A-489C-95DB-F98FE3D400AB"><gtr:id>0FFF0D86-B44A-489C-95DB-F98FE3D400AB</gtr:id><gtr:name>Manufacturing Technology Centre (MTC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/277D241B-DC33-47D0-9AC3-1A11FEFE6618"><gtr:id>277D241B-DC33-47D0-9AC3-1A11FEFE6618</gtr:id><gtr:name>Global Robots</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/119C5534-C0BC-4310-8481-C7E06B395A08"><gtr:id>119C5534-C0BC-4310-8481-C7E06B395A08</gtr:id><gtr:name>General Electric (GE)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AE2AAE91-F3E0-4643-AB17-F49D7C2791E2"><gtr:id>AE2AAE91-F3E0-4643-AB17-F49D7C2791E2</gtr:id><gtr:name>Alstom</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F8B15311-AF89-4BB3-8B15-B428490225EB"><gtr:id>F8B15311-AF89-4BB3-8B15-B428490225EB</gtr:id><gtr:firstName>Ashutosh</gtr:firstName><gtr:surname>Tiwari</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM506813%2F1"><gtr:id>7BB599B4-60B1-424F-BAEC-1B5A00E405FD</gtr:id><gtr:title>Towards Zero Prototyping of Factory Layouts and Operations Using Novel Gaming and Immersive Technologies</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M506813/1</gtr:grantReference><gtr:abstractText>Aim: The research aims to integrate Discrete Event Simulation (DES) with recent innovations in gaming interface technologies to incorporate novel immersive Virtual Reality (VR) and live event feedback capabilities into DES. The resulting technology will address the barriers that prevent more effective use of modelling and simulation in designing newbuilt factories and managing the operations of existing factories. The research results will be demonstrated by integrating Lanner's DES tool WITNESS with Oculus Rift, a VR goggle, and Microsoft Kinect, an integrated 3D sensing device, hence incorporating immersive VR (Immersive WITNESSS or IW) and live event feedback capabilities (Live WITNESS or LW) into WITNESS.
What is Immersive WITNESS (IW)? IW is the integration of the latest consumer device VR technology (Oculus Rift) with Lanner's DES tool WITNESS. At the moment, WITNESS mainly relies on standard (non-immersive) display technologies.
VR was a very popular topic in the 1990s, but interest waned away rapidly due to a gap between expectations and technological limitations. Recent developments have closed the gap considerably, opening up an opportunity for a fresh attempt to achieve the full potential of VR in manufacturing simulations.
How does IW bring value? The coupling of DES and VR opens up a new dimension for process simulation. Among the benefits cited in literature are increased involvement from decision makers resulting in an improved model and better understanding of the processes, increased confidence in the model, quicker and easier detection of errors and evaluation of model behaviour, facilitation of the generation of ideas, and better communication with clients and other stakeholders.
Oculus provides unprecedented immersion in a VR world at a fraction of the cost of traditional devices. Furthermore, new developments in human-computer interfaces (Leap Motion, Sixense STEM, Myo, Kinect) have opened up potentially useful
ways for users to interact with the virtual world.
What is Live WITNESS (LW)? LW is a novel means to synchronise DES simulation with real-world through the use of an integrated 3D-sensing consumer device (Microsoft Kinect) that can provide a cheap, robust and unobtrusive sensor system on the shop-floor to view a given scene, observe a process and generate appropriate signals to update the DES model.
How does LW bring value? The drawback of using DES is the effort and cost of processing the input data from various data sources to ensure valid simulation results. Attempts have been made for gathering data from existing ICT systems; dealing
with legacy data remains a great challenge. LW side-steps this problem by using a cheaply generated data stream. Success will mean that DES models can accurately represent real-world processes at all times.
Why are IW and LW being proposed together to create Immersive/Live WITNESS (I/LW)? 3D sensing and VR are complementary technologies; the former helps in constructing an accurate virtual mirror of the real world and the latter
visualises the resulting virtual world. For example, Kinect provides a way to rapidly generate virtual world that mirrors reality, which can be viewed and edited using Oculus. This project provides a setting where both technologies can complement each other. The proposed approach of developing IW and LW at the same time will also reduce risks whilst creating more value than if each component were developed separately. Cranfield University will lead the integrated development of I/LW.
Choice of technologies: There have been many recent developments in human-computer interface technologies rooted in
consumer devices, such as Oculus Rift and Microsoft Kinect. In manufacturing, these technologies have the potential to deliver an unprecedented level of immersiveness, detail and real-time accuracy to DES such that the virtual factory always
accurately mirrors the real factory. This is a new project with no direct competitors.</gtr:abstractText><gtr:potentialImpactText>Economic benefits for the consortium: The main beneficiaries of this project are the consortium members. The research
aims to integrate Discrete Event Simulation (DES) with recent innovations in gaming interface technologies to incorporate
novel immersive Virtual Reality (VR) and live event feedback capabilities into DES. The resulting technology will address
the barriers that prevent more effective use of modelling and simulation in designing new-built factories and managing the
operations of existing factories. The research results will be demonstrated by integrating Lanner's DES tool WITNESS with
Oculus Rift, a VR goggle, and Microsoft Kinect, an integrated 3D sensing device, hence incorporating immersive VR
(Immersive WITNESSS or IW) and live event feedback capabilities (Live WITNESS or LW) into WITNESS. The main
deliverables (IW, LW and integrated I/LW) will be commercialised by the consortium as add-on modules to WITNESS.
These deliverables will create direct economic benefits for all consortium partners through a revenue sharing agreement.
Three exploitation paths are envisioned: (i) The integrated I/LW will initially be licensed to large manufacturers as a standard package catering to the design and operations of factories. (ii) Each component (IW and LW) can also be licensed
to customers as standard packages, and as customised packages for specialised needs. (iii) Exploitation may also happen
through Alstom, which could adopt the deliverables within the company, towards deployment as a business wide system in
addition to the design of factory layouts.
Economic benefits for the UK and the EEA: This project will benefit the manufacturing and ICT companies in the UK,
particularly the manufacturers who use modelling and simulation in designing new-built factories and managing the
operations of existing factories, &amp;quot;manufacturers' manufacturers&amp;quot; who design and implement manufacturing systems,
designers and developers of machine tools and industrial robots, and ICT providers involved in the simulation and
optimisation of manufacturing systems, gaming technologies and immersive virtual environments. For manufacturing
companies, this project has the potential to deliver an unprecedented level of immersiveness, detail and real-time accuracy
to DES simulation such that the virtual factory always accurately mirrors the real factory. This will allow an engineering
team to reconstruct a shop-floor into a VR world, then walk through the 3D model that is updated live from the shop-floor,
make exploratory changes in the VR world directly, and verify and validate outcomes in VR. This project will provide the
ICT companies with a novel approach to integrate DES tools with state-of-the-art VR and 3D sensing technologies. The
EEA will benefit because Alstom and other manufacturing companies will remain competitive and continue to support their
partners/vendors in the EEA. The proposed technology will be useful for any manufacturing company that uses modelling
and simulation in designing new-built factories and managing the operations of existing factories, such as energy
equipment, train, automotive and aerospace manufacturers.
Environmental and social benefits: This project will have environmental and social benefits through right-first-time building
of factories and through more efficient factories in terms of energy and material usage. Reducing factory test runs and the
time needed for production ramp-up will reduce consumption of resources. By ensuring that factory layout modelling
incorporates live data about human movement, there will also be improvements in health and safety and workers' quality of life.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-09-26</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>330365</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>This video shows the end-to-end system demonstrator of project results.</gtr:description><gtr:id>4B937C45-DA48-482D-B657-950609F52251</gtr:id><gtr:impact>This video has been shown to potential partners and collaborators with good feedback, resulting in multiple follow-on project opportunities.</gtr:impact><gtr:outcomeId>58c879f5a16e95.26825637</gtr:outcomeId><gtr:title>Video of final demonstrator</gtr:title><gtr:type>Film/Video/Animation</gtr:type><gtr:url>https://www.youtube.com/watch?v=8U6u9N1nsqM</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Manufacturing Technology Centre (MTC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Creating a digital twin to investigate human-robot collaboration strategies in a virtual environment</gtr:description><gtr:id>D9820DD5-714A-4444-827F-A1C440021EFE</gtr:id><gtr:impact>This has resulted in a paper submitted to the EEE/RSJ International Conference on Intelligent Robots and Systems.</gtr:impact><gtr:outcomeId>58c13f2f546792.25429851-1</gtr:outcomeId><gtr:partnerContribution>The Manufacturing Technology Centre is providing the use case and the physical robot cell layout for tests.</gtr:partnerContribution><gtr:piContribution>Cranfield University is developing a digital twin of an actual physical robot cell at the Manufacturing Technology Centre (MTC). We are also developing mechanisms that measure human reactions to robot movements. So far, we have seen that different people have different reaction times as well as responses. This will be used to inform collaborative strategies with the virtual robot. The collaborative strategies will then be uploaded onto the physical robot for real world use. This approach enables the consortium to investigate human-robot collaborative strategies in a safe manner and use the outputs to inform future government policies.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2017-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Alstom</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Alstom UK</gtr:department><gtr:description>Collaboration with Alstom Transport to investigate the potential use of low cost robotic solutions in train maintenance</gtr:description><gtr:id>03D4E31E-119F-43D5-BB6B-00C2B3FDBAD5</gtr:id><gtr:impact>Resulted in submission of an innovate UK proposal.</gtr:impact><gtr:outcomeId>56d4229f3694d0.40282196-1</gtr:outcomeId><gtr:partnerContribution>Providing market need for low cost robotic train maintenance as well as use cases for feasibility studies</gtr:partnerContribution><gtr:piContribution>Providing technical information regarding potential use cases.
Taking the lead in writing an innovate UK proposal.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>General Electric (GE)</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Automated conversion of physical spaces into virtual spaces for updating maintenance records</gtr:description><gtr:id>5BF6960E-261C-4DCA-BA06-0ECC539E019C</gtr:id><gtr:impact>This will result in a part-funded project with Cranfield University.</gtr:impact><gtr:outcomeId>58c13cd97de3a4.73452391-1</gtr:outcomeId><gtr:partnerContribution>General Electric will be providing the use case as well as the industrial laser scanner.</gtr:partnerContribution><gtr:piContribution>Cranfield Team will be enhancing the virtual reality software tools developed as part of this project. Due to the limitations of the Microsoft Kinect, an industrial laser scanner will be used instead. Lessons learnt in manually converting physical spaces to virtual spaces will be exploited to develop an automated tool to achieve this.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2017-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>General Electric (GE)</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Investigating the use of smart objects and robots for intelligent manufacturing</gtr:description><gtr:id>509ED4D9-E8E2-4ED7-80C6-04EA39D661ED</gtr:id><gtr:impact>One Innovate UK proposal with another being prepared</gtr:impact><gtr:outcomeId>58c1383fcdb2f5.53244540-1</gtr:outcomeId><gtr:partnerContribution>Global Robots will be providing refurbished robots for demonstrators while GE Garages will investigate how the demonstrator could be used to develop their new line of products.</gtr:partnerContribution><gtr:piContribution>The Cranfield Team are working with Global Robots and General Electric (GE) Garages to develop an innovate UK proposal to investigate the possibility of &amp;quot;smartening up&amp;quot; objects on the manufacturing line. The aim is to achieve flexible manufacturing through distributed computing to reduce the computational burden on robotic arms used on manufacturing lines.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Global Robots</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Investigating the use of smart objects and robots for intelligent manufacturing</gtr:description><gtr:id>A013C295-5E76-46DC-9D47-183A0602A6D0</gtr:id><gtr:impact>One Innovate UK proposal with another being prepared</gtr:impact><gtr:outcomeId>58c1383fcdb2f5.53244540-2</gtr:outcomeId><gtr:partnerContribution>Global Robots will be providing refurbished robots for demonstrators while GE Garages will investigate how the demonstrator could be used to develop their new line of products.</gtr:partnerContribution><gtr:piContribution>The Cranfield Team are working with Global Robots and General Electric (GE) Garages to develop an innovate UK proposal to investigate the possibility of &amp;quot;smartening up&amp;quot; objects on the manufacturing line. The aim is to achieve flexible manufacturing through distributed computing to reduce the computational burden on robotic arms used on manufacturing lines.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>International industry-sponsored student engagement (China)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>F43546E5-8C15-455B-83D2-2F296D261FAB</gtr:id><gtr:impact>A joint presentation between Cranfield team, Lanner Group (simulation software company), and Virtalis (virtual reality company) to convey project goals and benefits to industry-sponsored MSc students from COMAC aerospace company, China. As a result, there is now increased interest among the students to make use of the project's offerings, firstly in their individual projects, and finally in their company.</gtr:impact><gtr:outcomeId>56d48e8c11cc72.27939183</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>GE Power Annual Science and Technology Day (Inaugural Event)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>8160D4D8-D6B9-444F-818E-76079BB0AF9B</gtr:id><gtr:impact>Around 80 GE engineers attended a one-day event to promote Digital activities inside the company so VR, Robotics, Optimisation &amp;amp; Automation were all featured. The company reported many positive comments from engineers who found the experience very interesting and informative. Having local universities and R&amp;amp;D organisations there brought an additional dimension to the event. They are confident that these initiatives will improve their links and knowledge transfer.</gtr:impact><gtr:outcomeId>58c6ced6de38f1.04984583</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Article in GE Reports</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FE8DD630-779D-426A-92E1-49EDFE29D0EA</gtr:id><gtr:impact>A GEReports.com article was published online to promote the project. The article outlines the work which has been developed throughout the project focussing on the link between Virtual Reality, visualisation and factory simulation models. The website has a global audience and hundreds of thousands of subscribers, including many journalists. A link to the piece has been included in subsequent GE Reports articles and in several internal news emails.</gtr:impact><gtr:outcomeId>58c141e4106543.46243396</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.gereports.com/call-of-duty-this-woman-is-using-video-games-kinect-and-vr-to-make-actual-factories-work-better/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>UK delegation to India</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>5E05ED50-265B-4C04-A2E1-2267FEE70049</gtr:id><gtr:impact>The project team was part of a UK delegation to India in November 2016. This visit was used by the project team to disseminate the successful project outcomes. A summary of the visit is provided as follows:
1) The delegation visited Delhi as part of TECH Summit (7-9 Nov), Pune (9-10 Nov) and Bangalore (UK-India Advanced Manufacturing Innovation workshop, 11 Nov). 
2) The project team prepared exhibition stands to demonstrate the potential of using simulation-driven Kinect and virtual reality on the shop floor to improve manufacturing processes.
3) An excellent response was received from stand visitors including VIP guests.</gtr:impact><gtr:outcomeId>58c142d43cd4e4.93560147</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Policymakers/politicians</gtr:primaryAudience><gtr:url>https://www.gov.uk/government/world-location-news/india-uk-tech-summit-2016</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>GE Power Leaders Workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>0254E113-681C-4FDB-82F4-49A101775359</gtr:id><gtr:impact>In January 2016, a 'GE Power Leaders Workshop' was held in Hammersmith, London. As part of the workshop, top executives from different GE businesses were invited to attend various lectures and discussions. The project team presented the outputs from this research. Subsequently, the team was awarded the Best Showcase Award. The event was also an opportunity to discuss the project with key stakeholders within GE.</gtr:impact><gtr:outcomeId>58c141152b6de3.82934395</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Middle School visit</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>2EC857FA-CD51-44E7-A8DC-42832F281333</gtr:id><gtr:impact>On 22 March 2016, students from Holywell Middle School visited the Manufacturing Informatics Centre at Cranfield University. Eighteen students accompanied by three staff members were met by Professor Ashutosh Tiwari and his team. Researchers John Oyekan and Chika Mgbemena led a session on the use of Microsoft Kinect sensors on manufacturing shop floors to help factories improve their productivity. Windo Hutabarat and Boyang Song guided the visitors on the latest in immersive and augmented reality technologies such as Oculus Rift and Google Glass. The day concluded with a pub quiz style session led by Michael Farnsworth and Divya Tiwari, where every student was presented with a Cranfield souvenir kindly donated by the Vice-Chancellor.

The event was very successful, with positive comments from the students and their teachers. Some students have even asked at what age they can enter Cranfield University!</gtr:impact><gtr:outcomeId>58c1424898c219.14761088</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Quarterly Progress Meetings with Industrial Partners (GE and Lanner Group)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>A93D376C-755C-4966-9F21-43CBECD2DD0D</gtr:id><gtr:impact>This is a regular quarterly event to review the progress of the research collaboration between Cranfield, GE and Lanner Group. This event discusses the risks and mitigation strategies required to bring the project into successful conclusion. It informs the next set of technological products being developed and used by the industrial partners. This informs our dissemination and engagement plans including the choice of use cases.</gtr:impact><gtr:outcomeId>56d426da208cb5.63614138</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2015,2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Workshop and Virtual Reality Demonstration</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1555D1FC-253D-4BA2-AE1B-CA93F344E90B</gtr:id><gtr:impact>On 25 January 2016, a workshop was held at GE, representing 30 stakeholders from a large range of business sectors. The workshop included a presentation on the capabilities developed by the project team and the results of the project to date. The project team demonstrated videos of a maintenance workshop model as well as a desktop factory with a Microsoft Kinect picking up material movement times. The workshop was very well received with many encouraging comments, suggestions and follow up emails.</gtr:impact><gtr:outcomeId>58c141867effc7.06881223</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Digital Technologies for Manufacturing Innovation: Embracing Industry 4.0</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1ACC7AA4-C429-417B-8842-ACAB2516AA49</gtr:id><gtr:impact>The research team was invited to this event to present its demonstrators on live simulation and immersive visualisation of factory environments. This enabled us to see the impact that our research will have on industry as well as identify how best to package the solutions being developed by the research team. The event was organised by the Institute for Advanced Manufacturing (ifAM) at the University of Nottingham, in collaboration with EPSRC and Innovate UK.</gtr:impact><gtr:outcomeId>56d425457b12a8.64771849</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>https://www.nottingham.ac.uk/conference/fac-eng/dtmi2015/index.aspx</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>12000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Investigating human-robot collaboration strategies in a virtual reality environment (MSc group project)</gtr:description><gtr:end>2017-05-02</gtr:end><gtr:fundingOrg>Manufacturing Technology Centre (MTC)</gtr:fundingOrg><gtr:id>85213FB2-38D9-43E9-99BA-DB9CEE15EF40</gtr:id><gtr:outcomeId>58c90b30609642.08977936</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2017-02-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>59623</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Industrial Systems in the Digital Age</gtr:description><gtr:end>2018-05-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:id>E5945F90-ACC7-4F7B-AE13-9B94E95F1280</gtr:id><gtr:outcomeId>58c13fd864b4b0.05225363</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2017-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>67608</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC High Value Manufacturing Catapult Fellowship</gtr:description><gtr:end>2018-11-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:id>BF14116B-161C-4B55-AD3B-D16D0B4A1226</gtr:id><gtr:outcomeId>56d4236537b393.23298481</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-12-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The project uses low-cost new innovative technologies within the gaming sector in the form of virtual reality and human-computer interface sensory technologies.

Developing Machine Learning Techniques to Mine Sensor Data: This project started with the recognition of the potential of sensor data feeds for better decisions in smart manufacturing. Towards this, mining of sensor data feeds is achieved using machine learning techniques. These techniques utilise previously generated simulation models and CAD models to train computer vision algorithms. The trained computer vision algorithms are capable of: (1) inferring the status of machines as well as material flows in a factory, (2) inferring the status of manual assembly tasks, and (3) updating simulation models. The updated models enable better prediction of future manufacturing states, for example, whether a manufacturing target will be achieved at the current production rate. Going forward, we envisage that these project outputs will be taken up by companies and fed into their smart manufacturing initiatives. 

Exploiting Virtual Reality Technologies for Zero Prototyping of Factory Layouts: We have developed techniques that enable users to simulate material and people flows on a shop floor. We can update the status of machines in the virtual reality environment and see the effect of the changes on production rates and targets. This helps decision makers experiment with various factory configurations without the need to disrupt a manufacturing line. We envisage that these outputs will be eventually assimilated into simulation products in the near future. The users of these products will have an option to use virtual reality immersion to show all potential stakeholders how a future planned factory will operate. These outputs have enabled the project partner, Lanner Group, to showcase futuristic capabilities that are within reach at conferences and user events. The tangible demonstrators developed by the project have enabled the project partner, GE Power, to connect with other teams across the wider GE organisation and inform a number of future applications within the business.

Societal Impact: The project team was also active in engaging with other audiences. On 22 March 2016, students from Holywell Middle School visited the Manufacturing Informatics Centre at Cranfield University. Eighteen students accompanied by three staff members were met by Professor Ashutosh Tiwari and his team. Selected project outputs, such as the use of Microsoft Kinect sensors on manufacturing shop floors to help factories improve their productivity, were showcased to the students. We believe that this public engagement exercise has enabled the team to inspire the next generation of students to take up manufacturing. 

Future: This project will have environmental and social benefits through right-first-time building of factories and through more efficient factories in terms of energy and material usage. Reducing factory test runs and the time needed for production ramp-up will reduce consumption of resources. For example, an ongoing work with the Manufacturing Technology Centre is looking at how Virtual Reality could be used to develop digital twins of a physical robot cell towards exploring human-robot collaboration strategies. The hypothesis is that the lessons learnt in a virtual environment will inform policies on safe human-robot collaboration.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>4A8E2AAD-B08D-4A98-ABAE-F15535419A16</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d55c3e95a9a7.15866691</gtr:outcomeId><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Energy,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have discovered that it is possible and valuable to develop convincing factory environments through the use of consumer-grade Virtual Reality. In this virtual environment, we can experiment with various factory layout possibilities and see which ones work best for a given scenario. As the virtual environment is linked with manufacturing simulation, we can also &amp;quot;run&amp;quot; the factory through various scenarios. For example, we can stop individual machines to see how this affects overall production. We can also experiment with various ways of addressing shop floor issues, thereby reducing the risk in actual implementation. Through simulation, we can discover layout and operational issues before any money is spent on building the actual factory. This translates into cost and time effectiveness.

We have also discovered that it is possible and valuable to feed data back into the manufacturing process simulation from the actual shop floor using consumer-grade sensors. One key contribution within this is our discovery of a way to train a computer equipped with a camera to recognise what it is looking at on a manufacturing floor. Training was achieved through the use of pre-defined simulation models and a database of shop floor CAD geometries. This enables the computer to infer manual handling tasks as well as the status of machines on the shop floor. From this, performance data of the actual process can be recorded. Comparison of this data with simulated data enables us to highlight potential bottlenecks and production shortfalls. 

Finally, by combining the virtual factory environment with live data feedback, we have developed a way to create a &amp;quot;digital twin&amp;quot; that can be used by factory managers to increase productivity while significantly de-risking the impact of factory layout changes.</gtr:description><gtr:exploitationPathways>Connecting Virtual Reality (VR) and Process Simulation (PS) in a hybrid framework is a powerful combination that is currently under-researched. We have shown that VR gives users the power to experience a factory before it is constructed while PS enables users to conduct predictive simulations to analyse the effects of various decisions on the factory. Other researchers can take forward our framework by combining VR with different types of PS, such as Agent-Based Simulation or System Dynamics Simulation. Our research on bootstrapping vision systems using process models can have great value in many industrial applications, for example, it can be used to upgrade the connectivity of legacy machines in a factory. In addition, our work on predictive simulation fed by real-time shop floor data can be expanded further by utilising the latest advances in machine learning technique, e.g. deep learning. Finally, these findings could be applied to a range of industrial sectors, such as power, automotive, aerospace, construction and healthcare management.</gtr:exploitationPathways><gtr:id>3B15A403-A9D6-45C6-9F84-C9BB0A2BDE3D</gtr:id><gtr:outcomeId>56d55c5b9b97e8.24093496</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Energy,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>We developed a virtual reality tool that provides a foundation to investigate human-industrial robot collaboration strategies in a safe environment. The hypothesis is that strategies developed in a virtual environment will inform kinematics control of real world industrial robots.</gtr:description><gtr:id>B8B6E9AE-F83B-43ED-B247-779999188871</gtr:id><gtr:impact>We are currently working with MTC to develop a digital twin of an industrial robot cell. The aim is to measure human reaction times and behaviours in a safe way to inform policies on human-robot collaboration.</gtr:impact><gtr:outcomeId>58c7cabd8a0d81.73230244</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Virtual reality tool to investigate human-robot collaboration strategies</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:researchMaterialOutput><gtr:researchMaterialOutput><gtr:description>We have developed a workflow that uses a set of software tools that use CAD models and shop floor measurements to convert physical spaces into virtual spaces.</gtr:description><gtr:id>4F2B0E22-DE67-4A76-BEF8-FA8A01423395</gtr:id><gtr:impact>The approach is currently being investigated to keep track of maintenance updates in manufacturing plants.</gtr:impact><gtr:outcomeId>58c14431df7029.81340069</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Virtual Reality work flow for developing manufacturing digital twins</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:researchMaterialOutput><gtr:researchMaterialOutput><gtr:description>This method uses a camera system to read and infer the state of a manufacturing shop floor. Based on this, our algorithms update a virtual model of the factory. The goal is to achieve accurate real time predictive analytics of factory shop floor.</gtr:description><gtr:id>8CD2D209-0915-4450-A0CF-3603A4CAB1DC</gtr:id><gtr:impact>This research is still ongoing but we foresee an industrial impact that would enable decision makers to have more accurate models of factories.</gtr:impact><gtr:outcomeId>56d428c8590ba8.02249482</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Updating Factory Layout Models Based on Computer Vision</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>71330E99-BA9A-42FE-9285-BC6616F28F2D</gtr:id><gtr:title>Impact of model fidelity in factory layout assessment using immersive discrete event simulation.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fa8bdf286a488ab095a5bab782bd4ba7"><gtr:id>fa8bdf286a488ab095a5bab782bd4ba7</gtr:id><gtr:otherNames>A Petti</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f59c77a073.85428267</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>17F5B277-8B42-4D14-9B2C-13C0800C0B15</gtr:id><gtr:title>Procedia CIRP</gtr:title><gtr:parentPublicationTitle>Layout Optimization of a Repair Facility Using Discrete Event Simulation.</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b8ee332f4b2cb71e2b7d313626313ff6"><gtr:id>b8ee332f4b2cb71e2b7d313626313ff6</gtr:id><gtr:otherNames>Neha Prajapat</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f4131f3ca3.62760826</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2AE4EDF5-A21A-41D2-817D-4B5A262CD780</gtr:id><gtr:title>Combining virtual reality enabled simulation with 3D scanning technologies towards smart manufacturing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c01efdacb0e8839f9feb9944e127fb09"><gtr:id>c01efdacb0e8839f9feb9944e127fb09</gtr:id><gtr:otherNames>Hutabarat W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c1310a09fea5.55839092</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>32269E63-1E5E-4754-88FF-477417C42A34</gtr:id><gtr:title>Immersive Interaction Techniques with Discrete-Event Simulation (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e18f64d502aaaad04f930fda509450b"><gtr:id>3e18f64d502aaaad04f930fda509450b</gtr:id><gtr:otherNames>Ximing Liu</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f74184a805.79518906</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B900EFB2-052C-4164-A96C-7F2FF0EB992A</gtr:id><gtr:title>A 3D Immersive Discrete Event Simulator for Enabling Prototyping of Factory Layouts</gtr:title><gtr:parentPublicationTitle>Procedia CIRP</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0d4ea8d23626da0c2bd154bd0d012d4b"><gtr:id>0d4ea8d23626da0c2bd154bd0d012d4b</gtr:id><gtr:otherNames>Oyekan J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d421462ead40.27885461</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9873D67E-F6F8-4ECE-9BAE-7641C3F5553B</gtr:id><gtr:title>Investigating Human-Robot Collaboration Using Immersive Virtual Reality (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e2ac48a46b2cee19c14081ae7422c486"><gtr:id>e2ac48a46b2cee19c14081ae7422c486</gtr:id><gtr:otherNames>Soren Dominik Sonntag</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f6f86a0370.25775692</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5B08C355-B216-448B-B336-7592364F525D</gtr:id><gtr:title>Discrete Event Simulation and Virtual Reality Use in Industry: New Opportunities and Future Trends</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Human-Machine Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b275411489d2e326e8859ee3bae6f17"><gtr:id>4b275411489d2e326e8859ee3bae6f17</gtr:id><gtr:otherNames>Turner C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d4139384ca6.59729405</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>37BFC397-9DA8-404D-8B88-C9512D5E8AE2</gtr:id><gtr:title>Adapting Petri Nets to Discrete-Event Simulation for the Stochastic Modelling of Manufacturing System (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d7d9adc8e4fb4e8cd5e72782e011151"><gtr:id>3d7d9adc8e4fb4e8cd5e72782e011151</gtr:id><gtr:otherNames>Ettiene Simon</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f60ee54957.73735451</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>11D5B0C8-CC8E-4EC7-AAFB-68BEB3FD8689</gtr:id><gtr:title>Investigation of Computer Vision Techniques to Track the Progress of a Manual Assembly Sequence (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3da071a35376bf917553c55a7bc7708b"><gtr:id>3da071a35376bf917553c55a7bc7708b</gtr:id><gtr:otherNames>Alex Fischer</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f64b6a9d14.45996483</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3AB34834-9B63-4ECA-B6B9-8AAA59F9156F</gtr:id><gtr:title>Exploration of Human-Computer Interaction for Immersive Virtual Reality in Discrete Event Simulation (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/58e36e808bb95e57cee1b426ae26cada"><gtr:id>58e36e808bb95e57cee1b426ae26cada</gtr:id><gtr:otherNames>Adrian Souto Moure</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58c7f85c051903.86847211</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E81E35AB-A522-46E0-9C7F-BB5630BF26BC</gtr:id><gtr:title>The Impact of Immersive Virtual Reality (IVR) Fidelity in a Discrete Event Simulation (DES) Model (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2ecbaeb33c3d74a36ba243dd81ff1ee0"><gtr:id>2ecbaeb33c3d74a36ba243dd81ff1ee0</gtr:id><gtr:otherNames>Alexandro Petti</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>58c7f89d329426.52444689</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EC969048-B352-4785-AB93-1D065858DDCB</gtr:id><gtr:title>Analysis of Automation Solutions for a Manual Assembly Line (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/eb1bf7466dc66ea875ac098e1553a9df"><gtr:id>eb1bf7466dc66ea875ac098e1553a9df</gtr:id><gtr:otherNames>Xiaobing Pang</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f791b996a7.05427016</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>36A3CE74-2311-4AC1-9B4A-B0DE287834F4</gtr:id><gtr:title>Adapting Petri Nets to DES: Stochastic Modelling of Manufacturing Systems</gtr:title><gtr:parentPublicationTitle>International Journal of Simulation Modelling</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fd59576e863062129a4e676da841d196"><gtr:id>fd59576e863062129a4e676da841d196</gtr:id><gtr:otherNames>Simon E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa8096aaebc68.35931959</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>167B523C-7EC3-4A86-BF13-87C563063793</gtr:id><gtr:title>Development of Embedded Smart Objects for Self-Controlled Manufacturing in Industry 4.0 Scenarios (MSc thesis supervised by Prof Ashutosh Tiwari)</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6374f3f1d892e8b5533fd3471c74db9b"><gtr:id>6374f3f1d892e8b5533fd3471c74db9b</gtr:id><gtr:otherNames>Clement Arnoult</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7f681c9b542.14919606</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A07FDE31-B873-47E5-9953-6D849F4FEE32</gtr:id><gtr:title>Survey on the use of computational optimisation in UK engineering companies</gtr:title><gtr:parentPublicationTitle>CIRP Journal of Manufacturing Science and Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ba831c4fe4149ae6d133271004fede65"><gtr:id>ba831c4fe4149ae6d133271004fede65</gtr:id><gtr:otherNames>Tiwari A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d07c21a48187.74093068</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M506813/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>