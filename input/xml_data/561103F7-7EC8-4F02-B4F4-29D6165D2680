<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Physiology Anatomy and Genetics</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/9790F323-3567-4859-B9D3-E372CA5B31A3"><gtr:id>9790F323-3567-4859-B9D3-E372CA5B31A3</gtr:id><gtr:firstName>Kerry</gtr:firstName><gtr:otherNames>Marie</gtr:otherNames><gtr:surname>Walker</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM010929%2F1"><gtr:id>561103F7-7EC8-4F02-B4F4-29D6165D2680</gtr:id><gtr:title>An integrative approach to uncovering the neural basis of pitch perception.</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M010929/1</gtr:grantReference><gtr:abstractText>After a sound wave enters your ear, the activity of hundreds of thousands of neurons throughout your brain transforms this signal into a perceptual experience. The tonal quality that we ascribe to sounds, known as their &amp;quot;pitch&amp;quot;, is one of the most important features of this experience. Pitch perception allows us to recognize a familiar musical melody, the low growl of a lion, or the inquisitive tone of someone's voice. Many animal species also use pitch to communicate and interpret their world. For instance, mother monkeys have been shown to raise the pitch of their voice when calling their young, just as human mothers do when speaking to their children. As we age, our ability use some types of pitch cues declines, even in individuals with normal hearing thresholds. Therefore, an understanding of how brain cells compute pitch, and how age and experience can change these processes, may help to improve hearing in elderly people.

While our ability to distinguish a low note from a high note comes effortlessly to us as listeners, it has proved a great challenge for neuroscience to fully understand how our brain accomplishes this feat. Functional imaging studies in humans suggest that certain parts of the brain may be specialized for pitch perception, but there is still much debate over where exactly the brain's &amp;quot;pitch center&amp;quot; is located. Moreover, these brain imaging techniques do not have sufficient resolution to tell us how nerve cells in the brain represent the pitch of a sound. Experiments that measure the activity of individual brain cells in animals are therefore essential to answering to this open research question. Our research at the University of Oxford will use an innovative combination of modern neuroscience methods to uncover the neural basis of pitch perception. 

It is unclear how pitch perception in many animals relates to that that of humans. We will therefore begin our studies by comparing the physical properties of sound that humans and our animal model, the ferret, use to determine its pitch. We will train the animals to distinguish low- from high-pitched sounds on a behavioural task, and human volunteers will be trained on a similar task. Because the nerve cells in the ear are better understood and simpler than brain cells, we can build computer models that predict how nerve cells in the ear will respond to different sounds. By comparing these model predictions to real behavioural performance, we will determine how animals and humans use sound features to make pitch judgments. To discover how neurons in different parts of the brain represent sound features that are relevant to pitch perception, we use microelectrodes to measure the activity of nerve cells in the animals while they perform the pitch judgment task. The microelectrodes will be implanted under surgical anaesthesia, so that the animals do not feel pain. By recording brain activity in the animals as they are trained to derive pitch from different sound properties, we will reveal how the brain's representation of pitch can adapt through experience. Finally, we will use new, laser-based microscope technology to make videos of the activity of large numbers of brain cells while animals are listening to sounds. These experiments will allow us to map out how pitch-selective nerve cells are distributed across the surface of the brain, with a density and resolution that have never before been possible. The results will indicate whether a pitch center exists in the brain, and, if so, where it is located. Together, these experiments will significantly advance our knowledge of the brain processes that allow us to follow the melody of our favourite tune.</gtr:abstractText><gtr:technicalSummary>Pitch is one of the most salient and behaviourally relevant perceptual features of sound for humans and animals. Poor encoding of temporal pitch cues is thought to underlie the communication difficulties experienced by elderly individuals, but little is known about how animal models make use of temporal pitch cues or how these cues are encoded by the auditory cortex. The studies proposed here will aim to answer these fundamental questions by combining the strengths of behavioural, computational, single-cell electrophysiological and single-cell imaging techniques. Firstly, we will compare how ferrets and human listeners use temporal and resolved harmonic cues on a pitch judgment task, and this performance will be compared to the predictions of auditory nerve models. Next, we will measure how neural spike trains represent pitch cues throughout the ascending auditory system (including the inferior colliculus, primary and secondary auditory cortical fields). By measuring neural responses in animals as they perform the pitch judgment task, we will investigate how training on specific pitch cues may change this neural code. Trends in our previous datasets suggest that a &amp;quot;pitch center&amp;quot; may exist on the low-frequency border of primary and secondary tonotopic auditory cortex, but this possibility requires direct experimental testing. We will use a combination of microelectrode recordings and 2-photon imaging of calcium dynamics to determine if a pitch-selective region exists in ferret auditory cortex. The temporal precision of microelectrode recordings will be used to identify the spiking codes for pitch in this region, while the superior spatial resolution of 2-photon imaging will allow us to densely sample the tuning properties of neighboring neurons in this region. The 2-photon imaging experiments are ideally suited to clarify whether the pitch of complex sounds is mapped across the auditory cortical surface.</gtr:technicalSummary><gtr:potentialImpactText>Our research investigates the sound properties that animals and humans use to determine the &amp;quot;pitch&amp;quot; (i.e. the tonal quality) of a sound, and determines how activity in brain cells carry out this process. The interdisciplinary nature of this research means that it will impact upon a wide range of academic fields, which are fully described in Academic Beneficiaries. Significantly advancing just one of these areas would provide a huge step forward for neuroscience. 

Our integration of computational modeling with behavioural and physiological studies aims to promote future links between mathematical biology and neuroscience. We will also develop methods to efficiently measure the activity of very large numbers of brain cells simultaneously, through multi-channel electrophysiology and 2-photon imaging. These methods allow neuroscientists to answer questions about brain function more quickly and economically. We know of only 2 other labs worldwide that carry out in vivo 2-photon imaging in ferrets, so by developing this technique we will enhance the UK's research portfolio. Together, these modeling and high-yield physiological studies answer society's call for replacement, reduction and refinement of the use of animals in scientific research. 

The public has a natural interest in how animals experience the world. Our research offers insights into how our own perception of the musical quality of sounds relates to that of other animal species. This knowledge can help pet owners and farmers communicate with animals, and may guide government regulations that protect animal's natural environments (e.g. does traffic noise affect animals' ability to communicate?). We will develop our computational model of animal hearing into one in which anyone can listen to the sounds in their current environment through &amp;quot;animal ears&amp;quot;. We will make this program available for people to use on our website, and if it is popular we will also develop it as an &amp;quot;app&amp;quot; for mobile phones and ipads. 

Ageing has a detrimental effect on people's ability to process temporal pitch cues, and this in turn limits their ability to communicate in moderately noisy environments, such as restaurants. One study suggests that this temporal processing impairment may begin as early as middle age, so it is likely to affect the day-to-day hearing and social health of a large portion of society. Our research will provide new insights into the relation between temporal processing and pitch perception. We will elucidate the neural codes for temporal pitch cues, which are likely to be the same neural mechanisms that are disrupted in aging hearing. Our research will help clinical audiologists understand the impact of age-related hearing impairments on pitch perception. 

The commercial development of training-based treatments for temporal processing impairments in children have had successfully improved hearing and language outcomes for some people. The hearing of elderly individuals may similarly be improved through training regimes, but this possibility remains to be explored. Our experiments will help to push this area forward, by testing how training in adult ferrets can improve pitch discrimination thresholds and how it may alter the neural code for pitch.

As predominantly temporal pitch processors, ferret experiments could be a useful model of pitch perception in cochlear implant (CI) users. Due to the technical limitations, CIs provide highly degraded spectral resolution to the auditory nerve, so CI users are more reliant on temporal cues than healthy listeners. Unfortunately, the temporal signals currently provided by cochlear implants are also very crude, and so pitch perception in these listeners is severely impaired to the point where they cannot hear the melody of most music. Therefore, understanding how the brain makes adaptive use of temporal and spectral pitch cues will help companies to design better cochlear implants and hearing aids.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-01-03</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2016-01-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>497364</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Oxford</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Plant Sciences</gtr:department><gtr:description>StringerAhmad</gtr:description><gtr:id>21D83B0D-8B3D-4262-A4D3-4EEF4810ABEA</gtr:id><gtr:impact>This project has already resulted in a joint peer-reviewed journal article, which describes an unsupervised learning network built to identify the fundamental frequency (i.e. the pitch) of sounds.
doi: 10.3389/fncom.2016.00024</gtr:impact><gtr:outcomeId>58c979de6909d4.91539135-1</gtr:outcomeId><gtr:partnerContribution>Simon has a long track record in computational models, especially in models of the visual system. He is guiding the development of our models. Nasir has been doing the hands-on programming work for this project, as well as integrating the expertise of Simon and I, as needed for the project. Another past student of Simon's, Dr Irina Higgins, contributed directly to this work by writing some of the original code we are using.</gtr:partnerContribution><gtr:piContribution>I am co-supervising a doctoral student, Mr Nasir Ahmad, with Prof Simon Stringer in our Dept of Experimental Psychology. Nasir's doctoral thesis is developing neural network models for the identification and classification of speech sounds, including pitch. Therefore, it is directly relevant to my research on the current BBSRC New Investigator Award. I am providing expertise on the acoustical cues that support the identification of phonemes and pitch in human listeners, and the brain mechanisms thought to underlie these processes.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>ARO 2017</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>35C88922-E505-49E3-8EE4-034E4AD9B7CD</gtr:id><gtr:impact>Dr Gaucher presented the initial results of our research at the annual meeting of the Association for Research in Otolaryngology. This meeting is not limited to academic researchers in the field of hearing, but is also attended by those working in industries that develop prosthetic hearing devices (e.g. cochlear implants) and medical practitioners (e.g. audiologists and ENT surgeons).</gtr:impact><gtr:outcomeId>58c9bd43105315.00959989</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.aro.org/?page=2017MWM</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Super Science Saturday</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>A4CFD349-807A-4095-A68F-B1C7C73F3D44</gtr:id><gtr:impact>The postdoctoral research scientist on this project, Dr Gaucher, took part in &amp;quot;Super Science Saturday&amp;quot; at the Natural History Museum, Oxford. He hosted an interactive activity display, which taught people how their brain interprets speech sounds. Over a hundred individuals, from young children to the elderly, took part in this event. People reported that they learned a lot about hearing from this activity, especially with regard to how visual input can alter their perception of sound.</gtr:impact><gtr:outcomeId>58c9bb4f945ae8.35527713</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.oum.ox.ac.uk/visiting/whatson.htm</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Guarantors of Brain Travel Grant</gtr:description><gtr:end>2017-02-02</gtr:end><gtr:fundingOrg>Guarantors of Brain</gtr:fundingOrg><gtr:id>4133A242-B73A-4CD4-8A8F-90C38D1F3CA5</gtr:id><gtr:outcomeId>58c97aa1bffaf9.13649474</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2017-02-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>96000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Christopher Welch Scholarship</gtr:description><gtr:end>2019-10-02</gtr:end><gtr:fundingOrg>University of Oxford</gtr:fundingOrg><gtr:id>FE3F4C3B-AB5F-400E-BBA5-04FC02E82879</gtr:id><gtr:outcomeId>58c97c7f633f46.42599949</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-10-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This research project aims to better understand how brain activity gives rise to the perception of the tonal quality of sound, known as &amp;quot;pitch&amp;quot;. Through two collaborative streams in this project, we have begun to achieve this aim using computer-based artificial neural networks (commonly known as &amp;quot;artificial intelligence&amp;quot;). In a collaboration with Prof Simon Stringer and Mr Nasir Ahmad (Experimental Psychology; University of Oxford) we have developed a computer program that uses a statistical approach called &amp;quot;unsupervised machine learning&amp;quot; to recognize the pitches of new sounds, based on previous sound exposure. The successes and failures of this algorithm offer new insights and hypotheses about how activity in nerve cells may give rise to our own experience of pitch. In the second collaboration with Prof Josh McDermott (MIT) and Mr Ray Gonzalez (Harvard University), we have developed related computer algorithms, called &amp;quot;deep neural networks&amp;quot;, that can discriminate high- from low-pitched sounds. In this research, the inner ear's responses to sounds were artificially generated using an established model of the human auditory nerve, which we modified to model the auditory nerve of ferrets. Our model provided us with predictions of how ferrets and humans would perform on a pitch discrimination task. In parallel, we have been testing the hearing of ferrets and human listeners on a pitch discrimination task, and the results of these studies identified key differences between how humans and animals hear the pitch of sounds. The computational modelling helps us understand that these species differences in perception may partly arise due to differences in the auditory nerve responses. Finally, our BBSRC-funded postdoctoral scientist, Dr Quentin Gaucher, along with a doctoral student, Mr Aleksandar Ivanov, and I have been using a modern microscope technique called 2-photon calcium imaging to video the activity of large numbers of neurons in the ferret brain while sounds are presented to the animal over headphones. The animal is under general anaesthetic during the procedure, so that they do not experience pain or discomfort. To our knowledge, we are the first group in the world to successfully apply this technology to study auditory processing in any species other than mice. This is essential in advancing hearing science, as the ferret hearing range and brain organization are more similar than mice to those of humans. Our initial results help settle a current debate in hearing science by demonstrating that although the auditory cortex contains a spatial map of tone frequency, this is a &amp;quot;messy&amp;quot; map. That is, individual neurons located nearby one another can have vastly different frequency responses. This had recently been demonstrated in mice, but it remained unclear whether it was a more general feature of mammalian brains. During this work, Dr Gaucher and Mr Ivanov developed many new surgical, analytical and managerial skills that will be valuable to them in their future scientific careers.</gtr:description><gtr:exploitationPathways>Our research has the potential to improve the design of prosthetic hearing devices or computer-based speech recognition software. Fostering links with industry will help us promote these applications. Dr Gaucher and I have been presenting our findings to specialists at conferences and seminars. Dr Gaucher recently presented our results at an international meeting which is attended by thousands of academics, individuals in the prosthetic designer industry (e.g. cochlear implants and hearing aids), and medical practitioners (e.g. audiologists and ENT surgeons). We have also been sharing our knowledge of hearing with the more general public at outreach events, and we are dedicated to continuing our involvement in these public engagement events.

Our computational models can be straightforwardly modified to provide predictions for other species. We will promote the use of these models to other labs by making the code freely available on our website. The general public may be interested in an &amp;quot;app&amp;quot; version, in which they can hear the world through simulated animal ears.

Finally, we have published our results in Frontiers, an open access journal where anyone may read our work online and free of charge. We will continue to prioritize open-access journals.</gtr:exploitationPathways><gtr:id>B4EA2CF0-A9A6-4B71-8F4E-69F1FECA2993</gtr:id><gtr:outcomeId>56d6f5febb0d69.77901975</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors><gtr:url>http://journal.frontiersin.org/article/10.3389/fncom.2016.00024/full</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>An unsupervised learning algorithm is used to train an artificial neural network to represent the pitch of sounds.</gtr:description><gtr:id>F9C7FA24-3B7F-458F-8D59-356811BAA702</gtr:id><gtr:impact>By using machine learning algorithms to help us understand potential brain processes, we promote the use of computer-based research that can help reduce the need for animal experimentation. Unfortunately, this approach does not replace the need for animal experiments entirely, as it can only be used to develop theories and make predictions that ultimately must be tested in physiological organisms. However, this complimentary approach of modelling and measuring should help us design better animal experiments that ask the right questions, thereby refining and reducing the use of animals in research.</gtr:impact><gtr:outcomeId>58c9c28019bf21.09922825</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Pitch learning in a neural network</gtr:title><gtr:type>Computer model/algorithm</gtr:type></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>We have made minor modifications to an existing model of the human auditory nerve, in order to use it to predict activity in the ferret auditory nerve. This model can be run on any desktop computer.</gtr:description><gtr:id>90C0BF14-32CA-481F-9D94-60690F1C4ECE</gtr:id><gtr:impact>These computational models may advance the 3R's by reducing the need for animal experiments. In particular, by providing reliable predictions of auditory nerve responses, we reduce the need to record these responses from animals.</gtr:impact><gtr:outcomeId>58c9c12a23fd41.82038800</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Auditory nerve model</gtr:title><gtr:type>Computer model/algorithm</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>We have developed techniques to apply 2-photon calcium imaging of neural responses in adult ferrets. This allows us to visualize and measure the activity of hundreds of neurons in the brain simultaneously. This technique has previously been used to study the auditory system of mice and the visual and somatosensory systems of juvenile ferrets, but so far methodological challenges have rendered this technique unfeasible in larger animals such as the adult ferret. Thanks to the BBSRC's funding of a dedicated postdoctoral scientist to this project, we have overcome these challenges and gained new information about the auditory cortex that was not attainable using previous techniques.</gtr:description><gtr:id>13284233-203E-499E-8ACB-5FB6D6304EE1</gtr:id><gtr:impact>Developing this technique helps us to improve on the 3R's. The ability to image large numbers of neurons simultaneously may help us reduce the number of animals used in neurophysiological research, as we can study a larger number of cells in each individual animal. By confirming that results previously obtained using this technique in mice also hold in the ferret, we provide support for mice as an animal model. This could lead to carnivores being replaced by mice in future studies of this sensory system.</gtr:impact><gtr:outcomeId>58c9bfe2011440.91441164</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>in vivo 2-photon calcium imaging in ferrets</gtr:title><gtr:type>Physiological assessment or outcome measure</gtr:type></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>78A3340C-A05F-44FC-B3D0-251AC2A8B70C</gtr:id><gtr:title>Harmonic Training and the Formation of Pitch Representation in a Neural Network Model of the Auditory Brain.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8ddc4f2aa0e381f4865faac43d0c603e"><gtr:id>8ddc4f2aa0e381f4865faac43d0c603e</gtr:id><gtr:otherNames>Ahmad N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn><gtr:outcomeId>585d435252fc62.45668204</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M010929/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>FA8953A0-71F7-49B0-AC17-5CC7AECA6A83</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>3Rs</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E793F7FE-614C-4A45-83A0-BE79B172092C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal &amp; human physiology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>