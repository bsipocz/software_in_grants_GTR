<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:department>Computing Science and Mathematics</gtr:department><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DDEAF342-ACDE-4E8A-A0F0-9B532DB0B35A"><gtr:id>DDEAF342-ACDE-4E8A-A0F0-9B532DB0B35A</gtr:id><gtr:name>QinetiQ Ltd</gtr:name><gtr:address><gtr:line1>Cody Technology Park</gtr:line1><gtr:line2>Ively Road</gtr:line2><gtr:postCode>GU14 0LX</gtr:postCode><gtr:region>South East</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/920D4B94-896B-439B-85B9-F1EEFBCCBF87"><gtr:id>920D4B94-896B-439B-85B9-F1EEFBCCBF87</gtr:id><gtr:firstName>Leslie</gtr:firstName><gtr:otherNames>Samuel</gtr:otherNames><gtr:surname>Smith</gtr:surname><gtr:orcidId>0000-0002-3716-8013</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG062609%2F1"><gtr:id>9D167220-24D9-4303-8A0A-BD2C314B6CC4</gtr:id><gtr:title>A multichannel adaptive integrated MEMS/CMOS microphone</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G062609/1</gtr:grantReference><gtr:abstractText>There are many different types of microphones: their primary function is transduction: converting pressure waves (within some range of frequencies) into a single electrical signal, usually as precisely as possible. After this, the signal may be used for recording or for interpretation (which is our interest here). A major problem in interpretation is that the signal may have a large amount of energy in some parts of the auditory spectrum, but much less in others, and that this distribution may alter rapidly. Often, it is the energy in these lower energy areas that is critical for interpretation. Current practice is to filter the single electrical signal from the microphone (whether using FFTs, or bandpass filters), then examine the signal so produced. We propose a different approach in which the pressure wave is directly transduced into multiple electrical signals, corresponding to different parts of the audible spectrum. By making the transducers active (i.e. providing them with a rapidly adjusting gain control), we will be able to increase the sensitivity of the filters in those areas where additional sensitivity can be useful in the interpretation task, and reduce the sensitivity in those areas where the signal is very strong. The auditory interpretation tasks undertaken by animals (solving the what and where tasks when there are - as is normally the case - multiple sound sources in a reverberant environment) is the same task that an autonomous robot's auditory system needs to undertake. Animal hearing systems include multiple transducers, and provide numerous outputs for different parts of the spectrum, whilst adjusting their sensitivity and selectivity dynamically. Current microphones provide a single electrical output, which is then either processed into a number of bandpass streams (maintaining precise timing), or into a sequence of FFT-based vectors, such as cepstral coefficients (losing timing precision). The proposed active MEMS microphone performs the spectral breakdown at transduction, providing an inherently parallel output whilst maintaining precise timing. Further, it is adaptive. This adaptive capability, non-existent in current microphones is important in hearing aids. Precise timing information is important for source direction identification using inter-aural time and level differences. Where there are multiple active sources, accurate foreground source interpretation requires some degree of sound streaming, requiring the ability to examine features of the sound, often in spectral areas which with relatively low energy.The active MEMS bandpassing microphone will consist of a membrane which will vibrate due to the external pressure wave. The membrane is physically linked to different resonant elements (bars) in the MEMS structure - these elements will have a range of resonant frequencies. Further, these bars will act as gates for MOS transistors, resulting in their vibration modulating the current passing through these transistors. The modulated current will be coded as a set of sequences of spikes, and these spikes processed to provide a signal to adjust the sensitivity of each of the resonators by using an electrostatic effect to change the response of the transistors to the vibration of the bars. The modulation will be used to adjust the gain so that quiet areas of the spectrum are selectively amplified and loud areas of the spectrum selectively attenuated. In this way, it will be possible to build an integrated MEMS/CMOS microphone which can attenuate loud areas of the spectrum concurrently with amplifying quiet areas of the spectrum. The spike coded output will be made available in a way compatible with the address-event representation (AER), making it compatible with existing and proposed neuromorphic chips form other laboratories.</gtr:abstractText><gtr:fund><gtr:end>2014-09-07</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-03-08</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>353817</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>IJCNN workshop</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A2A40366-B0F7-4F7A-AC4F-D18082DBA2A0</gtr:id><gtr:impact>Good questions, discussions

Good discussions and questions, also applicants for a PhD applied to Stirling internationally.</gtr:impact><gtr:outcomeId>545ca742b22172.21468442</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>ICANN 2014 conference</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>4BDCBC57-A65D-4083-8F24-02F8C5ED972A</gtr:id><gtr:impact>Good questions and discussion afterwards

Possible collaboration with a group in Hamburg.</gtr:impact><gtr:outcomeId>545ca839a38231.43380655</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Acoustical Society of America meeting Spring 2011</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>EE2955D8-84B3-4E2C-9231-B1794A893BF7</gtr:id><gtr:impact>Good questions, discussions, international interest in research area.

Real interest from a number of US groups, particularly those involved in music analysis</gtr:impact><gtr:outcomeId>545ca6be95e755.86213466</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Acoustical Society of America 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>DDC4290E-382F-4C40-8365-C1570884F524</gtr:id><gtr:impact>One talk given, one poster presented. Good questions and discussions from both

Interest from abroad - collaboration with groups in Barcelona and Mexico looks likely.</gtr:impact><gtr:outcomeId>545ca7ec6c7177.92631579</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>DemoFest2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>110721E0-54B0-4A45-98FA-F7606EE23E02</gtr:id><gtr:impact>Activity involved presenting research to a mixture of interested parties, including SMEs, industry partners, as well as academics. There has been some interest as a result , but it is still early days..

Considerable interest in possible application of t=some of the techniques demonstrated, most notably our new sound segmentation technique.</gtr:impact><gtr:outcomeId>546391ead38465.92561600</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.sicsa.ac.uk/knowledge-exchange/industry-collaboration/demofest/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>1ACCD988-6127-4ADB-9B0D-AB944D35353E</gtr:id><gtr:impact>Public lecture (in public lecture series organised by the University of Stirling) entitled &amp;quot;Hear here: from the ear to the brain&amp;quot;.</gtr:impact><gtr:outcomeId>56b084461051e1.04010546</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.maths.stir.ac.uk/lectures/lectures%202014.html</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The research aimed to develop MMS technology beams and membranes that could act as gates for resonant field effect transistors: the idea was that the beams or membranes would vibrate and modulate the current through the field effect transistor. What we found was that building such beams and membranes, with very small spacing s from the silicon substrate below them was very difficult. What we discovered was that different materials, including composite materials could be used to build the structures, and that these could then be annealed to reduce stresses. We discovered that a more complete material was required (and are now investigating graphene).</gtr:description><gtr:exploitationPathways>There is now a new grant using graphene and a redesigned microphone architecture being undertaken by part of the same team: see EPPSRC grant EP/M026914/1. The overall likely eventual applications remain in tiny microphones, particularly in specialised microphones that perform on-microphone signal processing, with likely application in hearing aids and hearing for autonomous devices.</gtr:exploitationPathways><gtr:id>E59D1765-E1FF-458F-B270-A60BA8208DE8</gtr:id><gtr:outcomeId>56b07cd7267995.00853418</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Electronics,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>A3849160-7761-43A6-A233-046028FF6282</gtr:id><gtr:title>A low-noise interface circuit for MEMS cochlea-mimicking acoustic sensors</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0218-0</gtr:isbn><gtr:outcomeId>doi_53d059059c2286d4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EC59FC59-9088-4DC2-9D04-FD146756C18B</gtr:id><gtr:title>Low frequency tantalum electromechanical systems for biomimetical applications</gtr:title><gtr:parentPublicationTitle>Journal of Vacuum Science &amp; Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/db23efad79e944462efb8618abf8fa68"><gtr:id>db23efad79e944462efb8618abf8fa68</gtr:id><gtr:otherNames>Latif R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d06d06d33cf71f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>54C76930-AFFC-44BC-8399-03D7BF679396</gtr:id><gtr:title>Microelectromechanical systems for biomimetical applications</gtr:title><gtr:parentPublicationTitle>Journal of Vacuum Science &amp; Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/db23efad79e944462efb8618abf8fa68"><gtr:id>db23efad79e944462efb8618abf8fa68</gtr:id><gtr:otherNames>Latif R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d06d06d2ece56c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>02881C5D-9940-4156-B41C-526FD0790B08</gtr:id><gtr:title>Bimaterial electromechanical systems for a biomimetical acoustic sensor</gtr:title><gtr:parentPublicationTitle>Journal of Vacuum Science &amp; Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5c996f449823c1ce831f5ded2521f7db"><gtr:id>5c996f449823c1ce831f5ded2521f7db</gtr:id><gtr:otherNames>Mastropaolo E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d06d06d35c029e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>844CEF0B-45E8-4F78-BBE1-A73A4A4D6601</gtr:id><gtr:title>Using spiking onset neurons and a recurrent neural network for musical sound classification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ffc427609257547264e55b13ee00299e"><gtr:id>ffc427609257547264e55b13ee00299e</gtr:id><gtr:otherNames>Leslie Smith (Co-author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>m_945404578313ed4820</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>98B0D126-AC2F-4A61-A324-74B0E05B90E8</gtr:id><gtr:title>A Power-Efficient Capacitive Read-Out Circuit With Parasitic-Cancellation for MEMS Cochlea Sensors.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on biomedical circuits and systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1932-4545</gtr:issn><gtr:outcomeId>585d49273de728.11693582</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>521B424D-30A4-4558-A31B-81F5B6E7C714</gtr:id><gtr:title>A Bio-Realistic Analog CMOS Cochlea Filter With High Tunability and Ultra-Steep Roll-Off.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on biomedical circuits and systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e28ac287c010756bd48daf4772ba293c"><gtr:id>e28ac287c010756bd48daf4772ba293c</gtr:id><gtr:otherNames>Wang S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1932-4545</gtr:issn><gtr:outcomeId>54468113ae6994.28824497</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CD2B9FE8-308E-4805-B51B-AAA93C4E0D39</gtr:id><gtr:title>A neurally inspired musical instrument classification system based upon the sound onset.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/774902c52117c0da8260269ee76957f4"><gtr:id>774902c52117c0da8260269ee76957f4</gtr:id><gtr:otherNames>Newton MJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>doi_53d06e06eb8c7124</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4A25B849-F1BF-4A59-9E56-612A60F945F1</gtr:id><gtr:title>Toward a neuromorphic microphone.</gtr:title><gtr:parentPublicationTitle>Frontiers in neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e033020c361df9cd7cd62f0a97c6aca2"><gtr:id>e033020c361df9cd7cd62f0a97c6aca2</gtr:id><gtr:otherNames>Smith LS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1662-453X</gtr:issn><gtr:outcomeId>56b07f46b9b442.01269879</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>10058B5F-8A5A-42F0-B93E-4A57E92219A6</gtr:id><gtr:title>Design of a spike event coded RGT microphone for neuromorphic auditory systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/af0ce792135955a14dd1c325b2ff242c"><gtr:id>af0ce792135955a14dd1c325b2ff242c</gtr:id><gtr:otherNames>Koickal T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4244-9473-6</gtr:isbn><gtr:outcomeId>doi_53d059059bf75589</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>23640D97-9099-4416-B8EF-439C0FAF4C61</gtr:id><gtr:title>A biologically inspired onset and offset speech segmentation approach</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5b7541c8847417d067197533703c402e"><gtr:id>5b7541c8847417d067197533703c402e</gtr:id><gtr:otherNames>Abel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56b07f8c63bc77.79448847</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G062609/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>67935C1F-34EE-43B3-9BBC-F5A8E0FB2365</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Electronic Devices &amp; Subsys.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>2770EFE0-D127-47F1-9FC0-AABDCE301DD3</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>VLSI Design</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>