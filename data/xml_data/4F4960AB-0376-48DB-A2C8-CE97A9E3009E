<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/83D87776-5958-42AE-889D-B8AECF16B468"><gtr:id>83D87776-5958-42AE-889D-B8AECF16B468</gtr:id><gtr:name>University of Leeds</gtr:name><gtr:department>Institute for Transport Studies</gtr:department><gtr:address><gtr:line1>University of Leeds</gtr:line1><gtr:line4>Leeds</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>LS2 9JT</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/83D87776-5958-42AE-889D-B8AECF16B468"><gtr:id>83D87776-5958-42AE-889D-B8AECF16B468</gtr:id><gtr:name>University of Leeds</gtr:name><gtr:address><gtr:line1>University of Leeds</gtr:line1><gtr:line4>Leeds</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>LS2 9JT</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/909C646F-C9A3-42E9-BB1D-579B9B63772D"><gtr:id>909C646F-C9A3-42E9-BB1D-579B9B63772D</gtr:id><gtr:name>Arup Group Ltd</gtr:name><gtr:address><gtr:line1>13 Fitzroy Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>W1T 4BQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/20C41513-4169-4544-AAC7-D255A0731E24"><gtr:id>20C41513-4169-4544-AAC7-D255A0731E24</gtr:id><gtr:firstName>Phil</gtr:firstName><gtr:surname>Purnell</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F98E7D09-FFFE-4212-844E-D01A5A03BCDD"><gtr:id>F98E7D09-FFFE-4212-844E-D01A5A03BCDD</gtr:id><gtr:firstName>Robert</gtr:firstName><gtr:surname>Richardson</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/536F3BE2-3643-4893-9C63-18E5969F363B"><gtr:id>536F3BE2-3643-4893-9C63-18E5969F363B</gtr:id><gtr:firstName>Roy</gtr:firstName><gtr:surname>Ruddle</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9C8650DA-6922-468E-819B-FA76044AB37E"><gtr:id>9C8650DA-6922-468E-819B-FA76044AB37E</gtr:id><gtr:firstName>Lisa</gtr:firstName><gtr:surname>Roberts</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DE0CEBB6-9C5F-4FEC-8714-B13526DCB21B"><gtr:id>DE0CEBB6-9C5F-4FEC-8714-B13526DCB21B</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Hogg</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DEBAD497-6B62-4964-B959-DCE14D4898FC"><gtr:id>DEBAD497-6B62-4964-B959-DCE14D4898FC</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:otherNames>McGilchrist</gtr:otherNames><gtr:surname>Wilkie</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/54C5F3C8-A506-44F4-9775-94370E0F3A08"><gtr:id>54C5F3C8-A506-44F4-9775-94370E0F3A08</gtr:id><gtr:firstName>Natasha</gtr:firstName><gtr:surname>Merat</gtr:surname><gtr:orcidId>0000-0003-4140-9948</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8E6A83D4-0580-4CAF-B5AE-CAFC732E8703"><gtr:id>8E6A83D4-0580-4CAF-B5AE-CAFC732E8703</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:surname>Romano</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FR008833%2F1"><gtr:id>4F4960AB-0376-48DB-A2C8-CE97A9E3009E</gtr:id><gtr:title>Multi-Disciplinary Pedestrian-in-the-Loop Simulator</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/R008833/1</gtr:grantReference><gtr:abstractText>Pedestrians represented roughly 24% of road fatalities and 22% of the seriously injured in the UK in 2015 (Department for Transport, Reported Road Casualties Great Britain: 2015, Annual Report). The most commonly recorded factors were: &amp;quot;in accidents where a pedestrian was killed or injured; pedestrian failed to look properly was reported in 59 per cent of accidents. Failed to judge other person's path or speed was the most typical secondary cause.&amp;quot; (DfT, 2015)

In this context, the increased use of Autonomous Vehicles (AVs) and new urban warning systems that can help monitor and assist pedestrians and their interactions with vehicles has the potential to dramatically reduce road deaths. A major concern, however, is that the AVs and warning systems must be designed to take into account the capabilities and limitations of pedestrians. 

This project will develop a new pedestrian laboratory to support safe experimental research in a repeatable fashion in which a variety of variables with respect to AV design, warning system design, and intersection configuration can be studied. The experiments can also look at the impacts of a wide range of human factors including age, vision and mobility.

The pedestrian laboratory (PEDSIM) will consist of a Virtual Reality (VR) simulator that will allow a participant to experience a variety of urban configurations and interact with new vehicles and urban robots. The pedestrian laboratory will track the participant's performance in a variety of tasks to compare the effectiveness of various designs.

What makes the PEDSIM unique in the world is its very high resolution displays combined with its large walkable environment (9 metres by 4 metres) and its integration with driving simulators to test interactions between pedestrians and drivers.

As automated and autonomous vehicles get closer to deployment, research into their design and impact has rapidly increased. There are several studies currently funded by the EPSRC that can take immediate advantage of the new research capabilities of the PEDSIM. These include research to evaluate solutions for cooperative interaction of automated vehicles and urban robots with pedestrians and research that will test various lighting conditions and its impact on visibility, trip hazards, and understanding intentions of other pedestrians and vehicles.</gtr:abstractText><gtr:potentialImpactText>The aim of PEDSIM is to provide a true-to-life, CAVE-based, simulated walking environment, for addressing a number of key research questions on human performance and interaction relevant to both today and tomorrow's needs. The PEDSIM will also be integrated with the other well established simulator facilities at the University of Leeds, to provide a distributed simulation suite, as part of the Virtuocity concept, delivering a pioneering and unique research environment in the UK for investigating the interaction of humans with new technologies and infrastructures, in a highly-controllable, low-cost and safe setting. Work achieved by the PEDSIM will provide the full range of impacts, including creating wealth, enhancing knowledge, informing policy, and improving quality of life.

Economic Impact -Work conducted on the PEDSIM and the distributed simulation suite is relevant to a vast range of disciplines, providing knowledge on matters such as: the design of effective road and pavement layouts for tomorrow's cities, understanding how technologies can assist impaired and disabled users, and how pedestrians will communicate with fully automated vehicles. This leads to direct economic benefit, via inward investment from relevant stakeholders wishing to investigate the interaction of humans with their prototypes, saving costs prior to production, and IP and commercialisation of new products and procedures. Research-led teaching programmes, using blended learning techniques, will provide a range of on-line learning platforms, accessible to a global student network, providing new revenue.

Societal Impact - The University of Leeds has a longstanding track record of translating research to knowledge for end-users, industrial partners, policy-makers, and the public at large. These activities are facilitated via direct collaboration, licencing of IP, or spin-out, all of which are used to provide a successful model for translational activity. The PEDSIM will be managed by the internationally renowned team at the University of Leeds Driving Simulator, who have longstanding strategic partnerships with a large group of industrial end-users in the UK, and beyond, including all leading vehicle manufacturers (e.g. Jaguar Land Rover, Volvo, VW, Ford, Fiat, Renault and Nissan). International development will be achieved by addressing future research needs on human factors of automated vehicles, discussed by members of the group at high-level UK, US and European steering group meetings such as the H2020 Transport Advisory Group, the EC's Strategic Transport Research and Innovation Agenda (STRIA), and the EC's high level GEAR2030 group, assembled to &amp;quot;boost competitiveness and growth in the automotive sector&amp;quot;.

Academic Impact forms part of the critical pathway towards economic and societal impact. The PEDSIM is accessible to a multidisciplinary team of leading academics in Leeds and beyond, who will disseminate results of research from the facility to an international audience, covering a range of disciplines; from Engineering and Infrastructure Design, to Human Interaction with Robotics, Psychology and Road User Behaviour, Virtual Reality testing, Artificial Intelligence, and Disability Studies. The facility will also provide exciting opportunities for collaboration across disciplines. Each academic partner and collaborator will also use the facility to provide training and new skills to students at undergraduate and postgraduate level, as well as enhancing the knowledge and expertise of current and future PDRAs and partnering on development of new teaching modules.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>653010</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/R008833/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>