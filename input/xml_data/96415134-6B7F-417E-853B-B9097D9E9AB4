<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:department>Sch of Life and Health Sciences</gtr:department><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7668367B-0887-49C4-A942-21A34A463430"><gtr:id>7668367B-0887-49C4-A942-21A34A463430</gtr:id><gtr:name>McGill Vision Research Unit</gtr:name><gtr:address><gtr:line1>McGill Vision Research Unit</gtr:line1><gtr:line2>687 Pine Avenue West</gtr:line2><gtr:line3>Rm. H4-14</gtr:line3><gtr:line4>Montreal</gtr:line4><gtr:line5>Quebec</gtr:line5><gtr:postCode>H3A 1A1</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/61571307-9F25-4F84-B4D5-C8ABCC05066B"><gtr:id>61571307-9F25-4F84-B4D5-C8ABCC05066B</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:otherNames>Andrew</gtr:otherNames><gtr:surname>Georgeson</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5B5C20B9-4E9D-44A6-87F9-45E09593090A"><gtr:id>5B5C20B9-4E9D-44A6-87F9-45E09593090A</gtr:id><gtr:firstName>Tim</gtr:firstName><gtr:surname>Meese</gtr:surname><gtr:orcidId>0000-0003-3744-4679</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FH000038%2F1"><gtr:id>96415134-6B7F-417E-853B-B9097D9E9AB4</gtr:id><gtr:title>The Spatial Integration and Segmentation of Luminance Contrast in Human Spatial Vision</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H000038/1</gtr:grantReference><gtr:abstractText>When we open our eyes, we see, without effort. Our visual experience begins with the mechanics of focussing the image on the back of eye; but to make sense of the image-to perceive-our brains must identify the various parts of the image, and understand their relations. Just like a silicon-based computer, the brain performs millions of computations quickly and effectively, more efficiently than we can ever sense. But what are the computations that are needed to recognise, say, your mother; to segment an object from its background; or even appreciate that one part of an image belongs with another? The starting point for this analysis is the distribution of light levels across the retinal image, which we can think of as a set of pixels. Interesting parts of the image (e.g. object boundaries) occur at regions of change: where neighbouring pixels have very different values. These regions are identified by neurons in primary visual cortex (V1) by computing differences between adjacent pixel values to build a neural image of local contrasts: the 'contrast-image'. These contrast-defined local image features are then combined across retinal space at later stages of the visual hierarchy to represent elongated contours (e.g. the branches of a tree) and textured surfaces (e.g. a ploughed field) in what is sometimes known as a 'feature-map'.One major goal in vision science is to construct accurate computer models of the visual system so that computers can be made to process images in the same way as human brains. But there has been a major obstacle. Experiments confirm that feature integration (summing) is involved in constructing the 'feature-map', but also imply that contrast is not summed beyond the neighbourhood of each local contrast processor in V1. But how can local feature representations be summed without also summing the underlying contrast codes?We achieved the breakthrough on this by designing novel images containing patches of contrast distributed over retinal space (Meese &amp;amp; Summers, 2007). These allowed us to measure the contrast integration process while controlling the confounding effects of neural noise and retinal-inhomogeneity that have plagued previous studies. By analysing the relation between visual performance (an observer's probability of detecting the target stimulus) and stimulus contrast, we showed that contrast is summed over substantial regions of the retina after all, but that under normal viewing conditions its effects go unnoticed because of a counterbalancing effect of blanket suppression from a system of contrast gain control. In other words, we have shown that contrast summation is organised very differently from the way first proposed. These results have dispelled orthodoxy and now prompt a thorough re-evaluation of our understanding of contrast and feature integration in human vision.In the current proposed project we will use our new type of stimulus and modelling framework to investigate the computational rules that control the point-by-point integration of information in the 'contrast image'. In particular, our working hypothesis proposes that the visual system does this by maximising the 'signal to noise ratio'. But what directs and limits the signal integration? And how does this relate to the grouping rules of Gestalt psychology and other results on contour integration and contrast perception? Through careful stimulus manipulations, our 19+ experiments will address these issues, mainly using normal healthy observers, but we will also study the disrupted amblyopic visual system as a way of further probing the system's organization. Overall, this work will illuminate the links between pixel-based contrast responses, and later region-based symbolic feature analyses. Only with these links in place can we begin to appreciate how the brain transforms the retinal image to the subjective experience of seeing.</gtr:abstractText><gtr:fund><gtr:end>2013-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>622851</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Our results have influenced work in several academic research laboratories across the globe.</gtr:description><gtr:firstYearOfImpact>2009</gtr:firstYearOfImpact><gtr:id>205E6362-7BD2-45FA-8090-96FD0AD3E2F8</gtr:id><gtr:impactTypes/><gtr:outcomeId>545d0b3201aff5.28276434</gtr:outcomeId><gtr:sector>Education,Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The image on the back of our eye is broken down into tiny fragments by the initial stages of visual processing in the primary visual cortex. This decomposition is an important part of the initial analysis of the image, but objects, textures, surfaces and so on extend over much larger areas than each of the fragments, so how is it all sewn back together? This project focussed on one particular part of this problem: how image contrast is analysed by the brain across those millions of fragments. The results of psychophysical investigation and computational analysis have shed new insights into this, showing how a neural hierarchy underpins our perception of image contrast.</gtr:description><gtr:exploitationPathways>Our results will be of interest to anyone working on the perception and detection of image contrast.</gtr:exploitationPathways><gtr:id>37B69BB9-DBB8-49FD-B75A-92205695ED2D</gtr:id><gtr:outcomeId>545d0b8b251d38.22042721</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>FCA97FA2-4D56-472F-B82F-82315DFADA46</gtr:id><gtr:title>Cross-orientation masking is speed invariant between ocular pathways but speed dependent within them.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5448f498a4fdc0.96921216</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>93EA3F83-72E9-4768-B241-6F29E00E16DD</gtr:id><gtr:title>Nonlinearities in the binocular combination of luminance and contrast.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f0ab74d4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9789FEF2-FA40-4551-A178-09C5487B371D</gtr:id><gtr:title>Grid-texture mechanisms in human vision: Contrast detection of regular sparse micro-patterns requires specialist templates.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn><gtr:outcomeId>58987044dcfb78.17514869</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>034432EF-44B7-4E21-B695-E566810192F1</gtr:id><gtr:title>Suppression pathways saturate with contrast for parallel surrounds but not for superimposed cross-oriented masks.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>5448ee0c9f92c6.18476308</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F32D609E-9AAC-48A3-B875-0562A40CEE0E</gtr:id><gtr:title>The slope of the psychometric function and non-stationarity of thresholds in spatiotemporal contrast vision.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b6e14f0bc8cf77a6720b4428a55e298"><gtr:id>3b6e14f0bc8cf77a6720b4428a55e298</gtr:id><gtr:otherNames>Wallis SA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f0d580b5</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>761419F3-DE4C-4EA4-A4DC-DF658EE2068A</gtr:id><gtr:title>Regarding the benefit of zero-dimensional noise.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5448f0626f1cb9.20036494</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F67709A4-4342-46E1-9C95-4DC69C998BA7</gtr:id><gtr:title>Blobs versus bars: psychophysical evidence supports two types of orientation response in human color vision.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/18d1999bc4a78b05d7404b261e0e9495"><gtr:id>18d1999bc4a78b05d7404b261e0e9495</gtr:id><gtr:otherNames>Gheiratmand M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770774b11dc8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CEA9D44A-3ADF-4F87-871B-37A6DCA61958</gtr:id><gtr:title>Zero-dimensional noise: the best mask you never saw.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d07707745e1693</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F9216AB6-BEB4-45C7-8BE2-2769BA08F099</gtr:id><gtr:title>Measuring the spatial extent of texture pooling using reverse correlation.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>5448f11cb12df1.89663420</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>00880FB3-1337-41B0-86CD-7AD0762A7143</gtr:id><gtr:title>Paradoxical psychometric functions (&amp;quot;swan functions&amp;quot;) are explained by dilution masking in four stimulus dimensions.</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>2041-6695</gtr:issn><gtr:outcomeId>doi_53d039039597c132</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>08FAE14F-47AA-4252-8F7B-D2288E364CEE</gtr:id><gtr:title>Perception of global image contrast involves transparent spatial filtering and the integration and suppression of local contrasts (not RMS contrast).</gtr:title><gtr:parentPublicationTitle>Royal Society open science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2054-5703</gtr:issn><gtr:outcomeId>5a2fe61f35e261.78085805</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C01816D8-A924-4F32-9E2E-3F2A18187FE0</gtr:id><gtr:title>Orientation masking and cross-orientation suppression (XOS): implications for estimates of filter bandwidth.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d07707734ca884</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5EE5337E-0061-4D05-B0C1-CD2EE7FB339D</gtr:id><gtr:title>Area summation of first- and second-order modulations of luminance.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/77b4ebd385367d16c6b1c21141c7ec84"><gtr:id>77b4ebd385367d16c6b1c21141c7ec84</gtr:id><gtr:otherNames>Summers RJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_55f952952ae8db30</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F878560C-7882-4DED-AC32-FE1C118F4B07</gtr:id><gtr:title>Contrast and lustre: A model that accounts for eleven different forms of contrast discrimination in binocular vision.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d14311e8f34322798b7a9de3e84289fb"><gtr:id>d14311e8f34322798b7a9de3e84289fb</gtr:id><gtr:otherNames>Georgeson MA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>585d6fdc93fc51.19763963</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C1375E5A-2F4D-4F74-B3B2-FAAD79543084</gtr:id><gtr:title>Theory and data for area summation of contrast with and without uncertainty: evidence for a noisy energy model.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770774703c86</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>39726523-2C70-411C-A607-6EAEB22D0710</gtr:id><gtr:title>Interocular transfer of spatial adaptation is weak at low spatial frequencies.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f0c6cc01</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>38231803-E1BB-40ED-A93D-A76C5BF04925</gtr:id><gtr:title>What is the primary cause of individual differences in contrast sensitivity?</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>doi_55f95d95df97a118</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F345C99D-B1F5-4148-86BA-003EEE950490</gtr:id><gtr:title>The effect of interocular phase difference on perceived contrast.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>5448ef6ff3b811.00255490</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A5FC2213-BFEF-477D-8386-7C9F19B2E078</gtr:id><gtr:title>A two-stage model of orientation integration for Battenberg-modulated micropatterns.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a4667b6f0027dec2f10fd47fccd7fa9c"><gtr:id>a4667b6f0027dec2f10fd47fccd7fa9c</gtr:id><gtr:otherNames>Baldwin AS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>5448f0d58fad55.69961080</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7DB83EE9-11E0-4E97-8F42-D8CAD54C0759</gtr:id><gtr:title>Interocular suppression in normal and amblyopic vision: spatio-temporal properties.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5af710f9148323a36fb66c3be2955ffc"><gtr:id>5af710f9148323a36fb66c3be2955ffc</gtr:id><gtr:otherNames>Huang PC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_55f9779778c22e89</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>830E3830-47C3-4F13-B3EB-5CA65D3E6E04</gtr:id><gtr:title>Contrast integration over area is extensive: a three-stage model of spatial summation.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d07707741e756a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>12E4B909-CAC9-4879-9790-66311044F337</gtr:id><gtr:title>The attenuation surface for contrast sensitivity has the form of a witch's hat within the central visual field.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a4667b6f0027dec2f10fd47fccd7fa9c"><gtr:id>a4667b6f0027dec2f10fd47fccd7fa9c</gtr:id><gtr:otherNames>Baldwin AS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d077077466db31</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D41BB049-7B50-42E8-9F6E-19B6CA12EBD7</gtr:id><gtr:title>A common rule for integration and suppression of luminance contrast across eyes, space, time, and pattern.</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>2041-6695</gtr:issn><gtr:outcomeId>doi_53d0390395a11851</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2F9D835C-3BAC-4339-BABF-77409E4EB0F3</gtr:id><gtr:title>Spatially extensive summation of contrast energy is revealed by contrast detection of micro-pattern textures.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770773c17ac5</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4196B78F-8F46-4971-B6C1-5C32F9D0B248</gtr:id><gtr:title>Contrast summation across eyes and space is revealed along the entire dipper function by a &amp;quot;Swiss cheese&amp;quot; stimulus.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d0770773f12cb3</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FA671EA6-53EA-4286-9D88-BB98BEEF8782</gtr:id><gtr:title>Fourth-root summation of contrast over area: No end in sight when spatially inhomogeneous sensitivity is compensated by a witch's hat.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a4667b6f0027dec2f10fd47fccd7fa9c"><gtr:id>a4667b6f0027dec2f10fd47fccd7fa9c</gtr:id><gtr:otherNames>Baldwin AS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56af7f0012c6b9.26102115</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BEA7DD15-124D-45D1-9AD2-43993DDAE26C</gtr:id><gtr:title>A reevaluation of achromatic spatio-temporal vision: Nonoriented filters are monocular, they adapt, and can be used for decision making at high flicker speeds.</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>2041-6695</gtr:issn><gtr:outcomeId>doi_53d03903958e0a26</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H000038/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>