<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Medical and Human Sciences</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EE325D76-40A5-49DD-9DEC-B36D4B8F266F"><gtr:id>EE325D76-40A5-49DD-9DEC-B36D4B8F266F</gtr:id><gtr:name>Chuo University</gtr:name><gtr:address><gtr:line1>6-5-2-401</gtr:line1><gtr:line2>Josui-Honcho</gtr:line2><gtr:line3>Kodaira-Shi</gtr:line3><gtr:line4>Tokyo</gtr:line4><gtr:line5>187-0022</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Japan</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/01826C2B-0F67-4BCC-923B-A715B729ADF7"><gtr:id>01826C2B-0F67-4BCC-923B-A715B729ADF7</gtr:id><gtr:firstName>Christopher</gtr:firstName><gtr:otherNames>John</gtr:otherNames><gtr:surname>Taylor</gtr:surname><gtr:orcidId>0000-0001-7867-9533</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6AE6D6CD-7058-4E6A-801A-95FA183DD878"><gtr:id>6AE6D6CD-7058-4E6A-801A-95FA183DD878</gtr:id><gtr:firstName>Karen</gtr:firstName><gtr:surname>Lander</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D162A102-AA77-4D42-83D8-7A83844243A5"><gtr:id>D162A102-AA77-4D42-83D8-7A83844243A5</gtr:id><gtr:firstName>Timothy</gtr:firstName><gtr:otherNames>Francis</gtr:otherNames><gtr:surname>Cootes</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD056942%2F1"><gtr:id>B7BD1EF2-8224-4550-963B-E794C7B2EF3C</gtr:id><gtr:title>Cognitive Systems Foresight: Human and computer face recognition from video sequences</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D056942/1</gtr:grantReference><gtr:abstractText>This 3-year project is a collaboration between experts in computer vision techniques for recognising faces and experts in the psychology of how humans interpret faces. The aim is to produce a generative computational model of human facial processing, capable of both synthesizing and interpreting sequences of face images.This project will form the central part of an effort to build a computational model which will account for both familiar and unfamiliar moving face-recognition phenomena. This will draw from and contribute to the psychological knowledge in this area. It will have particular relevance to the effects of movement on recognition and its interaction with the process of facial learning. It is known that there are two separate psychological effects of movement, firstly representational enhancement'', which relates to the construction of 3-D static representations of the face and is associated with relatively unfamiliar faces. The other, a dynamic signature'', is the characteristic motion pattern of an individual. This is associated with more familiar faces; previous relevant computational work has concentrated upon representational enhancement issues.The particular aim of this research will be to construct a generative computational model of human facial processing, able to cope with variations in familiarity. To achieve this, we need to (a) build a system capable of learning the static characteristics of faces from multiple frames and (b) build a description of behaviour and its variation. In addition, in humans, we need to (c) investigate the process of facial movement learning and (d) investigate the representation of dynamic signatures. To support this research, a cross-cultural database of moving faces suitable for human and computer experiments will be collected. The computational model will be used to generate data for psychological experiments investigating the effects of movement on recognition. The results of these experiments will inform development of automatic face interpretation algorithms.</gtr:abstractText><gtr:fund><gtr:end>2009-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>226745</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>38B1A57B-B2A1-401F-BC90-0907B1A2F856</gtr:id><gtr:title>Exploring the motion advantage: evaluating the contribution of familiarity and differences in facial motion.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2e7c54aab4ee788dbaebc228d47cd6f0"><gtr:id>2e7c54aab4ee788dbaebc228d47cd6f0</gtr:id><gtr:otherNames>Butcher N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>585d33f190fa26.15133896</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7FC5BB73-C492-4643-8BA1-CDA153C6586A</gtr:id><gtr:title>Automatic feature localisation with constrained local models</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/13730a4783becf1ac8ce2811396e94c7"><gtr:id>13730a4783becf1ac8ce2811396e94c7</gtr:id><gtr:otherNames>Cristinacce D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53d004004490f6ec</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D056942/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>