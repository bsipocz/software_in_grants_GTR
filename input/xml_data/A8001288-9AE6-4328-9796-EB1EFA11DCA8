<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B6B6F6F8-2492-4C78-B98C-71372DA3ABC3"><gtr:id>B6B6F6F8-2492-4C78-B98C-71372DA3ABC3</gtr:id><gtr:firstName>Anthony</gtr:firstName><gtr:surname>Hunter</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD078695%2F1"><gtr:id>A8001288-9AE6-4328-9796-EB1EFA11DCA8</gtr:id><gtr:title>Argumentation Factory: Algorithms and Software for Industrial Strength Inconsistency Tolerance</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D078695/1</gtr:grantReference><gtr:abstractText>Humans constantly deal with conflicting information in their everyday lives, but until recently the problem has been largely avoided in computing. Being based on mathematical thinking, the normal approach to inconsistency in computing is to not tolerate it. This is done either by arbitrary removal of conflicting information or by recourse to human intervention. But as computers are being pushed into more intelligent roles with the need for greater robustness, inconsistency tolerance is an increasingly important topic in many areas of computer science including artificial intelligence, robotics, natural language processing, databases, information systems, and software engineering. Inconsistency is omnipresent in the world. So we need to design systems that can address the problems and the opportunities raised by the widespread existence of inconsistency. Recent developments in the theory of argumentation are suggesting that the development and application of argumentation systems could offer a significant technological advance in the development of robust inconsistency tolerance in a wide range of applications.Argumentation is a vital aspect of intelligent behaviour by humans. Consider diverse professionals such as politicians, journalists, clinicians, scientists, and administrators, who all need to collate and analyse information looking for pros and cons for consequences of importance when attempting to understand problems and make decisions. Hence, the development of argumentation systems for decision-support systems for professionals is a promising area. More generally, argumentation systems are increasingly being considered for applications in developing software engineering tools, for constituting an important component of multi-agent systems for negotiation and problem solving, and for data + knowledge fusion. In these kinds of application there is a need to analyse inconsistent information, find competing viewpoints, and resolve conflicts. By argumentation, we can determine that a certain proposition follows from certain assumptions but that one of these assumptions could be disproved (or 'undercut') by other assumptions in our premises. In this way an argumentation system could help us analyse which assumptions were really giving rise the inconsistency and which assumptions were harmless. Argumentation systems can be used to draw arguments from inconsistent information, and to compare them with counterarguments. The theory of logic-based argumentation is therefore helpful in analysing inconsistency and there have been impressive research advances recently. However, argumentation is computationally expensive, and little consideration has been given to how it can be done efficiently.We therefore have a pressing need to develop algorithms and software for generating constellations of arguments and counterarguments. For this, we need automated reasoning technology. However, existing automated reasoning is not designed for finding arguments: It can be used to find a proof of an inference from a set of premises. But it is not intended for finding minimal consistent sets of formulae for proving some inference. Furthermore, with the generating arguments and counterarguments, there is much inefficient recomputation of consistency checks, and of minimality checks, for the supports of the arguments.To address these shortcomings, we want to explore four inter-connected lines of research: (1) Develop algorithms and prototype implementation of system for harnessing existing automated reasoning technology for providing the entailment relation as part of the process of constructing arguments; (2) Develop algorithms and prototype implementation for contouring (a form of lemma generation) of knowledgebases; (3) Develop algorithms and prototype implementation for compilation of knowledgebases; and (4) Develop algorithms and prototype implementation for approximate argumentation.</gtr:abstractText><gtr:fund><gtr:end>2010-01-07</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-01-08</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>318954</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>50AC34FC-9CAE-4939-B8E0-65A3094FCC23</gtr:id><gtr:title>Real Arguments are Approximate Arguments</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e0ac359a029b271e9bd8086e3318795e"><gtr:id>e0ac359a029b271e9bd8086e3318795e</gtr:id><gtr:otherNames> A Hunter</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_748907152913cc3ee6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>42C76A43-382F-4B81-96C1-14EE2C7A245F</gtr:id><gtr:title>Algortihms for effective argumentation in classical propositional logic</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e0ac359a029b271e9bd8086e3318795e"><gtr:id>e0ac359a029b271e9bd8086e3318795e</gtr:id><gtr:otherNames> A Hunter</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_692657159713cc3e3c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>991AFB0D-5ECC-46C5-9F24-5F9D42A37C9F</gtr:id><gtr:title>A Relevance-theoretic Framework for Constructing and Deconstructing Enthymemes</gtr:title><gtr:parentPublicationTitle>Journal of Logic and Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e09b7a5bf2069e031f2267a5b9166661"><gtr:id>e09b7a5bf2069e031f2267a5b9166661</gtr:id><gtr:otherNames>Black E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d04704741c45b9</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CA0A3912-80E4-4A2D-A40A-169E48F9CF9F</gtr:id><gtr:title>Encoding deductive argumentation in quantified Boolean formulae</gtr:title><gtr:parentPublicationTitle>Artificial Intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ae02218f7ff887291869b49d39e6483"><gtr:id>1ae02218f7ff887291869b49d39e6483</gtr:id><gtr:otherNames>Besnard P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53cfe4fe4ab28452</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D078695/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>76783275-A9F8-4B4E-B314-51363124259C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Fundamentals of Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>