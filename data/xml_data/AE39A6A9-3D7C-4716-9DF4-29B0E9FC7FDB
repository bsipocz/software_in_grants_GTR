<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name><gtr:address><gtr:line1>BBSRC</gtr:line1><gtr:line2>Polaris House</gtr:line2><gtr:line3>North Star Avenue</gtr:line3><gtr:line4>Swindon</gtr:line4><gtr:postCode>SN2 1UH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E7015D6B-3846-4E4F-A5BB-CBF9B025EB07"><gtr:id>E7015D6B-3846-4E4F-A5BB-CBF9B025EB07</gtr:id><gtr:firstName>Stephen</gtr:firstName><gtr:surname>Furber</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6D30A795-755B-43E8-B4CB-6ECD347F1B90"><gtr:id>6D30A795-755B-43E8-B4CB-6ECD347F1B90</gtr:id><gtr:firstName>David</gtr:firstName><gtr:otherNames>Roland</gtr:otherNames><gtr:surname>Lester</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ00457X%2F1"><gtr:id>AE39A6A9-3D7C-4716-9DF4-29B0E9FC7FDB</gtr:id><gtr:title>BABEL</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J00457X/1</gtr:grantReference><gtr:abstractText>Recent advances in behavioural and computational neuroscience, in cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. 
This project aims at advancing the understanding of neural and behavioural mechanisms in word learning, the validation of these principles in neuroanatomically grounded models, and real-time implementations of brain language models within the SpiNNaker neuromorphic architecture that will support comparisons with neuroimaging experiments. The scientific hypotheses and cortical language model will also be validated by implementing a model of embodied active language learning on the humanoid robot iCub. Specifically, in the project we will develop, based on neuroscientific principles, a theory of language learning at the neural circuit level and build a neurocomputational model of the language cortex that implements the learning of words used to speak about objects and actions in large-scale neuronal circuits. This theoretical work will be supported by novel, hypothesis-driven brain imaging investigations using MEG, EEG and fMRI to identify the neural correlates and mechanisms of the learning of words for objects and actions. Imaging results will inform the improvement of the large-scale neuroanatomical models. These models will be implemented on the SpiNNaker software and hardware infrastructure, to implement a scaled-up real-time model of the language cortex using more realistic spiking activity. Finally, the project will translationally apply these neuro-anatomical models and SpiNNaker system as controllers for language and action learning simulations with the humanoid robot iCub, within the embodied and active learning context where the semantics of the language is directly driven by the context of object manipulation tasks.
This is a highly interdisciplinary project that integrates essential expertise and methodologies from neuromorphic engineering, computational and experimental neuroscience, and cognitive robotics. The project is based around the unique and strategic partnership of applicants with an international track record in these areas of expertise and with previous collaborative experience. Furthermore, the project will benefit from an International Advisory Board, with both academic and industrial advisors, to foster the international dimension and impact of the project.</gtr:abstractText><gtr:fund><gtr:end>2016-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>418561</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>319B195F-7988-4FCB-9484-F21BB907738C</gtr:id><gtr:title>A location-independent direct link neuromorphic interface</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/22230f1b999922b2cf2cd26c0fcb7361"><gtr:id>22230f1b999922b2cf2cd26c0fcb7361</gtr:id><gtr:otherNames>Rast A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53d05905973a4446</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5650FFD3-F677-4CFB-8624-EE3C093005C9</gtr:id><gtr:title>Live demonstration: Ethernet communication linking two large-scale neuromorphic systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fdb4993e1098a9ae5172c88d4eb11857"><gtr:id>fdb4993e1098a9ae5172c88d4eb11857</gtr:id><gtr:otherNames>Partzsch J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>57c7ebf096f258.36376806</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AF574727-4EFF-454B-AE35-EB8389EDFFCA</gtr:id><gtr:title>Visualising large-scale neural network models in real-time</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f476b6babebc0165a21e194df1819559"><gtr:id>f476b6babebc0165a21e194df1819559</gtr:id><gtr:otherNames>Patterson C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1488-6</gtr:isbn><gtr:outcomeId>doi_53d0590596f193ea</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J00457X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>772CD758-53CD-407F-9B2C-F2B861E86155</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Mechanical Engineering</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>