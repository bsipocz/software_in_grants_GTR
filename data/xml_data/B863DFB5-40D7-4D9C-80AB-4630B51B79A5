<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C7510606-A36F-4725-A89B-9D592374972A"><gtr:id>C7510606-A36F-4725-A89B-9D592374972A</gtr:id><gtr:name>University of Stirling</gtr:name><gtr:address><gtr:line4>Stirling</gtr:line4><gtr:line5>Stirlingshire</gtr:line5><gtr:postCode>FK9 4LA</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B01BF354-7AC7-47C5-A1C9-62C10636DAA0"><gtr:id>B01BF354-7AC7-47C5-A1C9-62C10636DAA0</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:surname>Hancock</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/4256CC78-A8A7-4A75-A268-BC3BA3A6CA00"><gtr:id>4256CC78-A8A7-4A75-A268-BC3BA3A6CA00</gtr:id><gtr:firstName>Bernard</gtr:firstName><gtr:surname>Tiddeman</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FJ010081%2F1"><gtr:id>B863DFB5-40D7-4D9C-80AB-4630B51B79A5</gtr:id><gtr:title>A 3d psychological face database and tools</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/J010081/1</gtr:grantReference><gtr:abstractText>&lt;p>The overall aim of this project is to enable the next generation of research into face perception and recognition by making available a rich database of face images, including many 3 dimensional scans, and the tools to manipulate and present them.&amp;nbsp; There are many existing collections of face images, usually collected for a specific project and often either very consistent or very varied, limiting their general utility.&amp;nbsp; The aim here is to collect both highly consistent and highly varied images of the same people, including 3D scans, both standard and stereo video sequences, and a variety of photographs. 3D imagery is becoming more common but the images remain difficult to use.&amp;nbsp;&lt;/p>

&lt;p>The second part of this project is therefore to develop tools for handling 3d images, for example morphing between two faces to create an average, or making a given face look older, or more trustworthy. Finally, it will make available two different software packages for presenting 3D faces in experiments. It is hoped that the database will gradually grow in value as researchers contribute their data, for example ratings of faces.&lt;br />&lt;br />&amp;nbsp;&lt;/p></gtr:abstractText><gtr:potentialImpactText>This project is essentially all about end impact, the only proposed academic output being a paper describing the image set and software for Behavior Research Methods, which itself will be a route to increasing the visibility of the collection. The aim is to facilitate advanced research, primarily in psychology, but also in artificial face recognition, as described in the section on academic beneficiaries. The consequences of that work have the potential for much wider impact.

Understanding how humans perform face recognition may be key to building effective artificial systems. The best such can already out-perform humans given limited training on a new face, but human performance on really familiar faces is still far better. Understanding exactly how we do this will be of interest in its own right, since it is probably prototypical of the way we perform recognition of other things, but should inform those building computer systems. Truly effective automated face recognition could have enormous impact on society, with consequences that would be open for debate. While it would be much easier to track down those wanted for crime, for example, it would have potentially interesting consequences for our privacy. There are many potential applications; for example, if a cash machine did not recognise the person using a card it could trigger an alert, or ask additional security questions before continuing. Someone with Alzheimer's could be prompted about the identity of those they meet; indeed, such a device, if unobtrusive, could help most of us!

While the UK has a very strong face research community, both within Psychology and Computing Science, we expect this collection to be used world-wide, as both PsychoMorph and the PICS image collection already are.

Face research is inherently interesting to the general public; we all do face perception every time we meet someone. 3D imagery and stereo still has a 'wow' factor, providing a great opportunity to grab attention, for example at open days or science centre visits. The software will allow us to grab a 3D image with our camera, then present it in stereo on our 3D monitor, possibly transforming their apparent age or gender. This will provide a framework for explaining the serious research that we undertake. For those without their own camera, it will still be possible to show images changing in eye-catching ways.

Possible industrial beneficiaries from the improved software include those involved in perceptual evaluation of cosmetics and similar products. For example, Tiddeman is currently a joint principal investigator on a Unilever funded project relating to skin health and cosmetics, where improvements in such tools would prove extremely useful.

The Aberystwyth RA will benefit from learning about programming cutting-edge computer graphics; a highly marketable skill set.

The Stirling RA will learn the techniques of gathering and preparing complex and consistent image sets which would be an excellent base for pursuing further research in this area.</gtr:potentialImpactText><gtr:fund><gtr:end>2013-02-28</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2011-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>67127</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>BA festival of science</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>FC92111D-0BC7-4257-B34B-CE59BB5E56A3</gtr:id><gtr:impact>We collected 3D images of 96 people attending the festival of science, to add to the database. We gave them copies of their images and a display program with which to view them

None</gtr:impact><gtr:outcomeId>54634b9416ab13.78191053</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>6104265</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC Programme grant</gtr:description><gtr:end>2020-12-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/N007743/1</gtr:fundingRef><gtr:id>D93BFCD5-3561-494A-A4CE-24CCE0E3F6AE</gtr:id><gtr:outcomeId>56cb32ccb44864.30829568</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>A collection of face images, 2D, stereo, 3D and video</gtr:description><gtr:id>41D82193-1D58-469A-9C57-961372B6A268</gtr:id><gtr:impact>Too early to know</gtr:impact><gtr:outcomeId>546349e5bbc0d3.70279294</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>face database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://pics.stir.ac.uk/ESRC/</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>8DC3CC8F-D122-42A9-A7EC-76DC0286245C</gtr:id><gtr:title>Super-recognisers in Action: Evidence from Face-matching and Face Memory Tasks</gtr:title><gtr:parentPublicationTitle>Applied Cognitive Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6be9da0563d557c97a6f58b6724fac95"><gtr:id>6be9da0563d557c97a6f58b6724fac95</gtr:id><gtr:otherNames>Bobak A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56cb30b5d1c297.79513886</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/J010081/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>63F3D26F-05D5-477D-9F77-C6C8AC47C7DD</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Research approaches</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>FFA3A6C9-532B-4B83-B6F7-AAF3E63D34F0</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Social Stats., Comp. &amp; Methods</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>