<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A1FA5E2C-705B-4A74-9596-1A1CAC2A8375"><gtr:id>A1FA5E2C-705B-4A74-9596-1A1CAC2A8375</gtr:id><gtr:name>IBM</gtr:name><gtr:address><gtr:line1>IBM Corporation</gtr:line1><gtr:line2>1 New Orchard Road</gtr:line2><gtr:line4>Armonk</gtr:line4><gtr:line5>NY 10504-1722</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/B9D66421-09ED-4C76-8AF3-D38C6DDDC841"><gtr:id>B9D66421-09ED-4C76-8AF3-D38C6DDDC841</gtr:id><gtr:name>Royal Victoria Hospital, Belfast</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8A82DB92-2049-429C-BC69-8D7979E9BC43"><gtr:id>8A82DB92-2049-429C-BC69-8D7979E9BC43</gtr:id><gtr:name>Maxeler Technologies</gtr:name><gtr:address><gtr:line1>3-4 Albion Place</gtr:line1><gtr:postCode>W6 0QT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/EC23DA53-CA73-4104-A3F6-2A9523484E69"><gtr:id>EC23DA53-CA73-4104-A3F6-2A9523484E69</gtr:id><gtr:name>Queen's University of Belfast</gtr:name><gtr:department>Electronics Electrical Eng and Comp Sci</gtr:department><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Belfast</gtr:line4><gtr:line5>County Antrim</gtr:line5><gtr:postCode>BT7 1NN</gtr:postCode><gtr:region>Northern Ireland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EC23DA53-CA73-4104-A3F6-2A9523484E69"><gtr:id>EC23DA53-CA73-4104-A3F6-2A9523484E69</gtr:id><gtr:name>Queen's University of Belfast</gtr:name><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Belfast</gtr:line4><gtr:line5>County Antrim</gtr:line5><gtr:postCode>BT7 1NN</gtr:postCode><gtr:region>Northern Ireland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A1FA5E2C-705B-4A74-9596-1A1CAC2A8375"><gtr:id>A1FA5E2C-705B-4A74-9596-1A1CAC2A8375</gtr:id><gtr:name>IBM</gtr:name><gtr:address><gtr:line1>IBM Corporation</gtr:line1><gtr:line2>1 New Orchard Road</gtr:line2><gtr:line4>Armonk</gtr:line4><gtr:line5>NY 10504-1722</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B9D66421-09ED-4C76-8AF3-D38C6DDDC841"><gtr:id>B9D66421-09ED-4C76-8AF3-D38C6DDDC841</gtr:id><gtr:name>Royal Victoria Hospital, Belfast</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8A82DB92-2049-429C-BC69-8D7979E9BC43"><gtr:id>8A82DB92-2049-429C-BC69-8D7979E9BC43</gtr:id><gtr:name>Maxeler Technologies</gtr:name><gtr:address><gtr:line1>3-4 Albion Place</gtr:line1><gtr:postCode>W6 0QT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C39926DE-23DA-400B-AE94-DFB0CD10A2BE"><gtr:id>C39926DE-23DA-400B-AE94-DFB0CD10A2BE</gtr:id><gtr:name>Numerical Algorithms Group Ltd</gtr:name><gtr:address><gtr:line1>Wilkinson House</gtr:line1><gtr:line2>Jordan Hill Road</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:line5>Oxfordshire</gtr:line5><gtr:postCode>OX2 8DR</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B639A705-7752-4DDD-9D38-E52CEF7691D5"><gtr:id>B639A705-7752-4DDD-9D38-E52CEF7691D5</gtr:id><gtr:firstName>Norman</gtr:firstName><gtr:otherNames>Stanley</gtr:otherNames><gtr:surname>Scott</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2B246EC7-B958-4CC6-8C66-EF3A8BE8E99F"><gtr:id>2B246EC7-B958-4CC6-8C66-EF3A8BE8E99F</gtr:id><gtr:firstName>Bronis R.</gtr:firstName><gtr:surname>de Supinski</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/0476E774-3BFD-4827-80D1-190B2A4CC438"><gtr:id>0476E774-3BFD-4827-80D1-190B2A4CC438</gtr:id><gtr:firstName>Mike</gtr:firstName><gtr:surname>Ashworth</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D1E1B058-5D74-4D66-A6B4-252462C15E99"><gtr:id>D1E1B058-5D74-4D66-A6B4-252462C15E99</gtr:id><gtr:firstName>Hans</gtr:firstName><gtr:otherNames>Tim</gtr:otherNames><gtr:surname>Vandierendonck</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/1BCB7DE1-56BD-4235-82C5-D392E0D98FC6"><gtr:id>1BCB7DE1-56BD-4235-82C5-D392E0D98FC6</gtr:id><gtr:firstName>Dimitrios</gtr:firstName><gtr:surname>Nikolopoulos</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/40870D64-4FDD-4034-8B9A-4DC92D6DCCE2"><gtr:id>40870D64-4FDD-4034-8B9A-4DC92D6DCCE2</gtr:id><gtr:firstName>Jack</gtr:firstName><gtr:surname>Dongarra</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM01147X%2F1"><gtr:id>5DEF6008-A89B-4BB7-950E-B867ACD9B8FA</gtr:id><gtr:title>SERT: Scale-free, Energy-aware, Resilient and Transparent Adaptation of CSE Applications to Mega-core Systems</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M01147X/1</gtr:grantReference><gtr:abstractText>Moore's Law and Dennard scaling have led to dramatic performance increases in microprocessors, the basis of modern supercomputers, which consist of clusters of nodes that include microprocessors and memory. This design is deeply embedded in parallel programming languages, the runtime systems that orchestrate parallel execution, and computational science applications.

Some deviations from this simple, symmetric design have occurred over the years, but now we have pushed transistor scaling to the extent that simplicity is giving way to complex architectures. The absence of Dennard scaling, which has not held for about a decade, and the atomic dimensions of transistors have profound implications on the architecture of current and future supercomputers. 

Scalability limitations will arise from insufficient data access locality. Exascale systems will have up to 100x more cores and commensurately less memory space and bandwidth per core. However, in-situ data analysis, motivated by decreasing file system bandwidths will increase the memory footprints of scientific applications. Thus, we must improve per-core data access locality and reduce contention and interference for shared resources.

Energy constraints will fundamentally limit the performance and reliability of future large-scale systems. These constraints lead many to predict a phenomenon of &amp;quot;dark silicon&amp;quot; in which half or more of the transistors on each chip must be powered down for safe operation. Low-power processor technologies based on sub-threshold or near-threshold voltage operation are a viable alternative. However, these techniques dramatically decrease the mean time to failure at scale and, thus, require new paradigms to sustain throughput and correctness.

Non-deterministic performance variation will arise from design process variation that leads to asymmetric performance and power consumption in architecturally symmetric hardware components. The manifestations of the asymmetries are non-deterministic and can vary with small changes to system components or software. This performance variation produces non-deterministic, non-algorithmic load imbalance. 

Reliability limitations will stem from the massive number of system components, which proportionally reduces the mean-time-to-failure, but also from the component wear and from low-voltage operation, which introduces timing errors. Infrastructure-level power capping may also compromise application reliability or create severe load imbalances.

The impact of these changes on technology will travel as a shockwave throughout the software stack. For decades, we have designed computational science applications based on very strict assumptions that performance is uniform and processors are reliable. In the future, hardware will behave unpredictably, at times erratically. Software must compensate for this behavior. 

Our research anticipates this future hardware landscape. Our ecosystem will combine binary adaptation, code refactoring, and approximate computation to prepare CSE applications. We will provide them with scale-freedom - the ability to run well at scale under dynamic execution conditions - with at most limited, platform-agnostic code refactoring. Our software will provide automatic load balancing and concurrency throttling to tame non-deterministic performance variations. Finally, our new form of user-controlled approximate computation will enable execution of CSE applications on hardware with low supply voltages, or any form of faulty hardware, by selectively dropping or tolerating erroneous computation that arises from unreliable execution, thus saving energy. Cumulatively, these tools will enable non-intrusive reengineering of major computational science libraries and applications (2DRMP, Code_Saturne, DL_POLY, LB3D) and prepare them for the next generation of UK supercomputers. The project partners with NAG a leading UK HPC software and service provider.</gtr:abstractText><gtr:potentialImpactText>The project will achieve commercial impact through the development of production-level Computational Science and Engineering Software that will catalyse performance and productivity in applications within the EPSRC remit; industrial engagement with UK and international stakeholders, in particular through membership of project partners in the European Technology Platform for HPC (ETP4HPC); exploration of the potential to receive follow-on funding and create spin-out companies with instruments such as the Impact Account Acceleration at Queen's Belfast; and the organisation of an industrial workshop. The project will achieve further economic impact through better utilisation and reduction of the total cost of ownership of the major UK supercomputing infrastructures and improved productivity in sectors of the UK high-technology economy that depend on HPC.

The project will achieve academic impact by publishing results in the very best journals and conferences across the areas of high performance computing, computational science, scientific computing, programming languages and computer architecture. All publications will follow Green or Gold open access routes, the former leveraging institutional publication repositories and the latter institutional funding. All software developed in the project will be open-sourced, with associated training provision in the form of tutorials and short modules. Further academic impact will be achieved via exchange visits and demonstration sessions with project partner NAG, ClusterVision, and other HPC vendors and groups in the UK.

Societal impact will be achieved through prominent presence in social media (Web 2.0, LinkedIn, Twitter and YouTube Channels) to disseminate the results to professionals and the general public. Further societal presence will be achieved through distribution of news articles, press releases, and video presentations. The project will develop software technologies for emerging many-core systems, a skill which is highly marketable.

The project follows a comprehensive software management plan: It will produce three software outputs (Adaptor, RightSizer, Approximator), licensed under GPL. The tools will be developed, tested and maintained in a GITlab software repository, with the associated GIT revision control system hosted by Queen's Belfast and shared between the project partners. The software will be user-level and will not require interventions to the host operating system, which would prevent its deployment on the target systems (ARCHER, BlueJoule, NextScale, Titan). It will be based on the GNU stack for maximum portability across current and future platforms. The software will support and be compatible with widely used parallel programming languages (MPI, OpenMP, OpenCL) and libraries (MAGMA, PLASMA, ATLAS). Source code changes in MPI, OpenMP and OpenCL, where needed, will be feasible with the adoption of open-source implementations of them (e.g. OpenMPI, PoCL, GOMP).

The software will be released to and hosted for the public by Queen's Belfast during the course of the project, and later by STFC for production use on the targeted supercomputers. The GITlab repository that will house the software at QUB is well tested and already provides support for code development, maintenance, revision control and testing in nine large-scale software development projects (EPSRC, FP7/H2020, and industry-lead), involving 28 research groups in the UK, Germany, Switzerland, Sweden, Greece, Austria, Ireland and the US, and totalling hundreds of KLOC in C/C++ parallel code. We will use Doxygen for formal code documentation, DokuWiki for informal documentation and discussion among developers, and BugZilla for bug tracking. We will use nightly builds and regression tests. A permanent research engineer funded from Queen's will undertake the role of software maintenance and quality control manager and will be responsible for maintaining the highest coding and documentation</gtr:potentialImpactText><gtr:fund><gtr:end>2018-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>963928</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Maxeler Technologies</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with Maxeler on integrating dataflow accelerators in Big Data software stacks</gtr:description><gtr:id>67E561AC-90BE-4BE2-807A-8935B65F0247</gtr:id><gtr:impact>No outputs yet, extensions of Spark and Storm with streaming APIs using Maxeler dataflow engines are currently under design.</gtr:impact><gtr:outcomeId>56c4429c42b855.53344204-1</gtr:outcomeId><gtr:partnerContribution>Programming APIs for Maxeler dataflow accelerators.</gtr:partnerContribution><gtr:piContribution>Integration of Maxeler's dataflow engines into the Spark, Storm and other Big Data software stacks, in collaboration with Maxeler Technologies and STFC Hartree.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>IBM</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Collaboration with IBM on disaggregated memory technologies and near-data computing</gtr:description><gtr:id>BF32EEEC-9B34-4739-89A1-F500FF12D27E</gtr:id><gtr:impact>Materialised through an industrial placement of QUB research staff, this partnership is exploring designs to substantially improve the energy-efficiency of large memory systems, via the use of disaggregation of memory, RDMA-based networking to remote memory devices and near-data accelerators for in-situ, in-memory analytics.</gtr:impact><gtr:outcomeId>56c2f846272b05.93892412-1</gtr:outcomeId><gtr:partnerContribution>IBM has contributed novel remote memory server infrastructures and near-data acceleration technologies.</gtr:partnerContribution><gtr:piContribution>Our research team has contributed methods to manage data caching and placement on disaggregated memory architectures with near-data processing elements.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Royal Victoria Hospital, Belfast</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with NHS (Belfast HSCT) on real-time analytics of ICU patient data</gtr:description><gtr:id>847AB7D4-11DD-4AF2-934D-9A336D4C32DD</gtr:id><gtr:impact>Appliance operating and automatically detecting potential lung injury emergencies at Royal Victoria Hospital ICU.</gtr:impact><gtr:outcomeId>56c49c01db05d4.69058177-1</gtr:outcomeId><gtr:partnerContribution>Analytical algorithms and infrastructure support at Royal Victoria Hospital, Belfast.</gtr:partnerContribution><gtr:piContribution>A real-time analytics appliance (micro-server plus in-memory data analytics software) for analysing continuously respiratory data of ICU Patients, with the objective to regulate oxygen intake and prevent lung injury.</gtr:piContribution><gtr:sector>Hospitals</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>NVTV Interview on Superocmputing</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1BFD7F77-2DE3-43F4-8085-FBD01F17A6DE</gtr:id><gtr:impact>Interview in NVTV's Behind the Science program on Supercomputing as a technology with impact on our everyday lives.</gtr:impact><gtr:outcomeId>56c6fc155f3ee7.14124778</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.nvtv.co.uk/shows/behind-the-science-dimitrios-nikolopoulos/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>663625</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>EU Horizon2020 Programme: UniServer Project</gtr:description><gtr:end>2019-01-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>687628</gtr:fundingRef><gtr:id>7BC6C9DD-5923-45C7-942E-279231745746</gtr:id><gtr:outcomeId>56c49eabae2236.95797953</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2016-02-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>696750</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>EU Horizon2020 Programme: ECOSCALE: Energy-Efficient Heterogeneous Computing at Scale</gtr:description><gtr:end>2018-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>671632</gtr:fundingRef><gtr:id>E67B9874-8E30-4DBF-BA83-B8E984B1C16C</gtr:id><gtr:outcomeId>56c4a0a8b10ad6.05915232</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>438578</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>EU Horizon2020 Programme: AllScale: An Exascale Programming, Multi-objective Optimisation and Resilience Management Environment Based on Nested Recursive Parallelism.</gtr:description><gtr:end>2018-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>671603</gtr:fundingRef><gtr:id>E8C5016A-FC99-4C06-B877-8094D7EE636D</gtr:id><gtr:outcomeId>56c4a23ec70821.94036281</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>50000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Royal Society Wolfson Research Merit Award: Principles and Practice of Near-Data Computing</gtr:description><gtr:end>2020-08-02</gtr:end><gtr:fundingOrg>The Royal Society</gtr:fundingOrg><gtr:fundingRef>WM150009</gtr:fundingRef><gtr:id>D4BD776D-D8E1-465F-82B1-FC310C83F83A</gtr:id><gtr:outcomeId>56c49fc07de3d4.14919745</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>521947</gtr:amountPounds><gtr:country>Ireland, Republic of</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>SFI-DEL Investigators Programme: Meeting the Challenges of Heterogeneous and Extreme Scale Parallel Computing</gtr:description><gtr:end>2020-08-02</gtr:end><gtr:fundingOrg>Science Foundation Ireland (SFI)</gtr:fundingOrg><gtr:fundingRef>14/IA/2474</gtr:fundingRef><gtr:id>6ED5624D-E74D-4A93-8F5D-CFB42314DC71</gtr:id><gtr:outcomeId>56c4a03d199389.81826697</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2015-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings of the project are actively been used to inform software engineering practices and improve software productivity as well as resilience of production strength software in two supercomputing centres in the UK (STFC) and the US (LLNL).</gtr:description><gtr:firstYearOfImpact>2017</gtr:firstYearOfImpact><gtr:id>84837D51-1B63-4209-B2DD-92E3175B12B1</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56ced19b3b4244.12075010</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We developed a significant codebase of tools for improving the scaling of parallel programs. Specifically, we developed 
SCALO, a tool that increases throughput of jobs on supercomputer nodes. SCALO optimizes resource allocation of parallel 
programs running concurrently on the same node, by minimising contention and adapting resource allocation to the 
scalability potential of co-runners. A particular strength of our tool is that it can be deployed to existing supercomputer 
infrastructure, without disrupting the pre-deployed installations. The initial evaluation using benchmarks of HPC application 
proxies show promising results and we are expanding its use to large-scale application.

Approximation is an emerging research method for speeding up execution by trading computational accuracy for performance. 
We choose to extend the widely used OpenMP parallel language for including constructs to express approximation opportunities 
on parallel computations. We develop those extensions on already existing, industrial quality tools, including a compiler 
(Clang/LLVM) and parallel runtime (Intel OpenMP runtime). Through our extensions, HPC developers have a structured way to 
include approximation in parallel programs and dictate how this is implemented at the execution runtime. For example, the 
developer annotates computational tasks as amenable to approximation and configures the runtime to perform those computations 
with reduced accuracy or even completely drop them for aggressive speed optimisation. We have demonstrated the applicability 
of our approximation techniques in numerical kernels and we are in the process of evaluating them to on large-scale applications.</gtr:description><gtr:exploitationPathways>We make available all the tools we develop to our research partners which are HPC application and numerical library developers.
Also, we intent to release our software to the wider scientific community while fine-tuning it for usability and performance, 
using invaluable feedback from our partners and domain experts.

The vision for our SCALO tool is to be part of the system services provided by supercomputer facilities. Its usage will 
enable users to co-locate jobs on nodes for increasing utilisation and throughput of supercomputer installations. Our 
approximation framework presents a robust, ready-to-use solution by extending existing standards (OpenMP) used for programming HPC 
applications. This enables developers to include approximation in their applications.</gtr:exploitationPathways><gtr:id>2C0386DC-9AFC-40BC-9872-451E4515A48B</gtr:id><gtr:outcomeId>56d402f6b8a573.15190889</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>EPSRC ICT Delivery Planning Workshops</gtr:description><gtr:geographicReach>National</gtr:geographicReach><gtr:id>004312EE-5BF6-463C-A128-5659E1E8DAB0</gtr:id><gtr:outcomeId>56c7114869c387.01667751</gtr:outcomeId><gtr:type>Participation in a national consultation</gtr:type></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>D0F68696-4CE3-4CD6-9F84-1946867BD6AB</gtr:id><gtr:title>A scalable and composable map-reduce system</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/05bd3f2dde73b2c9c539a04beacd7656"><gtr:id>05bd3f2dde73b2c9c539a04beacd7656</gtr:id><gtr:otherNames>Arif M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b2ff22776754.98954246</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>79DDA698-5B58-4F4C-A8FC-1E3A65B27F9C</gtr:id><gtr:title>TwinPCG: Dual Thread Redundancy with Forward Recovery for Preconditioned Conjugate Gradient Methods</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/88f3193a784cdfa9fe54bfde0c1bef35"><gtr:id>88f3193a784cdfa9fe54bfde0c1bef35</gtr:id><gtr:otherNames>Dichev K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b302d288d768.25110398</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>06167921-E9B5-4A7E-9299-4573227AE4B9</gtr:id><gtr:title>TwinPCG: Dual Thread Redundancy with forward Recovery for Preconditioned Conjugate Gradient Methods</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/88f3193a784cdfa9fe54bfde0c1bef35"><gtr:id>88f3193a784cdfa9fe54bfde0c1bef35</gtr:id><gtr:otherNames>Dichev K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b300c9ae6d62.68184827</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ADB13211-3F6B-4AA1-AD70-441A9D5F57DD</gtr:id><gtr:title>On the Virtualization of CUDA Based GPU Remoting on ARM and X86 Machines in the GVirtuS Framework</gtr:title><gtr:parentPublicationTitle>International Journal of Parallel Programming</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a702379b5c160620ceac5c640bb7f325"><gtr:id>a702379b5c160620ceac5c640bb7f325</gtr:id><gtr:otherNames>Montella R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b2fce37ecee3.08656390</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>74CF0CB6-4B9B-4DEF-989B-F4B849C8F169</gtr:id><gtr:title>FairGV: Fair and Fast GPU Virtualization</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Parallel and Distributed Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed3d446e99e608edbeedf817697463e0"><gtr:id>ed3d446e99e608edbeedf817697463e0</gtr:id><gtr:otherNames>Hong C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8a7777872f06.97787186</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DF811D86-19D3-4FCF-9FE6-17712D49859F</gtr:id><gtr:title>A taxonomy of task-based parallel programming technologies for high-performance computing</gtr:title><gtr:parentPublicationTitle>The Journal of Supercomputing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6d1d2582e0f320769fed64f7b26f07c1"><gtr:id>6d1d2582e0f320769fed64f7b26f07c1</gtr:id><gtr:otherNames>Thoman P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a943da17aa399.48892219</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F58DA14C-FBB2-420B-93E8-E8F6C49A7551</gtr:id><gtr:title>Big data availability: Selective partial checkpointing for in-memory database queries</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ac791116662cc40c65fb1714a65a3e30"><gtr:id>ac791116662cc40c65fb1714a65a3e30</gtr:id><gtr:otherNames>Playfair D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b2ff9317f329.60914685</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>23AA87C4-8A8A-43D7-8014-C5391E980501</gtr:id><gtr:title>Relaxing DRAM refresh rate through access pattern scheduling: A case study on stencil-based algorithms</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7ef00dc3efa73ec5d12b9449fef74534"><gtr:id>7ef00dc3efa73ec5d12b9449fef74534</gtr:id><gtr:otherNames>Tovletoglou K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a94397cc8fd18.81006061</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D044516F-DEDC-4372-95E6-08CDEA6AD723</gtr:id><gtr:title>SCALO</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Architecture and Code Optimization</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5308f8dc58bc5d18860cfe8cd4aba0ed"><gtr:id>5308f8dc58bc5d18860cfe8cd4aba0ed</gtr:id><gtr:otherNames>Georgakoudis G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8a76db5aa047.31642384</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0A2C285A-7DDF-42B0-ACF7-9793C575F833</gtr:id><gtr:title>Accelerating Graph Analytics by Utilising the Memory Locality of Graph Partitioning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3fbee13de0f083ea68ae008d704b0ddd"><gtr:id>3fbee13de0f083ea68ae008d704b0ddd</gtr:id><gtr:otherNames>Sun J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a943ad6bfca99.81499160</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>60700EC5-8764-4F2B-9705-49E9EE893309</gtr:id><gtr:title>ECOSCALE: Reconfigurable computing and runtime system for future exascale systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f57801592bf5513205812d65fdd11d50"><gtr:id>f57801592bf5513205812d65fdd11d50</gtr:id><gtr:otherNames>Iakovos Mavroidis</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b308056b2781.90978064</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7C8E9FDA-F6C6-4A32-92F0-0E46EF272002</gtr:id><gtr:title>REFINE</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5308f8dc58bc5d18860cfe8cd4aba0ed"><gtr:id>5308f8dc58bc5d18860cfe8cd4aba0ed</gtr:id><gtr:otherNames>Georgakoudis G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9438fd639f71.27593466</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6C21AFC6-0702-401A-96F7-C98EB286579A</gtr:id><gtr:title>Performance and Fault Tolerance of Preconditioned Iterative Solvers on Low-Power ARM Architectures</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9977bb0a29b875ddbc6d3dc0fda20f54"><gtr:id>9977bb0a29b875ddbc6d3dc0fda20f54</gtr:id><gtr:otherNames>Aliaga J.</gtr:otherNames></gtr:author></gtr:authors><gtr:outcomeId>56b23ae6c5b0e0.73777695</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EE7D1880-119A-4659-8BA3-F4C621CA4FC9</gtr:id><gtr:title>DARE</gtr:title><gtr:parentPublicationTitle>The International Journal of High Performance Computing Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f4d245c7705247dfa8cdd8d7087efea3"><gtr:id>f4d245c7705247dfa8cdd8d7087efea3</gtr:id><gtr:otherNames>Chalios C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1094-3420</gtr:issn><gtr:outcomeId>5a63f23000ef50.51391386</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M01147X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>