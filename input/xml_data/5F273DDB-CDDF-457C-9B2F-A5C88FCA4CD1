<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Electrical and Electronic Engineering</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96A4DF35-42C5-4C25-8810-856526BFC86B"><gtr:id>96A4DF35-42C5-4C25-8810-856526BFC86B</gtr:id><gtr:name>British Broadcasting Corporation (BBC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AA12ECE2-2238-480C-9498-B92932045DAC"><gtr:id>AA12ECE2-2238-480C-9498-B92932045DAC</gtr:id><gtr:name>Watershed Media Centre</gtr:name><gtr:address><gtr:line1>1 Canons Rd</gtr:line1><gtr:line2>Harbourside</gtr:line2><gtr:line4>Bristol</gtr:line4><gtr:postCode>BS1 5TX</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F15CC95E-2AC8-45D6-A4B6-8507124470D3"><gtr:id>F15CC95E-2AC8-45D6-A4B6-8507124470D3</gtr:id><gtr:name>Fraunhofer</gtr:name><gtr:address><gtr:line1>Postfach 20 07 33</gtr:line1><gtr:line4>Munich</gtr:line4><gtr:line5>80007</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Germany</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/BAD3780F-6F65-4292-A69C-923CAE91A7BB"><gtr:id>BAD3780F-6F65-4292-A69C-923CAE91A7BB</gtr:id><gtr:name>British Broadcasting Corporation - BBC</gtr:name><gtr:address><gtr:line1>British Broadcasting Corporation</gtr:line1><gtr:line2>Broadcasting House</gtr:line2><gtr:line3>Portland Place</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>W1A 1AA</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/4D522324-5D72-4019-8565-80BFD38BB7D0"><gtr:id>4D522324-5D72-4019-8565-80BFD38BB7D0</gtr:id><gtr:firstName>Roland</gtr:firstName><gtr:surname>Baddeley</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/60D5ACA5-CD46-4D4F-B79D-0F574E16F291"><gtr:id>60D5ACA5-CD46-4D4F-B79D-0F574E16F291</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Bull</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/ABF1C165-0FD4-4743-BE25-371D4CF5C22F"><gtr:id>ABF1C165-0FD4-4743-BE25-371D4CF5C22F</gtr:id><gtr:firstName>Dimitris</gtr:firstName><gtr:surname>Agrafiotis</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8D5D1B19-A9B7-43A8-81C0-7DA3DEAB0B80"><gtr:id>8D5D1B19-A9B7-43A8-81C0-7DA3DEAB0B80</gtr:id><gtr:firstName>Paul</gtr:firstName><gtr:otherNames>Richard</gtr:otherNames><gtr:surname>Hill</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ019291%2F1"><gtr:id>5F273DDB-CDDF-457C-9B2F-A5C88FCA4CD1</gtr:id><gtr:title>COMPPACT: Compression of Video using Perceptually Optimised Parametric Coding Techniques</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J019291/1</gtr:grantReference><gtr:abstractText>It is currently a very exciting and challenging time for video compression. The predicted growth in demand for bandwidth, especially for mobile services is driven largely by video applications and is probably greater now than it has ever been. There are four reasons for this: 

(i) Recently introduced formats such as 3D and multiview, coupled with increasing dynamic range, spatial resolution and framerate, all require increased bit-rate to deliver improved immersion; 
(ii) Video-based web traffic continues to grow and dominate the internet; 
(iii) User expectations coninue to drive flexibility and quality, with a move from linear to non-linear delivery; 
(iv) Finally the emergence of new services, in particular mobile delivery through 4G/LTE to smart phones. While advances in network and physical layer technologies will no doubt contribute to the solution, the role of video compression is also of key importance.

This research project is underpinned by the assumption that, in most cases, the target of video compression is to provide good subjective quality rather than to minimise the error between the original and coded pictures. It is thus possible to conceive of a compression scheme where an analysis/synthesis framework replaces the conventional energy minimisation approach. Such a scheme could offer substantially lower bitrates through reduced residual and motion vector coding. 

The approach proposed will model scene content using combinations of waveform coding and texture replacement, using computer graphic models to replace target textures at the decoder. These not only offer the potential for dramatic improvements in performance, but they also provide an inherent content-related parameterisation which will be of use in classification and detection tasks as well as facilitating integration with CGI. 

This has the potential to create a new content-driven framework for video compression. In this context our aim is to shift the video coding paradigm from rate-distortion optimisation to rate-quality modelling, where region-based parameters are combined with perceptual quality metrics to inform and drive the coding and synthesis processes. However it is clear that a huge amount of research needs to be done in order to fully exploit the method's potential and to yield stable and efficient solutions. For example, mean square error is no longer a valid objective function or measure of quality, and new embedded perceptually driven quality metrics are essential. The choice of texture analysis and synthesis models are also important, as is the exploitation of long-term picture dependencies.</gtr:abstractText><gtr:potentialImpactText>The investigators and partners have a long track record of delivering impact and pulling through ideas from research into exploitation.

COMPPACT will provide impact through: 

- Shaping UK capability in video compression and delivery: It will deliver reference software that enables development
and evaluation. This will provide benefit to industry as well as to the research community, in providing an ability to evaluate and compare codec performance.

- Standardisation: We anticipate that the ideas and methods of COMPPACT will contribute to future video compression standardisation. This will provide new opportunities for video IC design companies in developing superior products. It will also provide benefits to the mobile communications industry through more efficient use of bandwidth, and to application developers and content providers in terms of being able to provide more immersive content at lower bit rates. 

- Society: A major impact of this project will be on the wider public, in terms of providing high quality bandwidth-efficient video services, more engaging content representations and enabling new more immersive formats.

- The Bristol Creative Community: will benefit through local events and workshops hosted at the Watershed Arts Centre. We will also provide access by the local creative sector to capture, display and quality assessment facilities in the BVI studio, in particular to SMEs through the Bristol Media Network and the BBC-Anchor Consortium.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-08-07</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-08-08</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>547101</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>British Broadcasting Corporation (BBC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>BBC Research &amp; Development</gtr:department><gtr:description>BBC Immersive Technology Laboratory</gtr:description><gtr:id>33486B16-ED3F-4A8B-88B8-9398A0EFF5B5</gtr:id><gtr:impact>New method of perceptual quantisation for HDR HEVC
Analysis of BBC archive in terms of feature classification</gtr:impact><gtr:outcomeId>56d87f77c26c43.72504528-1</gtr:outcomeId><gtr:partnerContribution>Provision of REDUX
Support for PhD students
Collaboration on perceptual quantisation
Secondment of BBC employees</gtr:partnerContribution><gtr:piContribution>High Dynamic range coding optimisation for HEVC
Perceptual video compression results
REDUX database analytics</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Keynote: IET ISP</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D6B8A87C-3645-41D4-8A99-B0E29A8BE3B0</gtr:id><gtr:impact>Keynote Lecture IET ISP- Perceptual Video coding</gtr:impact><gtr:outcomeId>56d87bf131bfb2.75410079</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1362874</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC Platform Grant</gtr:description><gtr:end>2020-02-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:id>4BA49519-992A-47B2-8813-E0EBCCB5A97A</gtr:id><gtr:outcomeId>56d87a8e05bf74.96650196</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-02-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>607602</gtr:amountPounds><gtr:country>Global</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:department>Initial Training Networks (ITN)</gtr:department><gtr:description>EU Marie Curie ITN</gtr:description><gtr:end>2017-09-02</gtr:end><gtr:fundingOrg>Marie Sklodowska-Curie Actions</gtr:fundingOrg><gtr:id>C91336DC-E63A-465B-9911-0A1AE930DBC4</gtr:id><gtr:outcomeId>56d87b42bb3474.99029887</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2013-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work of this project is likely to only have real impact during the next stage of video standardisation. There is currently a call for evidence being planned in MPEG, leading to a new H.266 standard in 2020. We anticipate contributing to this.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>59AAE07E-F6B6-4C58-B6CC-CCA84A67AE63</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic,Policy &amp; public services</gtr:impactType></gtr:impactTypes><gtr:outcomeId>545fb5be4c42d5.99394949</gtr:outcomeId><gtr:sector>Aerospace, Defence and Marine,Creative Economy,Digital/Communication/Information Technologies (including Software),Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Manufacturing, including Industrial Biotechology,Security and Diplomacy,Transport</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This project has developed a novel means of video compression based on texture warping and synthesis. Instead of encoding whole images or prediction residuals after translational motion estimation, our algorithm employs a perspective motion model to warp static textures and utilises texture synthesis to create dynamic textures. Texture regions are segmented using features derived from the complex wavelet transform and further classified according to their spatial and temporal characteristics. 

The project has also developed low complexity perceptual quality metrics that have the potential to be used in the coding loop to prevent warping and synthesis artefacts, as well as outside of it. The new perceptual video quality metric (PVM) out performs all previously published work. This work is now been published in IEEE Trans CSVT. 

The proposed algorithm has been integrated into an H.264 video coding framework. The results show significant bitrate savings, of up to 60% compared with H.264 at the same objective quality (based on AVM) and subjective scores. It is currently being integrated into the new HEVC video coding standard.

COMPPACT is currently undertaking further data collection exercises including various textural content acquired at high spatial resolution and high frame rates. 

Results of enhanced Rate Quality Optimisation have also been researched that have demonstrated significant improvements over the latest coding standard - HEVC. Content-adaptive Langragian multiplier selection methods have also been generated that improve upon HEVC performance by 3%.</gtr:description><gtr:exploitationPathways>A number of important collaborations have already arisen from this work where the findings and datasets are already being used. These include:
i) an EU Marie Curie Training Network, collaboratively with Fraunhofer HHI Berlin, Univ. Aachen, Univ. Nantes, BBC, Microsoft, Technicolor, Netflix, Google and Purdue Univ. This project builds on COMPPACT in the area of perceptual video coding and quality metrics and is targeting the next generation of video coding standards.
ii) An EPSRC Platform grant awarded to Bristol Vision Institute (Bull PI), 'Vision for the Future'. A key theme in this is visual immersion where compression techniques will be investigated that achieve compression ratios exceed 1000:1 while preserving the immersive properties of the format. Collaborators include the Academy of Motion Picture Arts and Sciences, Aardman Animations, BBC, and ARRI.
iii) A joint facility, 'The Bristol BBC Immersive Technology Laboratory has been established that is investigating compression for high frame rate and High Dynamic Range content.</gtr:exploitationPathways><gtr:id>2C521E31-B920-4A11-A01C-DE482174E46E</gtr:id><gtr:outcomeId>545fb35e6561d1.98727768</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Electronics,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Manufacturing, including Industrial Biotechology,Culture, Heritage, Museums and Collections,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.bristol.ac.uk/vi-lab/projects/parametricvideocompression/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>Collection of high frame rate clips with associated metadata for testing and developing future immersive video formats</gtr:description><gtr:id>09E5A082-588F-43D4-95FD-8FAD892EE439</gtr:id><gtr:impact>None at present</gtr:impact><gtr:outcomeId>56d8776c3ac756.55836741</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>BV High frame rate database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://data.bris.ac.uk/data/dataset/k8bfn0qsj9fs1rwnc2x75z6t7</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>Collection of static and dynamic video textures for compression testing</gtr:description><gtr:id>F9B5A05F-748E-4CD4-9223-F96F0439FB9F</gtr:id><gtr:impact>Used by several groups around the world</gtr:impact><gtr:outcomeId>56d8762701f7c4.88706249</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>BVI Texture database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://data.bris.ac.uk/datasets/1if54ya4xpph81fbo1gkpk5kk4/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>EDB3AAB2-6BA2-4A78-9AA0-6E9265569F75</gtr:id><gtr:title>HEVC enhancement using content-based local QP selection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1809274402a5f43e1a80a137e1986a33"><gtr:id>1809274402a5f43e1a80a137e1986a33</gtr:id><gtr:otherNames>Zhang F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>15224880</gtr:issn><gtr:outcomeId>58bd7db2485775.20012230</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6A9E3259-AABE-4EB2-B9B8-DD067D4D40A0</gtr:id><gtr:title>Context-based video coding</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e2fd0e475d4f704f695181ca06d9d586"><gtr:id>e2fd0e475d4f704f695181ca06d9d586</gtr:id><gtr:otherNames>Vigars R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545fbfb0cb9fb5.38284985</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8FD52521-AFF7-4507-898E-F8DBF0DF4852</gtr:id><gtr:title>A video texture database for perceptual compression and quality assessment</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/203f2dd42964fa838071f30128dfb755"><gtr:id>203f2dd42964fa838071f30128dfb755</gtr:id><gtr:otherNames>Papadopoulos M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d86442d595b9.78642820</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>523F4F5E-AF64-4C5B-95AE-7266F68ECFAA</gtr:id><gtr:title>High Dynamic Range Video</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d895db59e431e55ec84105d0da4fab0d"><gtr:id>d895db59e431e55ec84105d0da4fab0d</gtr:id><gtr:otherNames>Zhang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd7db2825182.81199937</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>866B418C-9177-4D32-A8C4-F353EDFF632F</gtr:id><gtr:title>A study of subjective video quality at various frame rates</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a4e7ed976e0e31d84ae2e5d14a361e7"><gtr:id>6a4e7ed976e0e31d84ae2e5d14a361e7</gtr:id><gtr:otherNames>Mackin A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d86443135b53.13620254</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C343240A-D7E3-43FF-BD5B-C358C1C7374F</gtr:id><gtr:title>Quality assessment methods for perceptual video compression</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1809274402a5f43e1a80a137e1986a33"><gtr:id>1809274402a5f43e1a80a137e1986a33</gtr:id><gtr:otherNames>Zhang F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545fc02f2a5e55.33232423</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1340A06C-8D19-4E70-9553-7D1F157FB958</gtr:id><gtr:title>High Dynamic Range Video Compression Exploiting Luminance Masking</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Circuits and Systems for Video Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d895db59e431e55ec84105d0da4fab0d"><gtr:id>d895db59e431e55ec84105d0da4fab0d</gtr:id><gtr:otherNames>Zhang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56d87d9b21c563.19510741</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>04C8B05A-8843-4BC2-B620-30BDC5C3FDF4</gtr:id><gtr:title>On the Optimal Presentation Duration for Subjective Video Quality Assessment</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Circuits and Systems for Video Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2e6dccd3d8651e8bdb660107cce52df1"><gtr:id>2e6dccd3d8651e8bdb660107cce52df1</gtr:id><gtr:otherNames>Mercer Moss F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56d86443d0db23.46948676</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A7A094E6-76C3-477D-9153-8B9D408AFF18</gtr:id><gtr:title>A Perception-Based Hybrid Model for Video Quality Assessment</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Circuits and Systems for Video Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1809274402a5f43e1a80a137e1986a33"><gtr:id>1809274402a5f43e1a80a137e1986a33</gtr:id><gtr:otherNames>Zhang F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56d86443a97353.24124431</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>43DD11A4-4F05-41D5-BA72-6F8934DA70B1</gtr:id><gtr:title>An adaptive Lagrange multiplier determination method for rate-distortion optimisation in hybrid video codecs</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1809274402a5f43e1a80a137e1986a33"><gtr:id>1809274402a5f43e1a80a137e1986a33</gtr:id><gtr:otherNames>Zhang F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d86443372ac9.37998681</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J019291/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0F8B7B13-F2F5-42B3-95C6-EF12D7877319</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Multimedia</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>