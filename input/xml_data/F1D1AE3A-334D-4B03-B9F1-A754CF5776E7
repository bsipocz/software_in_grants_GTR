<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:department>Sch of Engineering and Informatics</gtr:department><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/12618C57-F33F-4292-9753-5A263D162042"><gtr:id>12618C57-F33F-4292-9753-5A263D162042</gtr:id><gtr:firstName>David</gtr:firstName><gtr:surname>Weir</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/E23CC707-98E4-4234-94B4-54EB25EF1370"><gtr:id>E23CC707-98E4-4234-94B4-54EB25EF1370</gtr:id><gtr:firstName>William</gtr:firstName><gtr:otherNames>Ralph</gtr:otherNames><gtr:surname>Keller</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FI037458%2F1"><gtr:id>F1D1AE3A-334D-4B03-B9F1-A754CF5776E7</gtr:id><gtr:title>A Unified Model of Compositional and Distributional Semantics: Theory and Applications</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/I037458/1</gtr:grantReference><gtr:abstractText>The notion of meaning is central to many areas of Computer Science, Artificial Intelligence (AI), Linguistics, Philosophy, and Cognitive Science. A formal, mathematical account of the meaning of natural language utterances is crucial to AI, since an understanding of natural language (i.e. languages such as English, German, Chinese etc) 
is at the heart of much intelligent behaviour. More specifically, Natural Language Processing (NLP) --- the branch of AI concerned with the computer processing, analysis and generation of text --- requires a model of meaning for many of its tasks and applications.

There have been two main approaches to modelling the meaning of language in NLP, in order that a computer can gain some &amp;quot;understanding&amp;quot; of the text. The first, the so-called compositional approach, is based on classical ideas from Philosophy and Mathematical Logic. Using a well-known principle from the 19th century logician
Frege --- that the meaning of a phrase can be determined from the meanings of its parts and how those parts are combined --- logicians have developed formal accounts of how the meaning of a sentence can be determined from the relations of words in a sentence. This idea culminated famously in Linguistics in the work of Richard Montague in the 1970s. The compositional approach addresses a fundamental problem in Linguistics -- how it is that humans are able to generate an unlimited number of sentences using a limited vocabulary. We would like computers to have a similar capacity also.

The second, more recent, approach to modelling meaning in NLP focuses on the meanings of the words themselves. This is the so-called distributional approach to modelling word meanings and is based on the ideas of the &amp;quot;structural&amp;quot; linguists such as Firth from the 1950s. This idea is also sometimes related to Wittenstein's philosophy of &amp;quot;meaning as use&amp;quot;. The idea is that the meanings of words can be determined by considering the contexts in which words appear in text. For example,
if we take a large amount of text and see which words appear close to the word &amp;quot;dog&amp;quot;, and do a similar thing for the word &amp;quot;cat&amp;quot;, we will see that the contexts of dog and cat tend to share many words in common (such as walk, run, furry, pet, and so on). Whereas if we see which words appear in the context of the word &amp;quot;television&amp;quot;, for example, we will find less overlap with the contexts for &amp;quot;dog&amp;quot;. Mathematically we represent the contexts in a vector space, so that word meanings occupy positions in a geometrical space. We would expect to find that &amp;quot;dog&amp;quot; and &amp;quot;cat&amp;quot; are much closer in the space than &amp;quot;dog&amp;quot; and &amp;quot;television&amp;quot;, indicating that &amp;quot;dog&amp;quot; and &amp;quot;cat&amp;quot; are closer in meaning than &amp;quot;dog&amp;quot; and &amp;quot;television&amp;quot;.

The two approaches to meaning can be roughly characterized as follows: the compositional approach is concerned with how meanings combine, but has little to say about the individual meanings of words; the distributional approach is concerned with word meanings, but has little to say about how those meanings combine. Our ambitious proposal is to exploit the strengths of the two approaches, by developing a unified model of distributional and compositional semantics. Our proposal has a central theoretical component, drawing on models of semantics from Theoretical Computer Science and Mathematical Logic. This central component which will inform, be driven by, and evaluated on tasks and applications in NLP and Information Retrieval, and also data drawn from empirical studies in Cognitive Science (the
computational study of the mind). Hence we aim to make the following fundamental contributions:

1. advance the theoretical study of meaning in Linguistics, Computer Science and Artificial Intelligence;

2. develop new meaning-sensitive approaches to NLP applications which can be robustly applied to naturally occurring text.</gtr:abstractText><gtr:fund><gtr:end>2015-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>370065</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Our findings are being used in several ongoing projects being undertaking with commercial collaborators, in particular, projects funded by Innovation UK (formally TSB) where we are building applied Natural Language Processing tools. 

The impact of this project on these applied projects concerns the way that it is enabling the creation of more robust language processing tools. For example, in one project, where we are interfacing with arge product databases, we are using distributional methods arising out of this project to create less brittle database matching algorithms.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>FC7CD5A6-F460-48C0-8793-7F0078A792AE</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5460b7dcce2363.72864896</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have discovered a new way to conceive of distributional composition, and developed a theoretical framework called Anchored Packed Trees (APTs) that implements this conception. We have developed a software implementation of this theory and have demonstrated that it can achieve state-of-the-art performance on several key tasks.

We have demonstrated that it is possible for a machine learning model to learn to distinguish between different ontological relationships that distributional similarity measures typically conflate. 

We have compared the effectiveness of a wide variety of proposals regarding how to compose distributional representations of meaning. A distinctive feature of this work is that it is a so-called extrinsic evaluation, focussing on impact on practical applications rather than accuracy on artificial test sets. This has provided greater clarify as to where further research effort in this area should placed.

We have devised a novel approach to distributional composition that involves higher-order dependency relations and are investigating applications of the approach in a number of NLP contexts.

We have collaborated in a research initiative investigating ways in which to map distributional representations from one domain to another, and have shown that this very general approach can lead to effective cross-domain methods on a variety of tasks.</gtr:description><gtr:exploitationPathways>The methods being developed in this project (and in other related projects) are showing significant potential in applied natural language processing contexts. In general, this is a result of the fact that, in a machine learning scenario, these methods make it possible to generalise from knowledge of individual word forms to knowledge of the semantics that these words denote.</gtr:exploitationPathways><gtr:id>5CB964E5-BA5B-4F08-BC1B-56B9759554AE</gtr:id><gtr:outcomeId>5460be011b47c0.57049668</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Government, Democracy and Justice</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>FAF3988B-31DA-4ED2-80D6-CE088DCA1921</gtr:id><gtr:title>Fast Semantic Parsing with a Tensor Kernel</gtr:title><gtr:parentPublicationTitle>International Journal of Computational Linguistics and Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b962056d79be9dd8553e5e2a52343da"><gtr:id>4b962056d79be9dd8553e5e2a52343da</gtr:id><gtr:otherNames>Clarke D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56b884e8c5ccb7.28178205</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>408EB745-A62E-4325-8701-087B09D0090D</gtr:id><gtr:title>Cross-Domain Sentiment Classification Using a Sentiment Sensitive Thesaurus</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Knowledge and Data Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6afce059583770da6f2e72fa9bab7ca9"><gtr:id>6afce059583770da6f2e72fa9bab7ca9</gtr:id><gtr:otherNames>Bollegala D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545281bdef2209.54108114</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>60FE6401-48F1-4361-9239-B41A18BF7F9A</gtr:id><gtr:title>Distributional Composition using Higher-Order Dependency Vectors</gtr:title><gtr:parentPublicationTitle>EACL Workshop on Continuous Vector Space Models and their Compositionality</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2cb08494fd21ff0f30cea0eac28c1000"><gtr:id>2cb08494fd21ff0f30cea0eac28c1000</gtr:id><gtr:otherNames>Weeds J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>543bcce7743d75.84338841</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>51D7385E-C7D9-4CF5-97AB-3029FBD262EC</gtr:id><gtr:title>Learning to Distinguish Hypernyms and Co-Hyponyms</gtr:title><gtr:parentPublicationTitle>Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2cb08494fd21ff0f30cea0eac28c1000"><gtr:id>2cb08494fd21ff0f30cea0eac28c1000</gtr:id><gtr:otherNames>Weeds J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>543bcdaab06604.05489114</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>27D8C3CC-3D5F-457C-B3FE-894A7E565B0F</gtr:id><gtr:title>Aligning Packed Dependency Trees: A Theory of Composition for Distributional Semantics</gtr:title><gtr:parentPublicationTitle>Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/33bea909e260e2981517e1aefdbf0a78"><gtr:id>33bea909e260e2981517e1aefdbf0a78</gtr:id><gtr:otherNames>Weir D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58ae36acdc8566.88652507</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>33C1DAF7-815E-4E16-8C2F-BD9FFB4CB2AD</gtr:id><gtr:title>A critique of word similarity as a method for evaluating distributional semantic models</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8a8d659d3fea62ad009abe4c28b3c932"><gtr:id>8a8d659d3fea62ad009abe4c28b3c932</gtr:id><gtr:otherNames>Batchkarov M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58ae38730ecce6.65098571</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7EF8CA2D-BB6E-4A8E-80B3-C5B736763BEC</gtr:id><gtr:title>Learning to Predict Distributions of Words Across Domains</gtr:title><gtr:parentPublicationTitle>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2e45198954f51d9ed2ea3345be2ecece"><gtr:id>2e45198954f51d9ed2ea3345be2ecece</gtr:id><gtr:otherNames>Danushka Bollegala</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54528046a98f70.32948449</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/I037458/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>