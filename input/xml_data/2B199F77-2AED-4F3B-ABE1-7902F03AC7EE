<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:department>Informatics</gtr:department><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/C98A2D7F-8534-48C2-B91F-841B8DC58E9C"><gtr:id>C98A2D7F-8534-48C2-B91F-841B8DC58E9C</gtr:id><gtr:firstName>Elizabeth</gtr:firstName><gtr:surname>Black</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM01892X%2F1"><gtr:id>2B199F77-2AED-4F3B-ABE1-7902F03AC7EE</gtr:id><gtr:title>Planning an Argument</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M01892X/1</gtr:grantReference><gtr:abstractText>While in the past machines waited passively for our commands, we are moving to a future where humans and machines work in partnership, where machines are proactive and guide humans' activities (coined Human-Agent Collectives in the ongoing EPSRC project EP/I011587/1). A key challenge is how to allow humans to engage with these machines (which may be software systems or robots) in order to understand and engage with the decisions the machines take. These machines must be able to justify their choices and explain why a particular course of action is appropriate, and humans must be able to challenge these justifications and input into the machine's decision making process. Argument dialogues are an established approach to managing such interactions; they provide a principled way of structuring rational interactions between participants (machines or human) who may, e.g., assert arguments, beliefs and preferences, and question or challenge one another's assertions. A key benefit of argument dialogues is that they provide a familiar mechanism through which a human can engage with a machine's reasoning.

When a machine engages in an argument dialogue it must determine which of the available speech acts to make in order to try and achieve its dialogue goals, this is called its argument dialogue strategy. This proposal addresses the important open problem of how to generate an argument dialogue strategy, by leveraging the results of many years of automated planning research. Automated planning is one of the most well developed sub-fields of artificial intelligence and focuses on developing efficient and general approaches to determine which actions to perform in order to achieve some goal. This is exactly the problem we must solve in order to generate argument dialogue strategies, where the actions are the communicative speech acts and the goals typically refer to social constructs or commitments rather than physical states of the world. 

In order to apply automated planning techniques to generate an argument dialogue strategy, we must represent our argument dialogue strategy generation problem in a language that automated planners can understand; one of the main contributions of this work will be a set of implemented translations that take an argument dialogue strategy generation problem and output a planning problem (represented in a standard planning language), which can then be solved by an existing automated planner. This will provide the first general approach to generating argument dialogue strategies that is not tied to a particular type of dialogue (e.g., persuasion or negotiation) and does not assume the strategiser has knowledge of its interlocutor's dialogue strategy.

Our objectives are: 

O1: Define a general framework for representing an argument dialogue strategy generation problem (DSP). 
O2: Develop a set of benchmark DSPs, represented in the framework of O1, on which to evaluate our approach. This will include DSPs developed using real clinical knowledge.
O3: For each of two specified classes of DSPs (distinguished by the certainty of the beliefs the strategiser has about its interlocutor), formally define and implement translations that map from a DSP of that class to a planning problem defined in a standard planning language.
O4: Evaluate existing planning algorithms for solving the planning problems that result from applying the translations of O3 to the benchmark DSPs of O2, identifying the limitations of existing planning algorithms for solving the benchmark DSPs.

This work will allow humans to engage with and understand a machine's decision making process, which is crucial if we are to trust machines to take decisions for us. In this 14 month project we focus particularly on healthcare applications but the potential applications are wide ranging, including robots that do dangerous tasks and smart homes that manage our domestic life.</gtr:abstractText><gtr:potentialImpactText>In the UK, most humans are rarely far from a device (be it laptop, smart phone, tablet, etc.) through which they can access a multitude of services and an unprecedented amount of knowledge and data from diverse sources. Technology is becoming increasingly pervasive, embedded in the cars we drive and the buildings we inhabit, as we move to a future of Smart Cities and the Internet of Things. As technology advances, demands on our time grow, and the available knowledge and services becomes so great that humans can no longer be aware of it all, we are entrusting more, and more important, tasks to our machines, bestowing them with varying degrees of autonomy. Be they robots, e.g., that carry out unmanned missions to hostile environments such as the deep sea or the site of an earthquake, or software systems, e.g., a personal digital healthcare assistant (PDHA) to support elderly people living at home, these machines must be able to interact with humans in order to, e.g., jointly make decisions and reach agreements, explain why a particular course of action is appropriate, and take into account a human's knowledge or preferences. 

The foundational research we propose will allow a machine to determine the arguments or claims to assert, the questions to pose, and the justifications to challenge in order to successfully engage in such interactions. This will benefit society by allowing humans to engage in and understand the decisions these intelligent machines make, crucial if we are to trust and value their decisions. The potential applications of our research are wide ranging, including the robots and PDHAs discussed above, emergency response advice systems, and intelligent home management systems that order our groceries and manage our energy consumption. Such systems will have massive benefits for society, improving the quality of life, making home care more accessible, and avoiding risk to humans. Furthermore, the work carried out in this project will strengthen the UK's position as a global leader in robotics and autonomous system technology, one of eight great technologies that have been identified by the UK government as areas that can boost our exports and drive economic growth.

In this 14 month project, we will focus particularly on healthcare technology applications, considering benchmark examples from the clinical domain and with the support of our project partner, a leading expert in the development of healthcare technologies, identifying particular applications that can benefit from our results in the short term. Current theory and technologies will allow us to use our results to support highly structured human-machine dialogues where what the human can say is restricted; however, we envisage in the longer term applying our approach to allow much more flexible dialogues, where a machine can, e.g., interpret the intended meaning of an utterance from its context or develop a model of a human based on its interactions with them. We will engage with various UK research groups who work on the challenges related to this long term goal and who develop systems that can benefit from such dialogues, in order to produce a roadmap of open problems that must be addressed. This roadmap will benefit the UK by helping to focus research efforts on realising flexible human-machine interactions and has the potential to influence research funding strategy. 

We will engage with the public through social media channels and public engagement events. This is important as we must take account of the public's views on allowing machines to make decisions for us and on engaging with them on these decisions. These activities will allow us to educate the public about the theory that underlies these intelligent machines, mitigating public resistance to autonomous, or semi-autonomous, systems.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-02-25</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-05-26</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>98726</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Agents lecture</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>3E9A2749-5AF8-4DB2-B74E-D44C68AEE07A</gtr:id><gtr:impact>As part of the module I teach on Agents and Multi-Agent Systems, I have developed a lecture based on the research carried out in the Planning an Argument project. This module includes final year undergraduate students and masters students and feedback from the students indicated that they particularly enjoyed learning about this current research. I have delivered the lecture twice now, and found that it generates interesting discussion, during which students have made insightful suggestions for future research.</gtr:impact><gtr:outcomeId>58bd6c183e7471.92150743</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We are interested in a strategic argumentation setting where two agents exchange arguments, and the proponent aims to persuade its opponent of some goal arguments. Our proponent has an uncertain model of the opponent's arguments but no knowledge of its strategy, and so we aim to find a strategy that will be successful no matter which arguments the opponent asserts.
We have defined a translation from our strategic argumentation setting to a planning model. This means that we can use an off-the-shelf automated planner to determine which arguments a software agent should assert during a dialogue in order to persuade its opponent of some goal arguments.
We have shown that our approach finds persuader strategies with a certain probability of being guaranteed to successfully persuade the opponent, no matter which arguments the opponent chooses to assert, for a range of challenging problems. 
We have developed two families of benchmark problems for evaluating persuasion strategies. These benchmark problems pose particular challenges for the persuader due to the presence of arguments that may be either helpful or detrimental to the persuader's goal, depending on the actual arguments known by the opponent and the arguments that the opponent chooses to assert during the dialogue.</gtr:description><gtr:exploitationPathways>We have made our translation and our benchmarks publicly available, for use by other academic researchers. Strategic argumentation is receiving increasing interest from the research communities, with several new approaches being developed in the past couple of years. Our benchmarks and our translation will support evaluation of these, and future, approaches and should serve to help progress the field.
There is increasing interest in development of persuasion technologies that can be used to persuade humans to behave in beneficial ways (such as to eat healthily or to give up smoking). The research results from this project can be used to enable technology to select arguments that are likely to be persuasive to a particular user.
Results from this project can also be used in the development of e-democracy tools that engage citizens in a dialogue around key policy issues. Such tools could be used to better inform the public, or to solicit public opinion on a particular topic.</gtr:exploitationPathways><gtr:id>F8A7FFE9-BE73-41B6-B11C-20D37DC496DB</gtr:id><gtr:outcomeId>56b89a82638589.09125383</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare,Government, Democracy and Justice</gtr:sector></gtr:sectors><gtr:url>https://github.com/christopher-hampson/argstrat</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>Contains two families of strategic argumentation benchmark problems, that can be used to evaluate argumentation dialogue strategies.</gtr:description><gtr:id>E7BBC7F9-DA01-40A2-9951-AA0076CD5956</gtr:id><gtr:impact>These have been used to evaluate the research results of the Planning an Argument project.</gtr:impact><gtr:outcomeId>58bd69579b2ba4.26888977</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Strategic argumentation benchmark problems</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>https://github.com/christopher-hampson/argstrat</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The software takes as input a description of a strategic argumentation problem and outputs a description of that problem in PDDL. An automated planner can then be applied to solve the problem in order to generate a strategy for persuasion that has a certain probability of guaranteed success.</gtr:description><gtr:id>A8485527-71EF-460E-AD78-834A847ECE9F</gtr:id><gtr:impact>This implementation is being used by an undergraduate student as the basis of their final year project and by a masters student as the basis of their dissertation. It is also being further developed by a PhD student.</gtr:impact><gtr:outcomeId>58bd7b91223307.37472563</gtr:outcomeId><gtr:title>Implementation of translation from strategic argumentation problem to planning problem</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/christopher-hampson/argstrat</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>6B470C3E-01F7-453F-B47F-EA9BF2B87ED8</gtr:id><gtr:title>Optimal simple strategies for persuasion</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab9c46f2383681f1309606341de714c1"><gtr:id>ab9c46f2383681f1309606341de714c1</gtr:id><gtr:otherNames>Elizabeth Black</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a9d161a543e92.20696925</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2E0F5AB4-406F-4FDF-9FE1-28A84DC88D76</gtr:id><gtr:title>Optimal Simple Strategies for Persuasion</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e09b7a5bf2069e031f2267a5b9166661"><gtr:id>e09b7a5bf2069e031f2267a5b9166661</gtr:id><gtr:otherNames>Black E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd42f76397d8.87461001</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>55F29F95-7BE2-4704-B2AC-52E5800E3890</gtr:id><gtr:title>An Automated Planning Approach for Generating Argument Dialogue Strategies</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/018c270be5a85d3b5805c2085d8f42e9"><gtr:id>018c270be5a85d3b5805c2085d8f42e9</gtr:id><gtr:otherNames>Daub T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd46e62baf80.97515935</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D5291EE8-3BCF-45C7-99BF-4727D54DFEDD</gtr:id><gtr:title>An Automated Planning Approach for Generating Argument Dialogue Strategies</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/018c270be5a85d3b5805c2085d8f42e9"><gtr:id>018c270be5a85d3b5805c2085d8f42e9</gtr:id><gtr:otherNames>Daub T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd45b6e5bce4.44325393</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>44D76F53-99EA-4BEB-96F4-D780FD38E743</gtr:id><gtr:title>A Heuristic Strategy for Persuasion Dialogues</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dfd786f55172b9bb9f31fc5f0625c34e"><gtr:id>dfd786f55172b9bb9f31fc5f0625c34e</gtr:id><gtr:otherNames>Murphy J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58bd4227f13e56.07446332</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M01892X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>90</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>