<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/DC934AED-9432-4385-AEAF-006EA2369001"><gtr:id>DC934AED-9432-4385-AEAF-006EA2369001</gtr:id><gtr:name>University of Huddersfield</gtr:name><gtr:department>Sch of Music Humanities &amp; Media</gtr:department><gtr:address><gtr:line1>Queensgate</gtr:line1><gtr:line4>Huddersfield</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>HD1 3DH</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DC934AED-9432-4385-AEAF-006EA2369001"><gtr:id>DC934AED-9432-4385-AEAF-006EA2369001</gtr:id><gtr:name>University of Huddersfield</gtr:name><gtr:address><gtr:line1>Queensgate</gtr:line1><gtr:line4>Huddersfield</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>HD1 3DH</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/F2D42B07-0E54-47D1-ABD5-2CE6A6F6CE71"><gtr:id>F2D42B07-0E54-47D1-ABD5-2CE6A6F6CE71</gtr:id><gtr:firstName>Pierre Alexandre</gtr:firstName><gtr:surname>Tremblay</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=AH%2FG010587%2F1"><gtr:id>E5D4ED66-93A6-4F15-AB24-65F39DCD1690</gtr:id><gtr:title>Thinking Inside the Box: A New Integrated Approach to Mixed Music Composition and Performance</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/G010587/1</gtr:grantReference><gtr:abstractText>Mixed music is a hybrid music genre where electronic sounds are composed to be played with acoustic instruments.\n\nSince its invention, this genre has been a source of new and exciting possibilities for composers, and produced many seminal works, but there are several issues with live performance of mixed music which have not been addressed until now. The two main problems are (1) the dichotomy between the composed sound in the studio, and its concert rendition, and (2) the live blend between the instruments and the electronics in the concert hall.\n\nThe issue of sound blending between instruments and loudspeakers is due to a radical difference between their respective modes of sound production. Instruments, like all solid objects, radiate sound in all directions. While speaker cabinets act more like a canon, projecting sound along an axis. Traditionally, multiple loudspeakers are used to create the stereophonic illusion of space, a solution which works by over-riding the natural characteristics of a space's acoustic, but this only alienates the instrument sound more because it is radiating sound throughout the space.\n\nThe dichotomy between the studio composition and its concert rendition is related also to the means of sound projection. Here the problem is reversed, the composer uses a recording of the instrumental part with which to compose or guide the electronics, this recording is a reduction of the natural instrument sound to a stereo (or mono) image. Since both the electronics and the recorded instruments come out of the same monitoring system, usually a very good pair of speakers in a controlled acoustic environment, they will work well together. But the concert hall is very different acoustic environment, here the instruments are played live, therefore radiating sound, and the electronic part is played by loudspeakers projecting into the hall, this more often than not leads to a compromised situation where the instrument and electronics compete rather than blend, resulting in a less than ideal rendition.\n\nTo compensate for this, the historical solution is to amplify the acoustic instrument, reducing its image to its electronic reproduction. This rarely works properly, as it impoverishes the instrumental sound, as well as bringing its own problems. Instrumentalists are trained to play in ensembles of similarly radiating instruments, mixed music performance often involves using amplification and monitoring which require radically different listening modes of the player: the electroacoustic parts often sound distant and may have unnaturally exaggerated dynamics due to the loudspeakers' axial projection. Monitoring both the electronic sound and their own through foldback monitors can be a struggle as the system compromises the player's tone and reduces the ensemble to an audio cueing system. With compromises in sound, timbre and spatial identity, this situation can be off-putting for many performers.\n\nWhat is proposed in this project is to rethink the whole process, by thinking the music 'inside the box'. Firstly, by exploring radiating speakers, which produce sounds in patterns more similar to instruments, instead of an axis sound projection. Secondly, by taking impulse response recordings of the selected speaker set-up, using convolution reverb we can then reproduce the sound world of the concert hall inside the studio. Therefore, the composer will be able to make aesthetic decisions according to the real-world of the concert hall, by reproducing its bias in the studio. We hope that, with these two steps, we could avoid the amplification of the instrumental part, since the composer will have taken these acoustic considerations on-board during the composition process. The lot of the performer can also be improved by this project. By using radiating speakers, the electroacoustic sounds will in effect be members of the ensemble, with a live presence and their own spatial identity.</gtr:abstractText><gtr:fund><gtr:end>2009-04-05</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2008-10-06</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>15932</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">AH/G010587/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>0AEFDABE-67A4-48B1-9DB4-99393BDE6065</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Music</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A13304AD-8058-4333-86C7-DB798216A696</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Composition</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>55773495-BB0B-43EB-B99D-D5C15272A52F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Musical Performance</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>