<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/5F600791-9929-4BAE-9186-DB9F207BD7C1"><gtr:id>5F600791-9929-4BAE-9186-DB9F207BD7C1</gtr:id><gtr:name>McGill University</gtr:name><gtr:address><gtr:line1>845 Sherbrooke Street W</gtr:line1><gtr:line4>Montreal</gtr:line4><gtr:line5>Quebec, H3A 2T5</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/9B116CCE-C009-4010-8EC4-921CB86A6C0F"><gtr:id>9B116CCE-C009-4010-8EC4-921CB86A6C0F</gtr:id><gtr:name>Nanyang Technological University</gtr:name><gtr:address><gtr:line1>Nanyang Avenue</gtr:line1><gtr:line4>Singapore</gtr:line4><gtr:line5>639798</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Singapore</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/DC934AED-9432-4385-AEAF-006EA2369001"><gtr:id>DC934AED-9432-4385-AEAF-006EA2369001</gtr:id><gtr:name>University of Huddersfield</gtr:name><gtr:address><gtr:line1>Queensgate</gtr:line1><gtr:line4>Huddersfield</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>HD1 3DH</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/C63C524B-5AEC-4C18-A4B6-0173C2AC27BB"><gtr:id>C63C524B-5AEC-4C18-A4B6-0173C2AC27BB</gtr:id><gtr:name>Volvo Trucks</gtr:name><gtr:address><gtr:line1>Gotenberg</gtr:line1><gtr:line2>Sweden</gtr:line2><gtr:region>Outside UK</gtr:region><gtr:country>Sweden</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/DC934AED-9432-4385-AEAF-006EA2369001"><gtr:id>DC934AED-9432-4385-AEAF-006EA2369001</gtr:id><gtr:name>University of Huddersfield</gtr:name><gtr:department>Sch of Computing and Engineering</gtr:department><gtr:address><gtr:line1>Queensgate</gtr:line1><gtr:line4>Huddersfield</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>HD1 3DH</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/DC934AED-9432-4385-AEAF-006EA2369001"><gtr:id>DC934AED-9432-4385-AEAF-006EA2369001</gtr:id><gtr:name>University of Huddersfield</gtr:name><gtr:address><gtr:line1>Queensgate</gtr:line1><gtr:line4>Huddersfield</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>HD1 3DH</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5F600791-9929-4BAE-9186-DB9F207BD7C1"><gtr:id>5F600791-9929-4BAE-9186-DB9F207BD7C1</gtr:id><gtr:name>McGill University</gtr:name><gtr:address><gtr:line1>845 Sherbrooke Street W</gtr:line1><gtr:line4>Montreal</gtr:line4><gtr:line5>Quebec, H3A 2T5</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9B116CCE-C009-4010-8EC4-921CB86A6C0F"><gtr:id>9B116CCE-C009-4010-8EC4-921CB86A6C0F</gtr:id><gtr:name>Nanyang Technological University</gtr:name><gtr:address><gtr:line1>Nanyang Avenue</gtr:line1><gtr:line4>Singapore</gtr:line4><gtr:line5>639798</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Singapore</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C63C524B-5AEC-4C18-A4B6-0173C2AC27BB"><gtr:id>C63C524B-5AEC-4C18-A4B6-0173C2AC27BB</gtr:id><gtr:name>Volvo Trucks</gtr:name><gtr:address><gtr:line1>Gotenberg</gtr:line1><gtr:line2>Sweden</gtr:line2><gtr:region>Outside UK</gtr:region><gtr:country>Sweden</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/563116B4-ECCA-4CAC-B2D7-4096C75EF963"><gtr:id>563116B4-ECCA-4CAC-B2D7-4096C75EF963</gtr:id><gtr:firstName>Hyunkook</gtr:firstName><gtr:surname>Lee</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FL019906%2F1"><gtr:id>E93E6CF0-15FA-49DA-AC98-C3E51B413011</gtr:id><gtr:title>Perceptual Rendering of Vertical Image Width for 3D Multichannel Audio</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/L019906/1</gtr:grantReference><gtr:abstractText>Conventional surround sound systems such as 5.1 or 7.1 are limited in that they are only able to produce a two-dimensional (2D) impression of auditory width and depth. Next generation surround sound systems that have been introduced over recent years tend to employ height channel loudspeakers in order to provide the listener with the impression of a three-dimensional (3D) soundfield. Although new methods to position (pan) the sound image in the vertical plane have been investigated, there is currently a lack of research into methods to render the perceived vertical width of the image. The vertical width rendering is particularly important for creating the impression of a fully immersive 3D ambient sound in such applications as the production of original 3D music/broadcasting content and the 3D upmixing of 2D content. This project aims to provide fundamental understandings of the perception and control of vertically oriented image width for 3D multichannel audio. Three objectives have been formulated to achieve this aim: (i) to determine the frequency-dependent perceptual resolution of interchannel decorrelation for vertical image widening; (ii) to determine the effectiveness of 'Perceptual Band Allocation (PBA)', a novel method proposed for vertical image widening; (iii) to evaluate the above two methods in real-world 2D to 3D upmixing scenarios. These objectives will be achieved through relevant signal processing techniques and subjective listening tests focussing on perceived spatial and tonal qualities. Data obtained from the listening tests will be analysed using robust statistical methods in order to model the relationship between perceptual patterns and relevant parameters. The results of this project will provide researchers and engineers with academic references for the development of new 3D audio rendering algorithms, and will ultimately enable the general public to experience a fully immersive surround sound in the home-cinema, car and mobile environments.</gtr:abstractText><gtr:potentialImpactText>The proposed research investigates methods to render stereophonic image width across vertically arranged loudspeakers, which will ultimately enable the creation of immersive 3D auditory sensation through sound reproduction utilising loudspeaker formats employing height channels. This project transfers signal decorrelation methods that have been widely used for horizontal stereo width rendering to a vertical dimension. Furthermore, it explores a novel vertical width rendering method named 'Perceptual Band Allocation' (PBA), which is optimised for vertical stereophony in terms of perceived tonal quality. The most immediate economic and societal impacts are expected through uptake of the investigated methods by the following four sectors: professional audio R&amp;amp;D; consumer audio R&amp;amp;D; music production/broadcasting; and electroacoustic music composition. The following sections describe how they will benefit from this project. Please see Pathway to Impact for related impact activities planned.

1) Impact on pro audio R&amp;amp;D

The results of this project will become the basis for pro audio companies to develop new sound mixing tools for 3D music production and broadcasting (e.g. 3D reverberator, 3D image widening tool, etc.). The extensive data sets produced from this project will determine the effectiveness of each investigated method in vertical width rendering for various experimental conditions (frequency band, loudspeaker position and sound source characteristics). Audio engineers will greatly benefit from this in terms of the effective design and efficient implementation of a new rendering algorithm; e.g. the data will be references as to which parameters to focus on depending on the target loudspeaker position or source type. Furthermore, since this project examines the tonal quality of rendered sound as well as the spatial quality for each experimental condition, the results of this research will help the engineers to ensure the overall sound quality of the implemented algorithm. 
 
2) Impact on consumer audio R&amp;amp;D

This project will benefit consumer Hi-Fi audio manufacturers. For example, the results of this project will be useful for the development of new 2D to 3D upmixing algorithms for home-cinema AV receivers. In combination with an existing source/ambience separation technique (e.g. Principal Component Analysis), the investigated methods can be applied to the ambient parts of original 2D signals to create the impression of environmental width in the height dimension. This will enable consumers to experience the impression of 3D Listener Envelopment from 2D-encoded contents in the home-cinema environment. Car audio companies will be another beneficiaries of this project. The experiments conducted in this project can be repeated in a similar manner for car audio systems. This will enable the design of new 3D upmixing algorithms which are optimised for specific loudspeaker arrangements in automobile cabins. Last but not least, the methods investigated in this project can also be combined with an existing binaural synthesis technique to develop a new 3D sound engine for mobile devices. 

3) Impact on music production and broadcasting

Sound engineers in music production and broadcasting will be important end-users of the audio mixing tools developed based on this project. Currently, there exists no software plug-ins to flexibly control the perceived vertical width of sound image in music mixing. This project will enable the sound engineers to fully utilise the added height dimension of 3D multichannel audio to create the impression of a fully immersive soundfield. 

4) Impact on electroacoustic music composition

The tools developed from this project will help electroacoustic music composers who exploit multichannel spatialisation techniques to express their musical ideas more creatively in 3D. This will ultimately impact the way music is presented to the audience in concerts.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-09-09</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-09-10</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>100076</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>This audio recording has been made for Korean Chamber Orchestra's concert at Queens Elizabeth Hall in London in Feb 2015. The recording was made using a novel microphone technique for 3D reproduction.</gtr:description><gtr:id>1357EE1A-CB4E-43B6-81D1-22F309F4755C</gtr:id><gtr:impact>The recording technique used for this recording has been demonstrated to audio engineers at a number of international conferences. Schoeps, one of the most famous microphone manufacturers, adapted the main concept of the technique for their new product ORTF-3D.</gtr:impact><gtr:outcomeId>563aa63fc85d89.83059389</gtr:outcomeId><gtr:title>Live concert recording in 3D for Korean Chamber Orchestra</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>An organ performance by Dr Gordon Stewart on the 1870 Phillis organ at the Huddersfield Town Hall has been recorded in 9.1 multichannel 3D format. This recording exploited all of the three key methods developed from the EPSRC project: (i) 3D microphone array configuration (ii) Perceptual Band Allocation (PBA) and (iii) Virtual image elevation. The result of the recording was satisfactory. It was possible to represent the actual acoustics of the concert hall in reproduction using 9.1 channel loudspeakers. The vertical dimension of the organ was successfully represented in the recording.</gtr:description><gtr:id>C74F6481-337C-4211-AE94-631830548B02</gtr:id><gtr:impact>It is expected that this recording project will lead to a commercial release of 3D organ recording in the Auro-3D or Dolby Atmos Bluray format. The recording will be demonstrated in future conferences and workshops to show sound engineers and developers the merits of the new 3D recording and rendering techniques developed from the EPSRC project.</gtr:impact><gtr:outcomeId>56d8a666d88d51.18050496</gtr:outcomeId><gtr:title>3D recording of Organ at the Huddersfield Town Hall</gtr:title><gtr:type>Artefact (including digital)</gtr:type><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Surrey</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>3D loudspeaker configuration project with Surrey and York Universities</gtr:description><gtr:id>22FF838E-9F16-4681-A5B0-1C9B657F43D3</gtr:id><gtr:impact>- Generated detailed ideas for future collaborative project on 3D loudspeaker configuration.
- This collaboration is ongoing. A future funding application is being prepared.</gtr:impact><gtr:outcomeId>56d8b500ba1559.21403266-1</gtr:outcomeId><gtr:partnerContribution>- Discussed and generated future collaboration research ideas on 3D loudspeaker configuration.</gtr:partnerContribution><gtr:piContribution>- Discussed and generated future collaboration research ideas on 3D loudspeaker configuration.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Volvo Trucks</gtr:collaboratingOrganisation><gtr:country>Sweden, Kingdom of</gtr:country><gtr:description>Automotive 3D audio with Volvo Cars</gtr:description><gtr:id>E50926BE-B9EE-4D71-992C-A76A9B206DA5</gtr:id><gtr:impact>- Produced detailed specifications for 3D audio reproduction system for automotive 3D audio research.
- Evaluated various types of 3D upmixing algorithms in terms of perceptual attributes and subjective preference. 
- Generated further collaborative research topics on automotive 3D audio.</gtr:impact><gtr:outcomeId>56d8aaf831d552.75452851-1</gtr:outcomeId><gtr:partnerContribution>- Provided expert feedbacks on 3D recordings and upmixing methods. 
- Provided tele-conference meetings.
- Generated further collaborative research topics.</gtr:partnerContribution><gtr:piContribution>- Provided consultancy on building a 3D reproduction system. 
- Provided various types of 3D recordings for demonstration and listener training purposes.
- Conducted subjective evaluations on various 3D upmixing methods for car audio.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>McGill University</gtr:collaboratingOrganisation><gtr:country>Canada</gtr:country><gtr:description>3D Audio Workgroup</gtr:description><gtr:id>E9BF5A05-500B-421E-B8DE-965D75C4DE32</gtr:id><gtr:impact>This collaboration is currently in preparation. The main aims of the collaboration are (i) open discussion on all aspects in 3D sound (ii) networking through sharing resources and information (iii) conducting inter-disciplinary research on 3D sound recording.</gtr:impact><gtr:outcomeId>55ddf13ee8e235.64810670-1</gtr:outcomeId><gtr:partnerContribution>This collaboration is currently in preparation. The main aims of the collaboration are (i) open discussion on all aspects in 3D sound (ii) networking through sharing resources and information (iii) conducting inter-disciplinary research on 3D sound recording.</gtr:partnerContribution><gtr:piContribution>This collaboration is currently in preparation. The main aims of the collaboration are (i) open discussion on all aspects in 3D sound (ii) networking through sharing resources and information (iii) conducting inter-disciplinary research on 3D sound recording.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of York</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>3D loudspeaker configuration project with Surrey and York Universities</gtr:description><gtr:id>40C48A22-A598-42B3-9A97-1781E5932DD4</gtr:id><gtr:impact>- Generated detailed ideas for future collaborative project on 3D loudspeaker configuration.
- This collaboration is ongoing. A future funding application is being prepared.</gtr:impact><gtr:outcomeId>56d8b500ba1559.21403266-2</gtr:outcomeId><gtr:partnerContribution>- Discussed and generated future collaboration research ideas on 3D loudspeaker configuration.</gtr:partnerContribution><gtr:piContribution>- Discussed and generated future collaboration research ideas on 3D loudspeaker configuration.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Nanyang Technological University</gtr:collaboratingOrganisation><gtr:country>Singapore, Republic of</gtr:country><gtr:description>3D ambience upmixing project with Nanyang Technological University in Singapore</gtr:description><gtr:id>5518DD77-D9E5-4A50-A7B7-87C1F570F244</gtr:id><gtr:impact>This collaboration is in an early stage at the moment. The creation of test stimuli will be done by the end of June and listening experiments will be conducted during July and August 2016. The outcomes of the collaboration will include journal papers and potential IPs.</gtr:impact><gtr:outcomeId>56ddfb2be1ab05.96506407-1</gtr:outcomeId><gtr:partnerContribution>- Provided a novel ambience extraction algorithm for 3D upmixing</gtr:partnerContribution><gtr:piContribution>- Created multichannel audio samples for 3D upmixing.
- provided the PBA (perceptual band allocation) algorithm for 3D upmxing</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Huddersfield</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Centre for Research in New Music (CeReNeM)</gtr:department><gtr:description>CeReNeM</gtr:description><gtr:id>A9E1CF75-DEA7-4372-8CDD-35CF65BC450B</gtr:id><gtr:impact>Development of a new research topic in 3D spatialisation
- Psychoacoustics, music composition, musicology, software development</gtr:impact><gtr:outcomeId>55ddeffde93a22.91571436-1</gtr:outcomeId><gtr:partnerContribution>Free use of equipment - microphones, amplifiers and studios.
Free support of sound sources - musicians and instruments</gtr:partnerContribution><gtr:piContribution>I have contributed to the development of new collaborative research topics in 3D spatialisation for electroacoustic music composition.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>3D audio tutorial/demo - Audio Engineering Society 138th International Convention</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>DDD00FA9-D301-4966-91E4-A1B097678E7E</gtr:id><gtr:impact>The aim of this activity was to help people understand the psychoacoustic principles of 3D sound and their practical applications. It included many practical audio demos involving 3D loudspeaker setup. The talk/demo received very good feedbacks.

I think the talk/demo certainly raised the awareness of the benefit of 3D sound, and helped people expand their knowledge about how to apply different signal processing methods to produce good quality 3D sound. After the talk/demo, a number of people came to me to give positive feedbacks or to have further discussion.</gtr:impact><gtr:outcomeId>55dded39252296.94503505</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>PBA presentation - Audio Engineering Society 138th International Convention</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>BD3EF0A7-1809-4CEB-BC89-15A21CBF3883</gtr:id><gtr:impact>The presentation was about the main method called 'Perceptual Band Allocation (PBA)', which is being investigated for the current EPSRC project. It went very well, raising interesting questions and constructive discussion.

This talk gave an opportunity to raise the awareness of the current EPSRC project and also discuss with some of the leading academics.</gtr:impact><gtr:outcomeId>55ddeb451d2a88.77791131</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>HAART demo - Audio Engineering Society 138th International Convention</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C67109FD-184B-43F5-AFE1-4DD7BE0E2660</gtr:id><gtr:impact>The talk and demo was very successful. It dragged attention of many people and received positive and constructive feedbacks.

After the talk/demo of the HAART software, many people said the software would be highly useful for their research and teaching. They signed up for an emailing list to get further information about downloading and future update. The talk also gave opportunities to meet and discuss with many leading academics.</gtr:impact><gtr:outcomeId>55ddea30611d86.66383992</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Tonmeistertagung conference 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>7D5E9CE4-011E-46BA-9F2B-F5B42B2E3343</gtr:id><gtr:impact>The presentation raised high interest among some renowned academics in the current EPSRC funded research I am conducting. Many people who attended the talk agreed on the importance of the research.

This talk led to conversations with many leading academics, research institutes and companies about the topic area. Particularly IEM in Austria and Fraunhofer IIS in Germany showed interests in future collaboration, and this is being discussed.</gtr:impact><gtr:outcomeId>55dde76259c606.68804765</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>HULTI-GEN demo - Audio Engineering Society 138th International Convention</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>23F73AE0-4A14-4F7D-BE33-D3A7299E764D</gtr:id><gtr:impact>This talk was received very well. Many people were interested in the HULTI-GEN software demonstrated and gave positive feedbacks.

A number of people signed up an emailing list for getting future update information of the tool. This presentation/demo also led conversations and discussion with many leading people in the audio industry. Further, it helped raising the awareness of the current EPSRC-funded research being conducted at the University of Huddersfield.</gtr:impact><gtr:outcomeId>55dde9307fb5f6.99512197</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited panel for roundtable discussion at the 3rd International Conference on Spatial Audio</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>61E85DAD-5E39-4392-80F9-C2B94FF0E861</gtr:id><gtr:impact>I participated in a roundtable discussion on the future of 3D sound as an invited panel member. I mainly shared my view and provided discussion points on binaural 3D sound.

The participation gave me the opportunity of introducing my current research to a large audience from the industry. After the panel discussion a number of people from the industry agreed on the points I made during the discussion. It also enabled me to continue research discussion by emails with some of the key people from the industry such as Tom Holman of Apple and Gunther Theile of IRT.</gtr:impact><gtr:outcomeId>563aad15358f98.93030741</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation on virtual image elevation effect at the 139th AES convention in New York, 2015</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>15D5EA0F-E231-4EC6-8F25-C6371444EC52</gtr:id><gtr:impact>The talk was about my research findings on virtual auditory image elevation. After the presentation I received many positive feedbacks from industry experts. In particular they all supported my new theoretical explanation on the reason for the perception of virtual image elevation.</gtr:impact><gtr:outcomeId>56d8b6cc3ca152.93601007</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.aes.org/e-lib/browse.cfm?elib=17997</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited workshop/demo on 3D sound at the 3rd International Conference on Spatial Audio (ICSA)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E626AE3C-1F33-4B54-8982-DF1115EE812F</gtr:id><gtr:impact>The workshop/demo received very positive feedbacks from many industry and academia leading experts in spatial audio including Gunther Theile of IRT, Tom Holman of Apple and Florian Camerer of ORF, Robert Sazdov of Fraunhofer IIS and Franz Zotter of IEM Graz.

The workshop led to some constructive discussion on the improvement of the current 3D loudspeaker layout among people mentioned above. It also greatly raised the awareness of the importance of the current EPSRC project I am working on.</gtr:impact><gtr:outcomeId>563aaae0ea9538.77210434</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk at AES Midland workshop on Intelligent Music Production</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>3689D92E-F9E7-48AF-8264-7718E5DF7889</gtr:id><gtr:impact>Current research on semantic audio mainly focuses on the tonal and dynamic aspect of audio, but there is no much research conducted on the semantics of 3D audio. My talk on &amp;quot;intelligent 3D music production&amp;quot; led to a discussion on a collaborative research for semantic audio in spatial audio.

After my talk, several people from Queen Mary University and Birmingham City University showed a great interest in my research area and discussed future collaboration. Also a person from Music Group, one of the largest music technology companies in the industry, would like to visit my 3D sound lab in Huddersfield. I was invited for another talk at a future event on the same topic.</gtr:impact><gtr:outcomeId>563aa89e418df5.12944672</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:url>http://www.aes-uk.org/forthcoming-meetings/aes-midlands-workshop-on-intelligent-music-production/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>3D audio tutorial/demo - Audio Engineering Society 139th International Convention in New York</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>42B6474C-1557-4577-8FA7-EBEB6A9B3AD3</gtr:id><gtr:impact>The tutorial/demo session was highly successful. The demo room was full and the audience was engaged well in the session. After the session a number of people came to give me positive feedbacks and ask questions.

After the tutorial/demo session a number of industry experts gave highly positive feedbacks. Particularly people from Sennheiser, Volvo and Panasonic showed great interests in the research I am conducting and asked me to send them my papers and audio samples. They also said they would like to visit my lab when they next come to the UK.</gtr:impact><gtr:outcomeId>563ccef7c43a43.64775446</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.aes.org/events/139/spatialaudiodemos/?ID=4781</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>1. The main finding from the AES journal paper - Lee, H, and Gribben, C (2014) Effect of Vertical Microphone Layer Spacing for a 3D Microphone Array, J. Audio. Eng. Soc. 62, pp. 870-884 - has been used for a 3D microphone array called ORTF 3D-Flat by Schoeps, Germany, one of the most famous microphone manufacturer companies in the world. The information about the product can be found in http://www.hauptmikrofon.de/stereo-3d/3d-audio/67-ortf-3d-microphone-technique-for-3d-ambience-recording.

2. The PBA method presented in Lee, H (2015) 2D to 3D ambience upmixing based on perceptual band allocation, J. Audio. Eng. Soc., 63, pp. 811-821. was used for an automotive 3D sound system investigation by Volvo Cars, Sweden.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>79946029-6BAE-4B3C-A998-2C211324EF3B</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d819960a9341.47237636</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Electronics,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>1. The perceptual mechanism of the so-called Pitch-Height effect for virtual auditory images has been revealed. Formal experimental data on the perceived vertical positions of octave-band filtered virtual images have been provided for different azimuth angles. It has been found that the nature of virtual source elevation localisation is significantly different from that of real source elevation localisation. 
2. It has been shown that the aforementioned vertical image position data can be successfully exploited for rendering different degrees of vertical image spread. This method has been tested for the 2D to 3D sound upmixing of ambient sound. The results showed that the method was subjectively preferred to other conventional methods. 
3. The association between the loudspeaker base angle and the perceived image elevation has been investigated in depth. It was generally shown that the perceived image is elevated from the front to above of the listener as the loudspeaker base angle increases from 0 degree to 180 degrees. It was newly found that the effect significantly depends on the spectral and temporal characteristics of the sound source. Sources with a broad and Specifically, frequency bands centred around 500Hz and 8kHz were found to have the strongest elevation effect. These findings have important implications for practical applications such as 3D sound rendering, upmixing and downmixing.
4. A novel theory that ultimately explains the reason for the virtual image elevation effect has been established. Whilst the conventional theory based on the psychophysics of pinnae spectral distortion is limited to explaining the effect for high frequencies, the proposed theory is based on the brain's cognitive interpretation of ear-input signals is able to explain the effect for low frequencies also.</gtr:description><gtr:exploitationPathways>1. The PBA method can be used for developing 3D upmixing systems by audio software developers. The main application areas include home theatre audio-visual receiver (AVR), car audio, and virtual reality over headphones. 
2. The virtual image elevation method can be useful for 3D to 2D audio downmixing for home environment where height loudspeakers are not available. The upper-hemisphere amplitude panning (UHAP) method developed by exploiting the elevation principle can be used for 3D audio object panning without using height channels. This method can also be useful for binaural rendering for virtual reality applications.</gtr:exploitationPathways><gtr:id>1D751DC3-23AB-4897-AE22-96205C497EA1</gtr:id><gtr:outcomeId>56d8a332d44824.45066292</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Electronics,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:sectors><gtr:url>http://www.hud.ac.uk/research/researchcentres/mtprg/projects/apl/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>The Huddersfield 3D MRIR Database is a collection of multichannel room impulse responses captured using 48 different microphone configurations at St.Pauls concert hall in Huddersfield, UK.</gtr:description><gtr:id>6AA6ECC6-DCD1-4B82-9B79-C48177E8C5AE</gtr:id><gtr:impact>I am currently in preparation of releasing the database to the public through a website. It is expected that the database will become useful resources to spatial audio researchers, students and sound engineers for their research on 3D sound.</gtr:impact><gtr:outcomeId>56d8a75724d910.60560105</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Huddersfield 3D MRIR Database</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>Most auditory localisation tests typically use visual number scale or laser pointer as a response method. However, the number scale method has a visual bias. The laser pointer method is more intuitive than the others but requires a motion tracking device and a careful calibration. In order to overcome such limitation, I developed a new method using an LED strip and a wheel controller, which are controlled using the Arduino microcontroller and Max7 software. This method allows the test subject to move a single LED position to the corresponding perceived image position using the wheel controller. The position data is collected and saved by the software to produce a text file. This method has been used for a vertical localisation test and was shown to be very efficient. The subjects found it very easy and intuitive to use the method compared to the number scale method. The consistency of subjects responses was found to be significantly better than the number scale method. The test time spent using the method is also dramatically shorter than that using the number scale method. Additionally, the method also allows the subject to overlay the multiple LED positions to different positions. This is useful when judging the left/right or lower/upper boundaries of the perceived image as well as perceived image position.</gtr:description><gtr:id>FFC9B651-438C-4488-9FA4-C2E4296492FF</gtr:id><gtr:impact>This method is expected to become a useful resource for spatial audio researchers.</gtr:impact><gtr:outcomeId>56d8b1ea736e14.17768659</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>LED controller for localisation test</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>HULTI-GEN (Huddersfield Universal Listening Test Interface Generator) is a user-customisable environment, which takes user-defined parameters (e.g. the number of trials, stimuli and scale settings) and automatically constructs an interface for comparing auditory stimuli, whilst also randomising the stimuli and trial order. To assist the user, templates based on ITU-R recommended methods have been included. As the recommended methods are often adjusted for different test requirements, HULTI-GEN also supports flexible editing of these presets. Furthermore, some existing techniques have been summarised within this brief, including their restrictions and how they might be altered through using HULTI-GEN.</gtr:description><gtr:id>A452B276-34C8-436A-A21F-153A49E0C88A</gtr:id><gtr:impact>Since this software enables one to create a listening test GUI flexibly and quickly, it is expected to have a high impact in academic and research society. Researchers and students who work in subjective audio evaluation can greatly benefit from the software. Since this software became available in June 2015, the download count on the website is increasing rapidly every month. It is expected that the impact will continuously grow.</gtr:impact><gtr:outcomeId>55dde37ade09e6.92839102</gtr:outcomeId><gtr:title>HULTI-GEN</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://eprints.hud.ac.uk/24809/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>HAART (Huddersfield Acoustical Analysis Research Toolbox) is an all-in-one-box software that simplifies the measurement and analysis of multi-channel impulse responses (IRs). It is able to perform the acquisition, manipulation and analysis of IRs using subjective and objective measures described in acoustics literature. HAART is also able to convolve IRs with audio material and, most importantly, able to binaurally synthesise virtual, multichannel speaker arrays over headphones, negating the need for multichannel setups when out in the field.</gtr:description><gtr:id>30BA41ED-30E1-4615-B94A-98ED7076C4A2</gtr:id><gtr:impact>HAART was made available for free download in Aug 2015. HAART significantly improves the conventional workflow of impulse response capturing and acoustic analysis, and therefore it is expected to hugely benefit academics, students and researchers in the field of room/hall acoustics, psychoacoustics and spatial audio.</gtr:impact><gtr:outcomeId>55dde50d795288.20819259</gtr:outcomeId><gtr:title>HAART</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://eprints.hud.ac.uk/24579/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>IAR is a VST Plugin for 3D audio production. Developed by Leo McCormack and Hyunkook Lee at APL, the current version of IAR offers 3D panning (VBAP and DBAP) over 9.1 3D loudspeaker setup and the headphone externalisation of the loudspeaker signals. It also provides an innovative novel 3D GUI with multiple points of view.</gtr:description><gtr:id>92D42360-1A29-4DB9-9417-D16BEBDD23F9</gtr:id><gtr:impact>Since September 2015 the software has been downloaded 28 times.</gtr:impact><gtr:outcomeId>563a9e74bac554.33503092</gtr:outcomeId><gtr:title>Immersive Audio Renderer (IAR)</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://www.hud.ac.uk/research/researchcentres/mtprg/projects/apl/resources/iar/</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>1E927A35-FB05-466C-B1AB-95CECCB3F032</gtr:id><gtr:title>Perceptual Band Allocation (PBA) for the rendering of vertical image spread</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>563aa015287714.01082413</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CAF190AF-4C42-4476-9C71-C0B33C98D2EF</gtr:id><gtr:title>Directional bands revisited</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f62e9dbdf9d563e4f455a8133df400e5"><gtr:id>f62e9dbdf9d563e4f455a8133df400e5</gtr:id><gtr:otherNames>Wallis R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>563aa08524d7e1.35611186</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E25903C1-36E4-4041-92C6-D0B29B5645E8</gtr:id><gtr:title>The Perception of Vertical Image Spread by Interchannel Decorrelation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dacd1f549e8c99f106bfa1c2f05ff00c"><gtr:id>dacd1f549e8c99f106bfa1c2f05ff00c</gtr:id><gtr:otherNames>Gribben, C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>57db061a384298.87951285</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FDC91A36-86B8-497F-92F7-1B738A8E2FD5</gtr:id><gtr:title>Perceptual Band Allocation (PBA) for the Rendering of Vertical Image Spread with a Vertical 2D Loudspeaker Array</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>57db04b3b57a63.51464677</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5E5C346C-60A1-46C6-A5CB-CD10E04B6652</gtr:id><gtr:title>2D-to-3D Ambience Upmixing based on Perceptual Band Allocation</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>563aa15cbe1640.99403208</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FCC9BF1C-2499-43EB-8F05-4BC987CA9896</gtr:id><gtr:title>Investigation on the Phantom Image Elevation Effect</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d89ad356d031.08390328</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B113022C-2DA8-4C02-BF6B-36C0CB037032</gtr:id><gtr:title>A New Response Method for Auditory Localisation and Spread Tests</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cbb0412e06991f7f9f413ea53451178f"><gtr:id>cbb0412e06991f7f9f413ea53451178f</gtr:id><gtr:otherNames>Lee, H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>57db056accca64.84558997</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DBAEA99B-A1C1-4D4E-8A0F-B3325A03970F</gtr:id><gtr:title>Psychoacoustic Considerations in Surround Sound with Height</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d51d27ae45a90a741640847fefddf4ad"><gtr:id>d51d27ae45a90a741640847fefddf4ad</gtr:id><gtr:otherNames>LEE H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>55368b03ce3d15.03147816</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2D3BAC6D-9C6A-4FB0-94E0-ACE2B9CE04DB</gtr:id><gtr:title>Vertical Stereophonic Localisation in the Presence of Interchannel Crosstalk: the Analysis of Frequency-Dependent Localisation Thresholds</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/46171708760c56d26b625ce71b302fce"><gtr:id>46171708760c56d26b625ce71b302fce</gtr:id><gtr:otherNames>Wallis, R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>57db0456163eb7.86698075</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7BAB5056-1D66-4C64-9D92-1A325AE944FF</gtr:id><gtr:title>Evaluation of the Phantom Image Elevation Effect</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56d89b2634b634.84947432</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>804BFCFE-9F9B-4858-83C1-37406A869AD9</gtr:id><gtr:title>The Effect of Interchannel Time Difference on Localization in Vertical Stereophony</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f62e9dbdf9d563e4f455a8133df400e5"><gtr:id>f62e9dbdf9d563e4f455a8133df400e5</gtr:id><gtr:otherNames>Wallis R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>563aa1bd01a926.51049448</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>68E352D0-634B-427C-AC5F-7EE494CA75AE</gtr:id><gtr:title>Effect of Vertical Microphone Layer Spacing for a 3D Microphone Array</gtr:title><gtr:parentPublicationTitle>Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4835452f902a6cca2fd0be609e3178e"><gtr:id>c4835452f902a6cca2fd0be609e3178e</gtr:id><gtr:otherNames>Lee H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5536895b8e3114.23846531</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BE7DB9C4-AC92-4DF5-8432-D45A9A821E96</gtr:id><gtr:title>The Frequency Dependency Of Localisation Thresholds In The Presence Of Reflections</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f62e9dbdf9d563e4f455a8133df400e5"><gtr:id>f62e9dbdf9d563e4f455a8133df400e5</gtr:id><gtr:otherNames>Wallis R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b440423fdbe3.08268224</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E08544F2-1602-49F2-9DFC-93C7B26CFE3E</gtr:id><gtr:title>The Reduction of Vertical Interchannel Crosstalk: The Analysis of Localisation Thresholds for Natural Sound Sources</gtr:title><gtr:parentPublicationTitle>Applied Sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f62e9dbdf9d563e4f455a8133df400e5"><gtr:id>f62e9dbdf9d563e4f455a8133df400e5</gtr:id><gtr:otherNames>Wallis R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58c6bb494b7bd2.99844975</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D0815230-1870-4D22-8446-05F78B6DACDA</gtr:id><gtr:title>A Comparison between Horizontal and Vertical Interchannel Decorrelation</gtr:title><gtr:parentPublicationTitle>Applied Sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/85009c3a6e0db730d054e77b294f04d1"><gtr:id>85009c3a6e0db730d054e77b294f04d1</gtr:id><gtr:otherNames>Gribben C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a8b5d1d98d676.49075374</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/L019906/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>