<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/A08784FB-B6DC-4459-8A52-115C16157209"><gtr:id>A08784FB-B6DC-4459-8A52-115C16157209</gtr:id><gtr:name>Paris West University Nanterre La D?fense</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/6E750E7A-C076-435E-8AB0-484F65D6C7AD"><gtr:id>6E750E7A-C076-435E-8AB0-484F65D6C7AD</gtr:id><gtr:name>Kingston University</gtr:name><gtr:address><gtr:line1>River House</gtr:line1><gtr:line2>53-57 High Street</gtr:line2><gtr:line4>Kingston Upon Thames</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>KT1 1LQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A08784FB-B6DC-4459-8A52-115C16157209"><gtr:id>A08784FB-B6DC-4459-8A52-115C16157209</gtr:id><gtr:name>Paris West University Nanterre La D?fense</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/6E750E7A-C076-435E-8AB0-484F65D6C7AD"><gtr:id>6E750E7A-C076-435E-8AB0-484F65D6C7AD</gtr:id><gtr:name>Kingston University</gtr:name><gtr:address><gtr:line1>River House</gtr:line1><gtr:line2>53-57 High Street</gtr:line2><gtr:line4>Kingston Upon Thames</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>KT1 1LQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/08E9C038-DB22-4F79-B1D8-F8228F8DF0E4"><gtr:id>08E9C038-DB22-4F79-B1D8-F8228F8DF0E4</gtr:id><gtr:firstName>Oded</gtr:firstName><gtr:surname>Ben-Tal</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/F2F2E7CB-2E6B-4611-9DB6-985CD82F7C75"><gtr:id>F2F2E7CB-2E6B-4611-9DB6-985CD82F7C75</gtr:id><gtr:firstName>Bob</gtr:firstName><gtr:surname>Sturm</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=AH%2FN504531%2F1"><gtr:id>9F7B6EC2-767E-4AE7-92D6-F32A3B8DBF57</gtr:id><gtr:title>DaCaRyH (Data science for the study of calypso-rhythm through history)</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/N504531/1</gtr:grantReference><gtr:abstractText>DaCaRyH (Data science for the study of calypso-rhythm through history) is a collaboration of ethnomusicologists and archivists in France, and data scientists and composers in the UK. DaCaRyH has 3 objectives: 1) to enrich the domain of ethnomusicology by integrating data science and music information retrieval (MIR) methods into ethnomusicological archives and research practices; 2) to enrich the domains of data science and MIR by integrating ethnomusicological use cases into the practice of the research and development of intelligent systems; 3) to study the concept of musical style through a comparative diachronic analysis of a music corpus, and to transform the features extracted from the same corpus into new styles. DaCaRyH is aligned primarily with &amp;quot;'The Digital Age' and its effects on tangible and intangible heritage&amp;quot;, and secondarily with &amp;quot;representations and uses of the past.&amp;quot; DaCaRyH will work specifically with the music tradition of the steel band calypso. This provides focus on a variety of real and challenging ethnomusicological questions, which in turn drive the development of data science and MIR technologies. DaCaRyH helps pave the way to &amp;quot;big cultural data,&amp;quot; or the analysis of human culture at scales not possible without computational methods. DaCaRyH involves the Research Center for Ethnomusicology (CREM-LESC, France), and the Centre for Digital Music (C4DM, Queen Mary University of London, UK). CREM-LESC offers access to a large ethnomusicologic recordings database accessible worldwide through an online platform. C4DM is a world-leading group of specialists in data science applied to music. DaCaRyH will result in: two journal submissions (one in the respective fields of the PIs), a call for a special journal issue concerning cultural studies and data science, a music composition and performance project involving the use of the tools developed in DaCaRyH, and improved functionality integrated with the CREM-LESC ethnomusicological recordings archive.</gtr:abstractText><gtr:fund><gtr:end>2017-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2016-02-22</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>79934</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>The 3,000 tunes in this session volume have been generated entirely by a computerised system (named folk-rnn) trained on 23,636 tunes contributed by users of thesession.org. Each tune appears as ABC and in staff notation, and is hyperlinked to a synthesised realisation. Even though this work is not focused directly on calypso style music, it is a preliminary investigation of a music practice for which we have enough high level data.</gtr:description><gtr:id>CFA63245-23F3-45FD-B1EB-3C482B9E48D9</gtr:id><gtr:impact>A selection of transcriptions was performed by Torbj&amp;ouml;rn Hultmark (http://hultmark.me) on November 18, 2016 at &amp;quot;C4DM presents A brief evening of electroacoustic music&amp;quot; at QMUL: https://www.youtube.com/watch?v=4kLxvJ-rXDs

These transcriptions will also form material for upcoming workshops with session musicians.</gtr:impact><gtr:outcomeId>58945a59499ba4.30547735</gtr:outcomeId><gtr:title>The folk-rnn Session Book, Volume 1 of 10</gtr:title><gtr:type>Composition/Score</gtr:type><gtr:url>https://highnoongmt.wordpress.com/2016/09/12/folk-rnn-session-tunes-volume-1-of-10/</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Paris West University Nanterre La D?fense</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>Joint project with CREM/LESC, CNRS, France</gtr:description><gtr:id>5AAC7AC0-40C9-4B4B-85A6-AFC57646FAE3</gtr:id><gtr:impact>Joint journal article: &amp;quot;Quel devenir pour l'ethnomusicologie? Zoom arri&amp;egrave;re : L'ethnomusicologie &amp;agrave; l'&amp;egrave;re du Big Data&amp;quot; submitted Dec. 15 2016 to a special issue of &amp;quot;Cahiers d'ethnomusicologie&amp;quot;, France.</gtr:impact><gtr:outcomeId>58bea4716eb583.77759576-1</gtr:outcomeId><gtr:partnerContribution>Scholastic uses of state of the art computational ethnomusicology for ethnomusicological research questions.</gtr:partnerContribution><gtr:piContribution>Technical perspectives on state of the art in computational ethnomusicology practices.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Kingston University London</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Kingston University</gtr:description><gtr:id>4CAD600D-AF33-4279-949F-B3D6D1759E41</gtr:id><gtr:impact>- 2016 Concert at QMUL of work https://sites.google.com/site/c4dmconcerts1617/home/fixedmedia/brief 
- March 2017 workshop at Inside Out Festival http://www.insideoutfestival.org.uk/2017/events/folk-music-composed-by-a-computer/ 
- May 2017 Concert at QMUL of work https://www.eventbrite.co.uk/e/partnerships-tickets-31992055098</gtr:impact><gtr:outcomeId>58bea88a060cb3.13834413-1</gtr:outcomeId><gtr:partnerContribution>Creative applications of transcription models, and perspective of &amp;quot;composition teacher&amp;quot; for analysis of results.</gtr:partnerContribution><gtr:piContribution>Technical approaches to and analysis of music transcription modelling</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Autumn concert</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>12C4E4F3-55D3-40DF-AF7D-B1DFBADA041D</gtr:id><gtr:impact>Concert of electronic and computer music, some of which result from project outcomes.</gtr:impact><gtr:outcomeId>58bea5ea4f8ab9.80957166</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://sites.google.com/site/c4dmconcerts1617/home/fixedmedia/brief</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We are currently exploiting our findings on music representations to engage audiences with new music. For instance, an upcoming workshop (http://www.insideoutfestival.org.uk/2017/events/folk-music-composed-by-a-computer/) will demonstrate to the general public how computers and machine learning can be used to augment music traditions. This involves a trio of musicians who are learning tunes composed by a computer.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>7A57F507-A943-47F0-98B4-DBE7A53D3C4C</gtr:id><gtr:impactTypes><gtr:impactType>Cultural</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58beaa82cdfd63.86123890</gtr:outcomeId></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The representation of music data has a surprising impact on the quality of its computational modelling. We have studied two models, each built using a different representation of the same data: one model we build with high-level textual transcriptions, and the other is the Google model (magenta, basic rnn) built with low-level MIDI representations. Through expert elicitation we have found that the models built using the high-level textual representation demonstrate much more success when it comes to generation of music data having expected conventions. We are currently designing a listening test to more formally test this difference.</gtr:description><gtr:exploitationPathways>Our software models are freely available: https://github.com/IraKorshunova/folk-rnn</gtr:exploitationPathways><gtr:id>DEEF3910-29D5-454A-AFA3-8EE0C41E9763</gtr:id><gtr:outcomeId>58bea9f3e92ab2.45020222</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Education,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>E4AD00C7-8DA1-441B-B827-5F804015AA7B</gtr:id><gtr:title>Taking the Models back to Music Practice: Evaluating Generative Transcription Models built using Deep Learning</gtr:title><gtr:parentPublicationTitle>Journal of Creative Music Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4a0c3482fda06d77878414f5c5b1f683"><gtr:id>4a0c3482fda06d77878414f5c5b1f683</gtr:id><gtr:otherNames>Sturm B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a7b14af5da917.92602133</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">AH/N504531/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>