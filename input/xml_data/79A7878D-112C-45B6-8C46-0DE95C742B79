<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E0105716-F749-466B-9CE4-104705F0C755"><gtr:id>E0105716-F749-466B-9CE4-104705F0C755</gtr:id><gtr:firstName>Matt</gtr:firstName><gtr:surname>Davis</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MC_UU_00005%2F5"><gtr:id>79A7878D-112C-45B6-8C46-0DE95C742B79</gtr:id><gtr:title>Adaptive processing of spoken language</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Intramural</gtr:grantCategory><gtr:grantReference>MC_UU_00005/5</gtr:grantReference><gtr:abstractText>We are able to understand speech in a wide variety of situations that dramatically affect the sounds that reach our ears. For example, we can understand talkers who speak at different rates, or with wildly different accents or vocabularies. In many such situations, we find that comprehension improves over time reflecting people?s abilities to learn and adapt to new and challenging listening situations. These abilities are not only central to successful spoken communication in everyday situations but may also play an important role in situations where comprehension is challenged by hearing impairment, or in understanding educational achievements and failures (e.g. language impaired or dyslexic individuals). 
Our goal in this work is to use behavioural experiments and functional brain understand the brain mechanisms that allow healthy adult listeners adjust to and learn from encounters with different forms of challenging spoken language. A better understanding of these mechanisms will help us understand the listening abilities of language users and to understand and remediate disorders of spoken language following sensory impairment, brain injury or in developmental disorders.</gtr:abstractText><gtr:technicalSummary>Human listeners easily comprehend spoken language despite wide variation in the form and content of speech. This suggests that neural systems for speech perception and comprehension possess impressive capabilities for adjusting to variable and ambiguous speech. These processes are called on in everyday situations in which we understand speech that is presented in background noise or acoustically degraded, spoken in a novel accent, that includes unfamiliar words or phrases or in resolving transient ambiguities created by words with multiple meanings (e.g. bark). The ability of the comprehension system to adjust to incoming speech plays a critical role in supporting effective spoken language comprehension for post-lingually deafened individuals that receive a cochlear implant, in acquiring and maintaining the form and meaning of spoken words, as well as in supporting educational achievements that depend on spoken language (such as literacy and second-language acquisition).

In our research we conduct behavioural studies in which participants learn to understand artificially-manipulated speech (e.g. vocoded speech, or syllables containing ambiguous phonemes), novel words or novel word sequences and meanings. We explore the role of external feedback (e.g. presentation of non-distorted speech, or spoken/written context) in supporting initial learning. We also compare performance on learned and novel items in practiced or novel tasks at various delays after initial exposure in order to assess the role of offline, possibly sleep-associated consolidation processes in supporting language learning and generalisation.
 
By combining these methods with multimodal functional brain imaging (primarily fMRI and E/MEG) and brain stimulation we can study the neural systems that support these various forms of learning and adaptation. In this way we can uncover the functional and neural mechanisms that are critical for successful comprehension of spoken language in healthy volunteers, and that contribute to successful learning and rehabilitation in educational and clinical settings.</gtr:technicalSummary><gtr:fund><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2017-07-01</gtr:start><gtr:type>EXPENDITURE_ACTUAL</gtr:type><gtr:valuePounds>0</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>D48D3C45-E4CF-4578-AEC5-184FC67AB13A</gtr:id><gtr:title>Accent modulates access to word meaning: Evidence for a speaker-model account of spoken word recognition.</gtr:title><gtr:parentPublicationTitle>Cognitive psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c81183bcfa649e6e6590cd4bab6b0d90"><gtr:id>c81183bcfa649e6e6590cd4bab6b0d90</gtr:id><gtr:otherNames>Cai ZG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0010-0285</gtr:issn><gtr:outcomeId>5a84050b52fe25.19305915</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>24EDC17B-384A-45A0-B5CE-3CBB38F1880C</gtr:id><gtr:title>Evidence for causal top-down frontal contributions to predictive processes in speech perception.</gtr:title><gtr:parentPublicationTitle>Nature communications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7739cf3922211f1061792fc3fe057fa7"><gtr:id>7739cf3922211f1061792fc3fe057fa7</gtr:id><gtr:otherNames>Cope TE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2041-1723</gtr:issn><gtr:outcomeId>5a840531e6e626.22050280</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50225D22-0C8F-46DF-81B0-9A48A890CB9D</gtr:id><gtr:title>Phase Entrainment of Brain Oscillations Causally Modulates Neural Responses to Intelligible Speech.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8f01a8cf3c587fd95cf197688b7e86c0"><gtr:id>8f01a8cf3c587fd95cf197688b7e86c0</gtr:id><gtr:otherNames>Zoefel B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn><gtr:outcomeId>5a8404dea76e80.05669838</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>74E4CDAB-401E-4EF4-BB31-8B306A99AFAA</gtr:id><gtr:title>Listeners and Readers Generalize Their Experience With Word Meanings Across Modalities.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Learning, memory, and cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/45182eb286a8898fa0f80d521c56ffa1"><gtr:id>45182eb286a8898fa0f80d521c56ffa1</gtr:id><gtr:otherNames>Gilbert RA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0278-7393</gtr:issn><gtr:outcomeId>5a84048f96de15.36141921</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>92324CC6-A347-447B-AFE4-44759DA0247E</gtr:id><gtr:title>Semantic and phonological schema influence spoken word learning and overnight consolidation.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/55c4a90c104bb56163f7353f10e29245"><gtr:id>55c4a90c104bb56163f7353f10e29245</gtr:id><gtr:otherNames>Havas V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>5a8404b960c059.97475516</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">MC_UU_00005/5</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>