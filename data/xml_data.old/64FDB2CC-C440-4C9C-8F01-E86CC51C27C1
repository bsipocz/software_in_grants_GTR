<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AA1A5BCF-D910-48CE-B4DB-090E625003AD"><gtr:id>AA1A5BCF-D910-48CE-B4DB-090E625003AD</gtr:id><gtr:name>Ordnance Survey</gtr:name><gtr:address><gtr:line1>Explorer House</gtr:line1><gtr:line2>Adanac Drive</gtr:line2><gtr:line4>Southampton</gtr:line4><gtr:line5>Hampshire</gtr:line5><gtr:postCode>SO16 0AS</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/0A22058C-9F25-4FA7-A2EC-E20202E67B7C"><gtr:id>0A22058C-9F25-4FA7-A2EC-E20202E67B7C</gtr:id><gtr:firstName>Anna</gtr:firstName><gtr:otherNames>L</gtr:otherNames><gtr:surname>Cox</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/4FA651E1-596C-4E58-B179-2B323D5D9867"><gtr:id>4FA651E1-596C-4E58-B179-2B323D5D9867</gtr:id><gtr:firstName>Niloy</gtr:firstName><gtr:surname>Mitra</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5A5A7D90-A667-4BFC-8A2E-814AE73C1A88"><gtr:id>5A5A7D90-A667-4BFC-8A2E-814AE73C1A88</gtr:id><gtr:firstName>Anthony</gtr:firstName><gtr:surname>Steed</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FM013685%2F1"><gtr:id>64FDB2CC-C440-4C9C-8F01-E86CC51C27C1</gtr:id><gtr:title>Open3D: Collaborative Editing for 3D Virtual Worlds</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M013685/1</gtr:grantReference><gtr:abstractText>Digital 3D models are used in almost all areas of design and engineering from drug discovery through to architectural design optimization. With the advent of new imaging technologies such as more advanced remote sensing systems and consumer 3D cameras, there is a new capability to capture models that are both deep and broad in detail.

Currently there is a range of different software packages for editing 3D data but each is rather specialised to its domain. If data is to be exchanged between different users then the most usual way of doing this is to export files from one machine, move the file and import it on another machine. This can be facilitated by various file-sharing systems, but the unit of access is a file on a local file system. This presents multiple problems: as models grow in complexity managing them in files becomes problematic, collaborative editing is very hard and tracking of changes becomes challenging. In addition in the next few years, we should expect 3D model sizes to grow in size and detail at increasing rates. This will be driven both by consumer editing and scanning tools, but also increasing use of commercially scanned and produced models. One can extrapolate from the current extensive but crude representations of cities on Google Earth, or the highly detailed, but ultimately limited in scale models in modern video games, to imagine that models will reach 10^9 - 10^11+ polygons in scale within the next decade.

There is a domain where collaborative access to large models has been solved: Internet storage of documents. Systems as diverse as Wikipedia and Google Docs demonstrate that by decoupling storage from viewing and editing, extremely large repositories of information can be built.

In Open3D we will design the necessary algorithms and services that allow the hosting of 3D models of such scale on the Internet. Such 3D models, however, are fundamentally different from text counterparts: 3D models extend across space (e.g. 2-manifold data), lack an obvious extrinsic parameterization, and can have large variations in local details; while, text documents have a natural linear ordering making them much simpler to work with. Our observation is that while models may be big, the spatial scope of an editing or visualisation is usually limited. Thus we can imagine a network protocol that can exchange model assets based on spatial queries, rather than file access. Further, we can imagine that we can perform locking and revision control on this model to prevent inconsistent model states across multiple editors. 

Through Open3D's unique set of facilities we want to enable synchronous collaborative modelling of a unified model with the minimum of interference in the user experience. By doing this we hope to enable a new crowd-sourcing effort to develop large-scale models in a couple of domains. In particular, in our impact plan we target creating a virtual model of part of London, and an open access anatomical model of the human body.</gtr:abstractText><gtr:potentialImpactText>This project will have impact across a wide range of areas. 3D models are becoming pervasive in many domains. Access to shared 3D models as easily as other types of documents on the web will be disruptive. It will definitely cut costs of access to shared models, but also enable new types of working. If we can kick-start a new type of crowd-sourcing effort, the potential impact could be very significant. 

One example area of long-term impact will be, architecture, civil engineering and building services. The UK Government recently started to require the use of 3D formats (Building Information Models or BIM) in all centrally procured projects. From the client (government) point of view, the introduction of BIM will lead to efficiency, both in energy and cost, in the whole life cycle of buildings. The potential cost savings in building and other infrastructure management could be vast, and Open3D has a potential role to play in starting a service community around virtual models that can reliably predict the utilization of space and the resources needed for it. To set a 50-year vision, what if the built environment was entirely modelled in 3D down to individual building elements. This could have a very wide range of applications for smart building and infrastructure projects, heritage, and recreation. A detailed 3D model of a space, which could be updated based on manual and autonomous sensing, would enable a potential future where autonomous and semi-autonomous robots are fulfilling more complex transport and service roles. It would also be necessary for certain forms of augmented reality, where a 3D model is needed to control the rendering and visibility of objects. The same technology can be equally applied to Computer Aided Design (CAD) modelling for aerospace and automotive industries where much of the design and prototyping is performed digitally.

Another example of long-term impact can be found in the games industry. Part of the inspiration for work leading to this proposal came from one of the PI's own experience at Electronic Arts on constructing large models. Another UK studio, Rockstar North, with Grand Theft Auto V has created a large game world for players. The UK needs to keep at the forefront in tools for games development, so that its competitive advantage in this field is maintained. In the short to mid-term, we can envisage new tools improving the efficiency of games studios, and enabling medium-sized studios to develop larger games. To give a slightly less speculative vision, say 10-15 rather than 50 years, what if we could have fully open editable worlds in which multiple parties could edit and set tasks. This is partly the vision of various science-fiction/cyberpunk metaverse or cyberspace environments. The only large-scale systems of this nature are either completely closed (e.g., World of Warcraft), or are partly open, but still commercial (e.g., SecondLife). We can envisage an architecture where the editing and construction of worlds is decoupled from game-playing mechanics, so that multiple providers of content can utilize the under-lying virtual world, building independent or cooperating systems that use the same space. Imagine a version of Gotham City, Middle-Earth, or Rama that anyone could build games for.

To secure impact stories such as these we will undertake two case study demonstrators in this project: one on a virtual city model of London and another on anatomical modelling. These demonstrators were chosen because of the different types of impact: the first being mostly in business leading to greater efficiency, the second being within the university teaching domain and thus potentially contributing to medical training and research. We will also run workshops to publicize the open tools, with an eye on engaging with computer games and media industries in London and at a national level.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>712096</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We are starting to crowd source a city model of London. This can be compared to other existing surveyed models. It could be very high impact in the long run.</gtr:description><gtr:firstYearOfImpact>2017</gtr:firstYearOfImpact><gtr:id>8C882B14-73F5-44E8-9D3E-1FFC0FE47EAE</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56e04136786192.97128544</gtr:outcomeId><gtr:sector>Construction,Creative Economy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>That is is possible to crowd-source complex 3D models.

3D model editing is a complex skill, so to enable broad access to crowd-sourced models, we have developed simplified and assisted model editing process to allow casual users to interact with the system. 

We have defined a new class of implicit parametric modelling systems where we can learn how to simplify parametric models.</gtr:description><gtr:exploitationPathways>We are looking at developing new collaborations around new use cases. Our tools are agnostic to specifically what the application is. We have targeted city modelling for our own demonstrators, but users can appropriate the tools for completely new use cases.</gtr:exploitationPathways><gtr:id>05F91FDC-160D-402F-A3B3-D2DC6AE034C9</gtr:id><gtr:outcomeId>56e041a6980517.58308942</gtr:outcomeId><gtr:sectors><gtr:sector>Construction,Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Environment,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections,Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>9F5E8B2E-3638-4D94-B6E3-69C5B2577056</gtr:id><gtr:title>From urban planning and emergency training to Pok&amp;eacute;mon Go: applications of virtual reality GIS (VRGIS) and augmented reality GIS (ARGIS) in personal, public and environmental health.</gtr:title><gtr:parentPublicationTitle>International journal of health geographics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2a6b816cdb0e279bcaa97e6ce2cd1e57"><gtr:id>2a6b816cdb0e279bcaa97e6ce2cd1e57</gtr:id><gtr:otherNames>Kamel Boulos MN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1476-072X</gtr:issn><gtr:outcomeId>5a0c264eb21af5.73840910</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CAA908E2-EFE7-498C-9F4C-5AD8A293CCBB</gtr:id><gtr:title>Next-Generation Big Data Analytics: State of the Art, Challenges, and Future Research Topics</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Industrial Informatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a03b6f070728ac44072dc5204310b527"><gtr:id>a03b6f070728ac44072dc5204310b527</gtr:id><gtr:otherNames>Lv Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a352ee22d1e20.09398369</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BBB4548D-07E1-40CB-B2F1-767B751B2777</gtr:id><gtr:title>PATEX</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/197b98a97425d6a32beee21a4eac8689"><gtr:id>197b98a97425d6a32beee21a4eac8689</gtr:id><gtr:otherNames>Guerrero P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c131ad3aa0f7.59496581</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F7ECC1EC-10F3-4BE5-A10D-268C310E0DAB</gtr:id><gtr:title>Relationship templates for creating scene variations</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f76706732cc4158a7609b4aa9382a37e"><gtr:id>f76706732cc4158a7609b4aa9382a37e</gtr:id><gtr:otherNames>Zhao X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c131ad04b6f0.90729450</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>80E70C92-3501-46BE-BF02-FC14705654E6</gtr:id><gtr:title>Creativity in Citizen Cyberscience</gtr:title><gtr:parentPublicationTitle>Human Computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/581906ff3500b94e8257abb5d9b556a5"><gtr:id>581906ff3500b94e8257abb5d9b556a5</gtr:id><gtr:otherNames>Jennett C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5a0c24411ad488.37955938</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E77BBE05-89C3-4CA3-AA75-4E434EAD46BC</gtr:id><gtr:title>Case Study 3</gtr:title><gtr:parentPublicationTitle>International Journal of Game-Based Learning</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/581906ff3500b94e8257abb5d9b556a5"><gtr:id>581906ff3500b94e8257abb5d9b556a5</gtr:id><gtr:otherNames>Jennett C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a0c276730fec8.03640210</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EBB204D0-3135-4186-A7B7-489F3D943A2F</gtr:id><gtr:title>RAID</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/197b98a97425d6a32beee21a4eac8689"><gtr:id>197b98a97425d6a32beee21a4eac8689</gtr:id><gtr:otherNames>Guerrero P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c131ad683421.16073828</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M013685/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>76783275-A9F8-4B4E-B314-51363124259C</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Fundamentals of Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>34B6BDD6-DA02-4CA0-A969-29D50394A953</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Networks &amp; Distributed Systems</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>