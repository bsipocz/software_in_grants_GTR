<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/936D002F-A8D1-4A93-AE5D-825ED0903D8D"><gtr:id>936D002F-A8D1-4A93-AE5D-825ED0903D8D</gtr:id><gtr:name>University of Nottingham</gtr:name><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/C7BEDAAB-7E24-478F-ACEC-1CEFFDA05355"><gtr:id>C7BEDAAB-7E24-478F-ACEC-1CEFFDA05355</gtr:id><gtr:name>One-Handed Musical Instrument Trust</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/936D002F-A8D1-4A93-AE5D-825ED0903D8D"><gtr:id>936D002F-A8D1-4A93-AE5D-825ED0903D8D</gtr:id><gtr:name>University of Nottingham</gtr:name><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:line5>Nottinghamshire</gtr:line5><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C7BEDAAB-7E24-478F-ACEC-1CEFFDA05355"><gtr:id>C7BEDAAB-7E24-478F-ACEC-1CEFFDA05355</gtr:id><gtr:name>One-Handed Musical Instrument Trust</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/962E5496-3F9A-4625-BE77-9C45508669B6"><gtr:id>962E5496-3F9A-4625-BE77-9C45508669B6</gtr:id><gtr:name>ROLI</gtr:name><gtr:address><gtr:line1>2 Glebe Road</gtr:line1><gtr:postCode>E8 4BD</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/06843E0A-BF9B-4DE4-880A-A7643DA975F1"><gtr:id>06843E0A-BF9B-4DE4-880A-A7643DA975F1</gtr:id><gtr:name>The One-Handed Musical Instrument Trust</gtr:name><gtr:address><gtr:line1>Tyndallwoods Solicitors</gtr:line1><gtr:line2>29 Woodbourne Rd.</gtr:line2><gtr:postCode>B17 8BY</gtr:postCode><gtr:region>West Midlands</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/374CC611-8BEE-4FC5-906D-5BA19049C87B"><gtr:id>374CC611-8BEE-4FC5-906D-5BA19049C87B</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:otherNames>Palmer</gtr:otherNames><gtr:surname>McPherson</gtr:surname><gtr:roles><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FN005112%2F1"><gtr:id>30782685-3C2B-4E93-A3EE-36C36A4766EF</gtr:id><gtr:title>Design for Virtuosity: Modelling and Supporting Expertise in Digital Musical Interaction</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>EP/N005112/1</gtr:grantReference><gtr:abstractText>Musical performers spend many years achieving proficiency on their instruments. Newly-created digital musical instruments (DMIs) face a significant barrier to adoption in that few performers are willing to repeat these years of training to develop expertise on an unknown instrument. Without expert players, evaluating the success of a DMI design is challenging, and establishing its place in a broader musical community is nearly impossible. As a result, while many digital instruments have been created over the past decade, few have achieved lasting impact beyond the first few performances.

This fellowship proposes a new approach to DMI design which repurposes the existing skills and experience of trained musicians, providing them with a rapid path to virtuosity without years of retraining. The research programme is organised around two complementary themes: study of performer-instrument interaction and creation of new instruments which capture the full richness and subtlety of virtuosic performance.

First, models will be developed of the interaction between performer and instrument. Instrumental performance can be considered a special case of human-machine interaction which is interesting both for its complexity and for the common experience that the musical instrument becomes an extension of the body: while playing, the performer is often not consciously thinking about the instrument. Controlled experiments and participatory design exercises will establish how an instrument's design affects the development of expertise, and how existing expertise can be transferred to newly-created instruments.

Second, the resulting models will be applied to the DMI creation process, taking a holistic approach unifying hardware design, digital signal processing, human-computer interaction (HCI) and artistic considerations. Existing DMIs often implicitly prioritise the convenience of the computer over the experience of the human player. On acoustic instruments, the entire physical object contributes to the sound, however subtly, but the choice of sensors in a DMI typically reduces the performer's actions to just a few machine-tractable dimensions. This fellowship will create instruments which deliberately oversample the interaction, using more sensors and higher sampling rates than apparently necessary, not to create a more complicated instrument, but rather to capture the subtle nuances that experts prize. Evaluation of the new DMIs will help refine the original models of performer-instrument interaction.

This project focuses on musical interaction, but the principle of repurposing expertise is widely applicable within HCI. The capabilities of human users cannot be modelled only through generic cognitive and motor processes; real people have specialist skills developed over years of practice, and new technologies which connect to those skills are far more likely to find acceptance than ones which must be learned from scratch. Music is a good test case since instrumental training is widespread and reasonably standardised, but the findings will be relevant to other expert domains.

This fellowship supports the time of the PI and two postdoctoral researchers. One postdoc will focus on performer studies and interaction, the other on digital signal processing and data mapping strategies. Close collaboration with musicians throughout the research will ensure its relevance to that community. This research integrates hardware design, digital signal processing, human-computer interaction, cognitive science, musicology and arts practice. The PI, with background and professional activities in music composition, electronic engineering and HCI, is ideally placed to lead this multidisciplinary project.</gtr:abstractText><gtr:potentialImpactText>This fellowship holds benefits for a wide variety of groups beyond academic researchers, both in the UK and internationally:

Industry:

* Musical instrument manufacturers, who will benefit from new tools and approaches to instrument design. Selling the same instruments year-upon-year risks market saturation, but conversely, uptake of unfamiliar instruments is a challenge for the industry owing to long learning curves. This fellowship will demonstrate how to create instruments which are creatively distinct from previous designs but still connect to existing skills.
* The broader technology industry, through creation and sales of computer interfaces which integrate into a user's existing workflows.
* Concert venues and promoters, who will benefit from performances involving new creative digital tools.
* Electronics companies serving the open-source and maker communities, who can develop and sell tools based on the open-source hardware released during this project. Open-source hardware makes the designs available freely to all, but it is also an important economic engine, as evidenced by successful companies like Arduino in Italy and SparkFun and Adafruit in the United States. This project will support the UK's growing role as a driver of the open hardware movement.

Musicians:

* Professional performers, who will benefit from instruments which connect to their existing training. By reducing relearning, instruments on the fellowship will make better use of their time, which holds a direct economic benefit.
* Composers, who will benefit in two ways: from immediate opportunities to write for new instruments during the fellowship, and from continuing opportunities when new instruments become established in the musical community.
* Instrumental teachers and students, for whom a deeper understanding of performer-instrument interaction will be relevant to teaching the subtle details of performance technique.
* Disabled and special-needs musicians, who will benefit from instruments which make more effective use of their abilities (with assistance from project partner The One-Handed Musical Instrument Trust).

Schools and Third Sector:

* School music teachers, who can use new digital instruments to promote student interest in music learning.
* Science and technology teachers, who already use the CS4Fn/EE4Fn (Computer Science for Fun; Electronic Engineering for Fun) project at QMUL to promote student interest in computing/engineering careers. This fellowship will contribute new articles and activities on digital musical instruments to the project and assist with the project's dissemination into schools.
* Independent groups promoting STEM (Science/Technology/Engineering/Maths) education, who can use digital musical instruments as the basis of workshop and outreach activities for students.
* Charities promoting music accessibility, for whom the workshop organised by partner OHMI can serve as a model, and for whom the technologies developed on the fellowship can later be applied to create accessible musical interfaces.

Wider Public:

* Amateur musicians, who will benefit from new instruments which make effective use of their training time.
* Audiences, who will benefit from engaging digital musical instrument performances where the expertise of the performer is clearly evident.
* Electronics hobbyists, who can use the open-source tools created on this project; these tools will be designed to use commonly-available fabrication techniques such as 3D printing to make them more accessible.

In addition to the fellowship's primary research activities, a targeted programme of workshops, concerts, recordings, artist residencies, schools talks, industry events and release of open-source designs will ensure the fellowship reaches the beneficiaries named above. See Pathways to Impact for full details.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2016-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>897685</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>The magnetic resonator piano (MRP), an electronically augmented acoustic piano developed as part of my research, was featured in a 2-day composition and improvisation workshop at the International Conference on Live Interfaces in Brighton, UK in June 2016. I was invited to deliver this workshop by the conference organisers. During the workshop, 6 composers used the MRP in new short pieces which were played by pianist Kate Ryder at the end of the event.</gtr:description><gtr:id>79503690-EE31-43DC-A8E4-66177CA6CB9F</gtr:id><gtr:impact>The event looks likely to lead to future collaborations with some of the involved composers and other pianists who attended, and more immediately led to Kate Ryder participating in another concert at the Inter/Sections festival in September 2016.</gtr:impact><gtr:outcomeId>58c1df0654ebf6.73806993</gtr:outcomeId><gtr:title>Magnetic Resonator Piano at International Conference on Live Interfaces</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>In February 2017 at the University of Glasgow, we delivered an invited workshop using Bela, the open-source low-latency audio platform created in our research group. Following the workshop, we were invited to perform with the D-Box, a hackable digital musical instrument created as part of research into appropriation of music technology on the EPSRC Hackable Instruments project (EP/K032046/1). The concert was held at Stereo, a popular club in Glasgow, and also featured a performance using Bela by Sebastian Lexer of the University of Glasgow.</gtr:description><gtr:id>3E1ADB11-CEB1-47BF-BAC8-D2F59EAD2150</gtr:id><gtr:impact>The workshop and concert led to increased interest in Bela and the D-Box, and the trip also led to discussions about collaboration with the University of Glasgow on future funding proposals and joint research projects.</gtr:impact><gtr:outcomeId>58c1dfd1a8fea4.80854267</gtr:outcomeId><gtr:title>D-Box performance at Stereo</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:yearFirstProvided>2017</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>The magnetic resonator piano (MRP) was featured in an installation and performance as part of the Inter/Sections festival in September 2016, a multiday event in London organised by PhD students on the EPSRC and AHRC Centre for Doctoral Training in Media and Arts Technology. The MRP is an electromagnetically augmented acoustic piano which extends the capabilities of the traditional piano. It was set up as an interactive installation for the duration of the festival, and was featured in an evening performance with performances by pianist Kate Ryder.</gtr:description><gtr:id>99EB134A-6D11-41A7-86F1-61D5BA8AEB03</gtr:id><gtr:impact>Following the exhibition I have been invited to show the MRP in other venues, including an opera theatre in Rome where it will be used as part of a newly composed opera by Maria Kallionp&amp;auml;&amp;auml;.</gtr:impact><gtr:outcomeId>58c1de4c6875c5.53735275</gtr:outcomeId><gtr:title>Magnetic Resonator Piano at Inter/Sections</gtr:title><gtr:type>Artistic/Creative Exhibition</gtr:type><gtr:url>https://2016.intersections.io</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput><gtr:artisticAndCreativeProductOutput><gtr:description>With/Without was a concert held on 24 June 2016 at Schott Music in London, featuring the magnetic resonator piano (MRP), an electromagnetically augmented acoustic piano developed as part of my research. Prof. Elaine Chew (QMUL) played a new piece by Dr Oden Ben-Tal (Kingston University) and several other pieces on the MRP.</gtr:description><gtr:id>24EF4CF1-BD8D-493D-AB35-3110D41FD59D</gtr:id><gtr:impact>The performance increased awareness of my research among the general public, and I expect further collaborations with Elaine Chew and Oded Ben-Tal on this and other pieces.</gtr:impact><gtr:outcomeId>58c1dd6db69c27.62022943</gtr:outcomeId><gtr:title>With/Without</gtr:title><gtr:type>Performance (Music, Dance, Drama, etc)</gtr:type><gtr:url>http://elainechew-piano.blogspot.co.uk/2016/06/withwithout-excerpts.html</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>One-Handed Musical Instrument Trust</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>OHMI</gtr:description><gtr:id>3AA332C2-608F-40D0-BF23-10CCBBC01D39</gtr:id><gtr:impact>As a result of earlier collaborations, OHMI is now a project partner on my EPSRC Early Career Fellowship. The collaboration is multi-disciplinary: OHMI is primarily an arts and cultural organisation which also contributes to policy on music education for the disabled (e.g. through a recent House of Lords event hosted by the Lord Lipsey). This collaboration crosses from these areas over to science and engineering.</gtr:impact><gtr:outcomeId>56de29b378b228.57319556-1</gtr:outcomeId><gtr:partnerContribution>OHMI has provided guidance on design principles, access to professional instrument builders and feedback from teachers and students. They have provided financial support for ordering parts for PhD student projects.</gtr:partnerContribution><gtr:piContribution>We have contributed to the design of new musical interfaces accessible to musicians who lack the use of a hand or arm, following OHMI's core mission to enable &amp;quot;full and undifferentiated participation&amp;quot; in musical performance. I continue to serve as a judge on the annual One-Handed Musical Instrument competition and presented at the Ars Electronica festival where their awards were held in 2014. I also advise OHMI on new technologies for accessible music performance.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Nottingham</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>School of Computer Science</gtr:department><gtr:description>Mixed Reality Lab</gtr:description><gtr:id>2B2F0F3A-ED0E-4F56-9DF4-76AEF26C236D</gtr:id><gtr:impact>A paper was published at ACM Designing Interactive Systems 2016 (Brisbane, Australia): 

A. McPherson, A. Chamberlain, A. Hazzard, S. McGrath and S. Benford. Designing for Exploratory Play with a Hackable Digital Musical Instrument. Proc. DIS 2016.

A second paper has been accepted at the ACM SIGCHI Conference on Human Factors in Computing Systems (Denver, USA):

F. Morreale, G. Moro, A. Chamberlain, S. Benford and A. McPherson. Building a Maker Community around an Open Hardware Platform. Proc. CHI 2017.</gtr:impact><gtr:outcomeId>56de2c2d760257.58608842-1</gtr:outcomeId><gtr:partnerContribution>MRL contributed their Artcodes research to the project. Artcodes are a form of information encoding in images based on patterns of open and closed shapes; notably, nearly any physical design can be turned into an artcode through careful management of light and dark regions. Artcodes are useful for linking physical objects to their virtual records in an aesthetically elegant manner. 

MRL also led the data collection and transcription for the workshops. We jointly prepared papers on the results.</gtr:partnerContribution><gtr:piContribution>I have collaborated with members of the Mixed Reality Laboratory (led by Steve Benford) in Nottingham's computer science department on studies involving the D-Box hackable musical instrument. We have co-organised a series of free public workshops where people hack the D-Box instrument. I lead the workshop activities while the MRL researchers collect interviews and video footage as the event goes along, which we use for later analysis.

Subsequently, we worked with MRL on a workshop at the STEIM electro-acoustic music centre in Amsterdam, using the Bela audio platform created in our lab. We led the technical aspects of the workshop, while MRL contributed to ethnographic study of how people used the technology. A paper on the results was accepted to CHI 2017.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Bela at Heart n Soul charity events</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>E3A0A847-0086-40D8-9B73-C6F82BAC58B1</gtr:id><gtr:impact>Heart n Soul is a UK-based charity catering to children and adults with learning disabilities. Part of their activities involve a series of &amp;quot;SoundLab&amp;quot; events featuring music technology accessible to people with such disabilities. Each event includes participation from several companies or other music technology creators.

In November 2016, we presented Bela (our low-latency embedded audio platform -- http://bela.io) at the Beautiful Octopus Club, a large-scale evening festival held at the London Southbank Centre. The SoundLab was part of the Beautiful Octopus Club event; over the course of an evening, we demonstrated several accessible musical instruments to a crowd of hundreds of people of all ages, both disabled and not. Later, in February 2017, we were invited to present Bela at another SoundLab event in South London, which reached an estimated 30 people. Following that event, we have made plans to meet further with some of the participants to better understand how to support high-level music making by people with disabilities.</gtr:impact><gtr:outcomeId>58c1e3a9aa1ef8.82148551</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.heartnsoul.co.uk/category/taking_part/details/beautifuloctopusclub</gtr:url><gtr:year>2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Bela workshops</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>95409FD5-29E6-46A1-9877-04E0D5CE0702</gtr:id><gtr:impact>On 4-5 December 2015 we held two tutorial workshops on the Bela low-latency audio platform. These were free and open to the public. Originally the plan was to hold a single event, but high demand resulted in it filling up quickly, so we scheduled a second one the day before. In all we estimate the attendance at 40-50 people. Feedback was positive and many people bought hardware from us to continue using Bela in their own projects. This event was one of several that laid the groundwork for our highly successful Kickstarter crowdfunding campaign in March 2016.

Since the original workshop, we have held several additional workshops throughout 2016 and 2017, together reaching several hundred people. Events have taken place in London, Glasgow, Edinburgh, Brighton, Berlin, Toronto, Baton Rouge and Brisbane, among others. Some events have targeted hobbyists and makers; others have targeted musicians and industry professionals; still others have targeted undergraduate and postgraduate students. Collectively, these events have significantly expanded the profile of the Bela platform, leading to research collaborations, increased public profile of our work and commercial benefits (hardware sales through a spinout company).</gtr:impact><gtr:outcomeId>56deacd31f7dd5.98234748</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://bela.io</gtr:url><gtr:year>2015,2016,2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Accessible Music Hackathon</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>F534CA6C-D281-481A-A633-1E8032247B3F</gtr:id><gtr:impact>On 6 February 2016, my lab and the charity Drake Music jointly organised an Accessible Music Hackathon, a daylong event for creating new music technology for the disabled. The event was held at QMUL; it was free and open to the public, and advertised to Drake Music's community of supporters as well as local interest group mailing lists (e.g. Music Hackspace). At least 35 people attended (filling the venue to capacity) often working in small groups. At least 16 working projects were demonstrated at the end of the day.</gtr:impact><gtr:outcomeId>56deabc0118732.55938780</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Third sector organisations</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Bela at STEIM</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>5D85997B-EE06-48AE-9F56-95BDF5608D1B</gtr:id><gtr:impact>In August 2016, my research lab organised a 3-day hands-on instrument design workshop at the Studio for Electro-Instrumental Music (STEIM) in Amsterdam. The workshop featured Bela, an open-source embedded platform for ultra-low-latency audio and sensor processing, which was developed originally as part of the EPSRC-funded Hackable Instruments project. 

The workshop had 8 participants who were digital musical instrument designers, plus several other people attending as observers. The event was facilitated by two technical organisers and two other researchers. The instrument designers each brought an existing instrument design which they ported to Bela with the help of the organisers. We recorded audio and video from the session, including regular interviews with each participant. This event led to a paper in CHI 2017 (Denver, USA) on community formation around open-source hardware tools. It also led to several participants using Bela in their own music and art installations at a wider scale.</gtr:impact><gtr:outcomeId>58c1e2307e1cf3.54871555</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>http://steim.org/event/bela-workshop-call/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>C4DM at Sonar MarketLab 2016</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A6519F8E-0CBE-48EE-900C-F0FBCC811901</gtr:id><gtr:impact>C4DM presented a public exhibition of its research at the Sonar+D 2016 festival in Barcelona, 16-18 June 2016. Sonar+D is a high-profile annual exhibition of music technology attended by thousands of industry professionals, musicians and members of the general public. C4DM was chosen by competitive application for a booth on the exhibition floor. We showed 9 recent research projects supported by EPSRC funding (EP/K009559/1, EP/K032046/1, EP/G03723X/1). The booth attracted significant interest from a broad cross-section of the Sonar audience: it was nearly full for most of the three days, and anecdotally appeared to have more traffic than most of the booths at the exhibition. In parallel with this in-person exhibition, Sonar+D featured C4DM in their social media feeds, and we were interviewed for a broadcast on Spanish television. Aside from public engagement, the exhibition led to several new industry contacts, and it provided valuable feedback to the attending PhD students and postdocs on how to showcase their research in public.

The projects shown were:

1) Bela, an open-source platform for ultra-low-latency audio and sensor processing, which launched on Kickstarter in 2016;
2) TouchKeys, a transformation of the piano-style keyboard into an expressive multi-touch control surface, launched on Kickstarter in 2013 and spun out into a company in 2016;
3) Collidoscope, a collaborative audio-visual musical instrument which was a viral hit online with over 10M views;
4) RTSFX (Real-Time Sound Effects), an online library of real-time synthesised (rather than sampled) sound effects for a variety of different objects and environmental sounds;
5) Moodplay, a mobile phone-based system that allows users to collectively control music and lighting effects to express desired emotions;
6) Augmented Violin, a sensor-based extension of the traditional violin to give students constructive feedback on their playing
7) Tape.pm, an interactive object which explores novel ways to record and share an improvisation that is created on a musical instrument;
8) Aural Character of Places, an interactive online demo of soundwalks conducted around London;
9) MixRights, a demo of how content reuse is enabled by emerging MPEG standards, such as IM AF format for interactive music apps and MVCO ontology for IP rights tracking, driving a shift of power in the music value chain.

Several potential collaborations may result from this visit, including commercial opportunities related to the TouchKeys and Bela projects, and possible joint projects with other university labs who attended (e.g. IRCAM and the Music Technology Group at Universitat Pompeu Fabra in Barcelona). The publicity surrounding this exhibition may also serve as a recruitment tool for future research students in the Music and Acoustic Technology research area.

A particularly valuable outcome, especially for the PhD student attendees, was experience in showcasing their research to the public. Several students commented that they received valuable feedback on their projects and learned general skills in public engagement over the course of the three days. In one case (Tape.pm), interactions with the public helped generate a dataset which will be analysed in future research.

Finally, attendees at Sonar+D also had the opportunity to see other booths and talks at the event, generating new ideas and connections for future projects.</gtr:impact><gtr:outcomeId>58ac49984fea09.58330026</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>https://sonar.es/en/2016/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>IET Christmas Lecture at QMUL</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>549C0AD3-27DF-4A82-92E9-ECCA973DD458</gtr:id><gtr:impact>On 14 December 2016, I gave the annual IET Christmas Lecture in the School of Electronic Engineering and Computer Science at Queen Mary University of London. The event was entitled &amp;quot;The Sound of Computing&amp;quot; and discussed how computing and electronics could be used to augment familiar musical instruments. The talk was pitched to schools and was attended by students of a wide range of ages. It led to further invitations to speak at IET and other events, and an invitation to develop a school engineering design challenge with IET, which is planned for 2018.</gtr:impact><gtr:outcomeId>58c1e466c2cf10.15723768</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.eecs.qmul.ac.uk/news/view/music-transformed-by-technology-at-qmuls-christmas-lecture</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>24987</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Arts and Technology Pilot Programme</gtr:description><gtr:end>2017-10-02</gtr:end><gtr:fundingOrg>Innovate UK</gtr:fundingOrg><gtr:id>BBDACC03-3F0B-49E4-8A72-E2F07C4F67F9</gtr:id><gtr:outcomeId>58b99fcb4f63a3.87788082</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2017-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>One year into this 5-year project, impacts are already occurring in the artistic and commercial domains. The project has supported a detailed look at the interaction between performer and instrument, supported by a series of public concerts and specialist workshops. These events have ranged from studies of centuries-old traditional instruments (violin) to new looks at recently-created digital musical instruments (the D-Box, the magnetic resonator piano) to public engagement featuring completely new instruments based on the Bela embedded audio platform created in this lab.

In the commercial domain, research and development on the Bela platform has led to the creation of a spinout, Augmented Instruments Ltd, in September 2016. This company is aimed at developing and commercialising current and future projects from the Augmented Instruments Laboratory within QMUL's Centre for Digital Music. Bela is the company's first project. The company has launched a shop for public sale of Bela kits, and conducts commercial consultancy related to the platform. We anticipate further activities in the coming year supported, among other ways, by a grant from Innovate UK.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>8118368D-1D4F-4DB2-83D5-D67249F9E9F5</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>58c1f0a9e6cf88.49842849</gtr:outcomeId><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>US patent covers a method of adding touch position sensing to the surface of a piano-style keyboard. This relates to my research project TouchKeys, an augmented keyboard featuring capacitive touch sensing for continuous expressive control over each note.</gtr:description><gtr:grantRef>EP/N005112/1</gtr:grantRef><gtr:id>CE4A4BC3-E2CD-47E4-8AE2-CA1E584B445D</gtr:id><gtr:impact>In 2015, a spinout company TouchKeys Instruments Ltd was formed to commercialise the TouchKeys musical instrument. The company focuses on direct consumer sales of kits and keyboards plus the exploration of commercial licensing opportunity to established keyboard manufacturers. In December 2016, a new TouchKeys website and online shop launched to the public, which has generated sales and media attention.</gtr:impact><gtr:licensed>Yes</gtr:licensed><gtr:outcomeId>58c15bc664fae9.42431483</gtr:outcomeId><gtr:patentId>9324310</gtr:patentId><gtr:protection>Patent granted</gtr:protection><gtr:title>Multi-touch piano keyboard</gtr:title><gtr:yearProtectionGranted>2016</gtr:yearProtectionGranted></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:keyFindingsOutput><gtr:description>In the first year of the fellowship, the preliminary findings have divided into two categories: the influence of musical instrument design on the performer experience, and the ways that technical tools influence the actions and experience of the designer.

In the first category, we have conducted studies with violinists to understand how modifying the violin affects the existing expertise of the performer. We have found that violinists can easily adapt to small changes in the instrument, but that certain changes, such as reversing the order of the strings, result in a nearly complete inability to play fluently. This simple experiment demonstrates the importance of highly developed sensorimotor processes on musical performance. Publications on this study are in preparation, and in the coming year we will apply the results to the development of new instruments which seek to make optimal use of established sensorimotor skills. We have also conducted experiments with percussion instruments, showing how latency and the constraints of an instrument change the gestures that performers choose to interact with the instrument. Our results suggest that the relationship between the performer and instrument goes both ways: not only does the performer control the instrument, the instrument design implicitly influences what actions the performer chooses to take.

In the second category, we have studied how open source tools can be used to support musical instrument design, and we have investigated the process by which communities form around tools. For this work, we used the Bela audio platform developed in our lab (which has been significantly enhanced and expanded since the beginning 2016). A paper on open source community building was accepted for publication at CHI 2017, and further papers are under review.</gtr:description><gtr:exploitationPathways>It is still early in the project, but we expect a more thorough understanding of performer-instrument interaction will be useful for many aspects of the digital musical instrument design process. In particular, others may be able to design instruments which build on the established skills of expert performers.

Beyond the research domain, the instruments we build as part of our research will be used by performers and composers, and the technical tools we have created are already being adopted by a growing community of makers, musicians, engineers and researchers.</gtr:exploitationPathways><gtr:id>97E25D37-890D-4E39-9FB5-4063D16CB188</gtr:id><gtr:outcomeId>58c1ef5c2f5e39.47036328</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Bela (formerly called BeagleRT) is an ultra-low-latency real-time audio platform for the BeagleBone Black embedded computer. It can be used to build musical instruments, including the D-Box hackable musical instrument developed for the EPSRC Hackable Instruments project. The software is of particular interest to audio and music researchers, especially those building real-time systems.

With less than 1ms of latency between action and sound, Bela performs faster than any other computer-based environment on the market, including high-spec laptops. It also features audio-rate sampling of every analog and digital input which makes design of sensor systems convenient. In 2015, a built-in browser-based IDE was added along with support for the Pure Data graphical computer music language widely used in the digital music community. Since 2016, we have continued to add support for other programming languages and hardware accessories, as well as extending the documentation and online resources available to the community.</gtr:description><gtr:id>E7B3F8C9-8887-43B7-BEB4-9D2F21AABE6D</gtr:id><gtr:impact>Bela has gained significant traction amongst researchers, musicians and hobbyists in the 2014-17 period, with the number of users and community members growing every month.

On 29 February 2016, we launched a Kickstarter crowdfunding campaign for Bela, seeking &amp;pound;5k to build and distribute the hardware. We exceeded our funding goal in less than 4 hours (out of a 32-day campaign), ultimately raising &amp;pound;55k from over 500 backers. Following the campaign, we received invitations to collaborate from major academic institutions (IRCAM in France, STEIM in the Netherlands, University of Virginia, University of Edinburgh, University of Glasgow, Goldsmiths University and several others) and industry (Cycling74, makers of the popular Max/MSP software). 

Meanwhile, since 2014 we have held 10+ workshops on Bela and/or the D-Box instrument including 2 workshops at the Sonar music festival, a workshop at the NIME 2015 conference (Baton Rouge, LA, USA), an Audio Music Hackathon sponsored by Harman Audio, and an Accessible Music Hackathon with the charity Drake Music (held at QMUL). Following the successful Kickstarter campaign, we spun out a new company, Augmented Instruments Ltd, to commercialise the platform, and relaunched a public web shop in October 2016. We maintain several community resources, including a blog, wiki, web forum and several social media accounts. Our users actively contribute to these resources and frequently share projects they make using Bela. Community development itself has become an area of research for us (e.g. Morreale et al., &amp;quot;Building a maker community around an open hardware platform&amp;quot;, Proc. CHI 2017), and we have received a grant from Innovate UK (Feb-Oct 2017) to further develop the platform and build our community.</gtr:impact><gtr:outcomeId>545bb694961050.49097753</gtr:outcomeId><gtr:title>Bela Audio Platform</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://bela.io</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>Augmented Instruments Ltd</gtr:companyName><gtr:description>Augmented Instruments Ltd is a spinout from the Centre for Digital Music at Queen Mary University of London, incorporated on 8 September 2016. The aim of the company is to develop and commercialise digital musical instrument research developed in the Augmented Instruments Laboratory, a research team within the Centre for Digital Music led by Dr Andrew McPherson. Technology is licensed from QMUL to Augmented Instruments Ltd, which develops and sells direct to consumers and conducts business consultancy related to the technologies.

The company's first product is Bela (http://bela.io), an open-source embedded computing platform for ultra-low-latency processing of audio and sensor data. Bela, originally known as BeagleRT, was developed starting in 2014 in the Augmented Instruments Laboratory. Since its creation for a specific musical instrument, it has gradually grown into a general-purpose platform aimed at the maker and musician communities. It couples high performance (1GHz processor, submillisecond latency, high-bandwidth, synchronous gathering of audio and sensor data) with ease of use (a browser-based development environment and support for popular computer music programming languages).

On 1 April 2016, Bela completed a highly successful Kickstarter campaign which raised &amp;pound;54,902 (out of an original goal of &amp;pound;5k). This provided the seed funding to spin out the company, which has subsequently been supported by sales of Bela.</gtr:description><gtr:id>4F248B79-89E4-4585-B60B-DE2343A8ADBB</gtr:id><gtr:impact>Augmented Instruments Ltd launched Bela for public sale in October 2016. As of March 2017, sales through the Bela shop have reached a similar amount to the original Kickstarter campaign, with sales growing month by month. The company has now begun a consultancy project with a major European musical instrument manufacturer. It also continues to support a growing open-source community, providing resources including a repository of code and hardware designs, a tech support wiki, an online discussion forum, a blog featuring user-created projects, a YouTube channel and other social media links.</gtr:impact><gtr:outcomeId>58c15dd45818c0.44932601</gtr:outcomeId><gtr:url>http://bela.io</gtr:url><gtr:yearCompanyFormed>2016</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>D7E9EDF8-2960-4F4D-BB2E-561CF3BF35D2</gtr:id><gtr:title>Action-Sound Latency: Are Our Tools Fast Enough?</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c093896d33e6f08badff729bf0bb444f"><gtr:id>c093896d33e6f08badff729bf0bb444f</gtr:id><gtr:otherNames>A. McPherson</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b042e8749ad1.14477298</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0B83020D-475B-4131-84AF-DA18D247A9D7</gtr:id><gtr:title>Adapting the Bass Guitar for One-Handed Playing</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c4a9d8f0267f332dce0445e50d0e7122"><gtr:id>c4a9d8f0267f332dce0445e50d0e7122</gtr:id><gtr:otherNames>Harrison J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fe320beb4f4.48910987</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EB1E2A2A-1F39-4E46-AB72-F82572406874</gtr:id><gtr:title>Dynamic temporal behaviour of the keyboard action on the Hammond organ and its perceptual significance.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/52b7b26ba8cda936c6526c1ebc0ad45e"><gtr:id>52b7b26ba8cda936c6526c1ebc0ad45e</gtr:id><gtr:otherNames>Moro G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn><gtr:outcomeId>5aa1562b3f9e03.44848025</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4690CDBB-5E09-4C93-8A58-4FCCC17A0F1A</gtr:id><gtr:title>Smart instruments: Towards an ecosystem of interoperable devices connecting performers and audiences</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/769b079e8d22f487283488ef5019e3aa"><gtr:id>769b079e8d22f487283488ef5019e3aa</gtr:id><gtr:otherNames>L. Turchet</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b043f4d42a30.18403695</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A93F99D6-62B9-43C9-8826-011A023A2DB1</gtr:id><gtr:title>Skip the pre-concert demo: how technical familiarity and musical style affect audience response</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a6a5ce378a5ad3ab9c19d95950313cda"><gtr:id>a6a5ce378a5ad3ab9c19d95950313cda</gtr:id><gtr:otherNames>S. A. Bin</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b042acc01ac8.02921434</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/N005112/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>