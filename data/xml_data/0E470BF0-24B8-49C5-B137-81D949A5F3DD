<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/F7E13617-2678-475B-99E4-31479C92038D"><gtr:id>F7E13617-2678-475B-99E4-31479C92038D</gtr:id><gtr:name>University of Aberdeen</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>University Office</gtr:line1><gtr:line2>Regent Walk</gtr:line2><gtr:line4>Aberdeen</gtr:line4><gtr:line5>Aberdeenshire</gtr:line5><gtr:postCode>AB24 3FX</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F7E13617-2678-475B-99E4-31479C92038D"><gtr:id>F7E13617-2678-475B-99E4-31479C92038D</gtr:id><gtr:name>University of Aberdeen</gtr:name><gtr:address><gtr:line1>University Office</gtr:line1><gtr:line2>Regent Walk</gtr:line2><gtr:line4>Aberdeen</gtr:line4><gtr:line5>Aberdeenshire</gtr:line5><gtr:postCode>AB24 3FX</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/421C7D6A-EAA9-4885-A68C-556B32AC7EEB"><gtr:id>421C7D6A-EAA9-4885-A68C-556B32AC7EEB</gtr:id><gtr:firstName>A</gtr:firstName><gtr:otherNames>Mike</gtr:otherNames><gtr:surname>Burton</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role><gtr:role><gtr:name>FELLOW</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FJ022950%2F1"><gtr:id>0E470BF0-24B8-49C5-B137-81D949A5F3DD</gtr:id><gtr:title>Variability as a route to understanding face recognition</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>ES/J022950/1</gtr:grantReference><gtr:abstractText>&lt;p>This project represents a new way to look at the problem of human face recognition. This is a key problem in human perception, but it also has practical implications in forensic and security settings. It is based on the simple observation that different pictures of the same face can look very different indeed. These differences are normally not studied, and are either ignored or eliminated by systematically controlling the images used for research.&lt;/p>

&lt;p>This research programme takes exactly the converse approach. Instead of trying to control away this variability, it will be studied explicitly. Preliminary work suggests that a very important component of familiar face recognition is the ability to generalise over superficial image differences - differences which tend to fool unfamiliar viewers, as well as automatic computer-based systems. The approach taken will be both statistical (using analyses of pictures themselves) and experimental (testing viewers? face recognition ability over different ranges of images). The eventual aim is to gain a better understanding of human face recognition, and also to inform future work on automatic face recognition for practical purposes.&lt;/p>

&lt;p>&amp;nbsp;&lt;/p>

&lt;p>&amp;nbsp;&lt;/p></gtr:abstractText><gtr:potentialImpactText>The research planned here has direct relevance across a wide range of settings. Photo ID has become very common in the UK, in situations raging from the security-critical (e.g. proving one's identity at an airport) to the more prosaic (e.g. proving one's age in order to buy alcohol). Furthermore, the police and judicial system rely extensively on personal identification, for example when viewing crime-scene CCTV. Despite this reliance, it is simply an unreliably procedure: neither computers nor humans are good at matching unfamiliar people to their photos. 

Part of the planned work directly addresses how to improve the use of photo-ID. As a regular speaker to police agencies, and as a teacher at the Scottish Police Training College, I will use these opportunities to describe the latest research. These forums are key, because one has direct access to people operational in the field. Existing contacts with the Criminal Cases Review Commission, and its Scottish counterpart will also be used to engage relevant professionals in the results of this work. The commissioners are particularly concerned with ID at the present, because matters of disputed identification are at the heart of several high profile legal cases. For this reason, both agencies have requested reports from my lab in the past. 

My research group is involved in an on-going collaboration involving the University of New South Wales, and the Australian passport authority, and this is focused on the limits of facial identification (as well as potential improvements). This collaboration was originally funded by ESRC and the Australian Research Council, and has been very successful in passing research results to the Australian authorities. So far, the UK Border Agency has been less enthusiastic to engage with this research. However, in this project I undertake to develop contacts with UKBA, through the office of the Chief Scientific Adviser to the Home Office. 

A further impact opportunity arises through the interest of engineers in the problem of face recognition. Current automated systems (for example at airports) work only very poorly. The theory driving this proposal is that the typical engineering approach is unlikely to produce robust levels of recognition, and that advances in understanding human perceptual processes can improve automated systems. For this reason, I have requested support to disseminate research on human perceptual face processing to engineering audiences (in both private and public sectors). 

Throughout the period, I will continue to engage a broader audience with this research. I am regularly asked to speak at public engagement events, and to the media, and so there will be many opportunities to do this.</gtr:potentialImpactText><gtr:fund><gtr:end>2014-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2012-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>406814</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>About Face exhibition</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>30BEA350-0744-4F24-BD0C-4964A2674869</gtr:id><gtr:impact>An interactive exhibition of our work was housed in the York Explore Library, York. Three members of our group were there throughout, explaining our research to members of the public through interactive demonstrations.

Feedback was excellent throughout the event.</gtr:impact><gtr:outcomeId>56290de0c52390.89884549</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://yornight.com/2015/activities/york-explore/about-face/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>3C781C9F-6BEF-4308-B4F5-C1657A6F7101</gtr:id><gtr:impact>This short format of talk is designed to generate interest, and many attendees asked good questions afterwards.

Members of the audience volunteered to take part in future experiments.</gtr:impact><gtr:outcomeId>56291185c51e82.99305664</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Who's who? Human and computer face recognition</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>BF813A18-3F0E-47CA-B54C-7EF758F2B1AB</gtr:id><gtr:impact>We exhibited demonstrations of our work at the local science museum in Aberdeen - Satrosphere Science Centre. Members of the public who came to our exhibit asked interesting questions, seemed very engaged, and expressed interest in the work and ideas in the exhibition.

We received good feedback form the public and from the museum.</gtr:impact><gtr:outcomeId>565eed339c0f53.55032838</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.abdn.ac.uk/events/6072/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Face research aimed at children - International Women's Day research event</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>AE002D46-90D8-4288-8E84-4ECDB7F36B16</gtr:id><gtr:impact>We manned a stall demonstrating our work for one hour in the Yorkshire Museum, York. The exhibits were child-friendly and were geared towards helping children understand science.

The children and their parents were very enthusiastic about our demonstrations, and our exhibit was featured in a blog article about the event.</gtr:impact><gtr:outcomeId>56291027256585.41410327</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Face research exhibition</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>60F7C08A-2E70-40EE-B2AC-53846BF51D8E</gtr:id><gtr:impact>An exhibition on our face recognition research was mounted in Union Square, the main shopping Centre in Aberdeen. This was manned throughout, and several hundred members of the public approached the exhibition and took part in the various demonstrations we had put on.

Feedback at the time was very good, but it is hard to estimate longer term benefits.</gtr:impact><gtr:outcomeId>r-6930628294.9919142aeb66c0</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>23113CF3-5752-4BAF-9FAF-BC40F902A9B4</gtr:id><gtr:impact>The talk was well-attended by the public who were engaged throughout and asked interesting questions afterwards.

The talk raised awareness of our research in the local community.</gtr:impact><gtr:outcomeId>562910e5589a16.66919326</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>University Open Day events</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>7AABC692-75A0-4FAC-A443-9E332C112C5C</gtr:id><gtr:impact>Over several open days, we have presented interactive demonstrations of our research to University applicants.

Many applicants indicated afterwards that our demonstrations made them consider our university as their top choice. Many applicants and their parents noted that our demonstrations made them aware of issues surrounding face perception that they had not otherwise considered.</gtr:impact><gtr:outcomeId>56290eeb6ab529.43445743</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Press release on Passport Officers' errors in face matching</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>8C5602EC-E4D4-4853-9C04-9D7136270169</gtr:id><gtr:impact>This was a press release designed to publicise our work showing that Passport Officers are poor at matching faces. The press release led to worldwide press coverage.

As a direct result of this work, I was invited to speak to a meeting of Frontex - the European Border Agency for the Schengen area - at a high level meeting in Warsaw. 
I was also approached by other Border Agencies for further information about our work.</gtr:impact><gtr:outcomeId>55ae42da378ec0.19573846</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.facevar.com/science-media</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk to Frontex</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>ED51E1FE-B860-4523-A5CD-8E478244C144</gtr:id><gtr:impact>This was an invited talk to the 'Frontex Research Workshop on Vulnerabilities and Countermeasures in the First Line of Border Control'. This is the Euorpean Border Agency for the Schengen area. The meeting was attended by practitioners and policy makers from around Europe, and led to further collaborations and invitations to speak on our work about the reliability of face matching.

I received many invitations for further information, papers, and visits from Border Agencies around Europe.</gtr:impact><gtr:outcomeId>55ae4490c7fcd8.58374605</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Policymakers/parliamentarians</gtr:primaryAudience><gtr:url>http://www.facevar.com/passport-study</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This is an on-going project. We are working towards a new theoretical understanding of face recognition. In the process, we are engaged with professional groups, specifically passport officers and police, in improving the use of face recognition within these services.</gtr:description><gtr:exploitationPathways>By the end of the project, we expect to be able to make clear recommendations.</gtr:exploitationPathways><gtr:id>A4E41814-28BA-419F-9C38-28FD045D4B33</gtr:id><gtr:outcomeId>544b85a36984b9.12809409</gtr:outcomeId><gtr:sectors><gtr:sector>Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C3B96587-B4B1-4BF2-B159-650EEA2CE62B</gtr:id><gtr:title>Arguments Against a Configural Processing Account of Familiar Face Recognition.</gtr:title><gtr:parentPublicationTitle>Perspectives on psychological science : a journal of the Association for Psychological Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e9bbd50007d23d1dc9efe2ad51f37e07"><gtr:id>e9bbd50007d23d1dc9efe2ad51f37e07</gtr:id><gtr:otherNames>Burton AM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1745-6916</gtr:issn><gtr:outcomeId>55acdecd991dc3.66871395</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EEBA2FB7-9E79-4581-A905-27CC8805BD3B</gtr:id><gtr:title>Extracting mean and individual identity from sets of famous faces, European Conference on Visual Perception, Perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c522ca91b832efa57af5c92b2b0ecd2"><gtr:id>2c522ca91b832efa57af5c92b2b0ecd2</gtr:id><gtr:otherNames>Neumann, M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>562a4b9263e698.80519413</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4156608A-7187-49FE-BB00-70A8830FDFE8</gtr:id><gtr:title>Inaccuracies in judging aspect ratio of familiar and unfamiliar faces, European Conference on Visual Perception, Perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/da2163eeb32793ee81cbaa3dd9d82c66"><gtr:id>da2163eeb32793ee81cbaa3dd9d82c66</gtr:id><gtr:otherNames>Sandford, A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>562a49b2c97ab6.96752900</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F2D8DCFE-E878-4DAC-AB2E-F346CCAF678D</gtr:id><gtr:title>Understanding face familiarity.</gtr:title><gtr:parentPublicationTitle>Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/97bb10951c0d4a1b44ded5bb087ae8d3"><gtr:id>97bb10951c0d4a1b44ded5bb087ae8d3</gtr:id><gtr:otherNames>Kramer RSS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>0010-0277</gtr:issn><gtr:outcomeId>5a732cb2143709.48959460</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4902F42E-5C26-4324-8A4C-D00454BF97EE</gtr:id><gtr:title>Improving Unfamiliar Face Matching Using Multiple Images and Feedback</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/370872adb2c3dfee992477b7979532e7"><gtr:id>370872adb2c3dfee992477b7979532e7</gtr:id><gtr:otherNames>Dowsett A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>562a4c17ae1b84.72498731</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2E37BA79-B728-4DFB-9CEA-6FD1D1EC00E6</gtr:id><gtr:title>A familiarity disadvantage for remembering specific images of faces.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e433c9197f58d64a6360ad49f4d8ac94"><gtr:id>e433c9197f58d64a6360ad49f4d8ac94</gtr:id><gtr:otherNames>Armann RG</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>568a5c6c4bf694.33579133</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C7C8BC63-8FF4-48C4-9F2B-D45DB5AE32E8</gtr:id><gtr:title>Viewers base estimates of face matching accuracy on their own familiarity: Explaining the photo-ID paradox.</gtr:title><gtr:parentPublicationTitle>Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/16e88943e0d9c5741f261ffd54c0f186"><gtr:id>16e88943e0d9c5741f261ffd54c0f186</gtr:id><gtr:otherNames>Ritchie KL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0010-0277</gtr:issn><gtr:outcomeId>55acdecd41ef44.99980789</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FC4BBD85-CA72-4287-BB3B-FA8CF0780D0A</gtr:id><gtr:title>Passport officers' errors in face matching.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b271b74f4f099f7c253ed9450d31b25"><gtr:id>3b271b74f4f099f7c253ed9450d31b25</gtr:id><gtr:otherNames>White D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>541eb62f357de4.63149473</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9D460706-FA2D-4057-818B-EA2C05690D10</gtr:id><gtr:title>Natural variability is essential to learning new faces</gtr:title><gtr:parentPublicationTitle>Visual Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ab72aadedfcbb3a1d591d3e0d9f26b14"><gtr:id>ab72aadedfcbb3a1d591d3e0d9f26b14</gtr:id><gtr:otherNames>Kramer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>589462677253a0.81812730</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A8770E33-CDF1-4A01-B1BC-C33A3FC532CF</gtr:id><gtr:title>Face averages enhance user recognition for smartphone security.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b5a862af41fd0743e1e1ee2f0efa8ee"><gtr:id>3b5a862af41fd0743e1e1ee2f0efa8ee</gtr:id><gtr:otherNames>Robertson DJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>55acdeccdc7504.17326216</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>79E047C6-8B46-4A9D-9095-F102CCBC46EA</gtr:id><gtr:title>Viewers extract the mean from images of the same person: A route to face learning.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f54b7c9844e89ea476d3b02087d05284"><gtr:id>f54b7c9844e89ea476d3b02087d05284</gtr:id><gtr:otherNames>Kramer RS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>55acdecd7305d1.88216582</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>08C74F80-0686-47D9-A554-712A5954A0B7</gtr:id><gtr:title>Crowd Effects in Unfamiliar Face Matching</gtr:title><gtr:parentPublicationTitle>Applied Cognitive Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b271b74f4f099f7c253ed9450d31b25"><gtr:id>3b271b74f4f099f7c253ed9450d31b25</gtr:id><gtr:otherNames>White D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53cfbffbf314c83a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A790C94D-B6F4-4D85-A36F-A854CE20D38D</gtr:id><gtr:title>Unfamiliar face matching: Pairs out-perform individuals and provide a route to training.</gtr:title><gtr:parentPublicationTitle>British journal of psychology (London, England : 1953)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/38d80cf96a17535df7b47ec6de07f7bd"><gtr:id>38d80cf96a17535df7b47ec6de07f7bd</gtr:id><gtr:otherNames>Dowsett AJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0007-1269</gtr:issn><gtr:outcomeId>55acdecc457895.83924195</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ABE77E9E-7EFC-4F6A-9985-A2EE7EB9662D</gtr:id><gtr:title>Viewers extract mean and individual identity from sets of famous faces.</gtr:title><gtr:parentPublicationTitle>Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/013a5c38539cb34d43d7ac2b27036b12"><gtr:id>013a5c38539cb34d43d7ac2b27036b12</gtr:id><gtr:otherNames>Neumann MF</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0010-0277</gtr:issn><gtr:outcomeId>55acdf20d8df61.32972192</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>56C61EB7-3915-45A4-8438-266C6818E928</gtr:id><gtr:title>Face Recognition by Metropolitan Police Super-Recognisers.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b5a862af41fd0743e1e1ee2f0efa8ee"><gtr:id>3b5a862af41fd0743e1e1ee2f0efa8ee</gtr:id><gtr:otherNames>Robertson DJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>5728bb17c2ff30.13868343</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B7837C33-561A-4315-9488-9EE6ACB52063</gtr:id><gtr:title>Image Memory for Faces and Objects</gtr:title><gtr:parentPublicationTitle>i-Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/79ff041239c4cde3e0e353a34b43f8b3"><gtr:id>79ff041239c4cde3e0e353a34b43f8b3</gtr:id><gtr:otherNames>Ritchie K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>562a4c8e5f1cb4.65627877</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C597BC10-D8F3-4B60-BC0B-F49F8BEE271E</gtr:id><gtr:title>Identity From Variation: Representations of Faces Derived From Multiple Instances.</gtr:title><gtr:parentPublicationTitle>Cognitive science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e9bbd50007d23d1dc9efe2ad51f37e07"><gtr:id>e9bbd50007d23d1dc9efe2ad51f37e07</gtr:id><gtr:otherNames>Burton AM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0364-0213</gtr:issn><gtr:outcomeId>5728bbfd321784.75195337</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>98EC2A18-B884-498F-9329-248F0E74E156</gtr:id><gtr:title>Telling faces together: Learning new faces through exposure to multiple instances.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/24ad3fe2e0292b6202ffad7a7b84a060"><gtr:id>24ad3fe2e0292b6202ffad7a7b84a060</gtr:id><gtr:otherNames>Andrews S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>55acdecc822fa2.90549912</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E6CE0082-1CE7-4934-9231-85D1FFFF0A57</gtr:id><gtr:title>Contributions of feature shapes and surface cues to the recognition and neural representation of facial identity.</gtr:title><gtr:parentPublicationTitle>Cortex; a journal devoted to the study of the nervous system and behavior</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9324cf81a71a80ec155ce4eb4c316dc3"><gtr:id>9324cf81a71a80ec155ce4eb4c316dc3</gtr:id><gtr:otherNames>Andrews TJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0010-9452</gtr:issn><gtr:outcomeId>5a732870e20851.68989608</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0BE1F363-47BF-473A-8812-9760DCF8A95E</gtr:id><gtr:title>Passport Checks: Interactions Between Matching Faces and Biographical Details</gtr:title><gtr:parentPublicationTitle>Applied Cognitive Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ad49c227910700ae2a7b9da1b88f4e9c"><gtr:id>ad49c227910700ae2a7b9da1b88f4e9c</gtr:id><gtr:otherNames>McCaffery J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d51ffb9dd70.36318415</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A02D280A-09A9-4246-B164-0D201FAD8B3E</gtr:id><gtr:title>Memory for images of faces and objects, European Conference on Visual Perception, Perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/670c4d97b19d9efde7a8b4587352ec48"><gtr:id>670c4d97b19d9efde7a8b4587352ec48</gtr:id><gtr:otherNames>Ritchie, K. L.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>562a4b052569b6.60429145</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0028977D-E906-4E6B-8204-1BC22E483C2A</gtr:id><gtr:title>Redesigning photo-ID to improve unfamiliar face matching performance.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Applied</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b271b74f4f099f7c253ed9450d31b25"><gtr:id>3b271b74f4f099f7c253ed9450d31b25</gtr:id><gtr:otherNames>White D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1076-898X</gtr:issn><gtr:outcomeId>541eb6e01797f6.36928335</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>31AD3631-AE17-4601-BF79-1D8FB9B7E8F1</gtr:id><gtr:title>Event-related potentials reveal the development of stable face representations from natural variability.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/24ad3fe2e0292b6202ffad7a7b84a060"><gtr:id>24ad3fe2e0292b6202ffad7a7b84a060</gtr:id><gtr:otherNames>Andrews S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>585d5542997368.79668463</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8CE50761-864C-4DAC-9501-9F0513B230D6</gtr:id><gtr:title>Feedback training for facial image comparison.</gtr:title><gtr:parentPublicationTitle>Psychonomic bulletin &amp; review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b271b74f4f099f7c253ed9450d31b25"><gtr:id>3b271b74f4f099f7c253ed9450d31b25</gtr:id><gtr:otherNames>White D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1069-9384</gtr:issn><gtr:outcomeId>doi_53d0880882b3b9c0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3957E608-943D-4EA6-893F-47A6442E923F</gtr:id><gtr:title>Learning faces from variability.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/16e88943e0d9c5741f261ffd54c0f186"><gtr:id>16e88943e0d9c5741f261ffd54c0f186</gtr:id><gtr:otherNames>Ritchie KL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>585d5536ee34a9.46019532</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>47C0CFF3-AFBB-4515-AE5D-577E4C72BD3D</gtr:id><gtr:title>Learning faces from variability</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/79ff041239c4cde3e0e353a34b43f8b3"><gtr:id>79ff041239c4cde3e0e353a34b43f8b3</gtr:id><gtr:otherNames>Ritchie K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>562a4a5ec30471.30058101</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0916E17D-7F7E-4E7C-9978-4D38A75F3F86</gtr:id><gtr:title>InterFace: A software package for face image warping, averaging, and principal components analysis.</gtr:title><gtr:parentPublicationTitle>Behavior research methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/97bb10951c0d4a1b44ded5bb087ae8d3"><gtr:id>97bb10951c0d4a1b44ded5bb087ae8d3</gtr:id><gtr:otherNames>Kramer RSS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1554-351X</gtr:issn><gtr:outcomeId>589462a5234361.54004569</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C931B479-2BC0-41F4-8093-66DB1281E508</gtr:id><gtr:title>From policing to passport control: The limitations of photo ID</gtr:title><gtr:parentPublicationTitle>Keesing Journal of Documents &amp; Identity</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93f78822ce0e89f3d0d12b036ca42d20"><gtr:id>93f78822ce0e89f3d0d12b036ca42d20</gtr:id><gtr:otherNames>Robertson, D. J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>562a491f6ada21.81518412</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AE3D84E2-CAA7-41AD-9FC8-2F244CA4D44C</gtr:id><gtr:title>Tolerance for distorted faces: challenges to a configural processing account of familiar face recognition.</gtr:title><gtr:parentPublicationTitle>Cognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e2db57c5c0572833a48b1ad74c656318"><gtr:id>e2db57c5c0572833a48b1ad74c656318</gtr:id><gtr:otherNames>Sandford A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0010-0277</gtr:issn><gtr:outcomeId>55acdf211e7562.46496768</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3A67668-BE0E-449A-BDF0-E4F354F52EB6</gtr:id><gtr:title>Face matching impairment in developmental prosopagnosia.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b271b74f4f099f7c253ed9450d31b25"><gtr:id>3b271b74f4f099f7c253ed9450d31b25</gtr:id><gtr:otherNames>White D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>585d55399c14f4.49392875</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EF1823C6-08B0-46D8-BE94-36A91615570A</gtr:id><gtr:title>Fraudulent ID using face morphs: Experiments on human and automatic recognition.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b5a862af41fd0743e1e1ee2f0efa8ee"><gtr:id>3b5a862af41fd0743e1e1ee2f0efa8ee</gtr:id><gtr:otherNames>Robertson DJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>5a2fcb00f12d88.60390566</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3B1216AC-CC64-4E3E-8D9B-CD91EEA37609</gtr:id><gtr:title>Robust social categorization emerges from learning the identities of very few faces.</gtr:title><gtr:parentPublicationTitle>Psychological review</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f54b7c9844e89ea476d3b02087d05284"><gtr:id>f54b7c9844e89ea476d3b02087d05284</gtr:id><gtr:otherNames>Kramer RS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0033-295X</gtr:issn><gtr:outcomeId>589463c728d0c9.56057271</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2977AB43-773D-45D2-B924-B5CFCFFB7603</gtr:id><gtr:title>Face learning with multiple images leads to fast acquisition of familiarity for specific individuals.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/38d80cf96a17535df7b47ec6de07f7bd"><gtr:id>38d80cf96a17535df7b47ec6de07f7bd</gtr:id><gtr:otherNames>Dowsett AJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>568a5d27b60333.73031075</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>69603B8C-97D8-4836-A4B7-F0B6E48C02FF</gtr:id><gtr:title>Why has research in face recognition progressed so slowly? The importance of variability.</gtr:title><gtr:parentPublicationTitle>Quarterly journal of experimental psychology (2006)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/281467a0e7eba1b96212dc35d389968c"><gtr:id>281467a0e7eba1b96212dc35d389968c</gtr:id><gtr:otherNames>Mike Burton A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1747-0218</gtr:issn><gtr:outcomeId>pm_53cc023c023a9e753</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5405472B-20BC-42D7-9AEF-FF5334F791B9</gtr:id><gtr:title>Matching Face Images Taken on the Same Day or Months Apart: the Limitations of Photo ID</gtr:title><gtr:parentPublicationTitle>Applied Cognitive Psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b367449acd6f37069d35bfc4fb16c30a"><gtr:id>b367449acd6f37069d35bfc4fb16c30a</gtr:id><gtr:otherNames>Megreya A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53cfbffbf307aa89</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/J022950/1</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>0E470BF0-24B8-49C5-B137-81D949A5F3DD</gtr:id><gtr:grantRef>ES/J022950/1</gtr:grantRef><gtr:amount>406814.78</gtr:amount><gtr:start>2012-11-01</gtr:start><gtr:end>2014-12-31</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>654ADA88-2A8A-48ED-988A-2123654A6A1D</gtr:id><gtr:grantRef>ES/J022950/2</gtr:grantRef><gtr:amount>107750.82</gtr:amount><gtr:start>2015-01-01</gtr:start><gtr:end>2015-10-31</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>