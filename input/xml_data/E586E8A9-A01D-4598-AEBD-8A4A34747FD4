<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:department>Sch of Engineering and Informatics</gtr:department><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A8967420-49D3-4509-9912-25FB3EC75B74"><gtr:id>A8967420-49D3-4509-9912-25FB3EC75B74</gtr:id><gtr:name>University of Sussex</gtr:name><gtr:address><gtr:line1>The Administration</gtr:line1><gtr:line2>Sussex House</gtr:line2><gtr:line3>Falmer</gtr:line3><gtr:line4>Brighton</gtr:line4><gtr:line5>East Sussex</gtr:line5><gtr:postCode>BN1 9RH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8626333E-E918-4B61-8284-A57C58120FD5"><gtr:id>8626333E-E918-4B61-8284-A57C58120FD5</gtr:id><gtr:firstName>Thomas</gtr:firstName><gtr:surname>Nowotny</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ019690%2F1"><gtr:id>E586E8A9-A01D-4598-AEBD-8A4A34747FD4</gtr:id><gtr:title>Green Brain - Computational Modelling of the Honeybee Brain</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J019690/1</gtr:grantReference><gtr:abstractText>Building intelligent machines that can perform complex cognitive tasks as well as or better than the human brain is a long-standing challenge of modern science. This quest has seen one of its highlights when IBM's Deep Blue chess computer beat the world champion Kasparov in 1997. Despite its superior performance in chess, this system was however in no way similar to or as powerful and versatile as a brain. More recently the Blue Brain initiative, also partially funded by IBM, set out to build a real-scale model of a cortical column of the human brain, moving us closer to the goal of eventually building an artificial brain that works like its biological counterpart.
 
In the Green Brain project we propose to build such an artificial brain, but of the smaller brain of the honeybee. We will work with the world-leading research group of Prof. Martin Giurfa in Toulouse, who are experts in all aspects of bee brain anatomy, physiology and bee cognition and behavior. Bees have a surprisingly large cognitive capacity including transfer of learned associations across sensory modalities, e.g. from smells to colors, and learning abstract concepts such as the categories of &amp;quot;the same&amp;quot; and &amp;quot;different&amp;quot;. At the same time their brains are much smaller, structured and (proportionally) much better researched than the complex human brain. It is also much easier to perform invasive manipulations to dissect how different parts of the bee brain function.

In the Green Brain project we will build detailed computer models of the two most important sensory systems of the bee, the senses of smell (olfactory system) and of sight (visual system). In doing so, we will incorporate existing data, models and principles and identify further how they give rise to the observed impressive cognitive abilities. We will then combine the sensory systems with learning models and models of sensory integration in close collaboration with the experts in the Giurfa lab to eventually build a full-scale model of the bee brain. This model will be implemented on state-of-the-art massively parallel graphical processing unit (GPU) based super-computers, a new technology spearheaded by NVIDIA Corporation who is supporting this project with GPU hardware donations. Using GPU computing will allow us to simulate our Green Brain model in real time, which will be essential for the final phase of the project when we will put the Green Brain to work as the brain of an autonomous flying robot. This is an important further advance over current work on brain models because it is becoming more and more clear that an essential aspect of brain function is that the brain is not acting in isolation but in constant interaction with the body and the environment. This concept of &amp;quot;embodiment&amp;quot; and its consequences for cognition are important insights of modern cognitive science and will become equally important for modern neuroscience. 

The outputs from the Green Brain project will have impacts in several academic areas. In the neurosciences it will advance the field of large scale brain models and our understanding of how information is processed in the sensory systems of bees. We will also contribute new tools for the use of modern GPU technology for artificial brains and employing them in bio-mimetic robotics. For the cognitive sciences we will contribute to the understanding of embodiment in biologically realistic model systems.

Beyond academia, the development of autonomous flying robots may have applications in environmental exploration, search and rescue and artificial pollination. Developing a better understanding of the mechanisms underlying cognition may ultimately translate into greater insights into human cognition and cognitive disorders. Finally, developing a better understanding of the honeybee may prove to be important in its own right as bees are a key pollinator in most ecologies and hence a 'keystone species' and vital for food security.</gtr:abstractText><gtr:fund><gtr:end>2016-09-10</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-03-11</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>335477</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Sheffield</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with University of Sheffield</gtr:description><gtr:id>01B0F450-4FF8-4078-97A1-FF22DA32DB92</gtr:id><gtr:impact>The outputs are recorded as outputs of our joint EPSCR grant.</gtr:impact><gtr:outcomeId>56bcceccd54816.28055130-1</gtr:outcomeId><gtr:partnerContribution>The Sheffield partners provide robotics and visual system modelling.</gtr:partnerContribution><gtr:piContribution>We work together on the Green Brain project. Our team at Sussex contributes the GPU computing expertise and in particular the GeNN framework. We also provide models of olfaction.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Presentation at the workshop on Code Generation at the Institute for Theoretical Neuroscience in Paris</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>803712F1-BED6-4B00-BB23-EE6B9EC63674</gtr:id><gtr:impact>In this workshop I reported on our work of building a GPU meta-compiler for efficient simulation of Neural Networks on GPU accelerators. The remainder of the event was a lively exchange among practitioners of research involving advanced software development/ code generation.</gtr:impact><gtr:outcomeId>58ab4dfd112f33.06142569</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Green Brain: Modeling the honeybee brain</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>4E405C64-AB67-4B9E-86FE-00188B52828E</gtr:id><gtr:impact>There were several questions after the talk and lively informal discussions.

no measureable data available.</gtr:impact><gtr:outcomeId>5464aff1e778b0.88740866</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Visit and exhibition at the X Science fair in Mountain View California</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>4D6A53D3-21B1-40A5-8716-9319CF5220AF</gtr:id><gtr:impact>I was invited and accepted to present our research (in particular Green Brain and Odor Objects projects) at the X science fair, organized at X headquarters in Mountain View, California.</gtr:impact><gtr:outcomeId>58ab54c8494f73.40416261</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited scientific talk at Keele Univeristy</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>02E0084F-0C38-4B73-BC24-2FD25223DB2A</gtr:id><gtr:impact>I presented recent research at Keele University to an audience of researchers and students. Much of the work reported was based on the Green Brain Project.</gtr:impact><gtr:outcomeId>58ab4c42b8d5e3.08816079</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk at the Neuromorphic Computing workshop (NICE) in Berkeley, California</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>10C03550-B78E-4276-A463-AAFEECA0DD32</gtr:id><gtr:impact>Invited talk in which I presented our benchmarking work of neural network algorithms, comparing neuromorphic platforms against our GPU accelerator framework (developed within the Green Brain project)</gtr:impact><gtr:outcomeId>58ab50fc0d9053.70996581</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk at the Neural Codign workshop in Koeln, Germany</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>05D5ADB6-AC64-4980-AE58-CA34F919AA52</gtr:id><gtr:impact>Scientific talk covering work from the Green Brain project and the HFSP funded &amp;quot;Odor Objects&amp;quot; project.</gtr:impact><gtr:outcomeId>58ab542b28ca82.04314907</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Speaker in the Lewes U3A Science Series</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>14020072-22D7-4BBF-9830-1C1B9506E0CE</gtr:id><gtr:impact>Presentation of a research lecture involving work from the Green Brain project, Odor Objects project and the planned work in Brains on Board.</gtr:impact><gtr:outcomeId>58ab55d636d1c0.91060053</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Press release on our results of Drosophila Receptor responses to a large set of chemicals</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D831F51F-FD02-484D-8035-4C6F1A1EE386</gtr:id><gtr:impact>The press release sparked large media attention including print and online news, radio interviews and a short report on the local TV station. overall there were about
- 58 items in print and online media
- Interviews/news items on BBC world service (Reach: 409000), BBC Radio Sussex (Reach 73000), BBC Radio Shropshire (Reach 29666), BBC Radio Wales (Reach 137000), and more.
- News item on BBC Southeast (TV)

I do not know how to measure impacts on thousands of listeners/viewers.</gtr:impact><gtr:outcomeId>5464b890a96c25.67398152</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation of Green Brain and Brains on Board projects</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>DB7EEEC0-D5D0-4FAF-A74F-7A872E6816E5</gtr:id><gtr:impact>I presented our research portfolio at the &amp;quot;Digi Drop-in&amp;quot; of the Brighton Digital Catapult centre. Both, work from the Green Brain and the planned work for the Brains on Board project were presented.</gtr:impact><gtr:outcomeId>58ab55734be787.60344166</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Scientific talk at the Jubilee of Prof Ulrich Behn, University of Leipzig, Germany</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>CDDAE87B-8709-478A-896B-90C023DD7671</gtr:id><gtr:impact>Scientific talk drawing on results from the Green Brain Project among others.</gtr:impact><gtr:outcomeId>58ab50296bdfd7.23062838</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Closed Loop Electrophysiology - AIMS workshop on closed loop interaction, Madrid 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>9F0A930E-A9A9-4640-BE1C-BCCDB025F79B</gtr:id><gtr:impact>Lively discussion after the talk which was very well received.

no measurable data available.</gtr:impact><gtr:outcomeId>5464c547de7647.69422232</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Cafe Scientifique Brighton</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>5AB57FEA-B314-4670-A8C4-71BDD56FCB9C</gtr:id><gtr:impact>Presentation of research including the Green Brain Project and Human Frontiers Odor Objects project to the general public, including detailed Q&amp;amp;A.</gtr:impact><gtr:outcomeId>58ab539885b670.66584703</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Parameter Estimation using GPU super-computing - Neural Coding Workshop Versailles 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>54932DF1-B4F9-4958-83AC-AF1F70123A7C</gtr:id><gtr:impact>Several questions from the audience.

No measurable data.</gtr:impact><gtr:outcomeId>5464b3cc9fe312.65234727</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Media coverage including New Scientist and Sunday Times</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>38C7B4D1-036B-4776-BF8B-52C4EAF53F5D</gtr:id><gtr:impact>-

Coverage included (among others)

&amp;quot;Summon the bee bots: Can flying robots save our crops?&amp;quot;, November 18th November 2013, New Scientist (on the cover).
&amp;quot;Flight of the robo-bee to save fruit crops&amp;quot;, 7th October 2012, The Sunday Times.</gtr:impact><gtr:outcomeId>54638a67b305d1.37580661</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2012,2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation at the mini air show event in Brighton, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>6462ACA0-F461-4ED9-9BDF-44206134B8CF</gtr:id><gtr:impact>I gave a presentation related to the Green Brain project to an audience of drone enthusiasts at the min air show event, related to International Drone Day.</gtr:impact><gtr:outcomeId>58ab5304cf27c8.90269422</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.miniatureairshow.com/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation at the joint SP4/SP9 Human Brain Project workshop on at the European Institute for Theoretical Neuroscience in Paris</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>2506E271-F6CC-48E8-AF0F-B954A065A43F</gtr:id><gtr:impact>Gave a presentation on models that tolerate diversity and engaged on a debate on the theory and practice of neuromorphic computing.</gtr:impact><gtr:outcomeId>58ab4ea71d8712.64800856</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Big Bang SouthEast 2014 - outreach activity about bee vision</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>6959E3FC-D3F8-4017-A10E-683A0EA86A98</gtr:id><gtr:impact>Lots of interest in the activity; we brought 2 separate setups to accommodate large numbers of visitors and yet still incurred waiting lines.

We do not have access to this data.</gtr:impact><gtr:outcomeId>5464b5e4994e21.44344416</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Big Bang Solent 2014 - outreach activity about bee vision</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>D54A4BA1-7E6D-4AC8-B61C-E2ED69D83186</gtr:id><gtr:impact>We had long queues of school children who wanted to try our virtual reality simulation of bee vision. This was one of the most popular activities in the entire event.

We do not have access to this data.</gtr:impact><gtr:outcomeId>5464b514e6d260.84897155</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Scientific talk at the University of Edinburgh</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>74B4E67B-1CCE-41A7-BCA3-EE7C8404782E</gtr:id><gtr:impact>Gave and invited talk in the Informatics Forum of the University of Edinburgh drawing partially on the work in the Green Brain project.</gtr:impact><gtr:outcomeId>58ab4fccaec7a3.68346819</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Panelist at the National Women in Engineering Day - Celebration Event</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>5B5EDF1F-E4EA-4E80-B170-AD7FBCAFA198</gtr:id><gtr:impact>20 female students and 10 faculty members attended talks by female scientists and a panel discussion about women in neuroscience. The audience reported that they learned a lot from the experience of the participants and that the event encouraged them to pursue their career as a woman in STEM.</gtr:impact><gtr:outcomeId>58b8829c1b9b04.36026892</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>http://www.sussex.ac.uk/informatics/about/newsandevents?id=35932</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Scientific talk at the &quot;Brains and Roses&quot; workshop in London</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>2278BDB9-1ADE-41B8-93B0-B96808075F64</gtr:id><gtr:impact>Gave a presentation partially based on the work in the Green Brain project.</gtr:impact><gtr:outcomeId>58ab4f4709ed30.40386690</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Outreach event for school aged children</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>C7C556DB-E608-429A-B541-9F77A02CC1ED</gtr:id><gtr:impact>We organized two days of activities on &amp;quot;behavioral robotics&amp;quot; involving school aged children to work with simple controllers for autonomous robots in order to solve set challenges, e.g. following a light trace. The activities took place in teh framework of teh Brighton Science Festival &amp;quot;BrightSparks&amp;quot; event.</gtr:impact><gtr:outcomeId>58ab56a234fc60.33045784</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation at the &quot;X Science Fair&quot;</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6FDD63D3-14F4-4F05-A670-7593773323CE</gtr:id><gtr:impact>Prof Thomas Nowotny presented the work in the Green Brain project at the X Science Fair at the X headquarters in Mountainview, California.</gtr:impact><gtr:outcomeId>58b94531d56f85.21857602</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Big Bang Observatory Science Centre 2014 - outreach activity about bee vision</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>77CDD1E7-0762-4F60-9EBD-05EB6F9B5A18</gtr:id><gtr:impact>Large interest of school children to see and try our virtual reality simulation of bee vision. We had some very positive feedback from individual visitors afterwards.

We do not have access to data.</gtr:impact><gtr:outcomeId>5464b6c0787ff2.73250518</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Oral presentation in Bernstein Conference, Green Brain workshop in Goettingen (2-5 September 2014)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>24C8DE47-2982-49C5-AAFF-51C70115120C</gtr:id><gtr:impact>The talk helped better understanding of our goal and achievements by colleagues and it was followed by a discussion.

After the talk I could discuss with experts in my field about my and their methods and results.</gtr:impact><gtr:outcomeId>5463a70b786f31.93135117</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://www.nncn.de/en/bernstein-conference/2014/workshops/green-brain-how-models-of-invertebrate-brains-can-inform-our-understanding-of-cognition</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public talk in the FabLab London, within the &quot;Hacking the Senses&quot; series</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>E5E85BBF-A0E5-47D7-A63E-572697EFC5D2</gtr:id><gtr:impact>Invited talk presenting our research on insect olfaction (related to the Green Brain poject). Also demonstrated our Bee Eye virtual reality simulator.</gtr:impact><gtr:outcomeId>58ab51ea87f8c7.24292910</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.eventbrite.com/e/hack-the-senses-s01e04-animal-perception-tickets-22776381771#</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>231283</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:department>Seventh Framework Programme (FP7)</gtr:department><gtr:description>Marie Sklodowska Curie Fellow Dr. Michael Schmuker</gtr:description><gtr:end>2016-08-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:id>6A3FA41F-BE60-43DB-986E-4DE6DCD0E8AA</gtr:id><gtr:outcomeId>56aa6e99a56ee6.03014329</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>337500</gtr:amountPounds><gtr:country>France, French Republic</gtr:country><gtr:currCode>USD</gtr:currCode><gtr:currCountryCode>Ecuador</gtr:currCountryCode><gtr:currLang>es_EC</gtr:currLang><gtr:description>HFSP Program Grant</gtr:description><gtr:end>2018-06-02</gtr:end><gtr:fundingOrg>Human Frontier Science Program (HFSP)</gtr:fundingOrg><gtr:fundingRef>RGP0053/2015</gtr:fundingRef><gtr:id>82DE90FE-4345-468F-836B-4635CF663411</gtr:id><gtr:outcomeId>56a9283b27cfb4.30046444</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2015-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>46346</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EfuturesXD staff award</gtr:description><gtr:end>2014-09-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:id>29D00BA5-21F0-4690-89C8-8FC3C885926D</gtr:id><gtr:outcomeId>54541c16363329.71820509</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-03-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1504568</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC Programme Grant</gtr:description><gtr:end>2021-11-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/P006094/1</gtr:fundingRef><gtr:id>F369B64E-8E79-466B-8EA7-55BFE0D70D4B</gtr:id><gtr:outcomeId>58ab4869d10c38.75415875</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-12-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>113276</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:department>Seventh Framework Programme (FP7)</gtr:department><gtr:description>Task 11.3.6 of the Human Brain Project FET Flagship</gtr:description><gtr:end>2016-03-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:id>CA27603D-DE02-4DBB-8B9C-FC670418754D</gtr:id><gtr:outcomeId>56a9298b0d6280.41047957</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-04-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>44522</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>The Leverhulme Trust Senior Research Fellowship</gtr:description><gtr:end>2015-08-02</gtr:end><gtr:fundingOrg>Royal Academy of Engineering</gtr:fundingOrg><gtr:id>FFDB241F-47F0-4C05-AE8F-0BC88EBEBA0F</gtr:id><gtr:outcomeId>54541b98745403.83040586</gtr:outcomeId><gtr:sector>Learned Society</gtr:sector><gtr:start>2014-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have developed the code generation based GeNN framework for accelerated neuronal network simulations on GPUs.</gtr:description><gtr:exploitationPathways>The GeNN framework is freely available under the open source GPL v2 license. It can be used for research in computational neuroscience and artificial intelligence. It can also be used as a basis for developing further software for GPU acceleration.</gtr:exploitationPathways><gtr:id>57B4C8DB-A024-4564-BB04-1A211322C010</gtr:id><gtr:outcomeId>56b9d2256373f9.05711493</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Other</gtr:sector></gtr:sectors><gtr:url>https://github.com/genn-team/genn</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The SpineCreator graphical tool is a cross platform (OSX with retina support, Linux and (potentially) Windows) graphical drag and drop tool for SpineML model editing and simulation. It features OpenGL visualisation of networks, simulator integration and graphical analysis tools. See http://bimpa.group.shef.ac.uk/SpineML/index.php/Gui for details.</gtr:description><gtr:id>A1E25AE1-4A6D-4E78-A020-609021AE78DF</gtr:id><gtr:impact>The software is being used in the European seventh framework project NoTremor (http://notremor.eu/notremor/)</gtr:impact><gtr:outcomeId>546481c9982d91.82636080</gtr:outcomeId><gtr:title>SpineCreator</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/SpineML/SpineCreator</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Software package to simulate neuronal networks on GPU accelerators using a domain specific language/ code-generation approach. (latest release 1.2, 2014)</gtr:description><gtr:id>CB415EF8-F7E2-4D18-9CA5-56E12FC5E232</gtr:id><gtr:impact>The tool is still in alpha. Notable impacts are expected somewhat later.</gtr:impact><gtr:outcomeId>r-5721299783.9984486fd5d132</gtr:outcomeId><gtr:title>GPU enhanced Neuronal Networks (GeNN)</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/genn-team/genn</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>SpineML_2_GeNN converts neural models described in the SpineML description format into the GeNN GPU simulation framework</gtr:description><gtr:id>5A974433-D1AA-4868-9C3A-0085D5CFD2C0</gtr:id><gtr:impact>This software allows computational neuroscience models to be easily simulated on the embarrassingly parallel hardware of modern NVidia graphics cards, vastly decreasing the cost required to improve simulation performance.</gtr:impact><gtr:outcomeId>546490bf95d567.50293029</gtr:outcomeId><gtr:title>SpineML_2_GeNN</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/genn-team/genn</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>This software provides an interface from the popular &amp;quot;Brian&amp;quot; simulator (version 2) to our GPU enhanced neuronal networks (GeNN) framework that allows users to define computational neuroscience models in Brian 2 and with a single command run them on a GPU accelerator. Depending on the type of model and accelerator, considerable speedups are possible without any additional effort by the users.
The software is in pre-alpha stage and will be released in beta together with the first full release of Brian 2.</gtr:description><gtr:id>1A4B86D8-61D5-4CC4-BEDA-B1CD00B7E941</gtr:id><gtr:impact>We are waiting on measurable impacts which we expect upon the first public release.</gtr:impact><gtr:outcomeId>56a926801e9be9.31495529</gtr:outcomeId><gtr:title>brian2genn</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/brian-team/brian2genn</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>ACAA6AB2-4AF1-42F9-A0DA-061E346A602D</gtr:id><gtr:title>Simulating a biologically accurate model of the honeybee olfactory system on the GPU</gtr:title><gtr:parentPublicationTitle>Frontiers in Neuroinformatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf9aefc2c003dc0ce5a73abffa578e0e"><gtr:id>bf9aefc2c003dc0ce5a73abffa578e0e</gtr:id><gtr:otherNames>Esin Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b87dd7544e03.60343027</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DF2EA1AD-F519-43E7-A108-8A090B74A030</gtr:id><gtr:title>Stimulus-onset asynchrony can aid odor segregation</gtr:title><gtr:parentPublicationTitle>Flavour</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54647f2288c242.60825810</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>85A7CF44-9BE8-4CCB-9A9B-FF60D7C85114</gtr:id><gtr:title>Data-driven honeybee antennal lobe model suggests how stimulus-onset asynchrony can aid odour segregation.</gtr:title><gtr:parentPublicationTitle>Brain research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0006-8993</gtr:issn><gtr:outcomeId>5675d867e50cb</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AD76AF05-8EBF-4F35-B2BF-A038271AF3AE</gtr:id><gtr:title>Easy-to-use GPU acceleration of neural network simulations with GeNN</gtr:title><gtr:parentPublicationTitle>Frontiers in Neuroinformatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ec0dac6bfc1423c88ef584192aba005c"><gtr:id>ec0dac6bfc1423c88ef584192aba005c</gtr:id><gtr:otherNames>James T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58b87dd7065940.94963590</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>935764B3-5923-4525-A331-A0D649469074</gtr:id><gtr:title>More flexibility for code generation with GeNN v2.1</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56a921df8fbc89.12709825</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CC5D91B8-EE49-4105-BE52-F1D8757925E7</gtr:id><gtr:title>Machine learning for automatic prediction of the quality of electrophysiological recordings.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>doi_53d081081ebbd38c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CBF5C865-E638-45DC-B12B-B57A1D082664</gtr:id><gtr:title>Classifying chemical sensor data using GPU-accelerated bio-mimetic neuronal networks based on the insect olfactory system</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/301bfaf7882625b025b7afff88a67477"><gtr:id>301bfaf7882625b025b7afff88a67477</gtr:id><gtr:otherNames>Diamond A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54647f231f6be1.65411701</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4B92342E-2666-4B6E-8C37-C730319E9D3E</gtr:id><gtr:title>Simulating spiking neural networks on massively parallel graphical processing units using a code generation approach with GeNN</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b9715ce0cddf7845c226765e2877d7e"><gtr:id>9b9715ce0cddf7845c226765e2877d7e</gtr:id><gtr:otherNames>Yavuz E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54647f22c5f9a7.54984762</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>77C9E434-A1C7-4148-BF22-8DAB2946CDAB</gtr:id><gtr:title>Artificial neural network approaches for fluorescence lifetime imaging techniques.</gtr:title><gtr:parentPublicationTitle>Optics letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d34dc7692a0ceb7793c3dfcf9922e951"><gtr:id>d34dc7692a0ceb7793c3dfcf9922e951</gtr:id><gtr:otherNames>Wu G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0146-9592</gtr:issn><gtr:outcomeId>585d4b81deb608.45774907</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5A100F3F-1CFF-4D06-BA95-7918F94E0F4A</gtr:id><gtr:title>GeNN: a code generation framework for accelerated brain simulations.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b9715ce0cddf7845c226765e2877d7e"><gtr:id>9b9715ce0cddf7845c226765e2877d7e</gtr:id><gtr:otherNames>Yavuz E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn><gtr:outcomeId>56a921ded51a63.65364840</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9B026666-6E28-4B46-B56E-43FBED744EE8</gtr:id><gtr:title>Olfactory experience shapes the evaluation of odour similarity in ants: a behavioural and computational analysis.</gtr:title><gtr:parentPublicationTitle>Proceedings. Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/10adabcf7a8fb889ebe43f94d7e7f91c"><gtr:id>10adabcf7a8fb889ebe43f94d7e7f91c</gtr:id><gtr:otherNames>Perez M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0962-8452</gtr:issn><gtr:outcomeId>585d37448b1676.76075840</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A5024F46-2B01-423D-90E7-A4051DE289C3</gtr:id><gtr:title>Drosophila olfactory receptors as classifiers for volatiles from disparate real world applications.</gtr:title><gtr:parentPublicationTitle>Bioinspiration &amp; biomimetics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1748-3182</gtr:issn><gtr:outcomeId>54540d90499f22.11612064</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>27D87748-9E1E-4E0D-87D7-8C01A64C6552</gtr:id><gtr:title>A modelling framework for the olfactory system of the honeybee using GeNN (GPU enhanced Neuronal Network simulation environment)</gtr:title><gtr:parentPublicationTitle>Flavour</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b9715ce0cddf7845c226765e2877d7e"><gtr:id>9b9715ce0cddf7845c226765e2877d7e</gtr:id><gtr:otherNames>Yavuz E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54647f225ed4d8.64165612</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F41C6302-CA49-4F67-845F-2B5DA5D647A6</gtr:id><gtr:title>Two Challenges of Correct Validation in Pattern Recognition</gtr:title><gtr:parentPublicationTitle>Frontiers in Robotics and AI</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54540d9021c429.92081779</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FAAA018F-514F-4608-AC71-7254DD2DD97A</gtr:id><gtr:title>SpineML and Brian 2.0 interfaces for using GPU enhanced Neuronal Networks (GeNN)</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbcb1ec7fe3df269850fd7879f4cebe5"><gtr:id>fbcb1ec7fe3df269850fd7879f4cebe5</gtr:id><gtr:otherNames>Nowotny T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54647f22ebe265.91791708</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AA6CA335-AAD4-4AC8-862D-C46744B4DC59</gtr:id><gtr:title>Probabilistic Decision Making with Spikes: From ISI Distributions to Behaviour via Information Gain.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5852723236246f91dd79a21f353073a3"><gtr:id>5852723236246f91dd79a21f353073a3</gtr:id><gtr:otherNames>Caballero JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>5675e372e9c92</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3F30FD7F-BF00-48F2-AC30-104B0C7E52F3</gtr:id><gtr:title>Gain control network conditions in early sensory coding.</gtr:title><gtr:parentPublicationTitle>PLoS computational biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/759d9b88937a52483253f20b5989e933"><gtr:id>759d9b88937a52483253f20b5989e933</gtr:id><gtr:otherNames>Serrano E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1553-734X</gtr:issn><gtr:outcomeId>doi_53d080080a58fcd7</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8E9244FE-D0E4-4D76-B3D8-E4F95F655979</gtr:id><gtr:title>GPU acceleration of time-domain fluorescence lifetime imaging.</gtr:title><gtr:parentPublicationTitle>Journal of biomedical optics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d34dc7692a0ceb7793c3dfcf9922e951"><gtr:id>d34dc7692a0ceb7793c3dfcf9922e951</gtr:id><gtr:otherNames>Wu G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1083-3668</gtr:issn><gtr:outcomeId>56a921df0b2f47.03334225</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>77D884AC-2B75-4076-BC46-A5735EC65F10</gtr:id><gtr:title>Spiking neural network model of reinforcement learning in the honeybee implemented on the GPU</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b9715ce0cddf7845c226765e2877d7e"><gtr:id>9b9715ce0cddf7845c226765e2877d7e</gtr:id><gtr:otherNames>Yavuz E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56a921df669946.86898227</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J019690/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>