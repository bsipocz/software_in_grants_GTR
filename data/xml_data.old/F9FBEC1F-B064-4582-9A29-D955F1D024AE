<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4B79A750-5175-481D-A795-E5E1EC0A949A"><gtr:id>4B79A750-5175-481D-A795-E5E1EC0A949A</gtr:id><gtr:name>The ERA Foundation</gtr:name><gtr:address><gtr:line1>Cleeve Road</gtr:line1><gtr:line4>Leatherhead</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>KT22 7SA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/A3C215EE-5645-4543-ACD7-878BFB368AC7"><gtr:id>A3C215EE-5645-4543-ACD7-878BFB368AC7</gtr:id><gtr:firstName>Panos</gtr:firstName><gtr:surname>Kudumakis</gtr:surname><gtr:orcidId>0000-0003-0518-4198</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2D1D7ADD-45F8-4B1A-89C5-9D33EAA1E795"><gtr:id>2D1D7ADD-45F8-4B1A-89C5-9D33EAA1E795</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:surname>Sandler</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FH008160%2F1"><gtr:id>F9FBEC1F-B064-4582-9A29-D955F1D024AE</gtr:id><gtr:title>3D Audio Interface for Exploration of Audio Collections</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H008160/1</gtr:grantReference><gtr:abstractText>A large number of people own a portable digital audio player - in a recent market report by In-Stat the worldwide unit sales were predicted to be 286 million by 2010. Music collections on these devices are also sizeable, typically with many 1000s of songs. The songs are grouped together in various ways: historically as albums, but more recently in playlists either generated automatically by software, or generated by the user. The challenge with large groups of songs is to navigate effectively though the group, or playlist, to select the song, or songs of choice.Currently users interact with playlists through a visual interface - the screen on the front of the device. Proposed in this application is a purely audio means of interacting with a playlist. The user browses through the songs in the playlist, listening briefly to each and selecting the songs of choice. This is achieved by using 3D audio technology, which plays several songs simultaneously as if they were originating from different spatial locations. From trials of an early-stage prototype of the technology it has been established that 4 songs playing at the same time, located using virtual acoustics in different virtual positions around the listener's head, is the optimal set up. The user can then easily navigate around the 3D virtual sound space, either using buttons on the device, or by pointing and tilting the device appropriately, if it contains an accelerometer (or similar), as increasingly many devices do, including the iPhone and iPod Touch.The funding will be used to further develop the technology, ultimately so that it runs on a stand-alone hand-held device. This can then be demonstrated to potential licensees. We also intend to release a limited functionality version free from our isophonics web portal, which currently offers our SoundBite automatic playlisting tool. This limited functionality release will enable potential customers and end-users to trial the software before purchase. Additionally, it will enable us to engage with end-users, seeking their feedback for improving the software.The technology will be commercially exploited by licensing the software as an API. One of the commercial issues addressed by the work plan presented in this proposal is whether a spin-out company should be established as a licencing vehicle, or whether direct exclusive licensing to an major mobile handset manufacturer, such as Nokia is more appropriate.</gtr:abstractText><gtr:fund><gtr:end>2011-02-28</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>83126</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>An evaluation licence was taken out by Rocket Pictures. This is for the software library developed under the project, which renders multiple audio streams in 3D virtual space over headphones. Their intended application is confidential to Queen Mary.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>38BF7ED7-7629-498A-9BA8-52C456B8429D</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56dc1d4d7c24b2.76690601</gtr:outcomeId><gtr:sector>Creative Economy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project demonstrated the utilities of spacial audio rendering techniques such as Ambisonics in audio content management and navigation. It was found that positioning audio items organised by similarity in a three dimensional sound scape provides an immersive environments that facilitates access to audio collections. This effect was demonstrated using listening tests for music collection navigation. It was also found that there is an upper bound on the number of sound sources listeners can successfully localise and use in a 3D navigation environment.</gtr:description><gtr:exploitationPathways>The project outcomes may be utilised in audio content management and delivery platforms, audio archives and libraries, immersive interactive environments, 3D multimedia production and delivery, mobile platforms, as well as applications that require hands-free interaction, or applications that require audio only interaction, for instance, audio content management tools for the visually impaired. The amblr, a mobile spatial audio music browser was created to exploit research findings in further research or commercial applications including mobile devices. This was demonstrated at the 2011 IEEE International Conference on Multimedia and Expo. A software library facilitates the exploitation of the outcomes in future applications.</gtr:exploitationPathways><gtr:id>B8FCC565-B952-4B1A-A8D5-B0A616579BC9</gtr:id><gtr:outcomeId>r-5799838105.030208775b97f0</gtr:outcomeId><gtr:sectors><gtr:sector>Communities and Social Services/Policy,Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The library takes in several audio streams (typically songs) and renders them in 3D audio space using binaural technology. Up to 4 simultaneous streams are allowed (the upper limit is imposed by human hearing constraints on paying attention to multiple simultaneous sources) and these can be moved around in virtual 3D space, e.g. with external controls such as with a mobile computing platform.</gtr:description><gtr:id>B747DBF4-0D3D-44B2-9E51-B6E319EAFAC6</gtr:id><gtr:impact>It has been licensed for evaluation to Rocket Pictures.</gtr:impact><gtr:outcomeId>56dc24457c37d9.19016814</gtr:outcomeId><gtr:title>Amblr: C++ library for rendering multiple sound sources over headphones with &quot;out of head&quot; localisation</gtr:title><gtr:type>Software</gtr:type><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>8A446ABC-D428-4D97-8B85-9BA1A3841FD3</gtr:id><gtr:title>An Auditory Display in Playlist Generation</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/424da25bbe587e89ee3712f0b534778a"><gtr:id>424da25bbe587e89ee3712f0b534778a</gtr:id><gtr:otherNames>Stewart R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>doi_53d05b05bb1a7022</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H008160/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>