<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Engineering Science</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/72996AA7-FDB4-478F-9B23-DA2A150A528A"><gtr:id>72996AA7-FDB4-478F-9B23-DA2A150A528A</gtr:id><gtr:firstName>Stephen</gtr:firstName><gtr:surname>Roberts</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD030099%2F1"><gtr:id>AE4C9B94-74FE-4318-98C8-FA53D4F9BB0F</gtr:id><gtr:title>AABAC: Adaptive Asynchronous Brain-Actuated Control</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D030099/1</gtr:grantReference><gtr:abstractText>This proposed project aims to develop a novel adaptive and asynchronous brain-computer interface (BCI) system for brain-actuated control of intelligent systems and robots. Recent advances in science and technology have shed light on the possibility of fusing human's brain with intelligent machines to carry out challenging tasks that the state of the art autonomous machines cannot undertake. BCI is one of the key technologies to make this possible. A BCI system detects and analyses brain waves, e.g., electroencephalography (EEG) signals, in order to understand a user's mental states, and then translates the mental states into commands for communicating with and controlling computers, robots, and other systems. Almost all the current EEG-based BCI systems of high accuracy use synchronous protocols and recognise two mental states only. Their disadvantages include low information transfer rate and unnatural user interface, which impose severe limitations on BCI systems for real-world applications. Based on our previous research in BCI and related areas, we believe that it is now very timely to develop adaptive and asynchronous BCI systems that not only have the advantages of using asynchronous protocols, such as high information transfer rate and natural operation mode, but also benefit from adaptive learning so as to improve the system's accuracy and robustness. Apart from adaptive learning, in order to achieve high accuracy and robustness, this proposed programme will investigate novel effective indicators for onset detection and optimal timing schemes for asynchronous mental state classification, discover or invent new feature spaces on which it would be easier to classify EEG patterns, and develop new methods for increasing the number of control commands mapped from a limited number of mental states. The methods developed hereby will be assessed through extensive experimentation with real-time brain-actuated control of an intelligent wheelchair and a robotic arm.</gtr:abstractText><gtr:fund><gtr:end>2009-07-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>180462</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>When we talk about interfacing with a computer we typically mean typing at a keyboard or using a mouse. This project investigates using a new communication channel - the EEG. The EEG, or electroencephalogram, is electrical activity recorded from the scalp and produced by neurons in the brain. The development of a Brain Computer Interface, or in our case, an EEG-based communication device, requires the raw EEG signal to be converted into a new output channel through which the brain can communicate and control its environment. 



This projects builds on twenty years of research in the brain sciences and on recent developments in adaptive computing. In the 1970s it was discovered that subtle changes occur in the EEG when we plan movements. These changes are called Movement-Related Desynchronisations (or MRDs for short) because when movements are planned the activity of neurons in the motor cortex becomes desynchronised. But the MRD signals are tiny. They are rarely bigger than a few tens of microvolts and are often buried beneath other signals. We therefore need to use advanced pattern recognition methods to detect the MRD signals.



Our experiments have shown that it is possible to robustly control a variety of devices using these brain-only signals.</gtr:description><gtr:id>9ECE9CC0-B33A-4364-8A25-E2B208AB14E4</gtr:id><gtr:outcomeId>r-3091510835.18891777714398</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>77D825B1-BFD6-4CEC-B1AB-E880CD60EC2A</gtr:id><gtr:title>An adaptive, sparse-feedback EEG classifier for self-paced BCI.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dff0eeb57857972de01e5072f694a451"><gtr:id>dff0eeb57857972de01e5072f694a451</gtr:id><gtr:otherNames>S Roberts</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:outcomeId>m_826040720214055712</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E7EFE8B3-049E-429B-8F75-78DB7EA2091A</gtr:id><gtr:title>Adaptive classification for Brain Computer Interface systems using Sequential Monte Carlo sampling.</gtr:title><gtr:parentPublicationTitle>Neural networks : the official journal of the International Neural Network Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ee3260db23c2224693272a8fee8b269"><gtr:id>1ee3260db23c2224693272a8fee8b269</gtr:id><gtr:otherNames>Yoon JW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0893-6080</gtr:issn><gtr:outcomeId>doi_53d0020023cc6d6a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A0D63EF5-1AD4-4818-8475-871D179F22D1</gtr:id><gtr:title>A self-paced brain-computer interface for controlling a robot simulator: an online event labelling paradigm and an extended Kalman filter based algorithm for online training.</gtr:title><gtr:parentPublicationTitle>Medical &amp; biological engineering &amp; computing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1e5340dabd2bcc3885d527c6d2786f9a"><gtr:id>1e5340dabd2bcc3885d527c6d2786f9a</gtr:id><gtr:otherNames>Tsui CS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0140-0118</gtr:issn><gtr:outcomeId>doi_53cfdffdf76b5478</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6B55F2E3-0C8F-4F87-B478-330BBCCDE606</gtr:id><gtr:title>Fault Tolerant Control Using Gaussian Processes and Model Predictive Control</gtr:title><gtr:parentPublicationTitle>International Journal of Applied Mathematics and Computer Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/01b9bc8b57a0ba34caccb89dd0da9878"><gtr:id>01b9bc8b57a0ba34caccb89dd0da9878</gtr:id><gtr:otherNames>Yang X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56bc6f5aa111b4.49624919</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E2A1C506-7EC0-4302-A30B-DB564D9918A2</gtr:id><gtr:title>Sequential non-stationary dynamic classification with sparse feedback</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e3cf36ce949b0b53215df41ca94b5ad"><gtr:id>6e3cf36ce949b0b53215df41ca94b5ad</gtr:id><gtr:otherNames>Lowne D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d0040044ba3bbd</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B34DA920-F6CF-4FA7-9C55-91476ACFED04</gtr:id><gtr:title>Bayesian inference for an adaptive Ordered Probit model: an application to Brain Computer Interfacing.</gtr:title><gtr:parentPublicationTitle>Neural networks : the official journal of the International Neural Network Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ee3260db23c2224693272a8fee8b269"><gtr:id>1ee3260db23c2224693272a8fee8b269</gtr:id><gtr:otherNames>Yoon JW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0893-6080</gtr:issn><gtr:outcomeId>doi_53d00200240e39c1</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D030099/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>