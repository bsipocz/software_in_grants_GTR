<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/96BFFAB5-69B1-49E8-8F41-9C763818EFA6"><gtr:id>96BFFAB5-69B1-49E8-8F41-9C763818EFA6</gtr:id><gtr:name>Jaguar Land Rover</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:department>WMG</gtr:department><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2C7C1A46-3E61-4551-AF6C-30F8BC9BAF00"><gtr:id>2C7C1A46-3E61-4551-AF6C-30F8BC9BAF00</gtr:id><gtr:name>Jaguar Cars Ltd</gtr:name><gtr:address><gtr:line1>Engineering Centre</gtr:line1><gtr:line2>Abbey Road</gtr:line2><gtr:line3>Whitley</gtr:line3><gtr:line4>Coventry</gtr:line4><gtr:line5>Warwickshire</gtr:line5><gtr:postCode>CV3 4LF</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96BFFAB5-69B1-49E8-8F41-9C763818EFA6"><gtr:id>96BFFAB5-69B1-49E8-8F41-9C763818EFA6</gtr:id><gtr:name>Jaguar Land Rover</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3F54A5BE-E3D3-4248-B23F-4A26A8811E88"><gtr:id>3F54A5BE-E3D3-4248-B23F-4A26A8811E88</gtr:id><gtr:name>Jaguar and Land Rover</gtr:name><gtr:address><gtr:line1>Gaydon Engineering Centre</gtr:line1><gtr:line2>Lighthorne</gtr:line2><gtr:postCode>CV35 0RR</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/4E8EB4C1-E188-4F55-BAD5-C8CC9793F508"><gtr:id>4E8EB4C1-E188-4F55-BAD5-C8CC9793F508</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Chalmers</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D263A06A-C807-446A-BFE1-307EA6DC0F8A"><gtr:id>D263A06A-C807-446A-BFE1-307EA6DC0F8A</gtr:id><gtr:firstName>Christopher</gtr:firstName><gtr:otherNames>Bell</gtr:otherNames><gtr:surname>Moir</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/75B7012D-5F23-4948-930D-79288035D29C"><gtr:id>75B7012D-5F23-4948-930D-79288035D29C</gtr:id><gtr:firstName>Kurt</gtr:firstName><gtr:surname>Debattista</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FK014056%2F1"><gtr:id>5FDE12C5-BBD6-42C4-BBD1-CF612204E780</gtr:id><gtr:title>Theme 7: Visualisation and Virtual Experience</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K014056/1</gtr:grantReference><gtr:abstractText>Virtual reality (VR) systems strive to provide real world experiences in safe and controlled computer generated environments. VR systems attempt to deliver two key features: realism and real-time. In particular, the real time element is essential to provide an interactive experience to the user. To achieve this, current VR systems compromise the realism in the environments they are simulating. This is because even the very latest computer hardware is simply not capable of simulating, to a full degree of physical accuracy, in real time, the complexities of the real world. Furthermore, VR systems seldom offer more than two sensory stimuli (typically visuals and audio, or visuals and touch). 
Real Virtuality systems, on the other hand, are defined as virtual environments that are based on physical simulations and stimulate multiple senses (visuals, audio, smell, touch, motion etc.) in a natural manner. A key feature of Real Virtuality is the natural delivery of multiple senses to ensure cross-modalities (the influence of one sense on another) that would occur in the real environment are present in the virtual world, as these can substantially alter the way in which a scene is perceived and the way the user behaves. In this project we will consider environments that include 4 senses: visuals, audio, smell and feel (where feel includes motion, temperature and wind-speed). Real Virtuality systems are able to achieve a high level of authenticity in real time by selectively delivering real world stimuli; exploiting the fact that the human perceptual system is simply not capable of attending to all stimuli at the highest precision all the time. Rather humans selectively attend to objects within the scene. This can result in large amounts of detail from one sense going unnoticed when in the presence of competing sensory inputs from another modality, or subtle signals in one modality being strongly enhanced by congruent information in another sense. Knowledge of the relative importance of sensory information in a scene at any point in time, enables the areas being attended to, to be computed at the highest quality, while other areas can be delivered at a much lower quality (and thus at a significantly reduced computational effort), without the user being aware of this quality difference.
Visualisation and Virtual Experience, undertakes research into a novel, validated Real Virtuality Platform that will provide perceptually equivalent experiences between real world scenarios and their simulated virtual world equivalents. The authenticity of the results is key to enable decisions within the virtual environments to be taken with confidence that the same decision would be made in the equivalent real environment. The high-fidelity of the resultant virtual system will thus be thoroughly tested and fully validated against two real test cases: Gaydon and Sweden. The anticipated outcomes of the research will be techniques of visualisation applicable at all levels of vehicle design:
- from verification of individual components through to the verification of the final vehicle design, 
- and through all stages of the design process, from initial concept definition through to final design approval, through to manufacturing and onto the dealerships, and marketing.
Visualisation and Virtual Experience will remove the need to build physical prototypes and thus bring about a reduction in time to market. This would be impossible to achieve without the ability to effectively and authentically experience a product virtually in its intended context, and to make rapid, objective decisions as a result. The results of this project will address national UK priorities by providing step-change improvements in virtual experiences. The new algorithms and methodologies, although created and fully validated for the automotive industry, will be equally applicable to any sector engaged in the design and high value manufacture of products.</gtr:abstractText><gtr:potentialImpactText>This project will introduce truly new opportunities for authentically experiencing the real world in the safety, repeatable, and control of a virtual environment. We will deliver a novel high fidelity, multisensory Real Virtuality Platform to facilitate confident, informed decision making in the virtual environment. Our partner JLR provides world class domain expertise and direct routes to market. The project will clearly demonstrate the step-change in the fidelity of a virtual experience. In doing so, the partners will gain significant insights into: how Real Virtuality can best benefit automotive applications; how the results of the research could equally be useful to academics and other applications; and, the commercial merits of the proposed system. Who and what will benefit from the outcomes of this project and how this will occur can be summarised as follows. This includes those people and fields directly affected by the project, and those others who, while not directly involved, will nevertheless benefit from knowledge gained:
- Automotive, aerospace and rail (designers, engineers &amp;amp; management): Flexibility and increased speed in assessing alternative concept designs without the need for building clay models and other mock-ups; greater level of objective information to support the decisions making process; better quality, confident, up-front decisions; will move a company closer to the goal of zero prototypes (and reduction in costs and development timescales).
Defence training and planning: Experience fully all the sensory stimuli of a real world, potentially dangerous environment in a safe and controlled manner. 
General public: Able to experience a product before it is built enabling personalisation and informed customer choice.
Training for fire-fighters, commercial pilots, driving: accurate full multi-sensory simulation of highly dangerous conditions in a controlled environment.
Cultural heritage: Authentic recreation of how environments may have been perceived in the past.
Tourism: Remote experience of sites; allows social inclusion and access to possibly dangerous sites.
Architecture, building design, public consultation: Experiencing a design in its multisensory context 
Education: Experience current and past environments, for example learning French with the sights sounds and smells of Paris.
Medical and dentistry: Full multisensory experience of a procedure, the ability to assist in remote complex operation.
Game developers, game console manufacturers, and players: Multi-sensory realism within computer games enabling a more compelling, immersive game experience.
Whilst these are clear possibilities for our technology, there are many others. We will take a pro-active approach through existing and new methods to ensure others can also imagine their own applications and have the opportunity to benefit from our research. These methods include (1) taking advantage of partners' existing means of regular communication and engagement (meetings, visits, newsletters, press releases, workshops, exhibitions, etc) and Warwick (and in particular WMG)'s unique opportunities, such as:
-regular visits by high profile industrial and public policy makers
-extensive links with end user organisations
-WMG's dedicated Business Development Group, PR Department and Web services
- Warwick Ventures' (technology transfer office) own network of partners
And (2) new methods:
-extensive contacts of the academic and industrial partners
- wide dissemination routes of EU COST Action IC1005, which Chalmers chairs
-modern media opportunities
-services of a free-lance cartoonist</gtr:potentialImpactText><gtr:fund><gtr:end>2017-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>840939</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Jaguar Land Rover</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>PSi: Theme 7: Visualisation and Virtual Experiences</gtr:description><gtr:id>6620B1BB-6FA3-4A3C-9D61-9230632D786A</gtr:id><gtr:impact>Project completed 31 October 2016. One paper is still under review and some other papers are in preparation.</gtr:impact><gtr:outcomeId>56dd97f589b7a3.27395033-1</gtr:outcomeId><gtr:partnerContribution>Provide the scenarios required for the experiences and access to the real environments and material data necessary to achieve the required level of authenticity.</gtr:partnerContribution><gtr:piContribution>Investigating High-fidelity multisensory virtual experiences. My research team is building and validating the platform for delivering these experiences.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>NAB2016</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E7F93353-A4A1-4589-8888-BCB3546A2785</gtr:id><gtr:impact>The research was presented in the Futures Park section of the NAB 2016 show in Las Vegas, USA. NAB is the largest broadcast exhibition in the world that attracts over 92,000 participants. The exhibit attracted lots of interest in our HDR technologies.</gtr:impact><gtr:outcomeId>58c955ecda2435.20492343</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www.nabshow.com</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>IBC2016</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6515D9B2-D024-4C3F-8A9A-6F85BE3C14FB</gtr:id><gtr:impact>Our research was presented at the Future Zone section of IBC 2016. Held in Amsterdam each year, IBC is the largest European broadcasting exhibition that has over 52,000 participants each year. There was significant interest in our HDR technologies.</gtr:impact><gtr:outcomeId>58c95672328c58.53974880</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www.ibc.org</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The research showed that it was indeed possible to create high-fidelity multisensory virtual environments which are perceptually equivalent to the real world scenes they were recreating. This makes it possible to consider using such authentic virtual environments for other applications, especially those related to well being and virtual archaeology (specially for intangible heritage).</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>F7E6AA2E-4CB3-4F9E-ADB2-0D189A221367</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56dda291148e34.13426235</gtr:outcomeId><gtr:sector>Healthcare,Culture, Heritage, Museums and Collections</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The goal of the research was to create authentic multisensory virtual experiences that fully replicate the equivalent real world experience. A detailed experiment was undertaken in which participants experienced a real driving scenario and a multisensory virtual equivalent at different quality levels. The senses considered were visuals, audio, smell and the motion of the car. There were three &amp;quot;events&amp;quot; in the scenario: an emergency stop, a swerve and the release of a smell. Objective and subjective quality metrics were used to establish the correlation between the real and virtual world experiences. A high correlation was achieved between the real experience and the highest quality virtual experience.</gtr:description><gtr:exploitationPathways>The data captured in this project will be available to researchers in the investigators' current large academic and industrial networks and other partners through collaboration agreements. Furthermore the outputs could be incorporated to support lectures, case studies and student projects. The multi-disciplinary and novel nature of this research has enabled it to be presented (and be available as open source in line with EPSRC requirements), both as high quality research papers and tutorials, to a wide range of leading international conferences.</gtr:exploitationPathways><gtr:id>2AA62A80-5FD8-427F-9AF4-E7E9551AE872</gtr:id><gtr:outcomeId>56dda27d4fba95.50151077</gtr:outcomeId><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Construction,Digital/Communication/Information Technologies (including Software),Education,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections,Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>912CF058-4996-44A0-8B9F-D931F8747DBD</gtr:id><gtr:title>Acoustic Rendering and Auditory-Visual Cross-Modal Perception and Interaction</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cc2226cbc6c2d2baed251fe32e3c1f8d"><gtr:id>cc2226cbc6c2d2baed251fe32e3c1f8d</gtr:id><gtr:otherNames>Hulusic V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>54639cbc9102b9.87150696</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F383CCCE-3836-49BD-9F3A-D8268D0AFB6F</gtr:id><gtr:title>Olfactory Adaptation in Virtual Environments</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Applied Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3c674489d4cdc8b789109d1957322f1b"><gtr:id>3c674489d4cdc8b789109d1957322f1b</gtr:id><gtr:otherNames>Ramic-Brkic B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>54639b67a6ab56.33674822</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D6EE2867-3911-45CB-A844-275221C99B37</gtr:id><gtr:title>Smoothness perception</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cc2226cbc6c2d2baed251fe32e3c1f8d"><gtr:id>cc2226cbc6c2d2baed251fe32e3c1f8d</gtr:id><gtr:otherNames>Hulusic V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>54639c49aaf505.95985942</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F92764B9-E33D-4AAA-A560-BD8DBCD98569</gtr:id><gtr:title>Objective and subjective evaluation of High Dynamic Range video compression</gtr:title><gtr:parentPublicationTitle>Signal Processing: Image Communication</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/89e4904e5ae7ef9a9c5eb2c1a3496e7e"><gtr:id>89e4904e5ae7ef9a9c5eb2c1a3496e7e</gtr:id><gtr:otherNames>Mukherjee R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c90be1bf3b63.70868763</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D19B0BF3-531F-4974-B4F2-837920BD24FC</gtr:id><gtr:title>Multi-Modal Perception for Selective Rendering</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1b138f01a9844fe3cdb47724e4cfd9b1"><gtr:id>1b138f01a9844fe3cdb47724e4cfd9b1</gtr:id><gtr:otherNames>Harvey C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>56dd671b535377.88679492</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FEA20686-81CD-4F50-8DBF-B384434ABDEB</gtr:id><gtr:title>A Calibrated Olfactory Display for High Fidelity Virtual Environments</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/42ee7c031ecffa8267c14bae107a4b0d"><gtr:id>42ee7c031ecffa8267c14bae107a4b0d</gtr:id><gtr:otherNames>Dhokia A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c90d1b5403b4.37474868</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7DBCF558-4381-4DFE-B377-82A52026EDB2</gtr:id><gtr:title>How level of realism influences anxiety in virtual reality environments for a job interview</gtr:title><gtr:parentPublicationTitle>International Journal of Human-Computer Studies</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/db5de0ff9d9c8a16d85c75f8b466654d"><gtr:id>db5de0ff9d9c8a16d85c75f8b466654d</gtr:id><gtr:otherNames>Kwon J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>54639c0509c274.92814572</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8376B7CA-E338-487A-A38D-F7DC4E9B1C0F</gtr:id><gtr:title>Audiovisual Resource Allocation for Bimodal Virtual Environments</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c87535737a01ead3d7c9ac9df428912"><gtr:id>2c87535737a01ead3d7c9ac9df428912</gtr:id><gtr:otherNames>Doukakis E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a2fe17775aa18.30338721</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A9E20A66-DB11-40EF-88C8-0DDEC61BBCB6</gtr:id><gtr:title>Subjective Evaluation of High-Fidelity Virtual Environments for Driving Simulations</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Human-Machine Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/23e1205a583979e5157d2dd834f41c70"><gtr:id>23e1205a583979e5157d2dd834f41c70</gtr:id><gtr:otherNames>Debattista K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a352976738496.65919117</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D3A0B386-036A-44E6-A75C-D43D51EFF74A</gtr:id><gtr:title>Selective BRDFs for High Fidelity Rendering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed63b7271886f5f2a5822054f511d054"><gtr:id>ed63b7271886f5f2a5822054f511d054</gtr:id><gtr:otherNames>Bradley T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c90e78784f40.27333168</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>097D5CBE-EF7A-4331-AB5A-C197FFA1E57C</gtr:id><gtr:title>Remote rendering of High Dynamic Range graphics content</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f48b703cf0a1f5e733b6f96aaab264b4"><gtr:id>f48b703cf0a1f5e733b6f96aaab264b4</gtr:id><gtr:otherNames>McNamee J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c90d7d3a9e68.03298330</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E6F8551A-D8A8-464E-BD83-8C135E5405FF</gtr:id><gtr:title>A study on user preference of high dynamic range over low dynamic range video</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/89e4904e5ae7ef9a9c5eb2c1a3496e7e"><gtr:id>89e4904e5ae7ef9a9c5eb2c1a3496e7e</gtr:id><gtr:otherNames>Mukherjee R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c90c405704b6.41563849</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>83D8593B-B806-4734-ABD1-9A91E5C0CF81</gtr:id><gtr:title>A Machine Learning Driven Sky Model</gtr:title><gtr:parentPublicationTitle>IEEE Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/daab0332b4c3f7f6c81d4c477b9b5f72"><gtr:id>daab0332b4c3f7f6c81d4c477b9b5f72</gtr:id><gtr:otherNames>Satilmis P.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56dd66ce668865.53363064</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K014056/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>