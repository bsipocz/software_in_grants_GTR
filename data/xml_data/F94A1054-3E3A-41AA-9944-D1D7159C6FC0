<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/E4757A6E-7326-472B-9979-B47D77A65446"><gtr:id>E4757A6E-7326-472B-9979-B47D77A65446</gtr:id><gtr:name>Aberystwyth University</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>King Street</gtr:line2><gtr:line3>Ceredigion</gtr:line3><gtr:line4>Aberystwyth</gtr:line4><gtr:line5>Dyfed</gtr:line5><gtr:postCode>SY23 2AX</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E4757A6E-7326-472B-9979-B47D77A65446"><gtr:id>E4757A6E-7326-472B-9979-B47D77A65446</gtr:id><gtr:name>Aberystwyth University</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>King Street</gtr:line2><gtr:line3>Ceredigion</gtr:line3><gtr:line4>Aberystwyth</gtr:line4><gtr:line5>Dyfed</gtr:line5><gtr:postCode>SY23 2AX</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A8ABB09-1247-4B6C-9770-59151F09F641"><gtr:id>3A8ABB09-1247-4B6C-9770-59151F09F641</gtr:id><gtr:name>HM Revenue &amp; Customs</gtr:name><gtr:address><gtr:line1>HM Revenue &amp; Customs</gtr:line1><gtr:line2>4th Floor Central</gtr:line2><gtr:line3>100 Parliament Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SW1A 2BQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2BA3C484-FA19-4E5D-BBB7-2FCFAD740307"><gtr:id>2BA3C484-FA19-4E5D-BBB7-2FCFAD740307</gtr:id><gtr:name>The Home Office</gtr:name><gtr:address><gtr:line1>3rd floor, Seacole Bldg</gtr:line1><gtr:line2>2 Marsham Street</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW1P 4DF</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3F62EC70-1083-4D92-8373-E0E437A641B7"><gtr:id>3F62EC70-1083-4D92-8373-E0E437A641B7</gtr:id><gtr:firstName>Reyer</gtr:firstName><gtr:surname>Zwiggelaar</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/B5949024-22A0-414B-8D12-48359A2CCA77"><gtr:id>B5949024-22A0-414B-8D12-48359A2CCA77</gtr:id><gtr:firstName>Hassan</gtr:firstName><gtr:surname>Ugail</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG004137%2F1"><gtr:id>F94A1054-3E3A-41AA-9944-D1D7159C6FC0</gtr:id><gtr:title>Facial Analysis for Real-Time Profiling</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G004137/1</gtr:grantReference><gtr:abstractText>This project will develop an operationally and technically viable approach to cargo threat investigation. The main aim of the project is to provide a real-time dynamic passive profiling technique to assist Border Control Agencies and has the potential to improve hit rates; i.e. to improve targeting the people that carry contraband and hence ensure less is entering the UK.To be specific, the real-time dynamic passive profiling technique will be based on the modelling of facial expressions, eye movement and pupil changes in both the visual and thermal domains and link these to malicious intent and physiological processes (such as blood flow, eye movement patterns, and pupil dilation). To facilitate this process, one of the initial aspects of the project will be the collection, analysis and development of the dataset used to model the baseline of facial imagery behaviour of the general population against which physiological behaviours in people with malicious intent would need to be detected. Both the baseline and the dynamic profiling will be based on the response to a series of questions. The developed techniques will be evaluated in operational trails at border control points. The multi-modal facial analysis will provide additional information to the current profiling and the developed techniques will have a wider remit into other domains. It is envisioned that this will be easily integrated into the current process.There are three main challenges:a) to determine the facial/eye features, in combination with psychological profiling, to provide robust baselines that can be linked to malicious intent,b) to develop and combine the various dynamic real-time facial models (visual expression, thermal, eye movement) related to intent, andc) to evaluate the developed system within different environments, ranging from airport to port based border control points.</gtr:abstractText><gtr:fund><gtr:end>2011-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>544499</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs><gtr:artisticAndCreativeProductOutput><gtr:description>J. Auger, J. Loizeau, B. Rajoub and R. Zwiggelaar, &amp;quot;Happylife,&amp;quot; Talk to Me - Museum of Modern Art New York, July 24 - November 7, (2011).</gtr:description><gtr:id>D9142337-E923-4E92-A34D-F04E298C56E4</gtr:id><gtr:impact>Further collaboration, public engagement.</gtr:impact><gtr:outcomeId>545b6dfedfc130.44410093</gtr:outcomeId><gtr:title>Happylife</gtr:title><gtr:type>Artistic/Creative Exhibition</gtr:type><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:artisticAndCreativeProductOutput></gtr:artisticAndCreativeProductOutputs><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Thermal facial analysis can be used to discriminate between truth/lies in an interview setting.</gtr:description><gtr:exploitationPathways>The methodology can be translated.</gtr:exploitationPathways><gtr:id>9D98CA10-52E4-4F45-9193-F334341206C5</gtr:id><gtr:outcomeId>r-5860598195.21438177928512</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>55D7B6BA-EB08-41A4-B625-61559A82F2A1</gtr:id><gtr:title>Thermal Facial Analysis for Deception Detection</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Information Forensics and Security</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/044921ada26e9725fc01402991f22cd7"><gtr:id>044921ada26e9725fc01402991f22cd7</gtr:id><gtr:otherNames>Rajoub B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545b6cf810b5e6.88270002</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>336AFE89-D2B4-491C-8137-90778FA83F1A</gtr:id><gtr:title>Facial Behavioral Analysis: A Case Study in Deception Detection</gtr:title><gtr:parentPublicationTitle>British Journal of Applied Science &amp; Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/06cb273411cc43caf124d5f5471651bb"><gtr:id>06cb273411cc43caf124d5f5471651bb</gtr:id><gtr:otherNames>Yap M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>589b22e2394f93.73879878</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C3D09847-C332-4451-A5C5-4605F113F6E4</gtr:id><gtr:title>Facial Analysis for Real-time Application: A review in visual cues detection techniques</gtr:title><gtr:parentPublicationTitle>Journal of Communication and Computers</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/510702362d50484b0b892b7c4ca00c4d"><gtr:id>510702362d50484b0b892b7c4ca00c4d</gtr:id><gtr:otherNames>M-H Yap (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_2723530706138351e0</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G004137/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>