<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3C3CA393-793C-44B4-8CE2-ED279AB3D41A"><gtr:id>3C3CA393-793C-44B4-8CE2-ED279AB3D41A</gtr:id><gtr:firstName>Lewis</gtr:firstName><gtr:otherNames>Donald</gtr:otherNames><gtr:surname>Griffin</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/44B3B477-75B9-44EB-8916-318136B765B2"><gtr:id>44B3B477-75B9-44EB-8916-318136B765B2</gtr:id><gtr:firstName>Alan</gtr:firstName><gtr:surname>Johnston</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD030978%2F1"><gtr:id>8B71B27B-7C02-4F99-AE7F-4485520D047B</gtr:id><gtr:title>Basic Image Features</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D030978/1</gtr:grantReference><gtr:abstractText>This is a project about studying how the brain understands the image that the eye sees. We think that the brain analyzes each bit of the image separately, saying to itself 'that bit's an eye', 'that's an edge', 'that's a bit of shading' and so on. Then it stitches all these bits together so that it sees the whole image as one. We call the first stage (the looking-at-little-bits-of-the-image part) local analysis, and the second stage (the stitching-the-bits-together part) multi-local analysis. Both are important in understanding how vision works, but this project is only about the local part. To help explain what we will do in the project I'm going to describe a couple of activities that you might be asked to do in an art class.Imagine that you were given the task of making mosaic versions of ordinary colour photos; but, to make it a bit harder, you have to choose a limited palette of chip colours before you see the photographs. What colours would it be best to choose? Well, you could always do a reasonable job as long as you had some chips of each of the colours: black, white, grey, red, orange, yellow, green, blue, purple, pink and brown. These 11 colours are called the Basic Colours as everyone in the world, whatever language they speak, agrees that they are the main ones. Now imagine a different, odder task. Again we have to make versions of photos, but there are two differences from the mosaic task. First, the photos are black &amp;amp; white, not colour. Second, rather than making our versions out of little featureless mosaic chips, this time we are going to use something more like jigsaw pieces. These 'jigsaw pieces' don't have the lugs that ordinary pieces have (so we can always fit them together), but they do have a little patch of image detail on them like a regular jigsaw piece. If you had enough different 'jigsaw pieces' you could probably make versions of any ordinary photo. But what if, just like in the mosaic task, you had to choose some limited set of types with which to make versions of any photo? What kinds of 'jigsaw piece' would you need? Well you'd certainly need a line, and an edge; probably a corner and a T junction; maybe two dots close together, or perhaps a little bit of shading like that distinctive pattern you get on the folds of pushed-up shirt sleeves. Remember the mosaic task, and how all that you really needed were the 11 Basic Colours? Well, when we wonder what types of jigsaw piece we need, we are trying to work out the Basic Image Features. No-one knows what they are (though a few like 'edge' and 'corner' can be guessed), nor how many there are (I guess between thirty and one hundred).So what did the mosaic and jigsaw tasks have to do with how the brain understands what the eye sees? The idea that we will test in this project is that when the brain does local analysis of the image, it uses Basic Image Features to label each little patch. These labels are then analyzed (and probably improved) by the bit of the brain that does the global analysis, but we'll leave that for another project.In the project we will find out what the Basic Image Features are, and will program computers so that they can label images with them. We've got four different ways of trying to find the Basic Image Features, and we will try all of them. If they all give the same answer, we'll know that we are on the right track; if not, it may mean our idea is wrong.We came up with the four methods that we will use by thinking about the similarity between the jigsaw (pattern) and mosaic (colour) tasks. We think the similarities between colour and pattern run very deep, but they're not easy to explain as they are to do with how similar the maths of the two things are. Since they are so similar, and since a lot more is understood about colour than pattern, we can raid colour science for ideas to use in pattern science, and that's where our 4 methods come from.</gtr:abstractText><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>289637</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>16966819-87CC-41E5-B766-DA4D31D463B7</gtr:id><gtr:title>Statistics and category systems for the shape index descriptor of local 2nd order natural image structure</gtr:title><gtr:parentPublicationTitle>Image and Vision Computing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7cca88dc5d0e3cfc4e2b7aa61a7699bf"><gtr:id>7cca88dc5d0e3cfc4e2b7aa61a7699bf</gtr:id><gtr:otherNames>Lillholm M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53cff7ff76020bd8</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ACDADFB2-1CAD-4C88-9134-3E809AEEAF0A</gtr:id><gtr:title>Symmetry sensitivities of derivative-of-Gaussian filters.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9053211afd9065f4f2da8778f2eb136"><gtr:id>a9053211afd9065f4f2da8778f2eb136</gtr:id><gtr:otherNames>Griffin LD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>doi_53d05e05ef765662</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3689C276-C357-4AD8-83FC-7D8502042F32</gtr:id><gtr:title>Using Basic Image Features for Texture Classification</gtr:title><gtr:parentPublicationTitle>International Journal of Computer Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7eb519334f56635c9018ca1a4d3d5f44"><gtr:id>7eb519334f56635c9018ca1a4d3d5f44</gtr:id><gtr:otherNames>Crosier M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53cfdefdef52684e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FD91D5AD-0581-4DEB-8D11-879F00F1AFA3</gtr:id><gtr:title>The second order local-image-structure solid.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9053211afd9065f4f2da8778f2eb136"><gtr:id>a9053211afd9065f4f2da8778f2eb136</gtr:id><gtr:otherNames>Griffin LD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>doi_53d05e05ef00558e</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D030978/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>