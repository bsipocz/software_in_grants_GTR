<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/5EFEEA9A-A081-437B-A0C8-951478FB34F7"><gtr:id>5EFEEA9A-A081-437B-A0C8-951478FB34F7</gtr:id><gtr:firstName>Darren</gtr:firstName><gtr:otherNames>Peter</gtr:otherNames><gtr:surname>Cosker</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FL013932%2F1"><gtr:id>BCC8C475-2FD8-49C6-B1BB-15ACC0B28580</gtr:id><gtr:title>Visual Image Interpretation in Humans and Machines</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/L013932/1</gtr:grantReference><gtr:abstractText>The sense of vision is so fundamental to humans that it is a largely automated process which appears to us as extremely easy. This would suggest that it should be easy to make a computer see like a human. In fact this is a very difficult task because the biological visual system is very complex; occupying about one quarter of the human brain. Human vision is both highly effective and efficient. For example it is capable of identifying around 10,000 different object categories and can learn new categories from single examples. This in achieved with a system requiring just 20 watts of power and weighing 1.4kg. No computer system can match this performance for recognition ability, learning efficiency and power consumption.

One way to devise new computer vision methods is to understand how biological visual systems work. However, the complexity of vision has made this very difficult and some researchers have concentrated their efforts on understanding biological vision while others have sought independent solutions to specific problems in computer vision. For example, humans can read car number plates but we do so using a general purpose visual system that can also read gothic script and handwriting as well as performing a host of other tasks. Building a number plate recognition system to read letters in the same general way that humans do would be difficult. However, because number plates have a certain fixed format (they are always a certain, bright, colour, and the font is always a certain style and size) building a computer vision system just to read number plates, and nothing else, is a much simpler task. 

There are some tasks that have not proved simple for computer vision and where understanding biological vision is likely to be essential to future success. One example is matching the appearance of two surfaces. Suppose you wanted to make artificial stone to look exactly like the real stones in a building. To get the recipe just right you would have to know not just the physical properties of the original stone (which probably cannot be matched exactly) but also how the human vision system is likely to perceive the stone. You can then pick a recipe that may not mimic the stone exactly but which will look just like the real stone to humans. Moreover, if you know how the visual system processes the colours and textures of surfaces you can build a computerised tool that can predict recipes automatically. 

Another area of interest is computer graphics. One way to make computer graphics look convincing is to exactly model the physics of the thing you are trying to represent. However, such rendering methods are often very time consuming and computationally expensive. Because the human visual system does not see every detail in an object it is often possible to render graphics much more quickly and effectively using perceptual rendering techniques that exploit knowledge of how the human visual system will process each scene.

Because those researchers working on biological vision tend to be from Biology and Psychology backgrounds and those who research computer vision from Computer Science and Engineering backgrounds, there is often a gap in understanding between the two groups of researchers which makes it hard for them to work together on problems such as those outlined above. The aim of this Network is to bring such researchers closer together, both physically and scientifically, so that they can identify and work together on the challenging problems where success is most likely. We will achieve this by a series of away day style meetings and conferences and by funding junior scientists and PhD students to spend time working in another lab from a different discipline.</gtr:abstractText><gtr:fund><gtr:end>2017-10-08</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2014-04-09</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>45187</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Annual ViiHM Workshop - 2014</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>CEC95D31-842C-4178-A446-D734EE3AFC26</gtr:id><gtr:impact>The ViiHM Annual meeting ran in 2014, in Stratford -upon-Avon. The event was attended by national and international academics, who networked and presented work. From this meeting, micro-workshops were organised by the community, resulting in grant applications being generated. At least one has been submitted to EPSRC.</gtr:impact><gtr:outcomeId>56dd6e79c6c2f2.29743174</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.viihm.org.uk/home/events/first-workshop/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Annual ViiHM Workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>332D1950-21A7-4BC6-84F2-8A3B566F97B8</gtr:id><gtr:impact>The workshop brought together members of the ViiHM network to share research results and discuss collaboration.</gtr:impact><gtr:outcomeId>56d0688cece6b4.79818805</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.viihm.org.uk/home/events/second-workshop/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>VIIHM 2016 Annual Workshop - leading to mini-workshops, grant submissions and exchanges.</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E62D6D15-DCDB-4A12-BF76-40C21B4F64F9</gtr:id><gtr:impact>As part of the ViiHM network, annual events are held. These include invited submissions/talks/posters from the Human and Computer Vision communities, and invited keynotes. The reach of keynotes and participants is international (although registered attendees are mostly national).
The annual workshops are the flagship ViiHM event, and are the catalyst for other activities - including mini-workshops and exchanges.
Listed below are some the outcomes where the annual event is arguably the catalyst:
Mini-workshops
- Binocular Vision, Challenges and Techniques: Ross Goutcher
- Vision for movement, a comparative approach: Paul Graham
- Statistics in Human and Machine Vision: Joshua Solomom
- Advancements in Face Research: A Conversation Between Humans and Machines:Yukun Lai
- Higher level scene understanding and application in robotic vision: Deepayan Bhowmik
- Young Vision Research Colloquium: Dave Bull
- The Social Impact of Facial Appearance: Moi Hoon Yap
- Low power and adaptive computer vision for scene understanding: Deepayan Bhowmik
Grant writing workshops
- Dynamic Faces: Representations for Animation and Perception &amp;amp; Bio-inspired models of gaze, action and reward for robotics: Alan Johnston, Darren Cosker &amp;amp; Iain Gilchrist
- Visual, thermal, near-&amp;shy;infrared, chemical and perceptual analysis of human skin for application in health, cosmetics and rendering: Marina Bloj
- The role of chromatic signals in spatial vision: Jasna Martinovic
- Illumination in Natural Scenes: Andrew Schofield
- Exploring Gaze Dynamics for Human-Machine Interactions: Farzin Deravi
- Retina Models: Sonya Coleman
- How gaze behaviour contributes to individual differences in cognitive task performance - scanpath analysis: Jinghao Xue &amp;amp; Kun Guo
- Biological Vision Inspired Dynamic 3D Acquisition and Reconstruction using Statistical Machine Learning: Yukun Lai
Exchange visits
- Perceived gloss of HDR stimuli (Wendy Adams, Psychology @ Southampton -&amp;gt; Rafal Mantiuk, Computer Science @ Bangor)
- Exploration of optimal gaze pattern in eye tracking studies using deep learning approach and its application to automatic image retrieval and object detection (Ruixuan Wang, Engineering &amp;amp; Physical Sciences @ Heriot-Watt -&amp;gt; Kun Guo, Psychology @ Lincoln)
- Active Vision with Human-in-the-Loop for the Visually Impaired (&amp;nbsp;Mr Jacobus Lock PhD student,&amp;nbsp; School of Computer Science, University of Lincoln -&amp;gt; Professor Iain Gilchrest University, School of Experimental Psychology)</gtr:impact><gtr:outcomeId>58ca557471a1a8.87513358</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>http://www.viihm.org.uk/home/events/exchanges/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Mini-Workshops and Exchanges</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>C115FC6A-41AA-4468-B32F-D91EB10BBBEF</gtr:id><gtr:impact>As part of ViiHM, mini-workshops and grant writing events were organised by the community. The following exchanges/workshops have taken place so far:
Mini-workshops

- Binocular Vision, Challenges and Techniques: Ross Goutcher
- Vision for movement, a comparative approach: Paul Graham
- Statistics in Human and Machine Vision: Joshua Solomom

Grant writing workshops

- Dynamic Faces: Representations for Animation and Perception &amp;amp; Bio-inspired models of gaze, action and reward for robotics: Alan Johnston, Darren Cosker &amp;amp; Iain Gilchrist
- Visual, thermal, near-&amp;shy;infrared, chemical and perceptual analysis of human skin for application in health, cosmetics and rendering: Marina Bloj
- The role of chromatic signals in spatial vision: Jasna Martinovic
- Illumination in Natural Scenes: Andrew Schofield
- Exploring Gaze Dynamics for Human-Machine Interactions: Farzin Deravi

Exchange visits

- Perceived gloss of HDR stimuli (Psychology @ Southampton -&amp;gt; Computer Science @ Bangor): Wendy Adams
- Exploration of optimal gaze pattern in eye tracking studies using deep learning approach and its application to automatic image retrieval and object detection (Engineering &amp;amp; Physical Sciences @ Heriot-Watt -&amp;gt; Psychology @ Lincoln): Ruixuan Wang</gtr:impact><gtr:outcomeId>56dd6ef77979e5.47465445</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.viihm.org.uk/home/events/exchanges/</gtr:url><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>ViiHM is a network of researchers who are primarily based in the UK. The network's purpose is to foster dissemination and collaboration between the Computer and Biological Vision communities. A primary part of ViiHM for this is it's annual event, and this has been the catalyst for a range of activities such as mini-workshops and exchange visits. These provide focused mechanisms for dissemination/discussion but also opportunities to discuss research projects and further funding. ViiHM has successfully fostered a range of these activities, for example: 
Mini-workshops
- Binocular Vision, Challenges and Techniques: Ross Goutcher
- Vision for movement, a comparative approach: Paul Graham
- Statistics in Human and Machine Vision: Joshua Solomom
- Advancements in Face Research: A Conversation Between Humans and Machines:Yukun Lai
- Higher level scene understanding and application in robotic vision: Deepayan Bhowmik
- Young Vision Research Colloquium: Dave Bull
- The Social Impact of Facial Appearance: Moi Hoon Yap
- Low power and adaptive computer vision for scene understanding: Deepayan Bhowmik
Grant writing workshops
- Dynamic Faces: Representations for Animation and Perception &amp;amp; Bio-inspired models of gaze, action and reward for robotics: Alan Johnston, Darren Cosker &amp;amp; Iain Gilchrist
- Visual, thermal, near-&amp;shy;infrared, chemical and perceptual analysis of human skin for application in health, cosmetics and rendering: Marina Bloj
- The role of chromatic signals in spatial vision: Jasna Martinovic
- Illumination in Natural Scenes: Andrew Schofield
- Exploring Gaze Dynamics for Human-Machine Interactions: Farzin Deravi
- Retina Models: Sonya Coleman
- How gaze behaviour contributes to individual differences in cognitive task performance - scanpath analysis: Jinghao Xue &amp;amp; Kun Guo
- Biological Vision Inspired Dynamic 3D Acquisition and Reconstruction using Statistical Machine Learning: Yukun Lai
Exchange visits
- Perceived gloss of HDR stimuli (Wendy Adams, Psychology @ Southampton -&amp;gt; Rafal Mantiuk, Computer Science @ Bangor)
- Exploration of optimal gaze pattern in eye tracking studies using deep learning approach and its application to automatic image retrieval and object detection (Ruixuan Wang, Engineering &amp;amp; Physical Sciences @ Heriot-Watt -&amp;gt; Kun Guo, Psychology @ Lincoln)
- Active Vision with Human-in-the-Loop for the Visually Impaired (&amp;nbsp;Mr Jacobus Lock PhD student,&amp;nbsp; School of Computer Science, University of Lincoln -&amp;gt; Professor Iain Gilchrest University, School of Experimental Psychology)</gtr:description><gtr:exploitationPathways>As ViiHM is focused on research culture, it has fostered new collaborations and partnerships. These are arguably as a result of ViiHM.</gtr:exploitationPathways><gtr:id>AB4A2A09-E48B-411C-BC80-4AC5709A108F</gtr:id><gtr:outcomeId>56dd70471a9a22.35784613</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Pharmaceuticals and Medical Biotechnology,Security and Diplomacy</gtr:sector></gtr:sectors><gtr:url>http://www.viihm.org.uk/home/events/exchanges/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/L013932/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>