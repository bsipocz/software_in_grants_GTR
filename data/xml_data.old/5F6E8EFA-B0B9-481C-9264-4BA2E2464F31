<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Experimental Psychology</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3F5FF400-3C1E-434C-A2E6-73F6536F2ECA"><gtr:id>3F5FF400-3C1E-434C-A2E6-73F6536F2ECA</gtr:id><gtr:firstName>Iain</gtr:firstName><gtr:otherNames>Donald</gtr:otherNames><gtr:surname>Gilchrist</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FF000464%2F1"><gtr:id>5F6E8EFA-B0B9-481C-9264-4BA2E2464F31</gtr:id><gtr:title>Bilateral Netherlands: Scanpaths when viewing faces</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/F000464/1</gtr:grantReference><gtr:abstractText>&lt;p>Human vision is an active process. The eyes move to point at a new location about every quarter of a second. This process is essential because the visual resolution of the eye is best in the centre and falls off dramatically away for the centre. One major challenge in this field is the sheer complexity of the data that the sequence of eye movements represents and in turn the need to develop methods to identify when fixation sequences are different across different situation. If such methods were available then this would open up a wealth of new possibilities for studying this looking process.&lt;/p>

&lt;p>The current proposal is a joint ESRC-NWO application under the Bilateral Agreement. This agreement allows researchers from the UK and the Netherlands to combine their expertise to address difficult research questions like this. The grant funds an investigation of eye movement behaviour when humans look at faces. &lt;/p>

&lt;p>The project is in two parts:&amp;nbsp;&lt;/p>

&lt;p>&amp;nbsp;(1) The development of a set of methods to analyse scan paths (Bristol) &lt;/p>

&lt;p>(2) applying these methods to a number of important un-answered questions in the area of eye movements during face processing (Amsterdam).&lt;/p>

&lt;p>&lt;br />&amp;nbsp;&lt;/p></gtr:abstractText><gtr:fund><gtr:end>2012-08-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2008-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>87302</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The primary output of this grant was the development of a novel approach to comparing saccadic eye movement sequences based on the Needleman-Wunsch algorithm used in bioinformatics to compare DNA sequences. In the proposed method, the saccade sequence is spatially and temporally binned and then recoded to create a sequence of letters that retains fixation location, time, and order information. The comparison of two letter sequences is made by maximizing the similarity score computed from a substitution matrix that provides the score for all letter pair substitutions and a penalty gap. The substitution matrix provides a meaningful link between each location coded by the individual letters. This link could be distance but could also encode any useful dimension, including perceptual or semantic space. We showed, by using synthetic and behavioral data, the benefits of this method over existing methods. The ScanMatch toolbox for MATLAB is freely available online (www.scanmatch.co.uk) and this work was reported in Cristino, Mathot, Theeuwes &amp;amp; Gilchrist (2010).

In a subsequent paper (Math&amp;ocirc;t, Cristino, Gilchrist &amp;amp; Theeuwes, 2012) we proposed an alternative algorithm to estimate the similarity between a pair of eye movement sequences. The proposed algorithm relies on a straight-forward geometric representation of eye movement data. The algorithm is considerably simpler to implement and complements are previous similarity measure and is particularly suited for exploratory analyses. To validate the algorithm, we conducted a benchmark experiment using realistic artificial eye movement data. Based on similarity ratings obtained from the proposed algorithm, we defined two clusters in an unlabelled set of eye movement sequences. As a measure of the algorithm's sensitivity, we quantified the extent to which these data-driven clusters matched two pre-defined groups (i.e., the 'real' clusters). The same analysis was performed using two other, commonly used similarity measures. The results show that the proposed algorithm is a viable similarity measure.



Cristino, F., Mathot, S., Theeuwes, J. &amp;amp; Gilchrist, I. D. (2010). ScanMatch: A Novel Method for Comparing Fixation Sequences. Behaviour Research Methods, 42, 692-700. 



Math&amp;ocirc;t, S., Cristino, F., Gilchrist, I. D., &amp;amp; Theeuwes, J. (2012). A simple way to estimate similarity between pairs of eye movement sequences. Journal of Eye Movement Research 5(1):4, 115.</gtr:description><gtr:id>79017B8E-B669-4194-8D0A-4F3A10B49F9D</gtr:id><gtr:outcomeId>r-6142881071.328074b2f044c2</gtr:outcomeId><gtr:sectors><gtr:sector>Education,Energy,Retail,Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>EBA6E1B5-B162-4D44-A36C-63464EDAFFEC</gtr:id><gtr:title>ScanMatch: a novel method for comparing fixation sequences.</gtr:title><gtr:parentPublicationTitle>Behavior research methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fb755d3ff38fae9ac593b28940a67074"><gtr:id>fb755d3ff38fae9ac593b28940a67074</gtr:id><gtr:otherNames>Cristino F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1554-351X</gtr:issn><gtr:outcomeId>pm_53cbfcbbfcbd7bf08</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>25A63FA7-9251-46A4-9196-31B8063182F0</gtr:id><gtr:title>Children with autism are neither systematic nor optimal foragers.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/72b9fa66f3b496d365e168f3bb4544e7"><gtr:id>72b9fa66f3b496d365e168f3bb4544e7</gtr:id><gtr:otherNames>Pellicano E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>5464b530329a82.87746073</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8869013A-209B-47A2-99D9-3FC703136390</gtr:id><gtr:title>A simple way to estimate similarity between pairs of eye movement sequences</gtr:title><gtr:parentPublicationTitle>Journal of eye movement research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c3a768d987a580c82f5949b222359085"><gtr:id>c3a768d987a580c82f5949b222359085</gtr:id><gtr:otherNames>Sebastiaan Math?t (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_5813567907cb2da308</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RES">RES-000-22-2332</gtr:identifier><gtr:identifier type="RCUK">ES/F000464/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>