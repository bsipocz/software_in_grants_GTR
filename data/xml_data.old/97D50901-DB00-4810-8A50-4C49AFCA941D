<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/E594FDB4-DD6F-441F-90D6-C423A2916446"><gtr:id>E594FDB4-DD6F-441F-90D6-C423A2916446</gtr:id><gtr:name>Manchester Metropolitan University</gtr:name><gtr:department>Sch of Computing, Maths and Digital Tech</gtr:department><gtr:address><gtr:line1>Cavendish North Building</gtr:line1><gtr:line4>Manchester</gtr:line4><gtr:postCode>M15 6BG</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E594FDB4-DD6F-441F-90D6-C423A2916446"><gtr:id>E594FDB4-DD6F-441F-90D6-C423A2916446</gtr:id><gtr:name>Manchester Metropolitan University</gtr:name><gtr:address><gtr:line1>Cavendish North Building</gtr:line1><gtr:line4>Manchester</gtr:line4><gtr:postCode>M15 6BG</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7F767D93-BDFF-49AC-A7AE-72648CC6DC2D"><gtr:id>7F767D93-BDFF-49AC-A7AE-72648CC6DC2D</gtr:id><gtr:name>Agricultural university of Hebei</gtr:name><gtr:address><gtr:line1>No. 289, Lingyusi street</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F7A0D7AB-44B7-469F-9343-ECFB957021B0"><gtr:id>F7A0D7AB-44B7-469F-9343-ECFB957021B0</gtr:id><gtr:name>Beijing Mengbangda Biotechnology Co.Ltd</gtr:name><gtr:address><gtr:line1>Room 416, Jinyanlong Building</gtr:line1><gtr:line2>Huilongguan Town</gtr:line2><gtr:line3>Changping District</gtr:line3><gtr:postCode>100096</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/75B74A3B-D602-44C9-9E1E-595ACC62B7AD"><gtr:id>75B74A3B-D602-44C9-9E1E-595ACC62B7AD</gtr:id><gtr:name>Guyuan County Potato Association</gtr:name><gtr:address><gtr:line1>Room 422, Agriculture and Industry Offic</gtr:line1><gtr:line2>Agriculture and Animal Husbandry Bureau</gtr:line2><gtr:line3>Guyuan County</gtr:line3><gtr:postCode>076550</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B2AD55AC-1C78-4EDB-9DB3-2D6D36719B36"><gtr:id>B2AD55AC-1C78-4EDB-9DB3-2D6D36719B36</gtr:id><gtr:firstName>Liangxiu</gtr:firstName><gtr:surname>Han</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FR019983%2F1"><gtr:id>97D50901-DB00-4810-8A50-4C49AFCA941D</gtr:id><gtr:title>EPIC: An automated diagnostic tool for Potato Late Blight disease detection from images</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/R019983/1</gtr:grantReference><gtr:abstractText>The yields of crop plants are deleteriously affected by various diseases. It is estimated that almost 25% of worldwide crops are lost to diseases, which may cause devastating economical, social and ecological losses. In China, as the fourth important food crop, yield losses from potato late blight diseases can vary from 20%-40% in common years. In severe cases, the yield loss may reach 50%-100%. The estimated yearly economic losses due to this disease are around $5 billion in China. Early accurate detection and identification of crop diseases plays an important role in effectively controlling and preventing diseases for sustainable agriculture and food security.

In our previous funded projects, we have developed an innovative automated machine vision system for efficient crop disease diagnosis from images, which have proven the technical feasibility of using advanced image processing, machine learning, mobile and cloud computing approaches. 

This project will take it forward and develop a near-market product ready for commercialisation, which can provide more accurate real-time information for crop disease surveillance. The tool can run on mobile devices. Farmers with basic training can perform disease diagnosis immediately. Compared to the current practices using human visual observation (which is labour intensive, costly and error-prone), this machine vision system can dramatically speed up diagnosis, and give growers more accurate information on which to base their disease control strategies and stop crop yields from being reduced by infection. This technology can overcome lack of expertise, help make a significant impact on agricultural productivity and farmer incomes, ensuring food security, and deliver highly cost-effective, long-term economic and social impact in China.

To achieve actual impact and demonstrable benefits in China, this project will work closely with Chinese partners from academia, industry and farmers including: the project partner (Hebei Agriculture University (HEBAU)), and end users (Beijing Mengbangda Biotechnology Co. Ltd (BMB) and Guyuan County Potato Association (GCPA)). They will provide support in gathering the field data, setting up trial systems and domain knowledge input from plant pathologists for local agriculture and fine tuning the systems in the fields, as well as potential commercialization of this technology in China (Hebei province initially). The project focuses on three stages of translational/user engagement: 
1) System requirement gathering from users; 
2) System evaluation with input from users; 
3) Potential impact and commercial exploitation with end users. 

The tool will be initially deployed in the real fields provided by end users (BMB and GCPA) in Hebei province at the end of project. This will help protect potato-planting area of over 380k MU initially from the disease infection with reduced annual costs on fungicide usage and damages to environment. 

Other translational activities include organization of workshops, conference attendance and paper publications, which will be used for dissemination and engagement with a wide range of user groups on a large-scale.

This project will not only develop a near-market product but will also generate a significantly measurable impact, promote long-term sustainable growth, economic development and welfare in China and beyond.</gtr:abstractText><gtr:technicalSummary>This project seeks to exploit our previous funded work, develop a near-market, automatic diagnostic machine vision tool for accurate detection of crop diseases using advanced image analysis and cloud/mobile computing approaches and deliver benefits and impact in China, with an initial focus on potato late blight (the most sever potato disease in China and worldwide). Our cloud-based machine vision system can rapidly identify the disease based on smartphone images. The farmers with only basic training can perform diagnosis immediately, with no need for experts based in the fields. In collaboration with our project partner Hebei Agriculture University (HEBAU) and end users (Beijing Mengbangda Biotechnology Co. Ltd (BMB) and Guyuan County Potato Association (GCPA)), the tool will be initially deployed in Hebei Province protecting over 380,000MU planting area. This will help make a significant impact on agricultural productivity and farmer incomes, and generate robust social and commercial impact in China.</gtr:technicalSummary><gtr:potentialImpactText>N/A according to the call document</gtr:potentialImpactText><gtr:fund><gtr:end>2019-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2018-06-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>64591</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/R019983/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5B25B6A3-B218-4F11-8A9D-661236DF455C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Agri-environmental science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>FB535BD0-E265-4C0A-8532-32DCB83A3951</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Tools, technologies &amp; methods</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>1F190F7B-B800-40B2-B250-62AD4842598F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Bioinformatics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6F3E4891-E3E8-4568-94D8-075A0552DE90</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Crop protection</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>FA4A8455-3074-48A4-B0CD-5B85D94B79F5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>eScience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>