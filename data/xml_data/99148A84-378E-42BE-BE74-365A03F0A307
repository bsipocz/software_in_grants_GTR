<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:department>Mechanical Engineering</gtr:department><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F399131D-F394-413F-9FD8-160DFEF93D35"><gtr:id>F399131D-F394-413F-9FD8-160DFEF93D35</gtr:id><gtr:name>National Nuclear Laboratory Ltd</gtr:name><gtr:address><gtr:line1>Chadwick House</gtr:line1><gtr:line2>Warrington Road</gtr:line2><gtr:line3>Birchwood Park</gtr:line3><gtr:postCode>WA3 6AE</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E21B10F0-4EAF-4915-8EB0-653CDA6263EA"><gtr:id>E21B10F0-4EAF-4915-8EB0-653CDA6263EA</gtr:id><gtr:name>JET Propulsion Laboratory</gtr:name><gtr:address><gtr:line1>Jet Propulsion Laboratory</gtr:line1><gtr:line2>4800 Oak Grove Dr</gtr:line2><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6CC26E88-0596-4ED5-87F6-E035ECF24650"><gtr:id>6CC26E88-0596-4ED5-87F6-E035ECF24650</gtr:id><gtr:firstName>Klaus D</gtr:firstName><gtr:surname>McDonald-Maier</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/A8F0EB1E-B82D-4DCA-BE2F-0F62A7EA71C2"><gtr:id>A8F0EB1E-B82D-4DCA-BE2F-0F62A7EA71C2</gtr:id><gtr:firstName>Rustam</gtr:firstName><gtr:surname>Stolkin</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9C2D8593-EA64-4918-A394-C7BCBEDC9331"><gtr:id>9C2D8593-EA64-4918-A394-C7BCBEDC9331</gtr:id><gtr:firstName>Ales</gtr:firstName><gtr:surname>Leonardis</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8901C20A-32B5-4618-9701-DE7F5FC0FEC5"><gtr:id>8901C20A-32B5-4618-9701-DE7F5FC0FEC5</gtr:id><gtr:firstName>Shoaib</gtr:firstName><gtr:surname>Ehsan</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FP017487%2F1"><gtr:id>99148A84-378E-42BE-BE74-365A03F0A307</gtr:id><gtr:title>Robust remote sensing for multi-modal characterisation in nuclear and other extreme environments</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/P017487/1</gtr:grantReference><gtr:abstractText>This project addresses the problem of &amp;quot;characterisation&amp;quot; of Extreme Environments (EE), by deploying and combining information from a variety of different Remote Sensing modalities. Our principle application area is nuclear decommissioning, however our research outputs will be relevant to other EE.

Before nuclear decommissioning interventions can happen, the facility/plant being decommissioned must be &amp;quot;characterised&amp;quot;, to understand: physical layout and 3D geometry; structural integrity; contents including particular objects of interest (e.g. fuel rod debris). 3D plant models must further be annotated with additional sensed data: thermal information; types/levels/locations of contamination (radiological, chemical etc.). Characterisation may be needed before, during or after POCO (Post Operation Clean Out). &amp;quot;Quiescent buildings&amp;quot; may be over half a century old, with uncertain internal layout and contents.

Characterisation is needed in dry environments (e.g. contaminated concrete &amp;quot;caves&amp;quot;) and wet environments (e.g. legacy storage ponds). Caves may be unlit, causing difficult vision problems (shadows, contrast, saturation) with robot-mounted spotlights. Underwater environments cause significant visibility degradation for RGB cameras, and render most depth/range sensors unusable. New technologies, e.g. acoustic cameras, engender interesting new challenges in developing algorithms to process these new kinds of image data.

In many cases, robots are needed to deploy Remote Sensors into Extreme Environments and move them to desired locations and viewing poses. In some cases, robots must also assist characterisation by retrieving samples of contaminated materials. In many case real-time Remote Sensing data must also be applied to inform and control the actions of robots, while performing remote intervention tasks in EE.

This project brings together a unique, cross-disciplinary and international team of researchers and institutes, spanning three continents, to address these challenges. End-users NNL and JAEA will advise on scenarios and challenges for Remote Sensing in nuclear environments. Active facilities at JPL will be used to measure degradation of sensors, chips and software under a variety of radiation types and doses. JPL and Essex researchers will use this data to develop new models for predicting such degradation. Essex researchers will then develop new methods for software and embedded hardware design, which overcome radiation damage by incorporating new approaches to fault detection, tolerance and recovery.

The scenarios provided by the partners, and the degradation data measured by JPL, will be used to develop new benchmark data-sets comprising data from multiple sensing modalities (RGB cameras, depth/range cameras, IR thermal imaging, underwater acoustic imaging), featuring a vairiety of nuclear scenes and objects.

UoB and Essex researchers will develop new algorithms for real-time 3D characterisation of scenes, with intelligent and adaptive fusion of multiple sensing modalities. First, new multi-sensor fusion methods will be developed for 3D modelling, semantic/meta-data labelling, recognition and understanding of scenes and objects. Second, these methods will be extended to incorporate new algorithms for overcoming extreme noise and other kinds of degradation in images and sensor data. Third, we will develop the robots and robot control methods needed to: i) deploy remote sensors into extreme environments; ii) exploit remote sensor data to guide robotic interventions and actions in these environments.

Finally, we will carry out experimental deployments of these new technologies. Robust hardware and software solutions, developed by Essex, will be tested in active radiation environments at JPL. We will also carry out experimental robotic deployments of sensor payloads into inactive but plant-representative nuclear environments at NNL Workington and the Naraha Fukushima mock-up testing facilities in Japan.</gtr:abstractText><gtr:potentialImpactText>This project directly addresses the most important and difficult RAS and Remote Sensing challengs that must be overcome to enable safe, successful and timely decommissioning of difficult legacy nuclear facilities, many of them designated as representing &amp;quot;intolerable risk&amp;quot; to the nation. 

Decommissioning and disposal of the 4.9million tons of nuclear waste in the UK, represents the largest environmental remediation project in the whole of Europe, and is projected to cost as much as &amp;pound;220billion. Much of this work can only be done by remote methods, because the high levels of radioactive material are hazardous to humans. This directly engenders fundamental challenges for Remote Sensing in Extreme Environments.

This project will therefore deliver a number of key impacts:
1) It addresses the major UK societal challenge of cleaning up intolerable domestic legacy waste sites (impacting the UK population as a whole as well as future generations).
2) It enhances UK capabilities in decommissioning, where we have internationally recognised expertise, and which open up a &amp;gt;$300billion worldwide market to the UK economy (impacting the nuclear workforce in particular, and the overall UK economy more generally).
3) RAS (Robotics and Autonomous Systems has been identified as &amp;quot;one of the 'eight great technologies' which will propel the UK to future growth&amp;quot;. This project will directly develop the Remote Sensing methods and Extreme Environment hardware designs that are needed to enable UK RAS expertise to penetrate the economically large, and societally important, market of nuclear decommissioning and remediation.
4) It is a very strong fit to the existing EPSRC portfolio, including:
i) The EPSRC DISTINCTIVE (Decommissioning, Immobilisation and Storage soluTIons for NuClear wasTe InVEntories) consortium.
ii) The EPSRC AIS (Autonomous and Intelligent Systems) program, in which the UK nuclear industry is a major stakeholder.
iii) The major characterisation and robotics component of te EPSRC UK-Korea Nuclear Program.
iv) The remote sensing, characterisation and robotics components of the EPSRC UK-Japan calls.
5) We have proposed specific pathways to impact, through:
i) the successful embedded systems start-ups of C-I McDonald-Maier;
ii) our Knowledge Transfer collaboration with the UK subsidiary of a major global industrial robotics company;
iii) our direct collaborations with nuclear end-users in UK, Europe, Korea and Japan.
Much of the new technology developed during the project can find direct route to market through these collaborations. Thus, the proposed research will directly benefit UK industry, as well as enhancing the nuclear and robotics capabilities available to end-users worldwide.
6) We have proposed significant educational outreach and public communication of science activities to run in parallel with the research, thereby directly engaging with the non-expert population, promoting public awareness of the nuclear and other EE challenges, and promoting study and career interest from young people in Remote Sensing specifically, and science and engineering more generally.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>1398052</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>29D44E77-E22E-4BD3-9679-482E46DF7CB1</gtr:id><gtr:title>Intelligent intrusion detection in external communication systems for autonomous vehicles</gtr:title><gtr:parentPublicationTitle>Systems Science &amp; Control Engineering</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8e31b56660c171f77bd72ebfa6b40422"><gtr:id>8e31b56660c171f77bd72ebfa6b40422</gtr:id><gtr:otherNames>Ali Alheeti K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa6a4cbccba30.27152406</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CF3D8E9D-E1B2-4410-A1D9-F8FF12F104B6</gtr:id><gtr:title>Performance Characterization of Image Feature Detectors in Relation to the Scene Content Utilizing a Large Image Database</gtr:title><gtr:parentPublicationTitle>IEEE Access</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c418747ff58ea46bde6ee507fe34b763"><gtr:id>c418747ff58ea46bde6ee507fe34b763</gtr:id><gtr:otherNames>Ferrarini B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa6a1f7855382.77188192</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A7950866-369F-4A3C-8C58-E4ED7D84FDF8</gtr:id><gtr:title>Robust Fusion of Color and Depth Data for RGB-D Target Tracking Using Adaptive Range-Invariant Depth Models and Spatio-Temporal Consistency Constraints.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on cybernetics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/03f36af74ec4f9850aa93b5c629d1a42"><gtr:id>03f36af74ec4f9850aa93b5c629d1a42</gtr:id><gtr:otherNames>Xiao J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2168-2267</gtr:issn><gtr:outcomeId>5a2fe6de70abd7.16856199</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>81C746D9-71ED-452E-974C-0F31B03A3484</gtr:id><gtr:title>A hierarchical detection method in external communication for self-driving vehicles based on TDMA.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3f24475719624e3b3d76d8b702cd5758"><gtr:id>3f24475719624e3b3d76d8b702cd5758</gtr:id><gtr:otherNames>Alheeti KMA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>5aa6a37f6ef8b4.03770038</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/P017487/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>F95121C7-7C31-40CE-BDBC-1E2BF025AEA6</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Energy</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>772CD758-53CD-407F-9B2C-F2B861E86155</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Mechanical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0FE8D416-B45D-49A3-928D-3B94E03E72DD</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Energy - Nuclear</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>