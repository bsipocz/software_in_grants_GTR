<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Engineering</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D1F3E892-4604-464E-800E-922FD6C84A18"><gtr:id>D1F3E892-4604-464E-800E-922FD6C84A18</gtr:id><gtr:name>Medviso AB</gtr:name><gtr:address><gtr:line1>Griffelv?gen 3</gtr:line1><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CED0B9B7-1A47-4541-89C2-00CA9E9AF8E4"><gtr:id>CED0B9B7-1A47-4541-89C2-00CA9E9AF8E4</gtr:id><gtr:name>Cedars-Sinai Medical Center</gtr:name><gtr:address><gtr:line1>8700 Beverley BI #8211</gtr:line1><gtr:postCode>90048</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/46ED08F0-E9D0-41C7-A6D4-05C44A2F0B3D"><gtr:id>46ED08F0-E9D0-41C7-A6D4-05C44A2F0B3D</gtr:id><gtr:firstName>Sotirios</gtr:firstName><gtr:surname>Tsaftaris</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FP022928%2F1"><gtr:id>A05F2031-9E53-49EB-9CE1-54A431A2D8BE</gtr:id><gtr:title>CardiacA.I.: Machine learning for the analysis of multimodal cardiac MR images used in the diagnosis of coronary heart disease</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/P022928/1</gtr:grantReference><gtr:abstractText>A sedentary lifestyle, poor diet, smoking, and genetic and other health factors are major contributors to coronary heart disease (CHD). Despite recent medical advances that have lowered the number of deaths compared to the past decades, CHD still remains the number 1 disease in mortality in the UK (73,000 deaths per year) with a tremendous economic burden: estimates put the cost to UK's economy at &amp;pound;6.7 billion per year. The overriding goal of this project is to take advantage of multimodal information within cardiac magnetic resonance images to improve their analysis and facilitate the diagnosis and improve treatment of CHD.

Magnetic Resonance Imaging (MRI) as an imaging diagnostic tool is uniquely positioned to help as it is non-invasive and does not use radiation. A typical cardiac protocol relies on several MR imaging sequences to provide images of different contrast, termed as modalities hereafter, to assess disease progression and status. As a result of this range of acquisitions, hundreds of multidimensional multimodal images are generated in a single patient exam leading to severe data overload. 

Therefore, robust and automated analyses algorithms would help alleviate the clinical reading burden. Several algorithms have been proposed to segment and register the myocardium in the most commonly used modalities by considering them independently. However, the problem remains difficult and performance is not yet adequate. Currently, the analysis of cardiac imaging data still remains a manual, time consuming, and expensive process typically performed by clinical experts. As a result, despite the huge amount of data generated, not only in a clinical but also in a research setting, only a fraction is being analysed robustly, due to the vast amount of time required for the analysis of this data.

This proposal aims to address the above shortcomings by proposing mechanisms that take advantage of the shared information that exists across modalities to enable the jint analysis of cardiac imaging data and thus make a significant leap in how we approach their analysis. We propose new multimodal machine learning driven mechanisms to learn image features (i.e. how local image information is represented for an algorithm to use) that do not change between imaging modalities whilst preserving shared anatomical information. We will then use the learned features in multimodal patch-based myocardial segmentation and inter-modality non-linear registration (i.e. the non-linear registration between two images coming from different cardiac MR sequences) thus enabling us to relate images of the same patient across different modalities. To maximise impact, we will develop an inter-modality cardiac registration plugin for a commercial clinical package that is also offered as an open source variant for academic purposes. 

We expect that when our complete framework is integrated into clinical tools and becomes widely available it can radically change current clinical reading workflow and decision-making. It will permit the propagation of annotations across multimodal images of a patient exam effortlessly and seamlessly, thus significantly reducing reading time and permitting the analysis of cardiac data on a larger scale.</gtr:abstractText><gtr:potentialImpactText>This interdisciplinary project combines our knowhow in machine learning, image processing and medical image analysis to solve an important societal and health challenge: the diagnosis of Coronary Heart Disease (CHD) on the basis of MRI images. We propose a new concept on how to represent images in order to facilitate the analysis of cardiac data and ultimately, alleviate the efforts required by clinicians to render a diagnosis and guide treatment.

In the UK alone more than 73,000 deaths per year are attributed to CHD. This demonstrates a significant psychological burden to the patients and their families. Not only that, but CHD is truly expensive. According to the British Heart Foundation the cost to UK's economy is close to &amp;pound;6.7 billion/year. This not only affects the NHS (27% direct NHS burden) but the economy overall directly (47% productivity loss has been considered) and also indirectly due to cost of immediate support and informal care of patients by their families or support circle (another 26%). MRI offers unique diagnostic information that is repeatable (being non-invasive and non-ionizing) and can thus be used to diagnose, stratify and treat (by follow-up) patients and alleviate the above psychological and economic cost. Thus, even the general patient population will have direct interest in our developed tools in improving cardiac analysis. By translating our methods to the clinic and in linking with and informing the public (by liaising and collaborating with Chest Heart &amp;amp; Stroke Scotland), we aim to cultivate this interest and maximize the benefit to the patient population.

Naturally, clinicians working in cardiac MRI from a research perspective would also benefit. For example, MRI is the imaging modality of choice for the UK Biobank: a &amp;pound;92M investment and currently the world's largest health imaging study (100k people). Image and data analysis tools to analyze this enormous repository of data automatically are still lacking and this project directladdresses this national need. For this project we will collaborate directly with clinicians but we will also liaise with several local clinician networks interested in these problems.

Since clinicians do rely on software to read images, we will collaborate with an SME, that develops a clinical cardiac analysis software platform, to translate one of the algorithms developed within this project. The exchange of knowhow with industry and particular small enterprises is a key industrial exploitation of the work carried here. The company will benefit by introducing a new plugin that solves a critical clinical problem: inter-modality cardiac registration. Clinical users will save time and produce more robust outcomes when using this plugin. As a result, it will create added value to the customer (and the SME). Plugins developed for the software are available as open source to further the development of new tools since also the software is open source (for academic use). Our plugin, and the corresponding algorithm, can certainly be used to inspire new developments by similar companies throughout the world. 

Our methods deal with an important problem: relating images of different context and contrast in MRI such that we can unravel common information, but be resilient to nuisance factors. We propose machine learning methods, that build upon new developments in deep learning, that are able to discern useful from meaningless information. This is an important problem, in medical image analysis and in general. As a result, finding good solutions to it will have a direct impact to researchers working on multimodal data and aiming to find common patterns across them for whatever the application domain. The expected impact and uptake from the research will be maximised by publishing in top journals and conference proceedings, via our international collaborations, and by sharing code on our website.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>100903</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/P022928/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>