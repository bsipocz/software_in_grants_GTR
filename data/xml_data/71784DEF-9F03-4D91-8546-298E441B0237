<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:department>Sch of Life Sciences</gtr:department><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/113AB417-F607-4F2F-9367-870B6E7E1A05"><gtr:id>113AB417-F607-4F2F-9367-870B6E7E1A05</gtr:id><gtr:firstName>Marina</gtr:firstName><gtr:surname>Bloj</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG055289%2F1"><gtr:id>71784DEF-9F03-4D91-8546-298E441B0237</gtr:id><gtr:title>Feasibility study - The coloured brain: a photorealistic virtual model of living brain tissue</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G055289/1</gtr:grantReference><gtr:abstractText>Although cadaver dissection is widely accepted as being the 'gold standard' for anatomy education, its availability and usage is decreasing due to financial and ethical pressures. Even for those with access to cadaveric-based training, they find that the differences between the colour and appearance of living tissues that may be observed in the operating theatre are vastly different from what they first observed with the dead tissues of a cadaver. Their anatomy knowledge must therefore adapt to the reality of their working environment. Digital anatomy tools can provide a partial alternative to cadavaric-based training. One of the limitations here, however, is that grey scale or pseudo colour are typically used when rendering the anatomy as 3D models. Although we can attempt to use colours that more closely match that of real tissues, or maybe a texture map, it is difficult to reproduce an exact match of the colours and shading of living tissues. In computer graphics a technique that can be used for photorealistic rendering is to apply a bidirectional reflectance distribution function (BRDF), which is a 4-dimensional function that defines how light is reflected at an opaque surface. BDRFs have not yet been extensively applied to digital anatomy models.The aim of this feasibility study is to develop and pilot techniques that will allow us to significantly improve the quality of virtual anatomy teaching tools by incorporating the appearance of live tissues. It will bring together the research expertise in computer modelling and material capture as well as access to operating theatre and teaching forum. We propose to combine the knowledge and technological achievements of two labs to realise this unusual collaboration: Marina Bloj is a colour scientist with a background in physics; Nigel John is an established expert with over 15 years experience in medical virtual environments and data visualisation. This collaborative project will allow us to integrate techniques from these two groups for the first time and establish the platform for future extended collaborative projects.</gtr:abstractText><gtr:fund><gtr:end>2010-04-01</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-11-02</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>23364</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We conclude that using a carefully obtained BRDF (which only has to be acquired once) to create images of the brain's surface increases the images' realism. To obtain the parameters that we used for the BRDF renderings, visit http://medical-imaging.org.uk/cbrain.</gtr:description><gtr:exploitationPathways>Developing more realistic model for medical training.</gtr:exploitationPathways><gtr:id>AD06070A-2D08-4994-B0F4-F4B3A426F5C6</gtr:id><gtr:outcomeId>56cc4dc0460840.60576192</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors><gtr:url>http://medical-imaging.org.uk/cbrain</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>8BF0FAC3-2B29-47CD-B293-696D9284E27E</gtr:id><gtr:title>Visualizing the surface of a living human brain.</gtr:title><gtr:parentPublicationTitle>IEEE computer graphics and applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cebf509ffbeba4073ae64310f435a9b6"><gtr:id>cebf509ffbeba4073ae64310f435a9b6</gtr:id><gtr:otherNames>ap Cenydd L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0272-1716</gtr:issn><gtr:outcomeId>doi_53d05b05b7fcd49a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A6E6BD8D-297D-4A53-8470-DB660FB60322</gtr:id><gtr:title>Realistic visualization of living brain tissue.</gtr:title><gtr:parentPublicationTitle>Studies in health technology and informatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cebf509ffbeba4073ae64310f435a9b6"><gtr:id>cebf509ffbeba4073ae64310f435a9b6</gtr:id><gtr:otherNames>ap Cenydd L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0926-9630</gtr:issn><gtr:outcomeId>58c7f36f0aa479.43166846</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9EA1CB42-2C3C-4F52-8599-453243F43E1C</gtr:id><gtr:title>Why do coloured filters improve vision?</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a36daa994b2daa4229e2c674b18d9e9d"><gtr:id>a36daa994b2daa4229e2c674b18d9e9d</gtr:id><gtr:otherNames>Walter A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>54621f556c7165.72676637</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G055289/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>