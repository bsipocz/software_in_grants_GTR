<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/4AC4427C-1C27-4665-9256-F5448806A637"><gtr:id>4AC4427C-1C27-4665-9256-F5448806A637</gtr:id><gtr:name>Maastricht University (UM)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D50C3B58-FF77-4BB1-B965-C0CF5BDF7F8B"><gtr:id>D50C3B58-FF77-4BB1-B965-C0CF5BDF7F8B</gtr:id><gtr:name>Italian Institute of Technology (Istituto Italiano di Tecnologia IIT)</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/7DB68CCC-DD52-4CCA-AFFF-13BADAE898FB"><gtr:id>7DB68CCC-DD52-4CCA-AFFF-13BADAE898FB</gtr:id><gtr:name>University of Geneva</gtr:name><gtr:address><gtr:line1>University of Geneva</gtr:line1><gtr:line2>30 Quai Ernest-Ansemet</gtr:line2><gtr:postCode>CH-1211</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Switzerland</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/617E7220-F6C8-489B-991E-AFD367E83A93"><gtr:id>617E7220-F6C8-489B-991E-AFD367E83A93</gtr:id><gtr:name>Aix-Marseille University</gtr:name><gtr:address><gtr:line1>Aix-Marseille University</gtr:line1><gtr:line2>Pharo</gtr:line2><gtr:line4>Marseille</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/AE58F21F-3622-4382-97BB-1359BD183E9F"><gtr:id>AE58F21F-3622-4382-97BB-1359BD183E9F</gtr:id><gtr:name>University of Glasgow</gtr:name><gtr:department>College of Medical, Veterinary &amp;Life Sci</gtr:department><gtr:address><gtr:line1>University Avenue</gtr:line1><gtr:line4>Glasgow</gtr:line4><gtr:postCode>G12 8QQ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AE58F21F-3622-4382-97BB-1359BD183E9F"><gtr:id>AE58F21F-3622-4382-97BB-1359BD183E9F</gtr:id><gtr:name>University of Glasgow</gtr:name><gtr:address><gtr:line1>University Avenue</gtr:line1><gtr:line4>Glasgow</gtr:line4><gtr:postCode>G12 8QQ</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4AC4427C-1C27-4665-9256-F5448806A637"><gtr:id>4AC4427C-1C27-4665-9256-F5448806A637</gtr:id><gtr:name>Maastricht University (UM)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D50C3B58-FF77-4BB1-B965-C0CF5BDF7F8B"><gtr:id>D50C3B58-FF77-4BB1-B965-C0CF5BDF7F8B</gtr:id><gtr:name>Italian Institute of Technology (Istituto Italiano di Tecnologia IIT)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/78308CAA-8483-45C0-A280-0AB4B6AD9D35"><gtr:id>78308CAA-8483-45C0-A280-0AB4B6AD9D35</gtr:id><gtr:name>Medical Research Council</gtr:name><gtr:address><gtr:line1>Polaris House</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:postCode>SN2 1FL</gtr:postCode><gtr:region>South West</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7DB68CCC-DD52-4CCA-AFFF-13BADAE898FB"><gtr:id>7DB68CCC-DD52-4CCA-AFFF-13BADAE898FB</gtr:id><gtr:name>University of Geneva</gtr:name><gtr:address><gtr:line1>University of Geneva</gtr:line1><gtr:line2>30 Quai Ernest-Ansemet</gtr:line2><gtr:postCode>CH-1211</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Switzerland</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/617E7220-F6C8-489B-991E-AFD367E83A93"><gtr:id>617E7220-F6C8-489B-991E-AFD367E83A93</gtr:id><gtr:name>Aix-Marseille University</gtr:name><gtr:address><gtr:line1>Aix-Marseille University</gtr:line1><gtr:line2>Pharo</gtr:line2><gtr:line4>Marseille</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/06706DF4-EA2A-4E30-9F6B-67019B7A478D"><gtr:id>06706DF4-EA2A-4E30-9F6B-67019B7A478D</gtr:id><gtr:firstName>Joachim</gtr:firstName><gtr:surname>Gross</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/BA1958FA-5D03-43A8-8CB2-469390168B8A"><gtr:id>BA1958FA-5D03-43A8-8CB2-469390168B8A</gtr:id><gtr:firstName>Philippe</gtr:firstName><gtr:otherNames>Georges</gtr:otherNames><gtr:surname>Schyns</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/B808525F-AE46-4CAB-8422-5C4C4853D0E9"><gtr:id>B808525F-AE46-4CAB-8422-5C4C4853D0E9</gtr:id><gtr:firstName>Bruno</gtr:firstName><gtr:otherNames>Lucio</gtr:otherNames><gtr:surname>Giordano</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FM009742%2F1"><gtr:id>07BCE782-C2C9-4498-A403-B9229CEC742C</gtr:id><gtr:title>The neural representation of vocal emotion: representational similarity analysis and information-theoretic approaches</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M009742/1</gtr:grantReference><gtr:abstractText>Recognizing and interpreting emotions in other persons is crucial for social interactions. In particular, people of all cultures are able to recognize emotions in vocalizations without speech such as laughs, cries or screams of fear. But how our brain analyses emotion in voices remains poorly understood, compared to how we perceive emotion in faces, for example.
In this project we bring together several expert co-investigators and external collaborators to address two new streams of unanswered questions on the way our brain processes emotional information in voice. We will use several complementary neuroimaging techniques to measure cerebral activity with the best precision currently possible, and advanced analysis techniques to ask two main series of questions:
(1) Does the brain processes emotions as different categories (e.g., fear, anger, pleasure) or rather as a continuum emotions each characterized by different amount of activation (arousal) or how negative/positive the expression is (valence)?
(2) How do different nodes of the oscillatory network of brain regions responsible for analysing emotion in voice interact with one another? Do they share information between nodes in a synergistic way, or is there redundancy between the different nodes? And if yes, how, where and when is emotional information combined to arrive at the recognition of a specific emotion?
The results from this project will bring important new knowledge on how the normal brain works, with longer-term impact on the treatment and diagnosis of communication disorders and the development of better neural prostheses such as cochlear implants. The project will also contribute to consolidating and preserving UK's leading position in advanced neuroscience research.</gtr:abstractText><gtr:technicalSummary>A growing number of studies have contributed to an increasingly detailed picture of the network of cerebral regions involved in this task. Yet, the exact nature of information processing at the different nodes of the network and their associated representations remain largely unexplored.
In this project we bring together several expert co-investigators and external collaborators to address two new streams of unanswered questions on the way our brain processes emotional information in voice. We will use several complementary neuroimaging techniques to measure cerebral activity with the best precision currently possible, and advanced analysis techniques to ask two main sets of questions:
(1) How does the representation of the emotional stimuli evolve from acoustical-based at early levels of processing to more emotion-based allowing conscious emotional categorization at higher processing stages?
(2) How do different nodes of the oscillatory network of brain regions responsible for analysing emotion in voice interact with one another? Do they share information between nodes in a synergistic way, or is there redundancy between the different nodes? And if yes, how, where and when is emotional information combined to arrive at the recognition of a specific emotion?
To address question 1, we propose to use Representational Similarity Analysis (RSA) as a powerful framework for bringing together multiple types of measures (acoustical, perceptual, cerebral) and models (computational, theoretical) in a comprehensive evaluation of representations at different stages of cerebral processing.
To address question 2, We propose to use novel information-theoretic methods to first individuate network nodes and oscillatory components of activity carrying affective information, then to assess whether combinations of those information-bearing elements carry affect information that cannot possibly obtained by a single element alone (synergy).</gtr:technicalSummary><gtr:potentialImpactText>Outside of academia, the research is likely to have positive impact on several user groups in the longer term. Person with auditory perception deficits, such as cochlear implant patients and persons with hearing aids experience difficulties recognizing affective states in voice, with negative impact on their social interactions. As good social interactions are a primary determinant of healthy ageing, contributing to a better perception of affective states is likely to have positive outcomes on interactions and quality of life in older populations. Unfortunately, manufacturers of hearing aids and cochlear implants have largely concentrated so far on enhancing speech intelligibility - for obvious reasons. But other, socially-central aspects of vocal communication, such as the detection and recognition of affective states, have been comparatively neglected. The research we conduct in normal participants has the potential to be translated into clinical practice by providing mechanisms to enhance algorithms for auditory decoding in cochlear implants, or optimizing training and rehabilitation strategies. We have experience enhancing the impact of our work through links with industry. We have had funded collaborations with France -Telecom and with Cochlear, one of the leading cochlear implant manufacturers, and this research could lead to further similar collaborations in the longer term. 
Another potential pathway to impact in this research is to develop links with the growing industry of 'social computing'. Our results have the potential to be of interest for designers of software for automated extraction of affective states. Automated recognition of speech is now at a commercial stage, but automated recognition of affective states for more socially rewarding human-computer interactions is still poor. Information on the solutions to this problem found by our brain over millions of years of evolution could potentially give important clues to the design of more parsimonious, and especially more robust to degradation, recognition systems. Links will the industry in this domain will be specifically sought for with assistance from the Research and Enterprise office e at university of Glasgow.
Another important user group potentially affected by the research is the wider public. There is an enormous public and media interest in the voice and social interactions. Therefore we have had in general an excellent response to our activities to engage the public in our work. The laboratory has engaged with the public at several occasions such as at the Glasgow Science Centre during Brain Awareness Week. In addition to publishing in academic journals and presenting at Scientific Conferences, we engage with the press to improve the impact of our findings. The PI has received specific training with the media thanks to the BBSRC-organized Media Training Course, which has been instrumental in enhancing the profile of the laboratory's research (several journal and radio appearances in the past year, including the Sunday Telegraph and BBC4). 
Finally, the research will have an important impact on the career of Drs Emilie Salvia and Bruno Giordano. Both will greatly enhance their knowledge, CV and visibility as part of the project and would be in a competitive position on the academic market at the end of the grant period.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2015-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>743155</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>MRC Cognition and Brain Sciences Unit</gtr:department><gtr:description>Optimization of sound stimulation system for MEG</gtr:description><gtr:id>92D88AB2-EF90-42E1-BF04-EDBCA797FD51</gtr:id><gtr:impact>Optimized sound stimulation system for MEG</gtr:impact><gtr:outcomeId>56dff522eb00d8.92155772-1</gtr:outcomeId><gtr:partnerContribution>Provided new components of audio stimulation system</gtr:partnerContribution><gtr:piContribution>Provided measurements of frequency response of audio stimulation system in Glasgow</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Italian Institute of Technology (Istituto Italiano di Tecnologia IIT)</gtr:collaboratingOrganisation><gtr:country>Italy, Italian Republic</gtr:country><gtr:description>Development of information theoretic methods</gtr:description><gtr:id>A1D179E2-3A42-4B7F-BA55-2FBEA0DABA8A</gtr:id><gtr:impact>Novel methods for quantifying mutual information, redundancy and synergy in MEG and fMRI data</gtr:impact><gtr:outcomeId>56dff5d4973913.31764063-1</gtr:outcomeId><gtr:partnerContribution>Development of information theoretic methods for analysis of fMRI and MEG data</gtr:partnerContribution><gtr:piContribution>Development of information theoretic methods for analysis of fMRI and MEG data</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Medical Research Council (MRC) Centre Cambridge</gtr:department><gtr:description>Grant collaborations</gtr:description><gtr:id>CA58CF54-2076-4F3C-A5C9-77E205A8C968</gtr:id><gtr:impact>There is an EBR paper that has resulted from the grant (listed in output). We are still in the phase of collecting essential data before we will start with the analysis.</gtr:impact><gtr:outcomeId>56dee3d571cb64.18174475-2</gtr:outcomeId><gtr:partnerContribution>Partners bring essential world-leading expertise to the project. Specifically, expertise in analysing data (cambridge, IIT) and expertise in the neuroscientific aspects of the project (Marseille, Maastricht, Geneva).</gtr:partnerContribution><gtr:piContribution>We are leading the collaboration that is part of our grant. Collaborators are Co-Is or collaborators on the grant. We are providing most of the data and supervise the RAs on the project.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Medical Research Council (MRC)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>MRC Cognition and Brain Sciences Unit</gtr:department><gtr:description>RSA methods development</gtr:description><gtr:id>52A07795-75E9-428C-B080-952C7B39FA67</gtr:id><gtr:impact>Data analysis methods; refinement of acquisition protocols for fMRI data.</gtr:impact><gtr:outcomeId>56dff4a1486740.71113492-1</gtr:outcomeId><gtr:partnerContribution>Development of methods for the multivariate analysis of fMRI and MEG data</gtr:partnerContribution><gtr:piContribution>Development of methods for the multivariate analysis of fMRI and MEG data</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Geneva</gtr:collaboratingOrganisation><gtr:country>Switzerland, Swiss Confederation</gtr:country><gtr:description>Grant collaborations</gtr:description><gtr:id>8E9F5387-A331-4319-8E97-BE66C177AC39</gtr:id><gtr:impact>There is an EBR paper that has resulted from the grant (listed in output). We are still in the phase of collecting essential data before we will start with the analysis.</gtr:impact><gtr:outcomeId>56dee3d571cb64.18174475-5</gtr:outcomeId><gtr:partnerContribution>Partners bring essential world-leading expertise to the project. Specifically, expertise in analysing data (cambridge, IIT) and expertise in the neuroscientific aspects of the project (Marseille, Maastricht, Geneva).</gtr:partnerContribution><gtr:piContribution>We are leading the collaboration that is part of our grant. Collaborators are Co-Is or collaborators on the grant. We are providing most of the data and supervise the RAs on the project.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Aix-Marseille University</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>Grant collaborations</gtr:description><gtr:id>909D4AD2-CE11-4A05-A906-FABECA319E78</gtr:id><gtr:impact>There is an EBR paper that has resulted from the grant (listed in output). We are still in the phase of collecting essential data before we will start with the analysis.</gtr:impact><gtr:outcomeId>56dee3d571cb64.18174475-1</gtr:outcomeId><gtr:partnerContribution>Partners bring essential world-leading expertise to the project. Specifically, expertise in analysing data (cambridge, IIT) and expertise in the neuroscientific aspects of the project (Marseille, Maastricht, Geneva).</gtr:partnerContribution><gtr:piContribution>We are leading the collaboration that is part of our grant. Collaborators are Co-Is or collaborators on the grant. We are providing most of the data and supervise the RAs on the project.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Maastricht University (UM)</gtr:collaboratingOrganisation><gtr:country>Netherlands, Kingdom of the</gtr:country><gtr:description>Grant collaborations</gtr:description><gtr:id>402A52FE-BB6A-4092-8670-594953B31E27</gtr:id><gtr:impact>There is an EBR paper that has resulted from the grant (listed in output). We are still in the phase of collecting essential data before we will start with the analysis.</gtr:impact><gtr:outcomeId>56dee3d571cb64.18174475-3</gtr:outcomeId><gtr:partnerContribution>Partners bring essential world-leading expertise to the project. Specifically, expertise in analysing data (cambridge, IIT) and expertise in the neuroscientific aspects of the project (Marseille, Maastricht, Geneva).</gtr:partnerContribution><gtr:piContribution>We are leading the collaboration that is part of our grant. Collaborators are Co-Is or collaborators on the grant. We are providing most of the data and supervise the RAs on the project.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Aix-Marseille University</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>Development of materials and methods for study of cortical processing of vocal affect</gtr:description><gtr:id>A5C993CA-4796-433D-9A48-93C3126CC5CD</gtr:id><gtr:impact>Experimental protocol and software for implementing them.</gtr:impact><gtr:outcomeId>56dff9ec0f7790.13016301-1</gtr:outcomeId><gtr:partnerContribution>Sound stimuli. Experimental design.</gtr:partnerContribution><gtr:piContribution>Acquisition of pilot behavioral and neuroimaging data. Optimization of sound stimuli. Experimental design.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Italian Institute of Technology (Istituto Italiano di Tecnologia IIT)</gtr:collaboratingOrganisation><gtr:country>Italy, Italian Republic</gtr:country><gtr:description>Grant collaborations</gtr:description><gtr:id>6881A96F-901C-4089-A998-3960427F2CE8</gtr:id><gtr:impact>There is an EBR paper that has resulted from the grant (listed in output). We are still in the phase of collecting essential data before we will start with the analysis.</gtr:impact><gtr:outcomeId>56dee3d571cb64.18174475-4</gtr:outcomeId><gtr:partnerContribution>Partners bring essential world-leading expertise to the project. Specifically, expertise in analysing data (cambridge, IIT) and expertise in the neuroscientific aspects of the project (Marseille, Maastricht, Geneva).</gtr:partnerContribution><gtr:piContribution>We are leading the collaboration that is part of our grant. Collaborators are Co-Is or collaborators on the grant. We are providing most of the data and supervise the RAs on the project.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Talk: Institut de Neurosciences de la Timone, Marseille, France</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>B0B12072-59EA-4E7C-87BB-179E27F062F4</gtr:id><gtr:impact>Presentation of grant results.</gtr:impact><gtr:outcomeId>58bec713c35255.59791640</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk: Institut de Neurosciences des Syst?mes, Marseille, France</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>7019789D-57AF-4A48-8D60-6F4669554E2F</gtr:id><gtr:impact>Presentation of project results.</gtr:impact><gtr:outcomeId>58bec7735c7583.47892742</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk:  Institute for Computer Music and Sound Technology, Zurich University of the Arts, Zurich, Switzerland</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D44A0CEC-340E-4230-9A8F-FB57CE16C8EA</gtr:id><gtr:impact>Presentation of research results at a workshop on musical practice. Extended debates about research methods in experimental psychology.</gtr:impact><gtr:outcomeId>56dff8c9b488b2.93146349</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk:  Institut de Recherche et Coor- dination Acoustique/Musique (STMS-IRCAM-CNRS), Paris, France</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>85CEBDFB-EF06-479A-B052-CDEDF27529B2</gtr:id><gtr:impact>Presentation of research results at a CNRS center that groups psychologists, acousticians, sound engineers and artists focusing on sound. Discussion of research directions in the field of auditory perception and neuroscience.</gtr:impact><gtr:outcomeId>56dff7924f5f95.19508786</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talks</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>4923DAA2-94EA-4091-8B29-FF6797D2B105</gtr:id><gtr:impact>Preliminary outcomes from this grant were presented in four different talks reaching postgraduates and other scientists. 
These are the talks:

Joachim Gross
Presentation at MEG UK conference 2015
Seminar Talk at UCL, London 2015
Seminar Talk in Geneva, 2015

Bruno Giordano
Seminar Talk in Nottingham, 2016</gtr:impact><gtr:outcomeId>56def45a650e32.58002813</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>MEG UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>22D71094-2187-4788-8CBA-8FCADD4EE121</gtr:id><gtr:impact>Talk at national conference (MEG UK)</gtr:impact><gtr:outcomeId>58c2758339c544.56249453</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Royal Society of Medicine</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>1FC2B3C9-F1B5-48A9-803E-D60B4440F567</gtr:id><gtr:impact>Prof Joachim Gross presented at the joint Royal Society of Medicine/Institute of Engineering &amp;amp; Technology event on 6th May 2015 that included industry representatives, practitioners and scientists. 

I was contacted after the presentation to give a talk at another University and to collaborate in a grant application.</gtr:impact><gtr:outcomeId>56def71858b159.98159405</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk: NIHR Nottingham Hearing Biomedical Research Unit, Nottingham, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>0C33A471-BAF5-4FC4-94B2-C1673A369D49</gtr:id><gtr:impact>Presentation of research results to students and staff of NIHR and MRC centers in Nottingham involved in the health care sector (hearing deficit patients such as cochlear implant -- CI -- patients). Discussion of research directions in auditory perception and neuroscience. Discussion with staff about improvements to ongoing research in CI patients.</gtr:impact><gtr:outcomeId>56dff85659f163.72635585</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Zurich</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>3A8D81A2-F3BD-4295-9126-7E9CB4E882B3</gtr:id><gtr:impact>Workshop for postgraduate students</gtr:impact><gtr:outcomeId>58c275c9524934.52399126</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Over several months of dedicated work we have acquired a unique dataset that consists of brain responses to morphed emotional voicing in the same set of participants recorded with different brain imaging methods (fMRI, MEG, EEG). The functional brain data is complemented with behavioural data. This data will be used to investigate the processing of emotional stimuli in the brain especially with respect to the question if these stimuli are processed along continuous dimensions (valence, arousal) or categorical (by emotional categories). 
We have already fully characterised the behavioural response (paper is written and we will submit soon).
We have also developed the fMRI and MEG analysis pipeline using state-of-the-art representational similarly analysis (that involved new methods development and validation). Our first results indicate that categorical models explain MEG data better at early time points following stimulus onset than continuous models.This is a key finding that we are currently testing. the corresponding paper is in preparation.</gtr:description><gtr:exploitationPathways>Our results will be published in the near future and will allow to derive new hypothesis that can be experimentally tested. Also, the analysis pipeline is novel and will be of interest to others.</gtr:exploitationPathways><gtr:id>A99C8696-8702-44DB-B3C2-237E575EFEBF</gtr:id><gtr:outcomeId>56dffee9905ac3.58539410</gtr:outcomeId><gtr:sectors><gtr:sector>Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>A large database comprising data from 10 individuals each participating in 4 fMRI, 4 MEG and 3 behavioral sessions part of a study on the cortical/perceptual processing of emotions in vocal communication.</gtr:description><gtr:id>4A951F4F-5588-43A0-8E2A-3F5222CD9746</gtr:id><gtr:impact>We plan to publish the database at the end of the project.</gtr:impact><gtr:outcomeId>58becda8895308.59299648</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Multimodal MEG/fMRI dataset on encoding of vocal emotions.</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>Design of information-theoretic pipeline for the whole-brain network analysis of stimulus encoding in fMRI and MEG data.</gtr:description><gtr:id>69CAF599-84D8-49CA-931C-F9D1AFAF50DC</gtr:id><gtr:impact>Likely impact on community researching brain stimulus encoding at large.</gtr:impact><gtr:outcomeId>58becd0bcf78b8.94787311</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Design of whole-brain information-theoretic network pipeline</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type></gtr:researchMaterialOutput><gtr:researchMaterialOutput><gtr:description>Design and implementation of pipeline for the statistical analysis of fMRI and MEG data based on Representational Similarity Analysis (RSA) methods.</gtr:description><gtr:id>B00A270D-6C09-430D-A81B-1BD260480A69</gtr:id><gtr:impact>The state-of-the art pipeline will be available to additional projects beyond the current one. Portions of the improvements are being shared with the community of developers of open-source software for the analysis of brain imaging data.</gtr:impact><gtr:outcomeId>58beca21d35cc5.64462632</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Design and implementation of RSA pipeline</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B430201F-2DBA-4AA0-B98E-4619DF9C0B22</gtr:id><gtr:title>The dominance of haptics over audition in controlling wrist velocity during striking movements.</gtr:title><gtr:parentPublicationTitle>Experimental brain research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/62ff4b6acab0144776379ca37646bdc0"><gtr:id>62ff4b6acab0144776379ca37646bdc0</gtr:id><gtr:otherNames>Cao Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0014-4819</gtr:issn><gtr:outcomeId>56dee12524d715.47695644</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5D2D91BB-B9E0-4529-A96C-1BC7A6252B84</gtr:id><gtr:title>A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula.</gtr:title><gtr:parentPublicationTitle>Human brain mapping</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/339bb3b877cac9698849f38a0abddae3"><gtr:id>339bb3b877cac9698849f38a0abddae3</gtr:id><gtr:otherNames>Ince RA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1065-9471</gtr:issn><gtr:outcomeId>58ac5cd87e41a6.87708453</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>18A33830-37D4-415C-BB84-82A75E24AA53</gtr:id><gtr:title>From categories to dimensions: spatio-temporal dynamics of the cerebral representations of emotion in voice</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4356cfb27c4092926116c71e87f5e171"><gtr:id>4356cfb27c4092926116c71e87f5e171</gtr:id><gtr:otherNames>Giordano B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a9d5444afcde2.31745153</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E5078030-CC0E-4A88-A942-BE36C3628CFB</gtr:id><gtr:title>The Role of Semantic Context in Early Morphological Processing.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f8bc4628848a3ec0dfbd0f0371fc8a32"><gtr:id>f8bc4628848a3ec0dfbd0f0371fc8a32</gtr:id><gtr:otherNames>Whiting CM</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn><gtr:outcomeId>5a2fcc6fa18a90.81193796</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>61CFF355-1339-4628-837C-DA0E3DD1D917</gtr:id><gtr:title>Contributions of local speech encoding and functional connectivity to audio-visual speech perception.</gtr:title><gtr:parentPublicationTitle>eLife</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/847137823aa4a5a3be74fd867ce3e64d"><gtr:id>847137823aa4a5a3be74fd867ce3e64d</gtr:id><gtr:otherNames>Giordano BL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>2050-084X</gtr:issn><gtr:outcomeId>5a2fcc17ca4981.34520865</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E552E2AB-CA93-482F-AA01-3F13E2B46573</gtr:id><gtr:title>Vibrotactile Sensitivity in Active Touch: Effect of Pressing Force.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on haptics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/badce0a3cd2b72b2b83ac1bc7ba1d329"><gtr:id>badce0a3cd2b72b2b83ac1bc7ba1d329</gtr:id><gtr:otherNames>Papetti S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1939-1412</gtr:issn><gtr:outcomeId>585d3bb28f27a9.67371428</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M009742/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>56C9394E-9F52-4433-9619-6A14493473A8</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Social Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>