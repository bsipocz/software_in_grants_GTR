<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/68D0E3C9-9246-4CFC-B5E9-48584CF82993"><gtr:id>68D0E3C9-9246-4CFC-B5E9-48584CF82993</gtr:id><gtr:name>University of Manchester</gtr:name><gtr:address><gtr:line1>Oxford Road</gtr:line1><gtr:city>Manchester</gtr:city><gtr:postCode>M13 9PL</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/ECA91D9A-32DC-4828-A45C-DEB92B0515F2"><gtr:id>ECA91D9A-32DC-4828-A45C-DEB92B0515F2</gtr:id><gtr:name>Napper3D</gtr:name><gtr:address><gtr:line1>Napper3D</gtr:line1><gtr:line2>Image House</gtr:line2><gtr:line3>17 Carliol  Square</gtr:line3><gtr:line4>Newcastle Upon Tyne</gtr:line4><gtr:postCode>NE1 6UQ</gtr:postCode><gtr:region>North East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CC8A44C3-ACE7-4A20-9DBB-0B8C5BBC9E4C"><gtr:id>CC8A44C3-ACE7-4A20-9DBB-0B8C5BBC9E4C</gtr:id><gtr:name>Anyhere Software</gtr:name><gtr:address><gtr:line1>Anyhere Software</gtr:line1><gtr:line2>1200 Dartmouth St</gtr:line2><gtr:line4>Albany</gtr:line4><gtr:line5>CA</gtr:line5><gtr:postCode>94706-2358</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/98E13920-053D-4784-B87D-60D66F1C29ED"><gtr:id>98E13920-053D-4784-B87D-60D66F1C29ED</gtr:id><gtr:firstName>Mashhuda</gtr:firstName><gtr:surname>Glencross</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/3ABB0AA1-1D8C-4E72-8372-B7E8F3C143F3"><gtr:id>3ABB0AA1-1D8C-4E72-8372-B7E8F3C143F3</gtr:id><gtr:firstName>Roger</gtr:firstName><gtr:surname>Hubbold</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/595701C2-F8F8-4A9F-8975-228842840FEA"><gtr:id>595701C2-F8F8-4A9F-8975-228842840FEA</gtr:id><gtr:firstName>Toby</gtr:firstName><gtr:surname>Howard</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD069734%2F1"><gtr:id>E02DFCC0-530C-4611-85F8-9B23DA512965</gtr:id><gtr:title>Case for support : Perceptually Realistic Environments for Architectural Planning and Visual Impact Assessment</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D069734/1</gtr:grantReference><gtr:abstractText>Computer-generated high-fidelity augmented reality visualisations ofproposed architectural developments can play a significant role inhelping a viewer understand the visual impact on the environment,especially in sensitive locations. Such interactive visualisations havethe potential to greatly improve both the initial design process, and thesubsequent planning application and public consultation processes. Thecurrent lack of robust automatic methods for acquisition of site contextgeometry, together with the performance demands of producinghigh-fidelity renderings in real-time, has meant the adoption of suchtechniques within the architectural industry has, to date, been limited.The proposed research represents a unique confluence of computer vision,high-fidelity rendering, and real-time 3D augmented reality techniques,only possible through the combination of strengths of the partners. Thenovel techniques we will develop in the areas of automaticreconstruction from wide-baseline images, image-based lighting, andreal-time global illumination, will be scoped by the demands of a realarchitectural application with our industrial partner Napper Architects,and English Heritage. Our techniques will be informed by the stringentfidelity requirements of a mixed-reality application suited to providingvisual impact assessment for sensitive developments.The research plan comprises four work packages which will be integratedto deliver a prototype demonstrator system which will support: theautomatic creation of an accurate 3D computer model of the developmentsite, interactive experimentation with different design and lightingscenarios, and interactive exploration by the general public of thevisual impact of the proposed development. The system will beextensively validated at a number of stages throughout the project usinga combination of comparisons with still images, video footage,ground-truth data and public consultation. During the lifetime of thisproject, our industrial partner Napper Architects will be engaged in asmall and defined sensitive architectural project with English Heritage.Models and data from these will be made available as a test case. Inaddition to the novel research outcomes, and prototype software fromthis project, we will develop new fidelity metrics for the benefitof the architectural, planning, and consultation communities.</gtr:abstractText><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>356142</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>737A3979-E9DB-4FA0-BD8C-7D7348253D35</gtr:id><gtr:title>A perceptually validated model for surface depth hallucination</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/44761f233f257126318720668739bb35"><gtr:id>44761f233f257126318720668739bb35</gtr:id><gtr:otherNames>Glencross M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53d0740742c5c423</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D069734/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>