<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/A0A585E0-6B0D-4643-A3A6-47943B4CBFEF"><gtr:id>A0A585E0-6B0D-4643-A3A6-47943B4CBFEF</gtr:id><gtr:name>University of Liverpool</gtr:name><gtr:department>Institute of Psychology Health &amp; Society</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line2>Abercromby Square</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L69 3BX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A0A585E0-6B0D-4643-A3A6-47943B4CBFEF"><gtr:id>A0A585E0-6B0D-4643-A3A6-47943B4CBFEF</gtr:id><gtr:name>University of Liverpool</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line2>Abercromby Square</gtr:line2><gtr:line4>Liverpool</gtr:line4><gtr:postCode>L69 3BX</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/493308FC-AE1F-41FD-A444-97283B338D9E"><gtr:id>493308FC-AE1F-41FD-A444-97283B338D9E</gtr:id><gtr:name>OPTIS</gtr:name><gtr:address><gtr:line1>ZE La Farlede</gtr:line1><gtr:line2>60 Rue Parmentier</gtr:line2><gtr:region>Outside UK</gtr:region><gtr:country>France</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E768F048-1280-4724-BD0B-4D7E7660F8B4"><gtr:id>E768F048-1280-4724-BD0B-4D7E7660F8B4</gtr:id><gtr:name>3dMD Ltd</gtr:name><gtr:address><gtr:line1>40 Occam Road</gtr:line1><gtr:line2>The Surrey Reserach Park</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7YG</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5181E770-0402-4759-A692-BCEA172030C9"><gtr:id>5181E770-0402-4759-A692-BCEA172030C9</gtr:id><gtr:name>Spectromatch Ltd</gtr:name><gtr:address><gtr:line1>Units F266/7</gtr:line1><gtr:line2>Riverside Business Centre</gtr:line2><gtr:line3>Haldane Place</gtr:line3><gtr:postCode>SW18 4UQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/96693118-FA39-4298-9DE0-D0A579CB01E7"><gtr:id>96693118-FA39-4298-9DE0-D0A579CB01E7</gtr:id><gtr:name>Fripp Design Limited</gtr:name><gtr:address><gtr:line1>Advanced Manuafcaturing Park</gtr:line1><gtr:postCode>S60 5WG</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2E32E3D5-2BB3-4D69-ACBC-BFD49D4A1B6E"><gtr:id>2E32E3D5-2BB3-4D69-ACBC-BFD49D4A1B6E</gtr:id><gtr:name>Sony Computer Entertainment Europe</gtr:name><gtr:address><gtr:line1>Sony Computer Entertainment</gtr:line1><gtr:line2>15 Great Marlborough Street</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W1F 7HR</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/9AC0DE93-32AA-4EC4-B04D-7199FF477553"><gtr:id>9AC0DE93-32AA-4EC4-B04D-7199FF477553</gtr:id><gtr:firstName>Christopher</gtr:firstName><gtr:otherNames>John</gtr:otherNames><gtr:surname>Sutcliffe</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/AC0D2AFC-75D2-416E-986E-70CE17263448"><gtr:id>AC0D2AFC-75D2-416E-986E-70CE17263448</gtr:id><gtr:firstName>kaida</gtr:firstName><gtr:surname>xiao</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D33F271E-AB1B-4DC6-89EF-7B32A0459463"><gtr:id>D33F271E-AB1B-4DC6-89EF-7B32A0459463</gtr:id><gtr:firstName>Sophie</gtr:firstName><gtr:otherNames>M</gtr:otherNames><gtr:surname>Wuerger</gtr:surname><gtr:orcidId>0000-0003-0080-5813</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FK040057%2F1"><gtr:id>9AA7D210-B2B9-4072-B319-D8D1E3F695DF</gtr:id><gtr:title>MEASURING AND REPRODUCING THE 3D APPEARANCE OF HUMAN FACIAL SKIN UNDER VARYING ILLUMINATION CONDITIONS: A 3D IMAGING SYSTEM FOR HUMAN FACIAL SKIN</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K040057/1</gtr:grantReference><gtr:abstractText>Understanding human skin appearance is a subject of great interest in science, medicine and technology. In medicine, skin appearance is a vital factor in surgical/prosthetic reconstruction, medical make-up/tattooing and disease diagnosis. The production of facial prostheses to replace missing facial structures requires the skills of highly trained anaplastologists to correctly match the shape and colour of the prosthesis to that of the host skin. With the 3D printing of human skin now available the process involved in matching natural and manufactured skin samples has become essential; a robust, accurate and efficient imaging system is required that acquires the relevant skin information and predicts a good match and translates this information through this new and innovative manufacturing process. 

A major problem with manufactured skin is that the match to the individual's natural skin must hold not only be accurate under a particular ambient illumination but the match needs to be preserved when the individual is moving between different environments, e.g. when the individual moves from office or LED lighting into daylight. To achieve this illumination invariance, the physical properties of the skin need to be taken into account. A further requirement for successful skin reproduction is the development of appearance models. These can be considered as individual &amp;quot;recipes' or 'blueprints&amp;quot; for each skin type and these not only represent inter-personal differences - different ethnic groups and age ranges, but also intra-personal differences - for each individual. Features of the human skin (wrinkles, pores, freckles, spots etc) make human skin as individual as a finger prints and thus, for facial prosthetics applications, skin appearance models also need to be fine-tuned for each individual area. 

The purpose of this work is to develop a complete spectral-based 3D imaging system which will allow us to additively manufacture soft tissue prosthetics or deliver predictable tattooing techniques that will exactly match the skin colour of a particular individual (Application 1) or have the capability to rapidly manufacture/3D print soft tissue replacements representative of a particular ethnic/age/gender group with a high degree of accuracy (Application 2). In application 1, the input to this 3D imaging system will consist of a 3D colour skin image (of a particular individual) obtained with a 3D camera in conjunction other specific skin characteristics. The skin sample will then be printed using a printer profile that maximises the match between the natural and printed skin across different ambient illuminations. In application 2, the skin manufacturing process will not be fine-tuned for a particular individual, but input to the 3D imaging system will consist of basic information about the age, gender and ethnicity. Representative skin samples (colour; texture; translucency; geometry) for this group will then be loaded from a pre-computed library instead of using the measurements from an individual.</gtr:abstractText><gtr:potentialImpactText>1. Healthcare provision for general population: In medicine, skin appearance is a vital factor in surgical/prosthetic reconstruction, medical make-up/tattooing, disease diagnosis (e.g. skin cancer) and evaluation of phototherapy. 
2. Individualised health care: With 3D printing of skin on the horizon (see quotation and supporting statement from Fripp Design &amp;amp; Research), a robust and quick method to predict the appearance of skin prostheses is essential. With the knowledge gained in this project the skin manufacturing processes (traditional or new) can be tailored to individual patients to allow for colour shifts that occur during the production of facial prostheses. Quantitative colour models will allow clinicians to understand and improve predictions of colour changes that occur in donor tissues following reconstructive procedures. It may also allow for tissue selection based of predictive colour/aesthetic outcomes rather than solely on operator preference or &amp;quot;ease of harvest&amp;quot;. These could be tailored to patient specific requirements and outcomes.
3. Cosmetic Industry: The aesthetic relevance of skin appearance has led to an enormous investment in skin research, mostly for make-up development and cosmetic surgery. Accurate models of skin appearance, particularly under a change in ambient illumination, is vital for the production of skin make-up and will therefore support the UK economy.
4. Entertainment industry: The advent of new lighting technologies (LEDs) and image capture/projection systems generates new challenges for rendering skin on displays and this project will help developers in the entertainment industry to improve the rendering of human faces (see the attached supporting statement from SONY) 
5. National Security/Government: Computer vision systems for people tracking and face recognition used in national security applications rely on realistic skin appearance models. With the advent and continued evolution of high definition security/CCTV camera systems on the horizon, colour recognition as well as geometric recognition models will be vitally important.
6. CIE requirements: The CIE (Commission Internationale de l'Eclairage) is an international organisation that is active in all professional matters related to light, lighting and image technology. While the CIE cannot be a project partner, Professor Mike Pointer (CIE, Division I; see supporting letter) will provide his expertise on the acquisition process of the skin spectra and RGB images, which will then feed into the CIE committee on skin data bases (Reporter: KX, the co-investigator). Via the CIE the data bases will be made available for bench marking purposes to the computer vision and lighting/engineering community. 
7. Lighting, Engineering and Virtual Reality applications: Accurate rendering or simulation of human faces under different viewing conditions relies on satisfactory spectral reconstruction algorithms for facial skin and on a knowledge of the perceptual tolerance to skin tone and texture distortions. The outcome of this project will therefore benefit these emerging industries (see the attached supporting letter from OPTIS). 
8. Prosthetics industry: The Skin colour database and spectral reconstruction techniques of skin colour from digital camera images is essential for skin colour formulation used in the prosthetics industry. The outcome of this project will therefore benefit these industries (see supporting letter from SpectroMatch) 
9. Public Engagement Activities. After the successful completion of the proposed research we intend to put on a 3-months-long installation at the World Museum in Liverpool. Visitors will be able to have their 3D face picture taken and then manipulated. They will be able to manipulate their 3D facial image by making their skin look younger or older, change their skin texture, and view their face using the skin colour and texture of a different ethnicity.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>350357</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Colour group meeting, London, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C3259ABE-9EEE-436D-9972-B828D207BDDE</gtr:id><gtr:impact>Talk on the &amp;quot;The colour of skin&amp;quot;</gtr:impact><gtr:outcomeId>56dd9a93372318.55138205</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Meeting with Sensor City</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>992275BF-0E3A-4FB3-A117-43D175E21E35</gtr:id><gtr:impact>Engagement with SensorCity, a joint adventure between the University of Liverpool and the LJMU. We presented aspects of our work that could benefit from new sensor technology: 3D scanning of faces with higher precision than current commercial systems provide.</gtr:impact><gtr:outcomeId>58c7cc134d12b0.34069052</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>YES keynote lecture (Porto)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>F1613108-C47D-4CDF-A16B-FCA8885B596B</gtr:id><gtr:impact>YES keynote talk was given by Professor Yates, Manchester, who is a collaborator on this grant.

The YES meeting is a meeting for under- and postgraduate medical students. Our talk was about novel innovative healthcare technology and was well received.</gtr:impact><gtr:outcomeId>5460c0f9e9bd11.22624334</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Health professionals</gtr:primaryAudience><gtr:url>http://yesmeeting.org/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Attendance at EPSRC-funded Viihm workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>788C9943-5615-4933-BC61-5829A31ABF46</gtr:id><gtr:impact>We presented our work on skin appearance at an EPSRC-funded workshop [Chauhan, Wang, Yin, Xiao, Yates, Li &amp;amp; Wuerger (2014). Modelling Skin Appearance. Poster presented at the EPSRC workshop on Visual Image Interpretation in Humans and Machines (Viihm), Stratford-upon-Avon, Sep 24-25, 2014.].

As a result we have now submitted a proposal for funding for a specific workshop to explore possible applications of skin measurement in innovative healthcare technologies.</gtr:impact><gtr:outcomeId>5460a9eb304bb9.00045055</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>media interest (skin project)</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>BA87F616-D3A8-4BE6-BE9F-3E2EA5CC9F88</gtr:id><gtr:impact>2013-14 Various interviews with international radio and TV channels, e.g. Kurzweil; Premedia Broadcasting South Africa; polish and dutch radio channels.

After the various press releases numerous interviews were requested from media around the world. Several researches and health professionals indicate interest in further collaborations. These links are currently being pursued.

http://scienceofsingularity.com/tag/noses/; http://www.engineering.com/3DPrinting/3DPrintingArticles/ArticleID/6728/Natural-Looking-3D-Printed-Skin.aspx; http://phys.org/news/2013-11-natural-looking-3d-printed-skin.html; http://www.technology.org/2013/11/28/developing-convincing-3d-printed-skin/; etc.</gtr:impact><gtr:outcomeId>5460ba796eb580.47750330</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.technology.org/2013/11/28/developing-convincing-3d-printed-skin/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>22000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC Impact Acceleration Account</gtr:description><gtr:end>2017-03-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>JXR12276</gtr:fundingRef><gtr:id>9E2170BF-2247-4933-8D23-6EEA05155109</gtr:id><gtr:outcomeId>58a1db80f1ce69.78034476</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-03-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The project started in October 2013 and will be finishing end of April 2017. 

We have made contact with two local hospitals who have shown an interest in further collaboration in this research area (Alderhey; Whiston). 

We have also managed to forge close links with a 3DLifePrint, a provider for 3D printing application for healthcase. 3DLifePrint is now sponsoring a doctoral student to work jointly at the University of Liverpool and Alderhey Hospital on the mechanical properties of additively manufactured skin.</gtr:description><gtr:firstYearOfImpact>2017</gtr:firstYearOfImpact><gtr:id>DE453C95-5598-48FB-8EFC-25402E25DCC6</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5460cf13d58e33.16851721</gtr:outcomeId><gtr:sector>Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>To date, we have achieved the following:

(1) a systematic colorimetric characterisation of skin colours for different ethnicities (Xiao et al. , 2016a, 10.1111/srt.12295). We are still working on the age- and gender-specific analysis. The data base of colorimetric skin values has been made publicly available.

(2) The development of a novel spectral reconstruction algorithm (Xiao et al, 2016b; 10.1364/OE.24.014934 ) which enables us to obtain multispectral 3D facial images from RGB camera images. A reliable and efficient method to reconstruct skin spectra from camera images is a valuable tool for many healtcare applications, not only the additive manufacture of skin but also for the diagnosis of diseases including diabetes, cancer etc.

(3) We have determined the tolerance limits for the appearance of skin changes under different illumination conditions (Chauhan et al, 2017; JoV). This will allow us to predict whether a prostethics will appear sufficiently similar to natural skin when seen under different ambient viewing conditions. 

(4) We have optimised the printer calibration procedure for the 3D printing of prostheses and evaluated the quality of the printed prostheses for different skin types (Xiao, et al., 2016c; DOI: 10.5772/63339). We have also evaluated the appearance of the skin prosthetics under different illumination conditions (Daylight, office light, etc) using a colour appearance model and found that the appearance of the printed prosthetics is fairly invariant with the prevailing illumination (Sohaib et al, 2017; JoV).</gtr:description><gtr:exploitationPathways>We expect our findings to be used by 3DLifePrint, a company specialising in the additive manufacture of prosthetics. During the course of the this project, we have developed close contacts with 3DLifePrint who provide the interface to Alderhey Hospital (Liverpool) for us, hence facilitating impact in healthcare and the NHS.</gtr:exploitationPathways><gtr:id>F46430BE-5C62-4260-8F06-2389559FC267</gtr:id><gtr:outcomeId>5460d01dacc057.59323408</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Manufacturing, including Industrial Biotechology</gtr:sector></gtr:sectors><gtr:url>https://www.liverpool.ac.uk/psychology-health-and-society/staff/sophie-wuerger/research/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This is a data base containing the spectral measurements of a large skin sample, associated with the following publication:
Improved method for skin reflectance reconstruction from camera images (Journal article)
Xiao, K., Zhu, Y., Li, C., Connah, D., Yates, J. M., &amp;amp; Wuerger, S. (2016). Improved method for skin reflectance reconstruction from camera images. Optics Express, 24(13), 14934. doi:10.1364/OE.24.014934
DOI: 10.1364/OE.24.014934</gtr:description><gtr:id>33037A52-B8F6-4013-90B8-989F91331D55</gtr:id><gtr:impact>we expect this data base in conjunction with the publication to be used for benchmarking.</gtr:impact><gtr:outcomeId>58a1de8cd829f0.73171439</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Data base for spectral measurements</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://pcwww.liv.ac.uk/~sophiew/data/skindatabaseSpectra.zip</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>This is a large data base (~1000) of skin measurements for four different ethnicities (Caucasian, Chinese, Thai, Kurdish). The colorimetric values are provided (LAB space) for each observer and for 9 different body locations</gtr:description><gtr:id>E9672210-304D-4B0C-A9B3-17200506C897</gtr:id><gtr:impact>It will hopefully be used other researchers for modelling purposes.
Our own research group has used it to evaluate the quality of 3D printed prosthethics (Amano et al, JoV 2017; draft available).</gtr:impact><gtr:outcomeId>58a1dda506af61.37675354</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CIELAB skin data (colorimetric)</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://pcwww.liv.ac.uk/~sophiew/data/skindatabaseLAB.zip</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>This is a data base containing camera images and spectral measurements of human facial skin. 
Skin colour measurements were performed on over 500 subjects in three countries with a view to establishing a new skin colour database and improving our understanding of skin colour in different racial populations. Measurements were obtained in the following groups: Caucasians-, Chinese-, and Kurdish population. Skin colour appearance, skin colour distribution, skin colour variation and skin colour boundaries were investigated, and quantitative comparisons between three ethnics groups were made. The results demonstrated that, in general, there was a clear trend for Chinese and Kurdish skin to be darker and more yellow when compared to Caucasian skin. However, large skin colour boundary overlaps were present, thus indicating that on some occasions differences in skin colour cannot easily be distinguished between the three ethnics groups. It was also found that compared to other ethnic groups, Caucasians has the largest variation in skin tones, whereas Chinese have the least skin colour variation.</gtr:description><gtr:id>F8ADE793-7917-41A2-A9E1-D3BFDEE79F87</gtr:id><gtr:impact>Data collection is still ongoing. At the end it will be use by the CIE and made available to the general public.</gtr:impact><gtr:outcomeId>5460a6678eff22.50387699</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>CIE skin data base</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>We have developed a new algorithm to reconstruct the spectral reflectance distribution of human skin from a calibrated RGB camera image. This reconstruction method may be useful for many other healthcare applications, e.g. to diagnose diabetes, jaundice or other diseases that results in subtle skin tone changes</gtr:description><gtr:id>680808FE-2F2D-46E4-AB04-FE334D450AA4</gtr:id><gtr:impact>N/A</gtr:impact><gtr:outcomeId>58c7d21a11b1c0.22520941</gtr:outcomeId><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>Spectral Reconstruction Algorithm</gtr:title><gtr:type>Model of mechanisms or symptoms - human</gtr:type><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>CFA91830-1B07-48F7-BA95-2B628F3E350E</gtr:id><gtr:title>New Trends in 3D Printing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b09841d98ce7a008b261eb565a9b5e5"><gtr:id>4b09841d98ce7a008b261eb565a9b5e5</gtr:id><gtr:otherNames>Xiao K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:isbn>978-953-51-2479-5</gtr:isbn><gtr:outcomeId>58a1d6e367e6d8.84941736</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5675AA9D-6ACB-4D6C-AA69-C2FEAE1EAAF7</gtr:id><gtr:title>Conference Paper</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/355b62d037f4e8b7338c0ddb2858a004"><gtr:id>355b62d037f4e8b7338c0ddb2858a004</gtr:id><gtr:otherNames>Xiao, K.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5460a4c5019a87.26834143</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BF91D489-E4B0-41A1-A7A4-CC7E782A933E</gtr:id><gtr:title>Characterising the variations in ethnic skin colours: a new calibrated data base for human skin.</gtr:title><gtr:parentPublicationTitle>Skin research and technology : official journal of International Society for Bioengineering and the Skin (ISBS) [and] International Society for Digital Imaging of Skin (ISDIS) [and] International Society for Skin Imaging (ISSI)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b09841d98ce7a008b261eb565a9b5e5"><gtr:id>4b09841d98ce7a008b261eb565a9b5e5</gtr:id><gtr:otherNames>Xiao K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0909-752X</gtr:issn><gtr:outcomeId>585d4420bf3ef1.65982233</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2F7AA354-2978-4E70-BE93-1CAE228599A0</gtr:id><gtr:title>Colour quality of facial prostheses in additive manufacturing</gtr:title><gtr:parentPublicationTitle>The International Journal of Advanced Manufacturing Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f5cb9a29dbca049607c2d02d8fab7729"><gtr:id>f5cb9a29dbca049607c2d02d8fab7729</gtr:id><gtr:otherNames>Sohaib A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5aa7aaeadd3cc1.67805298</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6F8E498A-CB44-469E-A36E-EF4D20F77F8B</gtr:id><gtr:title>A colour image reproduction framework for 3D colour printing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b09841d98ce7a008b261eb565a9b5e5"><gtr:id>4b09841d98ce7a008b261eb565a9b5e5</gtr:id><gtr:otherNames>Xiao K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>58c7c773b98c55.62790897</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6568FBCE-DACF-4BC7-B4D5-AC2A6C53F97C</gtr:id><gtr:title>Developing a 3D Colour Reproduction System for Additive Manufacturing of Facial Prostheses</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/355b62d037f4e8b7338c0ddb2858a004"><gtr:id>355b62d037f4e8b7338c0ddb2858a004</gtr:id><gtr:otherNames>Xiao, K.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>541c4092b2b100.06350888</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2AB93DDF-703D-4A67-8101-5B5F9F7F9853</gtr:id><gtr:title>Encyclopedia of Color Science and Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5822aae981ae04a335aec2b69d2b60a9"><gtr:id>5822aae981ae04a335aec2b69d2b60a9</gtr:id><gtr:otherNames>Wuerger S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56dd901ed7dc05.26917738</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>88C01477-D738-42BB-BB52-5757CB8705E8</gtr:id><gtr:title>Unique hue data for colour appearance models. Part III: Comparison with NCS unique hues</gtr:title><gtr:parentPublicationTitle>Color Research &amp; Application</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b09841d98ce7a008b261eb565a9b5e5"><gtr:id>4b09841d98ce7a008b261eb565a9b5e5</gtr:id><gtr:otherNames>Xiao K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>541c42a89b85a1.85618137</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0F9FBCF4-5E88-47D9-B255-EFD2BCA182CD</gtr:id><gtr:title>The achromatic locus: effect of navigation direction in color space.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7ca2c5b3d852361f4bd9079a7843b8d8"><gtr:id>7ca2c5b3d852361f4bd9079a7843b8d8</gtr:id><gtr:otherNames>Chauhan T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>541c420ea22579.84388234</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E07D4CEC-FDB7-449C-9521-5B96152B1FE0</gtr:id><gtr:title>Improved method for skin reflectance reconstruction from camera images.</gtr:title><gtr:parentPublicationTitle>Optics express</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b09841d98ce7a008b261eb565a9b5e5"><gtr:id>4b09841d98ce7a008b261eb565a9b5e5</gtr:id><gtr:otherNames>Xiao K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1094-4087</gtr:issn><gtr:outcomeId>58a1d741ae72b9.06014797</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>23E0F368-5DD8-460F-8295-751CBCFAEC5B</gtr:id><gtr:title>Limitations of visual gamma corrections in LCD displays</gtr:title><gtr:parentPublicationTitle>Displays</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7fd7341651bffc83ce3d9faaa877cc2"><gtr:id>d7fd7341651bffc83ce3d9faaa877cc2</gtr:id><gtr:otherNames>Alejandro Parraga C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>541c42a9edda41.97676456</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B656B51C-8C97-4A13-AB8F-C5B1819BFD43</gtr:id><gtr:title>Modelling colour appearance : applications in skin image perception</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e7c177137fea4dda3248f5c6f1367549"><gtr:id>e7c177137fea4dda3248f5c6f1367549</gtr:id><gtr:otherNames>Chauhan T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>5aaaa85ea2fdd0.84729060</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K040057/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>