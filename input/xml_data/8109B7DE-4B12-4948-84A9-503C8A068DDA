<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/B2FB30E9-4CB4-4DB6-963E-98B3FEAFE794"><gtr:id>B2FB30E9-4CB4-4DB6-963E-98B3FEAFE794</gtr:id><gtr:name>Smart Surgical Appliances Limited</gtr:name><gtr:address><gtr:line1>INCUBATOR UNIT BESSEMER BUILDING IMPERIAL COLLEGE , PRINCE CONSORT ROAD</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>SW7 2BP</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:typeInd>P</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B2FB30E9-4CB4-4DB6-963E-98B3FEAFE794" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:type="gtr:organisationParticipantRole"><gtr:id>B2FB30E9-4CB4-4DB6-963E-98B3FEAFE794</gtr:id><gtr:name>Smart Surgical Appliances Limited</gtr:name><gtr:address><gtr:line1>INCUBATOR UNIT BESSEMER BUILDING IMPERIAL COLLEGE , PRINCE CONSORT ROAD</gtr:line1><gtr:city>LONDON</gtr:city><gtr:postCode>SW7 2BP</gtr:postCode><gtr:region>London</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PARTICIPANT</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_PARTICIPANT</gtr:name></gtr:role></gtr:roles><gtr:offerGrant>99991.0</gtr:offerGrant><gtr:projectCost>343375.0</gtr:projectCost></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6BAA32D3-0592-4662-8707-B8FF49287B99"><gtr:id>6BAA32D3-0592-4662-8707-B8FF49287B99</gtr:id><gtr:firstName>Unknown</gtr:firstName><gtr:otherNames>Unknown</gtr:otherNames><gtr:surname>Unknown</gtr:surname><gtr:roles><gtr:role><gtr:name>PROJECT_MANAGER</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=710188"><gtr:id>8109B7DE-4B12-4948-84A9-503C8A068DDA</gtr:id><gtr:title>SmartShadow</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>GRD Proof of Concept</gtr:grantCategory><gtr:grantReference>710188</gtr:grantReference><gtr:abstractText>Minimally invasive surgery (MIS) or ?keyhole surgery? is one of the most significant
developments in the field of medicine in recent history, gaining widespread acceptance across
many surgical disciplines. However, surgeons learning and performing MIS procedures are
faced with a unique set of challenges. The main challenge in MIS is the use of a video image
to view the patients internal anatomy or operative field. Drawbacks associated with the use of
video imaging include loss of depth vision due to the image being 2-D. The loss of depth
vision has been shown to lead to impaired performance in surgical tasks. Generally, there is
always a demand for surgery to become safer and reducing these vision constraints would
help significantly. Improving depth perception, facilitating instrument navigation, and
manoeuvring in MIS should be a priority.
Although advances in camera technology aim to improve depth perception, such systems have
limitations with respect to their use, as they tend to be expensive and not widely available.
For these reasons, it is useful to investigate other alternatives for conveying depth information
in MIS. It is well known that monocular cues i.e. perspective, relative size, can provide
adequate depth information for the performance of most MIS tasks. One of the primary
monocular cues is shadow but due to the arrangement of the camera (endoscope) and light
source used, shadow is missing in MIS rendering the operative scene shadowless. We are
proposing to further the development of our ?SmartShadow? system that introduces a faint
secondary light source into the operative field that casts a weak shadow of the surgical
instruments that is invisible to the human eye but detectable by a computer. The computer
detects the faint shadow then enhances it to create a digital shadow, which it then introduces
into the video image to be viewed by the surgeon to aid depth perception to facilitate and
enhance performance of surgical tasks.</gtr:abstractText><gtr:fund><gtr:end>2013-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/E18E2F0F-AC7D-4E02-9559-669F7C8FEC74"><gtr:id>E18E2F0F-AC7D-4E02-9559-669F7C8FEC74</gtr:id><gtr:name>Innovate UK</gtr:name></gtr:funder><gtr:start>2012-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>99991</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">710188</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>