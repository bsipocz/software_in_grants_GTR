<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.ukri.org:80/organisation/2A7C28CF-9DDC-46BD-8D6F-97E1671789CC"><gtr:id>2A7C28CF-9DDC-46BD-8D6F-97E1671789CC</gtr:id><gtr:name>NANOMATION LTD</gtr:name><gtr:address><gtr:line1>Butler House</gtr:line1><gtr:line2>177-178 Tottenham Court Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W1T 7NY</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/EAAD4D43-BD15-432B-9385-2DBD0C65958D"><gtr:id>EAAD4D43-BD15-432B-9385-2DBD0C65958D</gtr:id><gtr:name>University of Bath</gtr:name><gtr:address><gtr:line1>University of Bath</gtr:line1><gtr:line2>Claverton Down</gtr:line2><gtr:line4>Bath</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BA2 7AY</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2A7C28CF-9DDC-46BD-8D6F-97E1671789CC"><gtr:id>2A7C28CF-9DDC-46BD-8D6F-97E1671789CC</gtr:id><gtr:name>NANOMATION LTD</gtr:name><gtr:address><gtr:line1>Butler House</gtr:line1><gtr:line2>177-178 Tottenham Court Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W1T 7NY</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/7B3C0C16-DEA3-4C5B-8405-10907BB3B6C8"><gtr:id>7B3C0C16-DEA3-4C5B-8405-10907BB3B6C8</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:otherNames>Maxwell</gtr:otherNames><gtr:surname>Hall</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD064155%2F1"><gtr:id>C4C7672E-E0D5-4E81-AC2E-77F1991E29E3</gtr:id><gtr:title>3D Computer Vision for NPR from images and video</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D064155/1</gtr:grantReference><gtr:abstractText>Imagine a camera that could take photographs that looked like paintings. Some modern video cameras already allow this - I have such a camera. The software built into it traces over photographs to yield painterly effects that look like an oil painting, or a watercolour, or any of the many media available to commerical systems.But now, instead of just tracing, imagine a camera that is able to rotate objects so they are painted from new points of view, and even render different parts of the same object from different points of view. This camera can enhance the three-dimensional nature of objects by making marks that line-up with curves on it, and can even enhance prominent features by making them bigger still. And more, this camera works not just on still images but on moving images too, enabling cartoon-like effects - cartoon cars that really burn the road!This 3D-painting camera would allow you to snap your own old Masters, such as Van Eyck, who deliberately broke the rules of perspective to draw attention to what was going on in his pictures. Newer Masters like Matisse who liked to tilt and twist the objects as he painted them; and yet newer Masters like Hockney who has made a recent habit of painting by compositing photographs taken from different views. It would allow you to really bring out the shape of an object, shading it the way Durer once did. And it would allow you to create your own cartoons, complete with streak-lines, squash-and-stretch effects and dust-clouds, all in three-dimensions for the first time.Our research is about building such a camera.</gtr:abstractText><gtr:fund><gtr:end>2009-07-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>81536</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of York</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>University of York</gtr:description><gtr:id>9E142C9B-7405-4F17-BBB6-B20A2A254744</gtr:id><gtr:outcomeId>b9b37f4ab9b37f5e-1</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2006-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>NANOMATION LTD</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>NANOMATION LTD</gtr:description><gtr:id>63AEB587-7637-4AFD-8513-3776E9D98E35</gtr:id><gtr:outcomeId>b9b46392b9b463a6-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2006-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This provided the basis for further significant finding and industrial collaboration (EP/K02339X/1).</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>B44B43A3-5FDF-46DB-9466-108F00706F05</gtr:id><gtr:impactTypes/><gtr:outcomeId>546a18844ff059.31563667</gtr:outcomeId><gtr:sector>Creative Economy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>That &amp;quot;rules&amp;quot; for modelling trees can be learned from tree models acquired directly from video. That dynamic texture is too broad a class to be useful for modelling. That cameras can be modelled in very general ways.</gtr:description><gtr:exploitationPathways>This work formed the foundation of later grants and collaborations, including a close relationship with internationally known industrial partners.</gtr:exploitationPathways><gtr:id>9CF51527-FA79-4607-9A10-219A2D764E93</gtr:id><gtr:outcomeId>546a14fa245079.36343173</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Education,Environment,Culture, Heritage, Museums and Collections</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>9CCCF1B0-6E34-4FD0-A72D-69696C0ED3B2</gtr:id><gtr:title>Learning a Stable Structure to Describe Dynamic Texture</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed32699f57c619499b7358144178e2aa"><gtr:id>ed32699f57c619499b7358144178e2aa</gtr:id><gtr:otherNames>C Li</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_816141289813da641c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4170F2E0-8B68-4DB1-B913-255C28D983F9</gtr:id><gtr:title>ARTcams: Attributed Rational Tensor Cameras</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed32699f57c619499b7358144178e2aa"><gtr:id>ed32699f57c619499b7358144178e2aa</gtr:id><gtr:otherNames>C Li</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_426559825313da5f58</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>58FE1E75-C11C-4B1D-84A5-F8FD9BF0930A</gtr:id><gtr:title>RTcams: a new persepctive on non-photorealistic rendering</gtr:title><gtr:parentPublicationTitle>IEEE Trans. Vis. Comp. Graph,</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4d6d9bc4e2d0957503596da4493c6986"><gtr:id>4d6d9bc4e2d0957503596da4493c6986</gtr:id><gtr:otherNames>P Hall</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_4129874464137ed17e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>666BC0D7-E62F-4B24-8FFA-F4D31168F946</gtr:id><gtr:title>Environment matting into photographs using coloured RTcams</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a900d13b1b07a1d7ebe9c96f9b4655ae"><gtr:id>a900d13b1b07a1d7ebe9c96f9b4655ae</gtr:id><gtr:otherNames>Chuan Li</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:isbn>978 0 86341 973 7</gtr:isbn><gtr:outcomeId>doi_53d031031214561e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7C155FF3-2810-43C7-ABB6-CC6936B066B7</gtr:id><gtr:title>Colour Constancy Based on Model Selection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ed32699f57c619499b7358144178e2aa"><gtr:id>ed32699f57c619499b7358144178e2aa</gtr:id><gtr:otherNames>C Li</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_419164142113da6250</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D064155/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>