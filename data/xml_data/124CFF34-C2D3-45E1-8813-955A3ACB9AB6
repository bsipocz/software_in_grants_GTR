<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:department>Sch of Electronic Eng &amp; Computer Science</gtr:department><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D5337A10-AC8A-402A-8164-C5F9CC6B0140"><gtr:id>D5337A10-AC8A-402A-8164-C5F9CC6B0140</gtr:id><gtr:name>Queen Mary, University of London</gtr:name><gtr:address><gtr:line1>Mile End Road</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>E1 4NS</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/DB9B029E-6575-4ABC-A08F-ED21A698645B"><gtr:id>DB9B029E-6575-4ABC-A08F-ED21A698645B</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:surname>Plumbley</gtr:surname><gtr:orcidId>0000-0002-9708-1075</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FG007144%2F1"><gtr:id>124CFF34-C2D3-45E1-8813-955A3ACB9AB6</gtr:id><gtr:title>Machine Listening using Sparse Representations</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Fellowship</gtr:grantCategory><gtr:grantReference>EP/G007144/1</gtr:grantReference><gtr:abstractText>My aim for this Fellowship is to undertake a concerted programme of research in machine listening, the automatic analysis and understanding of sounds from the world around us. Through this research, and in collaboration with other international researchers, I aim to establish machine listening as a key enabling technology to improve our ability to interact with the world, leading to advances in many areas such as health, security and the creative industries.Human listeners have many capabilities a machine listening system should ideally have: to recognize a wide range of sounds; to segregate one sound source from a mixture of many sound sources; to judge complex attributes of sound such as rhythm and timbre (sound quality). Most human listeners take these abilities for granted, yet it has proved extremely difficult for conventional audio signal processing methods to tackle many of these tasks. Even currently successful tasks, such as automatic speech recognition, have typically led to very specialized techniques which cannot easily be applied to other domains. I propose to introduce new methods for machine listening of general audio scenes.As part of this work, I also will develop new interdisciplinary collaborations with both the machine vision and biological sensory research communities toinvestigate and develop general organizational principles for machine listening. One such principle that currently looks very promising is that of sparse representations. New theoretical advances and practical applications mean that sparse representations has recently emerged as a new and powerful analysis method, based on the principle that observations should be represented by only a few items chosen from a large number of possible items. This approach now has great potential for analysis and measurement of audio as well as other sensory signals. I also plan to use sparse representations to explore new biologically-inspired machine listening methods, and in turn to improve our understandingof biological hearing systems.Success in this research will open the way for new devices and systems able to process, identify and respond to a wide range of sounds, with diverse applications including: audio searching for the music and video industry; advances in hearing aids and cochlear implants; and incident detection for improved public safety on stations, roads and airports.</gtr:abstractText><gtr:fund><gtr:end>2014-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>1461379</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Machine Listening Workshop 2010</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>5B588FA6-8E8C-463A-A127-6FB364750CCA</gtr:id><gtr:impact>A one-day workshop to bring together researchers across the spectrum of machine listening towards the development of a coherent research community able to exploit our common interest in the analysis of audio.</gtr:impact><gtr:outcomeId>56d49f20751421.16464018</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>http://c4dm.eecs.qmul.ac.uk/mlw2010/</gtr:url><gtr:year>2010</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Listening in the Wild: Animal and machine hearing in multisource environments</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>484A388D-54F2-4571-8963-CD36D5CAF943</gtr:id><gtr:impact>This workshop brought together researchers in engineering disciplines (machine listening, signal processing, computer science) and biological disciplines (bioacoustics, ecology, perception and cognition), to discuss complementary perspectives on audition.</gtr:impact><gtr:outcomeId>56d49e0964dcf7.94531841</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>http://c4dm.eecs.qmul.ac.uk/events/litw2013/</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1275401</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Making Sense of Sounds</gtr:description><gtr:end>2018-12-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/N014111/1</gtr:fundingRef><gtr:id>B067D2C4-869A-4069-9882-DD16D2A66F32</gtr:id><gtr:outcomeId>568bdd81e07af0.10810814</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>3800000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>H2020 Marie Sklodowska-Curie Action (MSCA) Innovative Training Network</gtr:description><gtr:end>2018-12-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>642685</gtr:fundingRef><gtr:id>600F3190-1299-4BA2-9266-03367D7D78A7</gtr:id><gtr:outcomeId>568bdf68c296c2.55896834</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>217000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>TSB Data Exploration</gtr:description><gtr:end>2016-05-02</gtr:end><gtr:fundingOrg>Innovate UK</gtr:fundingOrg><gtr:id>97A4CE69-3F89-47BE-8806-0CE06CEF49EB</gtr:id><gtr:outcomeId>568be0a6a7aa51.02229105</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>2800000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>FP7 Marie Curie Initial Training Network</gtr:description><gtr:end>2018-09-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>607290</gtr:fundingRef><gtr:id>186FED9F-C4DF-4475-8ACE-6E21BD595FAD</gtr:id><gtr:outcomeId>568be1bcb9eb51.53728992</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>99000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>TSB Enabling the Internet of Sensors</gtr:description><gtr:end>2015-02-02</gtr:end><gtr:fundingOrg>Technology Strategy Board (TSB)</gtr:fundingOrg><gtr:fundingRef>40818-289315</gtr:fundingRef><gtr:id>B4B6949A-D171-4395-A3DA-1CA95FF16186</gtr:id><gtr:outcomeId>568be1596cf584.24155079</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2014-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>2980000</gtr:amountPounds><gtr:country>European Union (EU)</gtr:country><gtr:currCode>EUR</gtr:currCode><gtr:currCountryCode>Austria</gtr:currCountryCode><gtr:currLang>de_AT</gtr:currLang><gtr:description>H2020-ICT-2015 Audio Commons</gtr:description><gtr:end>2019-01-02</gtr:end><gtr:fundingOrg>European Commission</gtr:fundingOrg><gtr:fundingRef>688382</gtr:fundingRef><gtr:id>3A839C9B-1289-4A8F-A21A-8A6C15ED1EED</gtr:id><gtr:outcomeId>568bdebdb40db2.04379356</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2016-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work in machine listening has been further developed for applications in home security, and further work by one of the researchers has led to release of a smartphone app for birdsong recognition.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>94500BA9-3465-4B19-950D-F074BFC7B76E</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>54635e7dd45f83.31708196</gtr:outcomeId><gtr:sector>Environment,Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>I have introduced many new algorithms and theoretical advances in sparse representations. New algorithms include: a new &amp;quot;stagewise&amp;quot; Polytope Faces Pursuit algorithm; new algorithms for finding &amp;quot;block-sparse&amp;quot; representations, where groups of atoms turn on and off together; and new algorithms for finding representations with &amp;quot;analysis sparsity&amp;quot;, a new approach which produces many zeros after the transform. New dictionary learning methods include: a &amp;quot;double-sparsity&amp;quot; algorithm exploiting the structure of speech-like sounds; new algorithms exploiting harmonic structure; and new algorithms exploiting nonnegativity. New theoretical analysis includes: new convergence results for dictionary learning algorithms, a new approach to dictionary learning based on subspace identification, and new preconditioning and structure-aware methods for audio signals that do not satisfy the typical &amp;quot;restricted Isometry property&amp;quot; (RIP) sparse representations assumption. New methods for analysis of sounds include: audio source separation, including convolutive (echoic) and underdetermined cases (with more sound sources that microphones); direction of arrival (DOA) estimation using compressed sensing; sound timbre classification applied to non-speech vocals; pitch tracking and multipitch analysis for audio object modelling; and a new &amp;quot;audio inpainting&amp;quot; approach to audio restoration. New sound sequence analysis methods, particularly applicable to music, include onset detection, beat and rhythm tracking, with prediction methods based on sequence matching, autoregressive modelling, and information theoretic analysis. Work on heart sound separation was featured widely in medical media and on BBC Arabic TV, and work on birdsong analysis has led to a recent NERC &amp;quot;citizen science&amp;quot; project proposal. In promoting UK sparse representations research: I organized international workshops at Queen Mary in Jan 2011 and June 2012 (forthcoming); on the international SPARS committee, I worked with Davies &amp;amp; Tanner (Edinburgh) to bring SPARS'11 to the UK; and I co-organized special sessions at ICASSP, the main international signal processing conference, in 2011 and 2012 (forthcoming). 
Towards a UK machine listening community: I organized a UK workshop (2010), gave a well-publicized inaugural lecture (2011) on &amp;quot;Making Sense of Sounds and Music&amp;quot; (over 140 attendees), and contributed to UK workshops on &amp;quot;Computational Audition&amp;quot; (London, 2010) and &amp;quot;Making Sense of Sounds&amp;quot; (Plymouth, 2012). The exhibit at the EPSRC &amp;quot;IMPACT&amp;quot; Exhibition (2010) was featured in the Telegraph and on the Guardian Science podcast. I am building a community of UK audio and music researchers around SoundSoftware.ac.uk, promoting the development and re-use of research software, including training events, talks, tutorials, and lab visits. Forthcoming work will address visualization of sounds, and produce a real-time demonstrator. Changes: Audiovisual machine listening proved very vision-heavy and is left to other researchers in this area (e.g. Chambers at Loughborough). Parallels with biological processing is de-emphasized in favour of theory and algorithms with more potential.</gtr:description><gtr:exploitationPathways>Potential beneficiaries of new theory and algorithms for sparse representations will be other researchers in signal processing, looking to apply sparse representations to their own problems, such as image or video analysis.
Potential beneficiaries of successful machine listening research include those in industry looking to apply machine listening to a wide range of applications in many areas of human interaction with the world. Examples include:
* Music and video industries, through music classification, recommendation and searching systems;
* Artists, through e.g. installations which respond to sounds;
* Hearing aid researchers and manufacturers and end users with hearing problems, through improved hearing aids and cochlear implants;
* Police and security agencies, emergency response providers and planners, social services and health agencies, through sound-based identification and analysis of incidents at stations, roads and airports;
* Air, manufacturing or automotive industries, through machine condition monitoring in e.g. aircraft, plant or cars;
* Computer games industry, through analysis and representation of realistic environmental sounds.</gtr:exploitationPathways><gtr:id>AEEE95AE-0EE2-4C9C-A29C-80FD14F18A8B</gtr:id><gtr:outcomeId>r-1677604300.60103947760ad3a</gtr:outcomeId><gtr:sectors><gtr:sector>Communities and Social Services/Policy,Creative Economy,Digital/Communication/Information Technologies (including Software),Environment,Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.eecs.qmul.ac.uk/~markp/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>19BB7B65-2B48-4689-81F0-F6BC41217456</gtr:id><gtr:title>Gradient Polytope Faces Pursuit for large scale sparse recovery problems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/303475a79191325e38a730bc1d39b2f3"><gtr:id>303475a79191325e38a730bc1d39b2f3</gtr:id><gtr:otherNames>Gretsistas A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-4295-9</gtr:isbn><gtr:outcomeId>545ce4efb00af1.63728630</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>423FA971-6660-4FCA-8897-09227EDB8FCA</gtr:id><gtr:title>The Serendiptichord: A wearable instrument for contemporary dance performance</gtr:title><gtr:parentPublicationTitle>128th Audio Engineering Society Convention 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4f58d2ec71a362cbed4558897ec90b2c"><gtr:id>4f58d2ec71a362cbed4558897ec90b2c</gtr:id><gtr:otherNames>Murray-Browne T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce6077fff33.36810170</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CF9001C6-7834-4FD5-92B2-AB2C67660071</gtr:id><gtr:title>Multichannel High-Resolution NMF for Modeling Convolutive Mixtures of Non-Stationary Signals in the Time-Frequency Domain</gtr:title><gtr:parentPublicationTitle>IEEE/ACM Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6068d3617f1ae8cde762f03977b6bf83"><gtr:id>6068d3617f1ae8cde762f03977b6bf83</gtr:id><gtr:otherNames>Badeau R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>doi_55f982982f38f2cc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>75F10424-4FD4-4183-AFF2-6DB69CE7DD4F</gtr:id><gtr:title>Analysis-based sparse reconstruction with synthesis-based solvers</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b6802300bb7a33a45f9248ee678783b1"><gtr:id>b6802300bb7a33a45f9248ee678783b1</gtr:id><gtr:otherNames>Cleju N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>545ce4f747b700.72248976</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>94EA58CE-257C-451E-BC47-A9E643F6F440</gtr:id><gtr:title>A database and challenge for acoustic scene classification and event detection</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/65307ec8d51fb25a08f571252b0a59d7"><gtr:id>65307ec8d51fb25a08f571252b0a59d7</gtr:id><gtr:otherNames>Giannoulis D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce60ed38ec4.76491714</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50349ED3-F265-49AB-9D47-BE4F8E4348A3</gtr:id><gtr:title>Learning Incoherent Dictionaries for Sparse Approximation Using Iterative Projections and Rotations</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/95bd38a0450f7e3f704c0e410abd17d5"><gtr:id>95bd38a0450f7e3f704c0e410abd17d5</gtr:id><gtr:otherNames>Barchiesi D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4ee0ec869.76600539</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5A1FC899-AE08-4175-B27A-C3ED4DF5E493</gtr:id><gtr:title>Wideband Spectrum Sensing on Real-Time Signals at Sub-Nyquist Sampling Rates in Single and Cooperative Multiple Nodes</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2524137ad7970e31d771f34d140518f9"><gtr:id>2524137ad7970e31d771f34d140518f9</gtr:id><gtr:otherNames>Qin Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>585d429c16cba6.33942905</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>27DBB01A-DB63-4C57-8A8B-2A710686BE14</gtr:id><gtr:title>Score-Informed Source Separation for Musical Audio Recordings: An overview</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecbadd3514247d9dd2617ec865425671"><gtr:id>ecbadd3514247d9dd2617ec865425671</gtr:id><gtr:otherNames>Ewert S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>568ac018eddd75.58104781</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AB45FA9F-8333-4557-9AC6-885B9FC837C9</gtr:id><gtr:title>Separating musical audio signals</gtr:title><gtr:parentPublicationTitle>Acoustics Bulletin</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1ca75b454c4d5d53ba1cb324a1a32567"><gtr:id>1ca75b454c4d5d53ba1cb324a1a32567</gtr:id><gtr:otherNames>Plumbley M.D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0308437X</gtr:issn><gtr:outcomeId>5a8847c49d98e0.04983413</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>370C22F0-7936-4B18-A27E-0227F00813D3</gtr:id><gtr:title>Multi-target pitch tracking of vibrato sources in noise using the GM-PHD filter</gtr:title><gtr:parentPublicationTitle>Proceedings of the 5th International Workshop on Machine Learning and Music (MML12)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f983abfee5f1c8930980aa3371fd098b"><gtr:id>f983abfee5f1c8930980aa3371fd098b</gtr:id><gtr:otherNames>Stowell, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545cd830c0bc84.28870725</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ED333099-C387-431B-8460-9C32EC7D3C92</gtr:id><gtr:title>Blind source separation of periodic sources from sequentially recorded instantaneous mixtures</gtr:title><gtr:parentPublicationTitle>ISPA 2011 - 7th International Symposium on Image and Signal Processing and Analysis</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/46a1de75c85406c73c5b9493ca7c705f"><gtr:id>46a1de75c85406c73c5b9493ca7c705f</gtr:id><gtr:otherNames>Jafari M.G.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>545ce60d537316.78325491</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E61FF413-2810-4BA5-8C66-0E008779ED5C</gtr:id><gtr:title>On Theorem 10 in ?On Polar Polytopes and the Recovery of Sparse Representations? [Sep 07 3188-3195]</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Information Theory</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4a0c3482fda06d77878414f5c5b1f683"><gtr:id>4a0c3482fda06d77878414f5c5b1f683</gtr:id><gtr:otherNames>Sturm B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4f234d4e5.62592358</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>69EBE2E5-BF62-4769-89C4-6809DA040061</gtr:id><gtr:title>Improving the performance of pitch estimators</gtr:title><gtr:parentPublicationTitle>128th Audio Engineering Society Convention 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9e5bcdc982b4695ca47aab3dae48d94"><gtr:id>a9e5bcdc982b4695ca47aab3dae48d94</gtr:id><gtr:otherNames>Welburn S.J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce4eec56e52.06205215</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>18F921CD-EFFA-4FA4-A7A9-9660E4126294</gtr:id><gtr:title>Improving instrument recognition in polyphonic music through system integration</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8c511b3f7514c82954e8e1c2eac88927"><gtr:id>8c511b3f7514c82954e8e1c2eac88927</gtr:id><gtr:otherNames>Giannoulis D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545ce4eee9eab6.09523276</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2C019A7E-5CFC-4886-AD79-8843D4AE1926</gtr:id><gtr:title>Audio Inpainting</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b15e85e196a67dc10dd9b1bd1f0b0d3"><gtr:id>9b15e85e196a67dc10dd9b1bd1f0b0d3</gtr:id><gtr:otherNames>Adler A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545ce4f6cf9065.71136252</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E3137BB0-073D-4BEC-8C7E-D34B14E3E373</gtr:id><gtr:title>Recognition of harmonic sounds in polyphonic audio using a missing feature approach</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8c511b3f7514c82954e8e1c2eac88927"><gtr:id>8c511b3f7514c82954e8e1c2eac88927</gtr:id><gtr:otherNames>Giannoulis D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4e9336a57.18522244</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3F69D8B5-B05A-4113-A4C3-149B67DCA3C7</gtr:id><gtr:title>Hearing the shape of a room.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/dc1397f829349b7efce35f0459b7a887"><gtr:id>dc1397f829349b7efce35f0459b7a887</gtr:id><gtr:otherNames>Plumbley MD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>545ce4ef6af862.25227807</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50994AF6-1FBD-4A12-8C25-A23BECB80EEA</gtr:id><gtr:title>Synchronizing Sequencing Software to a Live Drummer</gtr:title><gtr:parentPublicationTitle>Computer Music Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c5fab8b9a72eda3e95e607775c722446"><gtr:id>c5fab8b9a72eda3e95e607775c722446</gtr:id><gtr:otherNames>Robertson A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0148-9267</gtr:issn><gtr:outcomeId>5a351aa00ef755.56292640</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>421DA1DD-3102-407B-A020-AB8523FE4A20</gtr:id><gtr:title>Efficient compressive spectrum sensing algorithm for M2M devices</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2524137ad7970e31d771f34d140518f9"><gtr:id>2524137ad7970e31d771f34d140518f9</gtr:id><gtr:otherNames>Qin Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>568b97862d64d4.55962731</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AA57078B-BBAA-4BA4-8B7D-8935BC0BDEFB</gtr:id><gtr:title>Exploring the effect of rhythmic style classification on automatic tempo estimation</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2efc44c5ee30e9e13d94cf029260baef"><gtr:id>2efc44c5ee30e9e13d94cf029260baef</gtr:id><gtr:otherNames>Davies M.E.P.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce4f1959180.90630867</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4EA67F65-8C5B-4563-BE2C-2A9BE659C0FC</gtr:id><gtr:title>Detection and classification of acoustic scenes and events: An IEEE AASP challenge</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8c511b3f7514c82954e8e1c2eac88927"><gtr:id>8c511b3f7514c82954e8e1c2eac88927</gtr:id><gtr:otherNames>Giannoulis D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545cd66b307060.46165254</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D4619250-B0A1-4048-AC2D-54775E91DFA6</gtr:id><gtr:title>Fast Multidimensional Entropy Estimation by $k$-d Partitioning</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce4f09d97c0.04129083</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>271B1B0C-D7D7-410A-B3D8-D3CDCF22FC58</gtr:id><gtr:title>Score informed audio source separation using constrained nonnegative matrix factorization and score synthesis</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c6313082ef632878917266679c74a9cc"><gtr:id>c6313082ef632878917266679c74a9cc</gtr:id><gtr:otherNames>Fritsch J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4e827e9c1.22280449</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3B34F69E-FDC0-402F-A873-23888BC43A2B</gtr:id><gtr:title>Handbook of Blind Source Separation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d0c432ed96e80ef56d3576086528c853"><gtr:id>d0c432ed96e80ef56d3576086528c853</gtr:id><gtr:otherNames>Plumbley M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>9780123747266</gtr:isbn><gtr:outcomeId>545ce4ec073896.73340575</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AC0A5806-FA2B-48A3-846E-68BAE35E79ED</gtr:id><gtr:title>A constrained matching pursuit approach to audio declipping</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9b15e85e196a67dc10dd9b1bd1f0b0d3"><gtr:id>9b15e85e196a67dc10dd9b1bd1f0b0d3</gtr:id><gtr:otherNames>Adler A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-0538-0</gtr:isbn><gtr:outcomeId>545ce4f968d5e7.69598213</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>22DB4B8D-F9A9-46CB-8F04-7EC594CFEBF2</gtr:id><gtr:title>Phase-based harmonic/percussive separation</gtr:title><gtr:parentPublicationTitle>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ea84a1585a23cbe3aa7ec3335a2419fd"><gtr:id>ea84a1585a23cbe3aa7ec3335a2419fd</gtr:id><gtr:otherNames>Cano E.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>19909772 2308457X</gtr:issn><gtr:outcomeId>5a8847c22c8871.79672951</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BCD0AF28-E4FD-4183-A99A-B7ACCD3479FA</gtr:id><gtr:title>Acoustic Scene Classification: Classifying environments from the sounds they produce</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/95bd38a0450f7e3f704c0e410abd17d5"><gtr:id>95bd38a0450f7e3f704c0e410abd17d5</gtr:id><gtr:otherNames>Barchiesi D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>568abac3bcd003.31029280</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>61F4BBB4-71DB-420C-B412-28CCE88D60F6</gtr:id><gtr:title>Structured sparsity for automatic music transcription</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>545ce4e53d7ee6.39209465</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FAAE242F-26D1-4459-9742-6177DF5AE454</gtr:id><gtr:title>Non-negative matrix factorisation incorporating greedy hellinger sparse coding applied to polyphonic music transcription</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>568b8ef4d34f57.79536908</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0C4EAF4F-1418-47ED-8139-DA5757E75A14</gtr:id><gtr:title>The Serendiptichord: Reflections on the Collaborative Design Process between Artist and Researcher</gtr:title><gtr:parentPublicationTitle>Leonardo</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/470a8b0324678cd2516daace017af908"><gtr:id>470a8b0324678cd2516daace017af908</gtr:id><gtr:otherNames>Murray-Browne T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4e42f4a78.39955194</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8C1A7BD9-DEA1-4AB0-833C-B8BEAE474A1C</gtr:id><gtr:title>Large-scale analysis of frequency modulation in birdsong data bases</gtr:title><gtr:parentPublicationTitle>Methods in Ecology and Evolution</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545cde21f37e57.74227323</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D54623A9-8D9F-4839-8FB5-43F7B795F682</gtr:id><gtr:title>Synchronizing sequencing software to a live drummer</gtr:title><gtr:parentPublicationTitle>Computer Music Journal</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/84e9f9af51bf5ccd371907e8be765707"><gtr:id>84e9f9af51bf5ccd371907e8be765707</gtr:id><gtr:otherNames>Robertson A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>01489267 15315169</gtr:issn><gtr:outcomeId>5a8847c28bcd22.39921482</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DB1101FA-5874-4D64-B337-D879B7FA0E0C</gtr:id><gtr:title>Choosing analysis or synthesis recovery for sparse reconstruction</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a1e35634f9a57b560b58e5b892a6b062"><gtr:id>a1e35634f9a57b560b58e5b892a6b062</gtr:id><gtr:otherNames>Cleju N.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce60d055b95.58421076</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>558CA46A-8C6E-4549-AD75-36D30E0776E0</gtr:id><gtr:title>Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning.</gtr:title><gtr:parentPublicationTitle>PeerJ</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545ce4f660a844.54975209</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>90C078ED-ADC1-4D7A-955D-8A0451EBFB8B</gtr:id><gtr:title>Learning Timbre Analogies from Unlabelled Data by Multivariate Tree Regression</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>545ce4ed6a5179.24818270</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DB57FD17-B374-4695-AFA5-E479E7B5AD2B</gtr:id><gtr:title>Segregating Event Streams and Noise with a Markov Renewal Process Model</gtr:title><gtr:parentPublicationTitle>JOURNAL OF MACHINE LEARNING RESEARCH</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4193fed805f732438d2edd0ab039c35e"><gtr:id>4193fed805f732438d2edd0ab039c35e</gtr:id><gtr:otherNames>Stowell Dan</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1532-4435</gtr:issn><gtr:outcomeId>5a884d7d3ea222.88087499</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DAA7CA19-E216-4E78-9D4D-D84876210ADC</gtr:id><gtr:title>Dictionary learning via projected maximal exploration</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0504c8e08c6cc4303fa9b6ccb79a0885"><gtr:id>0504c8e08c6cc4303fa9b6ccb79a0885</gtr:id><gtr:otherNames>Mailhe B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4f30101c9.60614978</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5A1D9AFE-BD8A-41D3-998D-E6CC2283FD20</gtr:id><gtr:title>Delayed Decision-making in Real-time Beatbox Percussion Classification</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce4f3da9e16.40360693</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>25577B1F-19E0-4021-A057-3958EB6DA506</gtr:id><gtr:title>Event-based Multitrack Alignment using a Probabilistic Framework</gtr:title><gtr:parentPublicationTitle>Journal of New Music Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c5fab8b9a72eda3e95e607775c722446"><gtr:id>c5fab8b9a72eda3e95e607775c722446</gtr:id><gtr:otherNames>Robertson A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>568abac38ea933.80583373</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8FCBF7E1-9042-4137-B0E8-33EC06A24449</gtr:id><gtr:title>Audio-only bird classification using unsupervised feature learning</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f983abfee5f1c8930980aa3371fd098b"><gtr:id>f983abfee5f1c8930980aa3371fd098b</gtr:id><gtr:otherNames>Stowell, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56a8874fb7ac18.19070885</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A8C03CEB-4DE9-430F-B5D2-F05E6F16B02B</gtr:id><gtr:title>An open dataset for research on audio field recording archives: Freefield1010</gtr:title><gtr:parentPublicationTitle>Proceedings of the AES International Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545ce60e4308e3.29440697</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>70022308-83E0-4C96-804C-CCABD044DCF1</gtr:id><gtr:title>INK-SVD: Learning incoherent dictionaries for sparse representations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0504c8e08c6cc4303fa9b6ccb79a0885"><gtr:id>0504c8e08c6cc4303fa9b6ccb79a0885</gtr:id><gtr:otherNames>Mailhe B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>545ce4ee5890a3.49035885</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9BD5A9EF-CFE0-471D-9F66-519CA8A83E43</gtr:id><gtr:title>Measuring the Performance of Beat Tracking Algorithms Using a Beat Error Histogram</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/18859fae61e0bc2d32267048f675108f"><gtr:id>18859fae61e0bc2d32267048f675108f</gtr:id><gtr:otherNames>Davies M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>545ce4ec7516f3.85754396</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>873B51D7-7A98-4BBC-8260-25A3C0AD7416</gtr:id><gtr:title>Speech denoising based on a greedy adaptive dictionary algorithm</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/46a1de75c85406c73c5b9493ca7c705f"><gtr:id>46a1de75c85406c73c5b9493ca7c705f</gtr:id><gtr:otherNames>Jafari M.G.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce4e5ade6b3.14773790</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EDB6EE02-4F4C-4E45-9501-27F6815934D9</gtr:id><gtr:title>Evaluation of live human&amp;acirc;??computer music-making: Quantitative and qualitative approaches</gtr:title><gtr:parentPublicationTitle>International Journal of Human-Computer Studies</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce4f1bb5021.68480057</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F824D3CB-8B08-4939-BED9-AE5CFE0F5A8A</gtr:id><gtr:title>Speech denoising based on a greedy adaptive dictionary algorithm</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/46a1de75c85406c73c5b9493ca7c705f"><gtr:id>46a1de75c85406c73c5b9493ca7c705f</gtr:id><gtr:otherNames>Jafari M.G.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce608419c16.01990524</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>17307BDC-DA3F-4A74-ABF3-3C93C6229519</gtr:id><gtr:title>DAFX: Digital Audio Effects - Z&amp;ouml;lzer/DAFX: Digital Audio Effects</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e9edbd5db1eac343df1611e60575c66"><gtr:id>3e9edbd5db1eac343df1611e60575c66</gtr:id><gtr:otherNames>Evangelista G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>9780470665992</gtr:isbn><gtr:outcomeId>545ce4e6a29132.31089025</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D9C1BBDA-5CAC-4C5F-9E5F-3B622439F981</gtr:id><gtr:title>Segregating event streams and noise with a markov renewal process model</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>15324435 15337928</gtr:issn><gtr:outcomeId>545cd70ec285f3.10914345</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D44727EF-50B0-467E-8009-696C7EAD879D</gtr:id><gtr:title>A database and challenge for acoustic scene classification and event detection</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/65307ec8d51fb25a08f571252b0a59d7"><gtr:id>65307ec8d51fb25a08f571252b0a59d7</gtr:id><gtr:otherNames>Giannoulis D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545cd6edd11191.10524394</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4B571DB9-286F-4090-9E3F-C0AABBDB4BF7</gtr:id><gtr:title>Performance following: Tracking a performance without a score</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b9f747a6debf100d2ca91ca80569874"><gtr:id>3b9f747a6debf100d2ca91ca80569874</gtr:id><gtr:otherNames>Stark A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-4295-9</gtr:isbn><gtr:outcomeId>545ce4ea9ed375.15707735</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>16ACCF87-6FB5-4568-AF70-C9754BD2B417</gtr:id><gtr:title>Sparse reconstruction for compressed sensing using Stagewise Polytope Faces Pursuit</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d0c432ed96e80ef56d3576086528c853"><gtr:id>d0c432ed96e80ef56d3576086528c853</gtr:id><gtr:otherNames>Plumbley M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-3297-4</gtr:isbn><gtr:outcomeId>545ce4e62e2de1.72910882</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5DDEB560-BD6D-4C1C-8D87-21C00E4C4B9B</gtr:id><gtr:title>Detection and Classification of Acoustic Scenes and Events</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Multimedia</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>5675ee81f0180</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F4686573-245B-476C-BD18-1AFC7F60F976</gtr:id><gtr:title>Improved multiple birdsong tracking with distribution derivative method and Markov renewal process clustering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3e643022f9b0ced350a17300c3f08bb4"><gtr:id>3e643022f9b0ced350a17300c3f08bb4</gtr:id><gtr:otherNames>Stowell D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545cd66b600c24.15746652</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EB087B41-A107-48A2-B09E-22055BEE0BB4</gtr:id><gtr:title>Segregating event streams and noise with a markov renewal process model</gtr:title><gtr:parentPublicationTitle>Journal of Machine Learning Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>15324435 15337928</gtr:issn><gtr:outcomeId>545ce6092e75a7.38812146</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8814F1B8-B6B5-4E07-9746-F7189F9B9458</gtr:id><gtr:title>A doubly sparse greedy adaptive dictionary learning algorithm for music and large-scale data</gtr:title><gtr:parentPublicationTitle>128th Audio Engineering Society Convention 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/46a1de75c85406c73c5b9493ca7c705f"><gtr:id>46a1de75c85406c73c5b9493ca7c705f</gtr:id><gtr:otherNames>Jafari M.G.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce4f91087d9.77997961</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F4663AE8-DEA1-412C-A7CC-4A5D1D6E71F9</gtr:id><gtr:title>Reliability-Informed Beat Tracking of Musical Signals</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e6ff1522b3fe45d9a0ebd4aebdbe638"><gtr:id>4e6ff1522b3fe45d9a0ebd4aebdbe638</gtr:id><gtr:otherNames>Degara N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545ce4e8de9706.33143916</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>46A63039-5807-4E47-A5CD-6DDD84926A44</gtr:id><gtr:title>Accounting for phase cancellations in non-negative matrix factorization using weighted distances</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecbadd3514247d9dd2617ec865425671"><gtr:id>ecbadd3514247d9dd2617ec865425671</gtr:id><gtr:otherNames>Ewert S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545ce4f82ac170.09445361</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6B0D1D99-EC5C-4917-923A-4FF338701400</gtr:id><gtr:title>Post-processing fiddle~: A real-time multi-pitch tracking technique using harmonic partial subtraction for use within live performance systems</gtr:title><gtr:parentPublicationTitle>Proceedings of the 2009 International Computer Music Conference, ICMC 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/faa27d0691e46a159226eb9f6ba26bd1"><gtr:id>faa27d0691e46a159226eb9f6ba26bd1</gtr:id><gtr:otherNames>Robertson A.N.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce4ea54f406.16591347</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E6F81D21-9091-495C-B18D-7D62BD012824</gtr:id><gtr:title>Polyphonic piano transcription using non-negative Matrix Factorisation with group sparsity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545ce4ea793070.33843732</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>20FC3EFE-8A7C-4C6A-B77F-601D5B270CDC</gtr:id><gtr:title>Probabilistic time-frequency source-filter decomposition of non-stationary signals</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c5f1709b11245289cf7ef54f936364dd"><gtr:id>c5f1709b11245289cf7ef54f936364dd</gtr:id><gtr:otherNames>Badeau R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce609ee3037.32148175</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ED310EAF-3C70-46E3-9E1A-BC03C2AA877F</gtr:id><gtr:title>Learning incoherent subspaces for classification via supervised iterative projections and rotations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/95bd38a0450f7e3f704c0e410abd17d5"><gtr:id>95bd38a0450f7e3f704c0e410abd17d5</gtr:id><gtr:otherNames>Barchiesi D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4edba9583.42108679</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A99E8083-70D6-423F-81F5-D9814598286D</gtr:id><gtr:title>A robust method for S1/S2 heart sounds detection without ecg reference based on music beat tracking</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ceee06c0eb82b24467959a0d7002ffed"><gtr:id>ceee06c0eb82b24467959a0d7002ffed</gtr:id><gtr:otherNames>Barabasa C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-1177-9</gtr:isbn><gtr:outcomeId>545ce4f87087f5.68856945</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>89A7B84A-F39E-4CAD-BE1A-C527F0CFCAE9</gtr:id><gtr:title>Robustness and independence of voice timbre features under live performance acoustic degradations</gtr:title><gtr:parentPublicationTitle>Proceedings - 11th International Conference on Digital Audio Effects, DAFx 2008</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>545ce60955ead5.74306712</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B82A9CAC-85C9-4F0E-A09C-A8CF2E3EF284</gtr:id><gtr:title>Onset Event Decoding Exploiting the Rhythmic Structure of Polyphonic Music</gtr:title><gtr:parentPublicationTitle>IEEE Journal of Selected Topics in Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e6ff1522b3fe45d9a0ebd4aebdbe638"><gtr:id>4e6ff1522b3fe45d9a0ebd4aebdbe638</gtr:id><gtr:otherNames>Degara N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>545ce4eb4029d9.60018294</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B992F3BE-A2E1-476A-8BD6-BAE0628B8A18</gtr:id><gtr:title>Sequential minimal eigenvalues - An approach to analysis dictionary learning</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fa51e21697681990bf1b62894ba982e7"><gtr:id>fa51e21697681990bf1b62894ba982e7</gtr:id><gtr:otherNames>Ophir B.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce4e7675324.63240326</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>3BA1CF0A-61E0-4239-8931-237649961E46</gtr:id><gtr:title>Best practices for scientific computing.</gtr:title><gtr:parentPublicationTitle>PLoS biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/deb5f0f607f9a5b24127fdedd8ca5fb7"><gtr:id>deb5f0f607f9a5b24127fdedd8ca5fb7</gtr:id><gtr:otherNames>Wilson G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1544-9173</gtr:issn><gtr:outcomeId>545ce4f52acd43.76620280</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A8416B3C-41AB-4FA7-83AA-DBFBFE0367C1</gtr:id><gtr:title>Automatic Music Transcription using row weighted decompositions</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4f617deb9.78669515</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7FA3FC03-51B8-4388-B459-23F3CCF73735</gtr:id><gtr:title>Multichannel HR-NMF for modelling convolutive mixtures of non-stationary signals in the time-frequency domain</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6068d3617f1ae8cde762f03977b6bf83"><gtr:id>6068d3617f1ae8cde762f03977b6bf83</gtr:id><gtr:otherNames>Badeau R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4ec4e39c1.30768565</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AFA9225D-1975-4AC6-B4E9-D7BF6532E46E</gtr:id><gtr:title>Machine Audition - Principles, Algorithms and Systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0a8c2cc2bb228e69afdb9499243f0469"><gtr:id>0a8c2cc2bb228e69afdb9499243f0469</gtr:id><gtr:otherNames>Nesbit A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>9781615209194</gtr:isbn><gtr:outcomeId>545ce4f6ad2a47.65380444</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0A6C6008-C000-4FAE-B2B0-4A746AB18DD4</gtr:id><gtr:title>Performance Following: Real-Time Prediction of Musical Sequences Without a Score</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b9f747a6debf100d2ca91ca80569874"><gtr:id>3b9f747a6debf100d2ca91ca80569874</gtr:id><gtr:otherNames>Stark A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545ce4eac3caa9.13591326</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>831D5817-2BDA-423F-B2D7-51BA64E91F2D</gtr:id><gtr:title>Structured sparsity using backwards elimination for Automatic Music Transcription</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/39e3bd84fdffd71be640e63dd3ce7b04"><gtr:id>39e3bd84fdffd71be640e63dd3ce7b04</gtr:id><gtr:otherNames>Keriven N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4e5173a27.65037723</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>29FD85DD-055B-4D16-93AA-FAB3FEF67DC1</gtr:id><gtr:title>Audio-only bird classification using unsupervised feature learning</gtr:title><gtr:parentPublicationTitle>CEUR Workshop Proceedings</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>16130073</gtr:issn><gtr:outcomeId>5a8847c61ddd69.16327698</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7042F819-A2A0-4D57-8937-40497F30F819</gtr:id><gtr:title>Low-rank matrix completion based malicious user detection in cooperative spectrum sensing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2524137ad7970e31d771f34d140518f9"><gtr:id>2524137ad7970e31d771f34d140518f9</gtr:id><gtr:otherNames>Qin Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4ece75801.91099668</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9DAA2805-D144-4003-A1CD-24778B450282</gtr:id><gtr:title>Real-time beat-synchronous analysis of musical audio</gtr:title><gtr:parentPublicationTitle>Proceedings of the 12th International Conference on Digital Audio Effects, DAFx 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/392c34ed66fa8cdfe99ddeac1107ddbc"><gtr:id>392c34ed66fa8cdfe99ddeac1107ddbc</gtr:id><gtr:otherNames>Stark A.M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce609c7f766.15387551</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>530919E9-F32E-42BF-AD7F-A7360C737B42</gtr:id><gtr:title>Note onset detection using rhythmic structure</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4e6ff1522b3fe45d9a0ebd4aebdbe638"><gtr:id>4e6ff1522b3fe45d9a0ebd4aebdbe638</gtr:id><gtr:otherNames>Degara N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-4295-9</gtr:isbn><gtr:outcomeId>545ce4ebd95dc6.06628946</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D3195699-3358-4C3A-A19C-C9BCDAF5E303</gtr:id><gtr:title>An alternating descent algorithm for the off-grid DOA estimation problem with sparsity constraints</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ce37422917ed26e89e731381ce319ac9"><gtr:id>ce37422917ed26e89e731381ce319ac9</gtr:id><gtr:otherNames>Gretsistas A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce60e67a1e7.19224591</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E0F90C88-DDD1-4C79-A930-DCA9BCB2FB91</gtr:id><gtr:title>Sound Software: Towards software reuse in audio and music research</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/de82f753a4c19dbf093d1cd4c2aecc91"><gtr:id>de82f753a4c19dbf093d1cd4c2aecc91</gtr:id><gtr:otherNames>Cannam C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>545ce4e6c88451.67026992</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>574C6120-91EE-41F8-AAEC-19120A9F38E0</gtr:id><gtr:title>The melody triangle: Exploring pattern and predictability in music</gtr:title><gtr:parentPublicationTitle>AAAI Workshop - Technical Report</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9be36c10d9b6d229fc14cd58e96c82af"><gtr:id>9be36c10d9b6d229fc14cd58e96c82af</gtr:id><gtr:otherNames>Ekeus H.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>545ce607ec7e29.62878170</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>03AD57AC-4292-4D56-9C78-9ED767F8FAD6</gtr:id><gtr:title>Timbre remapping through a regression-tree technique</gtr:title><gtr:parentPublicationTitle>Proceedings of the 7th Sound and Music Computing Conference, SMC 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce4e3dd9e35.38140219</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AEFE15EB-EAA3-42A9-A9AA-0B4A712FAB25</gtr:id><gtr:title>Towards a musical beat emphasis function</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/18859fae61e0bc2d32267048f675108f"><gtr:id>18859fae61e0bc2d32267048f675108f</gtr:id><gtr:otherNames>Davies M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-3678-1</gtr:isbn><gtr:outcomeId>545ce4e3ba5560.48396359</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>65EDFB3D-CBC7-4DEC-B40E-E3407BDA71E2</gtr:id><gtr:title>Framewise heterodyne chirp analysis of birdsong</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce60b952238.54959506</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>093F557F-8A83-4DDE-B607-2E76D05C5AEF</gtr:id><gtr:title>Software techniques for good practice in audio and music research</gtr:title><gtr:parentPublicationTitle>134th Audio Engineering Society Convention 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b411e8033856bfead458237efbef0a9"><gtr:id>4b411e8033856bfead458237efbef0a9</gtr:id><gtr:otherNames>Figueira L.A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce6088aef57.81358358</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EB71C1F5-C923-4A1D-95B4-5712A9C3BEAB</gtr:id><gtr:title>Structure-aware dictionary learning with harmonic atoms</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d51d34b97b9a658c96d918de242e7f25"><gtr:id>d51d34b97b9a658c96d918de242e7f25</gtr:id><gtr:otherNames>O'Hanlon K.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>22195491</gtr:issn><gtr:outcomeId>545ce4e561ab85.32441355</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5BC736C0-87A7-4368-B4FB-9747EEBD37BC</gtr:id><gtr:title>Fast Dictionary Learning for Sparse Representations of Speech Signals</gtr:title><gtr:parentPublicationTitle>IEEE Journal of Selected Topics in Signal Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8b9356ae1bbebe4e3099c1a924c5866a"><gtr:id>8b9356ae1bbebe4e3099c1a924c5866a</gtr:id><gtr:otherNames>Jafari M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>545ce4f14b3462.11407289</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5A079287-EC62-4C37-BADF-CF8068472D29</gtr:id><gtr:title>Behavior of greedy sparse representation algorithms on nested supports</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0504c8e08c6cc4303fa9b6ccb79a0885"><gtr:id>0504c8e08c6cc4303fa9b6ccb79a0885</gtr:id><gtr:otherNames>Mailhe B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4f575d1e3.70041708</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F564FDA6-D0EC-4163-8AF2-515403D83C35</gtr:id><gtr:title>Separating sources from sequentially acquired mixtures of heart signals</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e3f629f784eea9e5448ce18a7251ac7d"><gtr:id>e3f629f784eea9e5448ce18a7251ac7d</gtr:id><gtr:otherNames>Hedayioglu F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-0538-0</gtr:isbn><gtr:outcomeId>545ce4e7b14f04.66150146</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4E559BFC-998E-4AE7-B2F5-A421DE6D484A</gtr:id><gtr:title>An L1 criterion for dictionary learning by subspace identification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f8244d97fc72add9fbdfee2b16770c54"><gtr:id>f8244d97fc72add9fbdfee2b16770c54</gtr:id><gtr:otherNames>Jaillet F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-4295-9</gtr:isbn><gtr:outcomeId>545ce4f78e7655.14485191</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F9A796DD-60C0-442C-903F-AEAFAA0C577F</gtr:id><gtr:title>Machine Audition - Principles, Algorithms and Systems</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/76932d4d499b7c53fc66a3b063bfd255"><gtr:id>76932d4d499b7c53fc66a3b063bfd255</gtr:id><gtr:otherNames>Vincent E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>9781615209194</gtr:isbn><gtr:outcomeId>545ce4e9ed0f83.38576242</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>76A6B2FA-3AF0-482D-BD8A-6883969FB73C</gtr:id><gtr:title>Learning Incoherent Subspaces: Classification via Incoherent Dictionary Learning</gtr:title><gtr:parentPublicationTitle>Journal of Signal Processing Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/95bd38a0450f7e3f704c0e410abd17d5"><gtr:id>95bd38a0450f7e3f704c0e410abd17d5</gtr:id><gtr:otherNames>Barchiesi D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>doi_55faa0aa0f245544</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7891521D-CD9B-455E-849E-93968B46221A</gtr:id><gtr:title>Learning overcomplete dictionaries with l0-sparse Non-negative Matrix Factorisation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/845955cb409b459776fd0fe8bfe01bf7"><gtr:id>845955cb409b459776fd0fe8bfe01bf7</gtr:id><gtr:otherNames>O'Hanlon K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>545ce4ed974610.81205245</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E90C20E9-6C74-4240-A837-1AABFD23E4EE</gtr:id><gtr:title>Denoising and segmentation of the second heart sound using matching pursuit.</gtr:title><gtr:parentPublicationTitle>Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e3f629f784eea9e5448ce18a7251ac7d"><gtr:id>e3f629f784eea9e5448ce18a7251ac7d</gtr:id><gtr:otherNames>Hedayioglu F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4244-4119-8</gtr:isbn><gtr:issn>1557-170X</gtr:issn><gtr:outcomeId>545ce4f3b65fe6.95997028</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A083B751-78C5-4364-883A-8EAE76349894</gtr:id><gtr:title>On the disjointess of sources in music using different time-frequency representations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8c511b3f7514c82954e8e1c2eac88927"><gtr:id>8c511b3f7514c82954e8e1c2eac88927</gtr:id><gtr:otherNames>Giannoulis D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4577-0692-9</gtr:isbn><gtr:outcomeId>545ce4eb8d88e2.37377013</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C6134A22-C48C-41F0-BECA-9EC34B2BF91F</gtr:id><gtr:title>Instrumentation-based music similarity using sparse representations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/155af9d38a47288306120f1be2a4c14a"><gtr:id>155af9d38a47288306120f1be2a4c14a</gtr:id><gtr:otherNames>Fujihara H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-1-4673-0045-2</gtr:isbn><gtr:outcomeId>545ce4ee330859.15757477</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DFD936BB-4AB2-4025-9A5B-695647E6B914</gtr:id><gtr:title>Rendering audio using expressive MIDI</gtr:title><gtr:parentPublicationTitle>127th Audio Engineering Society Convention 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9e5bcdc982b4695ca47aab3dae48d94"><gtr:id>a9e5bcdc982b4695ca47aab3dae48d94</gtr:id><gtr:otherNames>Welburn S.J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce4e8bb7187.43189234</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>340F623A-1DF3-4FEA-9D48-1F27366A945C</gtr:id><gtr:title>An open dataset for research on audio field recording archives: Freefield1010</gtr:title><gtr:parentPublicationTitle>Proceedings of the AES International Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b5969e311616c4fb9a3c0656f8f4546e"><gtr:id>b5969e311616c4fb9a3c0656f8f4546e</gtr:id><gtr:otherNames>Stowell D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>545cd72c0f7dd0.45152614</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>9645662B-75D8-420B-A737-86A12108308B</gtr:id><gtr:title>Real-time chord recognition for live performance</gtr:title><gtr:parentPublicationTitle>Proceedings of the 2009 International Computer Music Conference, ICMC 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/392c34ed66fa8cdfe99ddeac1107ddbc"><gtr:id>392c34ed66fa8cdfe99ddeac1107ddbc</gtr:id><gtr:otherNames>Stark A.M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce4e95cb4a6.28004026</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A74CCE63-0BDE-4BFE-A301-0126B4A9F191</gtr:id><gtr:title>Sparse Representations in Audio and Music: From Coding to Source Separation</gtr:title><gtr:parentPublicationTitle>Proceedings of the IEEE</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d0c432ed96e80ef56d3576086528c853"><gtr:id>d0c432ed96e80ef56d3576086528c853</gtr:id><gtr:otherNames>Plumbley M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>545ce4e607c6d2.89197191</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B250A475-A00F-4049-BE67-D42500850722</gtr:id><gtr:title>Estimating parameters from audio for an EG+LFO model of pitch envelopes</gtr:title><gtr:parentPublicationTitle>Proceedings of the 12th International Conference on Digital Audio Effects, DAFx 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a9e5bcdc982b4695ca47aab3dae48d94"><gtr:id>a9e5bcdc982b4695ca47aab3dae48d94</gtr:id><gtr:otherNames>Welburn S.J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>545ce60be4eb95.81716139</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G007144/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>12FC01EE-4952-4AE4-883A-D3E83A89C5C6</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Digital Signal Processing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>