<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/6C2C296C-940A-43CD-82E3-EBF6C0D54BA5"><gtr:id>6C2C296C-940A-43CD-82E3-EBF6C0D54BA5</gtr:id><gtr:name>Beihang University</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF"><gtr:id>CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF</gtr:id><gtr:name>Loughborough University</gtr:name><gtr:department>Aeronautical and Automotive Engineering</gtr:department><gtr:address><gtr:line1>Loughborough University</gtr:line1><gtr:line4>Loughborough</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE11 3TU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF"><gtr:id>CAA9A40D-0226-4A4F-AC0D-D8299E30A1EF</gtr:id><gtr:name>Loughborough University</gtr:name><gtr:address><gtr:line1>Loughborough University</gtr:line1><gtr:line4>Loughborough</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE11 3TU</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/6C2C296C-940A-43CD-82E3-EBF6C0D54BA5"><gtr:id>6C2C296C-940A-43CD-82E3-EBF6C0D54BA5</gtr:id><gtr:name>Beihang University</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/E57B96EF-0EE6-4396-B430-34A8E360FF76"><gtr:id>E57B96EF-0EE6-4396-B430-34A8E360FF76</gtr:id><gtr:name>Beijing Aerospace Automatic Control Inst</gtr:name><gtr:address><gtr:line1>No 50 Yong Ding Road</gtr:line1><gtr:line2>Haidian district</gtr:line2><gtr:postCode>100083</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/43677F22-1D69-40F2-BD35-68EF1A556C69"><gtr:id>43677F22-1D69-40F2-BD35-68EF1A556C69</gtr:id><gtr:name>Beihang University (BUAA)</gtr:name><gtr:address><gtr:line1>NO. 37, Xueyuan Road, Haidian</gtr:line1><gtr:postCode>100191</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/1CEF96C4-F457-47FC-9A23-7040961A75A1"><gtr:id>1CEF96C4-F457-47FC-9A23-7040961A75A1</gtr:id><gtr:firstName>Antonios</gtr:firstName><gtr:surname>Tsourdos</gtr:surname><gtr:orcidId>0000-0002-3966-7633</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8D08FA43-0800-4944-B819-36375F9DBB47"><gtr:id>8D08FA43-0800-4944-B819-36375F9DBB47</gtr:id><gtr:firstName>Hyondong</gtr:firstName><gtr:surname>Oh</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/EF6C94A2-8221-458A-8C4E-A8A083D81BA2"><gtr:id>EF6C94A2-8221-458A-8C4E-A8A083D81BA2</gtr:id><gtr:firstName>Zhengtao</gtr:firstName><gtr:surname>Ding</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9E43E594-6E3C-4BC1-820E-3844B1D1DE98"><gtr:id>9E43E594-6E3C-4BC1-820E-3844B1D1DE98</gtr:id><gtr:firstName>Wen-Hua</gtr:firstName><gtr:surname>Chen</gtr:surname><gtr:orcidId>0000-0003-3356-2889</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/73446D9F-81E9-4F34-9E27-A9B4E850F15B"><gtr:id>73446D9F-81E9-4F34-9E27-A9B4E850F15B</gtr:id><gtr:firstName>Sujit</gtr:firstName><gtr:surname>Pedda baliyarasimhuni</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6EDC39D3-EB00-4EE1-B852-3EA13A4FEF34"><gtr:id>6EDC39D3-EB00-4EE1-B852-3EA13A4FEF34</gtr:id><gtr:firstName>Alexandru</gtr:firstName><gtr:otherNames>Stelian</gtr:otherNames><gtr:surname>Stancu</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9C120987-6210-4A90-A8CC-D5CA088E3872"><gtr:id>9C120987-6210-4A90-A8CC-D5CA088E3872</gtr:id><gtr:firstName>Cunjia</gtr:firstName><gtr:surname>Liu</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/D91C109C-B986-47A3-9058-E9855B6BBCCD"><gtr:id>D91C109C-B986-47A3-9058-E9855B6BBCCD</gtr:id><gtr:firstName>Abdul</gtr:firstName><gtr:otherNames>Mounem</gtr:otherNames><gtr:surname>Mouazen</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ST%2FN006852%2F1"><gtr:id>98FCD4F0-31E1-4B0C-951C-1EF44446D611</gtr:id><gtr:title>Enabling wide area persistent remote sensing for agriculture applications by developing and coordinating multiple heterogeneous platforms</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ST/N006852/1</gtr:grantReference><gtr:abstractText>This project is to develop wide area, persistent remote sensing capability for agriculture applications by developing and coordinating a number of sensing platforms such as satellites, unmanned aerial vehicles, airships, and even ground unmanned vehicles. It is aimed to provide an unprecedented high density of spatial and temporal information required in sustainable agriculture. Agriculture is currently facing serious challenges in securing food supply to the world population. Global population will continue to grow in the near future with an increasing aging-population structure. Thus the demand for food is expected to continue to rise as global population grows and a rising middle class desires more meat and dairy products in rapidly developing countries like China. Similarly, the total demand for energy and fresh water will increase as a result of economic growth in China. The increased frequency of extreme weather events occurring will seriously hamper food production. Sustainable intensive agriculture is widely perceived to be the answer to the challenge, which aims to increase food production without adversely damaging natural resources and environment. This increased food production is achieved through breeding cultivars with increased resource efficiency and yield potential, better deployment of these cultivars, and better crop husbandry to reduce crop losses due to adverse factors (e.g. pests, diseases, flooding, drought). Remote sensing plays a key role in developing sustainable agriculture for China and other countries. Remote sensing provides timely, synoptic, cost-effective and repetitive information about crops, their growth environments and other key relevant elements such as migratory insects and diseases. The observed data from the remote sensing can find a wide range of applications; for example, not only providing timely information for farm management or early detection of diseases but also for understanding the biological science involved in agriculture and developing statistical crop modelling for future predictions. Despite all the advances in remote sensing platforms particularly unmanned aerial vehicles, they are still not able to provide required wide area persistent remote sensing capability; for example, both macroscopic and microscopic data are required in understanding outbreak and the propagation of some diseases and pests. This project is to advance the current remote sensing capability by two approaches: 1) further improving the current sensing platforms particularly airships and small scale unmanned aircraft including both pointing systems and vehicles; 2) more importantly coordinating different types of existing sensing platforms (i.e. satellites, unmanned aircraft, or airship) based on their performance and characteristics. With the aim of reducing operation cost and the reliance on the operator's experience/skills while fulfilling the remote sensing requirements for a specific application, both strategical and tactical decision making, planning and coordination tools for the deployment of the platforms will be developed to automate most of the remote sensing tasks for agriculture using autonomous system technologies.</gtr:abstractText><gtr:potentialImpactText>The direct impact of this work would be on agriculture and environment of China. This project will develop technologies enabling wide area persistent remote sensing with a high density of spatial and temporal observation information as required by sustainable intensive farming. This would enable a wide range of applications of remoting sensing technologies such as better crop health monitoring, early detection of pest and disease, and provision of information for better farm management including targeted intervention/treatment. 

The outcome of this project will also support a better understanding in a number of biological science subjects including plant science, while providing new understanding in pest and disease. For example, it is quite challenging to understand the influence of nutrition and other environment factors on the migration of locusts, and the relationship between group collective behaviour and individual ones. Large amounts of observation data at different spatial and temporal scales are required continuously to track a large swarm of locusts and some specific individual movement (day and night). Observation data collected at different scales are also important to build the links between microscopic and macroscopic studies of biological science and crop growth. Various modelling tools and methods have been proposed in agriculture but, at each level, it is imperative to collect adequate and sufficient data to calibrate models. Thus, this project will benefit UK, China and other countries in biological science and other subjects.

The wide area persistent remote sensing capability can find a wide range of applications in addition to sustainable intensive agriculture. For example, it can be directly applied to forest protection and monitoring including fire detection and monitoring and pest/disease monitoring. It could also be applied to wild animal protection and tracking (e.g. migratory animals), pollution monitoring and tracking, flooding prediction, etc., where wide area and persistent remote sensing capability is required.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-04-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/D7F4F462-0518-4784-908A-D12633C139B3"><gtr:id>D7F4F462-0518-4784-908A-D12633C139B3</gtr:id><gtr:name>STFC</gtr:name></gtr:funder><gtr:start>2016-05-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>1207493</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Beihang University</gtr:collaboratingOrganisation><gtr:country>China, People's Republic of</gtr:country><gtr:description>BUAA</gtr:description><gtr:id>12B29A66-904C-467F-B8E4-E37A0802C44D</gtr:id><gtr:impact>This is a typical multi-disciplinary project which covers satellite application, UAVs, agriculture, and data processing with optical sensors. Some initial data sets have been been provided by BUAA.</gtr:impact><gtr:outcomeId>58bd7b21c45a72.03499904-1</gtr:outcomeId><gtr:partnerContribution>BUAA collect remote sensing data from the selected test fields in various seasons by operating UAV and corresponding payload. It also helps to talk with farmers and local agriculture organisations to get the ground truth and local data. BUAA has managed to secure &amp;pound;3M RMB from the National Science Foundation of China for supporting this project.</gtr:partnerContribution><gtr:piContribution>We are working very closely with Beihang University (BUAA) on this project. This project is about remote sensing for agriculture application in China, particularly supporting precision agriculture. We develop and provides data processing and fusion algorithms for early detection of disease/pest for crops and assess the level of damages.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>40000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Agri-Tech China Network+</gtr:description><gtr:end>2017-08-02</gtr:end><gtr:fundingOrg>Rothamsted Research</gtr:fundingOrg><gtr:fundingRef>Proof-of-Concept-Round 1: PC003</gtr:fundingRef><gtr:id>97FB5469-FCDA-4D42-9529-72D9B7F080DF</gtr:id><gtr:outcomeId>58bd7c33871b38.39721432</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2017-04-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>D0597B3D-B7C5-46F5-8E44-3C15D64B74FF</gtr:id><gtr:title>Predictor-Based Extended-State-Observer Design for Consensus of MASs With Delays and Disturbances</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Cybernetics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/55e9c812cfbba94f1e7e00b693cdb8e1"><gtr:id>55e9c812cfbba94f1e7e00b693cdb8e1</gtr:id><gtr:otherNames>Wang C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a95232b40d666.33075005</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5904F1BA-7597-4E45-B981-BEE284E86964</gtr:id><gtr:title>Control scheme for LTI systems with Lipschitz non-linearity and unknown time-varying input delay</gtr:title><gtr:parentPublicationTitle>IET Control Theory &amp; Applications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/55e9c812cfbba94f1e7e00b693cdb8e1"><gtr:id>55e9c812cfbba94f1e7e00b693cdb8e1</gtr:id><gtr:otherNames>Wang C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9464f4674c63.06629995</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>48C3EEA7-313C-4E29-B6A0-AFDFD31A9BE6</gtr:id><gtr:title>Band selection in sentinel-2 satellite for agriculture applications</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b2a42f54432a63b7a88ae42e6aa48538"><gtr:id>b2a42f54432a63b7a88ae42e6aa48538</gtr:id><gtr:otherNames>Zhang T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a946553bda987.75826265</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>17539617-C831-4512-A539-5221B6559DBE</gtr:id><gtr:title>Robust Cooperative Guidance Law for Simultaneous Arrival</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Control Systems Technology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5a4e3979f177e6ad9e72d3a5c818988a"><gtr:id>5a4e3979f177e6ad9e72d3a5c818988a</gtr:id><gtr:otherNames>Li Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:outcomeId>5a9964ee9845d0.31554523</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>36DAEE65-0591-4007-B813-68C751A21760</gtr:id><gtr:title>Boustrophedon coverage path planning for UAV aerial surveys in wind</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cb029a9c75b1edc81dec5e7aa7d5ea1d"><gtr:id>cb029a9c75b1edc81dec5e7aa7d5ea1d</gtr:id><gtr:otherNames>Coombes M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a94655369d774.71807942</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7A05CB82-58E0-452C-BD53-6CC1339255A0</gtr:id><gtr:title>Dimension Reduction Aided Hyperspectral Image Classification with a Small-sized Training Dataset: Experimental Comparisons.</gtr:title><gtr:parentPublicationTitle>Sensors (Basel, Switzerland)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2442d53819c02a917a449e45bee162c0"><gtr:id>2442d53819c02a917a449e45bee162c0</gtr:id><gtr:otherNames>Su J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1424-8220</gtr:issn><gtr:outcomeId>5a9464f4095ff4.98243295</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C86A1E63-4378-4CCE-9490-FC7D5D2A57BB</gtr:id><gtr:title>Robust
 
 disturbance attenuation for a class of uncertain Lipschitz nonlinear systems with input delay</gtr:title><gtr:parentPublicationTitle>International Journal of Control</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ffbab00bdc1ffcee4551a8048b9029c5"><gtr:id>ffbab00bdc1ffcee4551a8048b9029c5</gtr:id><gtr:otherNames>Zuo Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a2fbf7b809837.56908651</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ST/N006852/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5B25B6A3-B218-4F11-8A9D-661236DF455C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Agri-environmental science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>895D1683-DC4B-4292-BBC6-EC38672BFD10</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>RCUK Programmes</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>53F27348-198B-4AEF-A34B-8307067F507C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>794345CD-A1D5-4984-ADDD-088BCF41822F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Agricultural systems</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6F3E4891-E3E8-4568-94D8-075A0552DE90</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Crop protection</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>4237918D-61A8-47E0-91EE-65E98661A88B</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Earth &amp; environmental</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>87A865C6-1151-4169-B57A-6B39807A3BE2</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Intelligent Measurement Sys.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes><gtr:rcukProgramme><gtr:id>C11BDEA9-7D9D-4728-B6A9-31032921B328</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Newton</gtr:text></gtr:rcukProgramme></gtr:rcukProgrammes></gtr:project></gtr:projectComposition></gtr:projectOverview>