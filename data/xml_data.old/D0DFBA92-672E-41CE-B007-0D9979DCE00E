<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6A3E13C0-5735-497A-8998-D8325BC36C1F"><gtr:id>6A3E13C0-5735-497A-8998-D8325BC36C1F</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:otherNames>Jeremy</gtr:otherNames><gtr:surname>Prince</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE013309%2F1"><gtr:id>D0DFBA92-672E-41CE-B007-0D9979DCE00E</gtr:id><gtr:title>Mosaic Class Models for Complex Shape and Appearance Distributions</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E013309/1</gtr:grantReference><gtr:abstractText>This project deals with the difficult problem of how to mathematically represent the shape and appearance of classes of visual objects (e.g. faces, human bodies or bicycles). We need to find statistical models which exploit the similarity between all members of the class, but are flexible enough to represent the individual examples.The importance of object class modelling lies in the breadth of application. Consider a statistical description of images of cars. Such a model can be used for vehicle detection, vehicle identity recognition, or for predicting characteristics of cars such as their age or type (SUV, compact car etc.). The model can be used to segment vehicle pixels precisely from a larger image, to generate new photo-realistic images or animations of cars, and to denoise, enhance or super-resolve existing images. One might use the model to help track cars in complex scenes, estimate vehicle speed, assess driving ability, or to edit movies to change the identity, position or color of cars in the footage. There are obvious real-world uses for these capabilities. A similar variety of applications is found if we consider other classes such as human body models, or faces. Our assertion is that a significant development in the statistical description of object classes will make an enormous contribution to the field of computer vision.In this project, we will develop a gold-standard'' statistical model of class appearance and shape, which can be applied to all of the above tasks. We aim to exploit recent, exciting developments in the development of generic image priors and texture generation methods. It is appropriate and timely to apply these advances to the problem of image class modeling. We term our scheme a class mosaic model, because it represents an image as a composite picture made up of smaller patches.</gtr:abstractText><gtr:fund><gtr:end>2009-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>209998</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>97875184-C692-4839-AAF3-8469E1DBA193</gtr:id><gtr:title>Scene shape priors for superpixel segmentation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e77f248010c1b434120ad44ce4ec6fd"><gtr:id>6e77f248010c1b434120ad44ce4ec6fd</gtr:id><gtr:otherNames>Moore A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4420-5</gtr:isbn><gtr:outcomeId>doi_53d058058657e4c6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E6D69CEB-026B-48F3-9FAE-3205F229F51F</gtr:id><gtr:title>Patch-based within-object classification</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/27517952b16830ddc71aca5a77f97a18"><gtr:id>27517952b16830ddc71aca5a77f97a18</gtr:id><gtr:otherNames>Aghajanian J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4420-5</gtr:isbn><gtr:outcomeId>doi_53d0580586828804</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EC4CAB7A-BCA3-41EA-907F-D81C514B3157</gtr:id><gtr:title>Visio-lization</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/b477c2e7c13fae01512da43245cec330"><gtr:id>b477c2e7c13fae01512da43245cec330</gtr:id><gtr:otherNames>Mohammed U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d07407469d908a</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E013309/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>