<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:department>Psychology</gtr:department><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7A0397DD-E0C6-4EA3-8031-B841D2503C4D"><gtr:id>7A0397DD-E0C6-4EA3-8031-B841D2503C4D</gtr:id><gtr:name>Royal Holloway, University of London</gtr:name><gtr:address><gtr:line1>Egham Hill</gtr:line1><gtr:line4>Egham</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>TW20 0EX</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/53614C37-5923-4DAD-B1B7-FF4BFC37BAFE"><gtr:id>53614C37-5923-4DAD-B1B7-FF4BFC37BAFE</gtr:id><gtr:firstName>Carolyn</gtr:firstName><gtr:surname>McGettigan</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6F4E6B43-DC5F-41BE-90EB-8C1DD80883C1"><gtr:id>6F4E6B43-DC5F-41BE-90EB-8C1DD80883C1</gtr:id><gtr:firstName>Samuel</gtr:firstName><gtr:otherNames>David</gtr:otherNames><gtr:surname>Evans</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8283549F-7F64-4434-A6A6-10BEF72A0D71"><gtr:id>8283549F-7F64-4434-A6A6-10BEF72A0D71</gtr:id><gtr:firstName>Marc</gtr:firstName><gtr:otherNames>Eric</gtr:otherNames><gtr:surname>Miquel</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FL01257X%2F1"><gtr:id>34B6F5DA-05B1-4527-9D07-1A68CC39E85C</gtr:id><gtr:title>Vocal Learning in Adulthood: Investigating the mechanisms of vocal imitation and the effects of training and expertise.</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/L01257X/1</gtr:grantReference><gtr:abstractText>We are genetically programmed to acquire spoken language from our environment, and infants can master native pronunciation in multiple languages without explicit tuition. However, in adolescence and adulthood we have a limited capacity to achieve accurate pronunciation of unfamiliar languages, and even highly competent users of a language learned in adulthood might speak with a strong, non-native accent. The UK currently lies behind other EU nations in foreign language skills at school and in the workplace, therefore research into skill development has important educational and economic implications.

Previous research has used functional MRI to measure how the activity of functional systems in the brain changes as new speech sounds are learned. This work has described the integration of novel speech sounds into a talker's existing speech repertoire as it becomes more familiar. Within this, however, some talkers are more successful than others at attaining native-like pronunciation of new sounds, and this variability is correlated with the activation, size and structural composition of specific brain structures.

To date, the cognitive neuroscience of speech learning has assessed performance by measuring or judging the sounds of speech. However, there isn't a simple one-to-one relationship between how speech sounds in the air, and the underlying movements in the vocal tract. Therefore, an important missing piece of the puzzle is an understanding of how vocal articulations relate directly to brain activation during learning. Recent developments in MRI have shown that rapid 'real-time' anatomical scans can be used to create videos of the interior of the mouth and vocal tract, such that we can view how the lips, tongue and voice box are moved and configured to perform speech. We propose to combine real-time MRI with measures of brain structure and function to investigate the relationship between brain and behaviour during the learning of new speech sounds.

Our project will focus on short-term learning of novel and unfamiliar vocal sounds by native speakers of English, where the participants will aim to imitate the sounds accurately and with native-like pronunciation. In an MRI scanner, listeners will repeatedly produce these novel sounds, as well as native sounds of English, while scans of the brain will measure neural activity. Interleaved with these scans, we will collect real-time images of the vocal articulators during imitation. Acoustic recordings will be made using an in-scanner microphone, and we will additionally collect high-resolution images of brain structure from each participant. With these data, we will investigate vocal learning in terms of i) the functional brain systems supporting learning, ii) the acoustic accuracy of vocal output and iii) the accuracy of the movements generating the sounds, as well as the relationship between these elements. Further, we can explore how individuals differ in their performance of vocal learning in terms of meeting these acoustic and motor targets, and how this relates to their brain structure and function. Across a series of experiments, we will also investigate how novel sounds are sequenced into new words, and assess the effects of expertise on vocal learning by comparing English speakers with highly-proficient students of modern languages and professional beatboxers.

Our proposed approach is truly novel, with potential to make groundbreaking developments in the cognitive neuroscience of vocal communication. To deliver the project, we have assembled a uniquely qualified research team with shared and individual expertise in phonetics, cognitive neuroscience and MRI. The data will directly inform our understanding of language learning and accent acquisition. Further, our new methodology has potential future application to other questions, such as the assessment of brain and behaviour relationships in patients with speech impairments following brain injury.</gtr:abstractText><gtr:potentialImpactText>The proposed research project bears direct relevance to language learning in adolescence and adulthood. Teenagers in the UK currently perform poorly in their use of foreign languages compared with students in the rest of Europe (&amp;quot;European Survey on Language Competences: Language Proficiency in England&amp;quot;, National Foundation for Educational Research, 2013). Meanwhile, the demand for foreign language skills at all levels in the workforce is increasing, and the UK faces a growing deficit in the ability to supply adequately skilled individuals (&amp;quot;Languages: State of the Nation&amp;quot;, British Academy, 2013). Thus, research on the mechanisms for developing new language skills speaks to issues concerning the educational and economic future of our country. More generally, research on the neural and behavioural correlates of vocal learning is of relevance to all users of spoken language, whether they are acquiring a language for the first time, working to improve a second language, or re-learning speech after a brain injury.

We have identified several potential beneficiaries of this research outside the academic community:

Students and teachers of modern languages: Interest in studying foreign languages has declined in the UK in recent years; moreover, there is an imbalance in uptake that favours students from higher socio-economic status backgrounds (&amp;quot;Languages: State of the Nation&amp;quot;, British Academy, 2013). The proposed project will respond to these current issues. In planned impact activities in the short to medium term, we will engage primary and secondary school students' interest in language learning by illustrating the vocal articulatory system using the visually engaging medium of real-time MRI videos, and in entertaining contexts such as beatboxing performance. In the medium term, targeted articles for vocational publications will directly engage teachers with results of the project relevant to language education. Further, a planned database of real-time MRI videos of the vocal tract will be made available to language teachers in the medium to long term, to illustrate aspects of phonetics and the motoric correlates of speech in the classroom.

Education policy makers: In the medium term, the results of this project and the published materials will potentially be of interest to policy makers considering how to improve foreign language performance by UK students, for example by enhancing understanding of specific challenges in language acquisition such as individual differences in vocal learning.

NHS professionals: In the short to long term, speech and language therapists, neurologists, radiographers, radiologists and clinical scientists will be interested in the development of new methodologies to study vocal learning, for application in contexts such as recovery of speech after stroke.

Royal Holloway, University of London (RHUL) and Queen Mary, University of London (QMUL): The proposed work stands to enrich the cultural and educational experience of current and prospective students at RHUL and QMUL, by introducing them to the nature of research in a way that is academically accessible and visually engaging.

Journalists and media: In the short to medium term, the outputs of the proposed research will be communicated for publication in online, print and broadcast media. The use of real-time MRI in expert populations (e.g. beatboxers) will support communication of the findings in a way that is both intellectually accessible and culturally enriching.

General public: Vocal communication is central to everyday human experience, but many people have little insight into the exquisite complexity of the articulations underlying our speech. In the short to medium term, a range of planned public events will engage people of all ages and backgrounds with the method and results of the project, using a combination of live performance and scientific presentation to enhance scientific understanding of the brain and vocal behaviour.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-06-28</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2015-01-12</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>364898</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Article on The Mirror website</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>F8C71206-047B-4146-B8CD-7BAAC0FB54E2</gtr:id><gtr:impact>On the basis of a very popular Facebook post showing a real-time MRI video of lip-syncing to Adele's &amp;quot;Hello&amp;quot;, we approached the ESRC Press Office, who put together a press release about the funded project using the video. The story was picked up by The Mirror, who featured the video and an interview with Dr McGettigan on their website.</gtr:impact><gtr:outcomeId>56d45892811486.65756385</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.mirror.co.uk/news/uk-news/amazing-mri-brain-scan-shows-6970049</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Interview on BBC Radio Wales</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>6A841A44-4AEF-45D0-81B9-EDEEE233EC4B</gtr:id><gtr:impact>Dr McGettigan was interviewed on BBC Radio Wales about the British Science Festival in Swansea, and her award lecture which took place at the festival on Tuesday 6th September 2016. She had the opportunity to talk about the flexibility of the human voice and her interest in this area of research, as well as to preview the content of her lecture.</gtr:impact><gtr:outcomeId>58bd795f010556.88693015</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Royal Holloway Science Festival 2016</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>C11FD0DB-7220-4162-9CFC-3348B36235C7</gtr:id><gtr:impact>On March 5th 2016, the Royal Holloway Vocal Communication Laboratory gave demonstrations of real-time MRI of the vocal tract to show the movements of the articulators during singing. Demonstrators inside the MRI scanner performed short periods of lip-syncing to popular songs while another member of the lab described the images and their meaning to the audience - this demonstration was based on our successful media clip of Adele's &amp;quot;Hello&amp;quot; which reached very wide audiences in December 2015. The Royal Holloway Science Festival has been running for 25 years - it is a free 1-day event attracting over 5,000 visitors (mainly school-aged children and their parents) to the campus from the Surrey area each year.</gtr:impact><gtr:outcomeId>56d45ae3102090.50850929</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.royalholloway.ac.uk/science/sciencefestival/home.aspx</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Facebook post: Real-time MRI during lip-synching to Adele's &quot;Hello&quot;</gtr:description><gtr:form>Engagement focused website, blog or social media channel</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>42920EA4-1CF4-475B-AF86-FCC485D6ED0B</gtr:id><gtr:impact>On 1st December 2015 we posted on Facebook a clip of real-time MRI footage of a lab member lip-syncing to the song &amp;quot;Hello&amp;quot; by Adele. This employed the vocal tract imaging method being used as part of the ESRC funded project. The clip was shared widely by Facebook users, generating (as counted on 29th February 2016) 93,508 views, 1,572 shares, 346 likes, and 54 comments. We received direct contact from a number of user groups to express interest and/or indicate onward usage of the clip, including teachers (in a variety of locations across the world, including a neurobiology class at Harvard, and a phonetics class at the University of Manchester), UK speech and language therapists, and oral surgeons. One user even followed up to tell us that she had annotated the clip to specifically highlight individual speech sounds for her students: https://blogs.ntu.edu.sg/blip/files/2016/02/AdelefMRIDemo-2gw21ei.gif.

The Facebook post linked directly to the Royal Holloway Vocal Communication Laboratory website - inspection of the Google Analytics report shows that in the period from 1st December 2015 to 28th February 2016 we received 1616 visits directly from Facebook. We also embedded a version of the video on the lab website, which has had a further 409 views.

The success of the video through social media led to coverage of the research on the website of The Mirror (covered as a separate output here).</gtr:impact><gtr:outcomeId>56d44f7decc879.52194167</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.facebook.com/nadinelavan/videos/10153716278513917/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk at the Norwich Science Festival, Norwich, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>4DD97A5A-F6BD-4ED1-991B-607B2087B06E</gtr:id><gtr:impact>Dr McGettigan gave her British Science Festival award lecture for an audience at the Norwich Science Festival in Norwich, UK, on 26th October 2016. The talk was well received and engaged a great deal of audience interest in the questions and discussion following the presentation.</gtr:impact><gtr:outcomeId>58bd78db867175.00867006</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://norwichsciencefestival.co.uk/events/the-voice/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Award lecture at British Science Festival, Swansea, UK</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>B415C8FA-5AB1-4697-9624-4DA93284A787</gtr:id><gtr:impact>As part of her Charles Darwin prize (see Awards &amp;amp; Recognition), Dr McGettigan gave a 1-hour talk on The Voice, for an audience of the general public attending the British Science Festival in Swansea, on 6th September 2016. In this talk, she focussed on the remarkable flexibility of the human voice, illustrated this with vocal tract videos of speech and song obtained during her ESRC award. She also presented findings from the first study in the ESRC Vocal Learning award, which is now in press at Cerebral Cortex (Carey et al., in press).</gtr:impact><gtr:outcomeId>58bd77f01da037.90099525</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://www.britishscienceassociation.org/blog/carolyn-mcgettigans-the-voice</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>As detailed in other sections of the submission, our work has reached a wide audience through a video demonstration of real-time vocal tract MRI posted on Facebook and in the national media (The Mirror).

Directly from the Facebook post, we have received comments and direct messages from users in speech and language therapy, and in higher education, to say that they have been using our video as a teaching and demonstration tool with their users. As we later plan to compile a library of real-time vocal tract images to make publicly available to end users in teaching and research, we take these initial examples of onward use as a strong indication that our work will be employed in enhancing wider understanding of the complexity of speech and plasticity in vocal behaviour, both in clinical and non-clinical settings.

A substantial development in the non-academic impacts of the work has come through our lab being accepted, alongside colleagues from UCL and the University of Sussex, to run a stand at the 2017 Royal Society Summer Science Exhibition. This prestigious exhibition, held annually at the Royal Society in London, will give us the opportunity to engage with around 15,000 visitors including school pupils and members of the general public. Our exhibit, entitled &amp;quot;What's in a voice?&amp;quot; will include a discussion of the flexibility of the human voice and its various uses. The Royal Holloway Vocal Communication Laboratory will be showcasing the work carried out as part of the ESRC Vocal Learning award, including demonstration of vocal tract images of speech, song and beatboxing, as well as the results of the studies run to date.</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>C8567FA5-B24C-47E8-866A-29ECBA4BD2A1</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56d475bf780fd0.99774281</gtr:outcomeId><gtr:sector>Education</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This project set out with the primary objective of developing a new approach to studying speech learning by directly collecting movement data from the vocal tract and bloodflow data from the brain, using magnetic resonance imaging (MRI). 

The groundbreaking finding from Experiment 1 is a demonstration that we can use images of the vocal tract during speech to directly identify representations of speech movements in the brain. In our experiment, we successfully trained adult speakers of English to produce non-English vowels that required additional rounding of the lips. We showed improvements in acoustic accuracy on trained vowel production, and further that the degree of this improvement was significantly related to the acquisition of the appropriate lip rounding articulation (as measured using vocal tract MRI). We analysed MRI of neural bloodflow to identify brain regions whose activation showed the effects of training, and a difference between English and foreign vowels, during listening and imitation of speech. Further, in the first analysis of its kind, we demonstrated that the shaping of the vocal tract and articulators used to produce different vowels is directly reflected in the patterning of activations in motor and sensory parts of the brain. This first experiment crucially underlines the feasability and utility of this method for the study of speech, addressing several of the key objectives of the award.

In the second experiment, we developed our vocal learning paradigm to measure the generalisation of non-native vowel production to word-like contexts (of 1 and 3 syllables long). Behaviourally, we have shown that single-syllable contexts (e.g. &amp;quot;Tyb&amp;quot;, where /y/ is the non-native vowel) seem to yield the most accurate imitation of vowels, and this is reflected in reduced processing costs within the brain (relative to enhanced activations seen for non-native vowels in isolation, or in longer utterances). Our functional MRI data show that overall, increasing the challenges of speech imitation leads to greater activation in a range of brain regions relevant to sensorimotor transformation and imitation of speech. As set out in our grant proposal, we also probed the striking individual differences in speech imitation performance, and how these were related to brain function. Some listeners' acoustic imitations of vowels improved considerably during training, while others in fact got worse. Using these behavioural data to probe the neural data, we found several significant relationships in regions associated with the control of movement and speech. Specifically, we we found increases in activation in participants who had been more effective learners, while those who had not learned showed decreased activation in line with their poorer behavioural performance. These findings are in line with existing work on non-native speech imitation and provide potential sites for training interventions, for example transcranial stimulation to enhance learning.

One over-arching objective of the award is to explore learning, which we have so far done by probing the outcomes of pre-scan speech training in terms of acoustic imitation performance, articulatory behavioural (vocal tract MRI) and brain function. A further aspect of learning is characterising the gradual changes in behaviour and the brain over time, as measured at different points within the ~1hr scanning sessions while participants continually imitated speech. The question of the nature and timecourse of these changes is the subject of ongoing analyses on Experiment 1 and 2 data. Here, we have benefitted greatly from the work of student interns HS, CH, MR and EK in extracting and labelling these data.

Now in Month 26 of the award, we have completed data collection and analysis on Experiment 1 and Experiment 2 of the grant. There have been several academic outputs: 
- The Researcher (Dr Daniel Carey) has presented the results of Experiment 1 at two international conferences (Society for Neuroscience and Society for the Neurobiology of Language, 2016 and 2017), and will give three invited seminars on the research at Imperial College, UCL and the University of Oxford in 2016.
- The PI has presented the results of this and related work (employing the real-time vocal tract imaging method) at the same two international conferences, and in an invited symposium presentation at the London meeting of the Experimental Psychology Society. She has also given invited seminars in the University of Geneva (June 2016) and the University of Roehampton (February 2017). 
- We have published 2 papers based on the funded work: one methodological review paper (Carey and McGettigan (2016), Neuropsychologia) and one empirical paper based on the data collected in Experiment 1 (Carey, Miquel, Evans, Adank &amp;amp; McGettigan (in press), Cerebral Cortex). A further empirical paper covering the functional MRI results of Experiment 2 will be submitted for publication in March 2017.</gtr:description><gtr:exploitationPathways>Our work has produced a truly groundbreaking new method for the study of plasticity in speech, and in human sensorimotor learning more generally. Our methodological review and initial empirical findings will allow other researchers to apply our approach to a variety of questions, including those related to language learning, and in clinical settings such as the recovery of speech articulation and reorganisation of brain function in post-stroke aphasia.</gtr:exploitationPathways><gtr:id>90593217-0A79-437F-A111-9348D5013F4B</gtr:id><gtr:outcomeId>56d464e3d772c3.62540660</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.carolynmcgettigan.com/#!esrc---vocal-imitation/cisw</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>F27752C5-0F04-4346-B9D9-FB1901038690</gtr:id><gtr:title>Magnetic resonance imaging of the brain and vocal tract: Applications to the study of speech production and language learning.</gtr:title><gtr:parentPublicationTitle>Neuropsychologia</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7900e7ec3712f9b0d11d5be95cef367a"><gtr:id>7900e7ec3712f9b0d11d5be95cef367a</gtr:id><gtr:otherNames>Carey D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0028-3932</gtr:issn><gtr:outcomeId>585d535c702839.86472593</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F35ADF6E-F377-47FD-B15A-CDE941C3C576</gtr:id><gtr:title>Vocal tract images reveal neural representations of sensorimotor transformation during speech imitation</gtr:title><gtr:parentPublicationTitle>Cerebral Cortex</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a08d44ce8d6d31b9d53b7f0122fbeb9"><gtr:id>6a08d44ce8d6d31b9d53b7f0122fbeb9</gtr:id><gtr:otherNames>Carey, D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>58bd7d1baeec92.56925424</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0C75E15C-816A-4211-82C6-5C58AFCDCA11</gtr:id><gtr:title>Functional brain outcomes of L2 speech learning emerge during sensorimotor transformation.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7900e7ec3712f9b0d11d5be95cef367a"><gtr:id>7900e7ec3712f9b0d11d5be95cef367a</gtr:id><gtr:otherNames>Carey D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn><gtr:outcomeId>5a2fcb1b2ce594.53243846</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>70C94F09-BF98-404D-9311-47CADA0EFE8D</gtr:id><gtr:title>Vocal Tract Images Reveal Neural Representations of Sensorimotor Transformation During Speech Imitation.</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7900e7ec3712f9b0d11d5be95cef367a"><gtr:id>7900e7ec3712f9b0d11d5be95cef367a</gtr:id><gtr:otherNames>Carey D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>5a350d114ba7c9.37962599</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/L01257X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>78C47607-4818-4A9C-B510-D5D9A368C83F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Phonetics</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>