<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:department>WMG</gtr:department><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B6FB652A-60C3-48DD-9A33-075D1F759B48"><gtr:id>B6FB652A-60C3-48DD-9A33-075D1F759B48</gtr:id><gtr:name>University of Warwick</gtr:name><gtr:address><gtr:line1>Warwickshire</gtr:line1><gtr:line4>Coventry</gtr:line4><gtr:line5>West Midlands</gtr:line5><gtr:postCode>CV4 7AL</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/909C646F-C9A3-42E9-BB1D-579B9B63772D"><gtr:id>909C646F-C9A3-42E9-BB1D-579B9B63772D</gtr:id><gtr:name>Arup Group Ltd</gtr:name><gtr:address><gtr:line1>13 Fitzroy Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>W1T 4BQ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D069A2DE-5A1B-41C7-8B44-E658A808F970"><gtr:id>D069A2DE-5A1B-41C7-8B44-E658A808F970</gtr:id><gtr:name>goHDR Ltd</gtr:name><gtr:address><gtr:line1>78 Woodcote Avenue</gtr:line1><gtr:postCode>CV8 1BE</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/75B7012D-5F23-4948-930D-79288035D29C"><gtr:id>75B7012D-5F23-4948-930D-79288035D29C</gtr:id><gtr:firstName>Kurt</gtr:firstName><gtr:surname>Debattista</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FI038780%2F1"><gtr:id>5CF087ED-AB73-4097-82A5-D55BB61C56B8</gtr:id><gtr:title>Dynamic Real-World Lighting for Complex Scenes with Applications to Design of the Built Environment</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/I038780/1</gtr:grantReference><gtr:abstractText>Physically-based rendering is the process of creating accurate computer generated images using physically accurate materials and light sources and computing a simulation of the lighting. Physically-based rendering is needed by any discipline that requires an accurate representation of the lighting in an computer generated environment, it makes it possible to accurately predicate how a new building will affect the environment around it, it allows designers to test their products under any possible lighting environment at the click of a button, it enables archaeologists to delve into reconstructions of the past, and it allows entertainers to create realistic environments that may have never existed before. 

This 12 month project will improve the realism of physically-accurate computer generated images, and the time it takes to compute them for complex lighting scenarios. The novel methods will be used for applications in the built environment through consultancy and evaluation from Arup, a global firm providing engineering design, planning and project management services in all areas of the built environment. The realism of computer generated images has been improved by a process known as image-based lighting (IBL) which relies on the capture of High Dynamic Range (HDR) images. Unlike normal images, HDR images can represent most of the real world luminance and has made it possible to capture the entire lighting at a single point in an environment. This captured HDR image, termed an environment map is used to accurately relight a virtual environment with the captured real world luminance. This process is relatively straightforward for scenes which are directly lit by the environment map, but can be very slow to compute for scenes where the lighting needs to be computed indirectly, such as is common in applications in the built environment, for example when computing the lighting of a view from inside an office building which is entirely lit from the outside. The first goal of this project is to create a novel rendering algorithm that uses clever sampling methods which will reduce the computation of such complex scenarios to that of the straightforward case. 

The capture of environment maps for IBL has, until now, due to limitations in hardware capture, been limited to static scenarios. WMG is in possession of the world's first HDR video camera which can capture up to 20 f-stops at an HD resolution of 1920x1080 pixels at 30 frames per second, making it possible to capture dynamic environment maps. goHDR a company with HDR expertise will provide their compression method that will enable the dynamic environment maps to be stored as HDR videos. When not compressed, HDR videos would consume 24MB for a single HD resolution frame. This compression will allow HDR videos to be stored with a minimal overhead over a standard video, and make processing of dynamic environment maps feasible. This will enable the second major goal of this research which is to create algorithms that can compute physically-accurate rendered animations using dynamic environment maps for dynamically change lighting for complex scenarios.</gtr:abstractText><gtr:potentialImpactText>The major beneficiaries of this project will be users of physically-based rendering applications and computer graphics practitioners. This work will enable computer graphic practitioners and general rendering application users to create scenarios with never seen before lighting complexity and authenticity. This will be performed with real-world captured lighting within reasonable times. Furthermore, it will not require the use of rendering experts.

While this will be primarily focused on application on the built environment, the underlying work can be used to directly benefit similar applications in a number of fields such as automotive, visualisation, cultural heritage, manufacturing, advertising and video games.

Built Environment - The ability to generate and demonstrate highly realistic images and animations of complex realistic scenarios with captured lighting within reasonable times and the ability to do so without the need of rendering experts.

General Public- As customers, and for public consultations, to be able to have demonstrated high-fidelity animations of complex scenarios before they are built.

High dynamic range - The research in the field of IBL provides a distinct market for new companies working in the area of HDR such as goHDR. HDR equipment and expertise is currently limited only to such companies and university labs. When dynamic IBL begins being used in earnest these companies will be in the ideal solution to be able to provide software, hardware, and expertise to already established companies. 

Manufacturing - The ability to view design prototypes under any form of lighting that can be captured, and changed with the click of a button.

Automotive - While not being targeted as an application in this current proposal automotive companies stand to benefit from this research as it will potentially enhance the digitisation of their manufacturing pipeline via rendering accurate car models in various surroundings. This enables concept design verification, acceptance of concepts by senior management and customer evaluation without the need of creating physical models. 

Film/Television - This work will provide a basis to enhance the already existing abilities of re-lighting virtual objects. Our research will make it possible to use dynamic lighting and make complex scenes feasible to be used by the special effects industry. 

Games industry - The facility in the future to adopt similar technologies, or potentially approximate results to improve the quality of the lighting in games and/or reduce the time required to create and animate complex environments.</gtr:potentialImpactText><gtr:fund><gtr:end>2013-05-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>99952</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>20000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Dynamic Image-Based Lighting for Real-World Applications</gtr:description><gtr:end>2013-06-02</gtr:end><gtr:fundingOrg>Technology Strategy Board (TSB)</gtr:fundingOrg><gtr:fundingRef>1000817</gtr:fundingRef><gtr:id>62AFA6D2-D970-4A14-8654-8432ECBCF1CC</gtr:id><gtr:outcomeId>5ee0c0d85ee0c0ec</gtr:outcomeId><gtr:sector>Public</gtr:sector><gtr:start>2013-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work was investigated by our collaborators at ARUP as a potential method for improving their lighting simulations. A KTP in industrial mathematics was also funded to look into taking this further.</gtr:description><gtr:firstYearOfImpact>2013</gtr:firstYearOfImpact><gtr:id>B4D99BCA-453E-4F1A-B5B5-509B6B07F1FB</gtr:id><gtr:impactTypes/><gtr:outcomeId>56d5daf763d209.69462516</gtr:outcomeId><gtr:sector>Environment,Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The accurate simulation of lighting for virtual environments permits the evaluation of how light will influence an environment for applications ranging from architecture to entertainment. The lighting in certain virtual environments whereby lighting is complex, for example, coming from a distant source (such as the Sun) and interacting with multiple objects are difficult to compute within reasonable time frames. This work looked into accelerating the computation of such environments and extending it into the temporal domain. The result was an algorithm that significantly accelerated the computation of lighting for certain complex scenarios by over an order of magnitude.</gtr:description><gtr:exploitationPathways>This method could be used to accelerate lighting in commercial and research computer graphics projects. It is useful in industrial applications such as architecture for analysing the impact of lighting in the inside of buildings in highly occluded environments/areas; automotive to analyse lighting inside moving vehicles; archaeological reconstructions to help identify the impact of sunlight on rituals; entertainment to accurately model lighting at faster rates.</gtr:exploitationPathways><gtr:id>504B9644-C34A-4B7A-96C5-DE42216AAFD2</gtr:id><gtr:outcomeId>56d5d769a14b44.81326540</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>80289811-1CDE-4483-A799-B21D853518B9</gtr:id><gtr:title>Importance Driven Environment Map Sampling.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ee72ac20de2130c223ad389932b17b5b"><gtr:id>ee72ac20de2130c223ad389932b17b5b</gtr:id><gtr:otherNames>Bashford-Rogers T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_55f9749743c55381</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>83B5CC76-FD41-4F94-AB83-319A3548434D</gtr:id><gtr:title>Evaluation of HDR video tone mapping for mobile devices</gtr:title><gtr:parentPublicationTitle>Signal Processing: Image Communication</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/87c17ab23d902ebca61862851f54a4e6"><gtr:id>87c17ab23d902ebca61862851f54a4e6</gtr:id><gtr:otherNames>Melo M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>doi_53cff7ff75cd446e</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/I038780/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>