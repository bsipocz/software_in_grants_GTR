<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/7801F008-7C77-45E7-90E9-4345B47D138E"><gtr:id>7801F008-7C77-45E7-90E9-4345B47D138E</gtr:id><gtr:name>University of Plymouth</gtr:name><gtr:department>Sch of Art &amp; Media</gtr:department><gtr:address><gtr:line1>Drake Circus</gtr:line1><gtr:line4>Plymouth</gtr:line4><gtr:line5>Devon</gtr:line5><gtr:postCode>PL4 8AA</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7801F008-7C77-45E7-90E9-4345B47D138E"><gtr:id>7801F008-7C77-45E7-90E9-4345B47D138E</gtr:id><gtr:name>University of Plymouth</gtr:name><gtr:address><gtr:line1>Drake Circus</gtr:line1><gtr:line4>Plymouth</gtr:line4><gtr:line5>Devon</gtr:line5><gtr:postCode>PL4 8AA</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/0A7F6855-B4EB-470F-B983-56001A4E3B58"><gtr:id>0A7F6855-B4EB-470F-B983-56001A4E3B58</gtr:id><gtr:firstName>Jane</gtr:firstName><gtr:surname>Grant</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=AH%2FE510825%2F1"><gtr:id>8C48B8FF-1D8E-40D1-81C8-246279CB88F6</gtr:id><gtr:title>Merging the human voice with with neurological time patterns</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>AH/E510825/1</gtr:grantReference><gtr:abstractText>Recently there has been much progress in philosophical, neuroscientific and artistic enquiry into the boundaries between perception, thought and action. Much of this work (often carried out independently, without knowledge of work in separate disciplines) has focused on the importance of the processing part of experience the part between sensing and action.

Recent neuroscientific developments have considered the internal workings of real and model connected spiking neurons and seem to indicate that the processing (cortical) part of the brain relies on the formation of groups of neurons which adapt their internal connections according to the timings of spiking, a process which relies on the voltage across a neural membrane being above a certain threshold. The enquiries of philosophers such as David Wood consider the dynamics of the boundaries and thresholds associated with perception and artists such as Gary Hill explore the effect a voice modified by an action has with regard to utterance and movement associated with process or thought.

From an artistic point of view I wish to investigate the effect of merging the time patterns, the rhythms of the processing or 'cortical' part of the brain with a voice, thus merging the internalised 'thought' with an externalised action.

I am particularly interested in the effect neural rhythms may have in rupturing the pattern of the voice such that it seems at a liminal threshold.
In order to do this, the objectives are:
 To record a number of human voices in real time and investigate the merging of the voice with the neurogranular sampler, a new instrument which triggers grains of sound when one of a group of connected model spiking neurons fires.
 To make a series of experiments of this 'merging'.
 To create a user interface with a research assistant, adapting the newly invented neurogranular sampler based on the vocal-neural experiments, which will be used to create the audio part of a sound and video installation that will be exhibited at Artsway in 2007.

This will be the first time that speech has been merged with the newly found cortical rhythms (which seem to lie in-between a synchronised pulse and a random set of events). The natural rhythms of the vocalisation will be merged with the unperceived, yet internal rhythms of processing. It is possible that there will be many applications outside of the remit of the work here; new sonorities and rhythms are a constant source of inspiration for recording artists and the newly discovered cortical rhythms are currently being used to study brain function.</gtr:abstractText><gtr:fund><gtr:end>2007-11-10</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/1291772D-DFCE-493A-AEE7-24F7EEAFE0E9"><gtr:id>1291772D-DFCE-493A-AEE7-24F7EEAFE0E9</gtr:id><gtr:name>AHRC</gtr:name></gtr:funder><gtr:start>2007-05-11</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>15554</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">AH/E510825/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>972C8509-5001-4523-9E10-7FA67E2F2E69</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Visual arts</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A8CCE2FA-9D1B-4880-9BD3-C4C078F9CD7F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Fine Art HTP</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>2D2B04A8-2CC9-41D9-B5EF-78E0AF1A8B24</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Installation &amp; Sound Art HTP</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>02EB1D72-607A-4467-BF3A-A60E567738E9</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Time-Based Media HTP</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>