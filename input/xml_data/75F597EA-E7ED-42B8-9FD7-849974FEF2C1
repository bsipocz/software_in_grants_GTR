<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Philosophy Psychology &amp; Language</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/08FA944A-CF78-4441-A534-73D9F607C62F"><gtr:id>08FA944A-CF78-4441-A534-73D9F607C62F</gtr:id><gtr:firstName>Matthew</gtr:firstName><gtr:otherNames>Aubrey</gtr:otherNames><gtr:surname>Roberts</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/2039084B-CAFA-4CEF-8DCD-80BF6EAEAA52"><gtr:id>2039084B-CAFA-4CEF-8DCD-80BF6EAEAA52</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:otherNames>Charles</gtr:otherNames><gtr:surname>Shillcock</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/C28028F7-1832-480A-97CA-F976CFB751F5"><gtr:id>C28028F7-1832-480A-97CA-F976CFB751F5</gtr:id><gtr:firstName>Hamutal</gtr:firstName><gtr:surname>Kreiner</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=ES%2FH002839%2F1"><gtr:id>75F597EA-E7ED-42B8-9FD7-849974FEF2C1</gtr:id><gtr:title>Acquisition of a rich annotated corpus of binocular eye-movements from dyslexic readers</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/H002839/1</gtr:grantReference><gtr:abstractText>&lt;p>In this project representative numbers of high-achieving (ie university student) dyslexics will be studied reading 5000 words of English text on a screen. Their precise eye-movements will be monitored and recorded, showing the exact locations and durations of the fixations of the right and left eye on the text. This information will be compared with that from an existing large corpus of the eye-movements of more typical readers. &lt;/p>

&lt;p>The goal is to understand the differences between these two populations of readers, in terms of the effects of a range of different aspects of the text, such as the length of a word, its frequency in the language, or the details of the adjacent words, which have all been shown to affect individual fixations in reading. These data will speak to ongoing controversies about both normal and impaired reading, such as the degree of high-level control exerted during reading, how many words are being processed at any one time, and the ways in which the two eyes relate to each other behaviourally. &lt;/p>

&lt;p>The dyslexic readers will be tested on a range of language and visual processing tasks to confirm their status as dyslexics.&lt;/p></gtr:abstractText><gtr:fund><gtr:end>2010-11-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2009-12-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>80579</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We have continued to work on the corpus of eye-movements, using it to inform our own theorising about the reading capacities of dyslexics. The database is complex and is closely tied to the computational and methodological infrastructure in which the data were acquired, together with theoretical assumptions concerning the binocular reading of multiline text. These considerations have meant that we have restricted the analysis of the database to our own group.</gtr:description><gtr:firstYearOfImpact>2010</gtr:firstYearOfImpact><gtr:id>BB138B53-C105-4FED-9BE7-9F5B615166B6</gtr:id><gtr:impactTypes/><gtr:outcomeId>546e012ec5d596.96635201</gtr:outcomeId><gtr:sector>Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The dyslexics made more and longer fixations, and some of them made more regressive fixations, compared with the typical readers. Dyslexic and typical readers behaved comparably in that the final binocular disparity within a fixation was about 90% of the initial disparity.We have concentrated on exploring the movements of the two eyes within fixations. We have discovered that in dyslexics there are more directionally variable horizontal movements, particularly left-to-right ones, compared with more typical readers, and beginning from a more leftward position within the word. Dyslexic reader, particularly males, move their left eye more variably. This variability is interpretable within our own hemisphere-based analysis of eye-movements in reading.We have also demonstrated precise coordination between the two eyes in the first published eye-tracking of an individual with Duane's Syndrome, in which the left eye is inhibited from moving to the left of the middle of the page.</gtr:description><gtr:exploitationPathways>We are continuing to work on the statistical analysis of the full dataset, which will allow us to test various hypotheses about the dyslexics' reading behaviours.</gtr:exploitationPathways><gtr:id>C184D8D8-490B-4756-8524-161E9D6C848D</gtr:id><gtr:outcomeId>r-5352740348.645244b2f1d076</gtr:outcomeId><gtr:sectors><gtr:sector>Education</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>The database is a record of the movements of both the left and the right eyes of some 63 self-selecting dyslexic university students, together with a range of behaviours on cognitive tasks, plus demographic data. The participants read some 5000 words of journalistic text (representing the English component of the Edinburgh 5-Language Corpus of Eye-Movements in Reading).</gtr:description><gtr:id>8BCC70F7-E10B-49B0-B7AE-60B5AF62DE0E</gtr:id><gtr:impact>We have gained insight into characteristic differences between dyslexics and typical readers that occur within individual fixations. We have also fortuitously tested a self-selecting dyslexic who presented with Duane's Syndrome, a genetic condition affecting the movement of (typically) the left eye. This subject's pattern of eye-movements has been analysed with respect to the coordination of the two eyes, revealing normal binocular coordination of the two eyes during reading of the right half of a line of text, and still-coordinated but widely disparate fixations during the reading of the left half of a line of text, during which time the right eye's input must be dominant.</gtr:impact><gtr:outcomeId>546deff16e0428.89701896</gtr:outcomeId><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Edinburgh Binocular Eye-Movements in Dyslexia Database</gtr:title><gtr:type>Database/Collection of data</gtr:type></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>E92724EB-E3C7-46A0-9701-2BD47440DD87</gtr:id><gtr:title>Principles in the computational modelling of eye-movements in reading</gtr:title><gtr:parentPublicationTitle>Perception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e58b53dbeb75f71d9dd9fb445de51ac5"><gtr:id>e58b53dbeb75f71d9dd9fb445de51ac5</gtr:id><gtr:otherNames>Richard Shillcock (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>r_644194890263c119c2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>256F92ED-5B4A-412D-8635-17BF35ED5998</gtr:id><gtr:title>Binocular foveation in reading.</gtr:title><gtr:parentPublicationTitle>Attention, perception &amp; psychophysics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f48a9281451af158432eda05da305c4"><gtr:id>2f48a9281451af158432eda05da305c4</gtr:id><gtr:otherNames>Shillcock R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1943-3921</gtr:issn><gtr:outcomeId>pm_53cbfd3bfd380e78d</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>35042FE7-2011-4DDF-89E7-B8CC7EA8734E</gtr:id><gtr:title>Multiple models and multiple perspectives approaches in modelling eye-movements in reading</gtr:title><gtr:parentPublicationTitle>Journal of Eye Movement Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e58b53dbeb75f71d9dd9fb445de51ac5"><gtr:id>e58b53dbeb75f71d9dd9fb445de51ac5</gtr:id><gtr:otherNames>Richard Shillcock (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>r_447793630963c11e86</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>09F7B7E4-3C7E-4CCD-9E48-CE78E874A11C</gtr:id><gtr:title>Some issues in computational modelling: Occam's Razor and Hegel's hair gel.</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f48a9281451af158432eda05da305c4"><gtr:id>2f48a9281451af158432eda05da305c4</gtr:id><gtr:otherNames>Shillcock R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>546dd83a06b368.13481877</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B3AAB32B-DB0D-4C3A-B5AB-7545BCD3E093</gtr:id><gtr:title>The Concrete Universal and Cognitive Science</gtr:title><gtr:parentPublicationTitle>Axiomathes</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2f48a9281451af158432eda05da305c4"><gtr:id>2f48a9281451af158432eda05da305c4</gtr:id><gtr:otherNames>Shillcock R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>546dd4504a9918.93418136</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RES">RES-000-22-3600</gtr:identifier><gtr:identifier type="RCUK">ES/H002839/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>64564C94-AC7F-4056-903D-0AED107A359E</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Education</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>64564C94-AC7F-4056-903D-0AED107A359E</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Education</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>