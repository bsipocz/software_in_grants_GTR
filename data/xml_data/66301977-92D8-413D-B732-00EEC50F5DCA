<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/AA6E6E03-A703-45C0-8978-64589E5CECD4"><gtr:id>AA6E6E03-A703-45C0-8978-64589E5CECD4</gtr:id><gtr:name>University of A Coruna</gtr:name><gtr:address><gtr:line1>Campus da Zapateira</gtr:line1><gtr:line2>9 calle maestranza</gtr:line2><gtr:postCode>15001</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Ophthalmology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/AA6E6E03-A703-45C0-8978-64589E5CECD4"><gtr:id>AA6E6E03-A703-45C0-8978-64589E5CECD4</gtr:id><gtr:name>University of A Coruna</gtr:name><gtr:address><gtr:line1>Campus da Zapateira</gtr:line1><gtr:line2>9 calle maestranza</gtr:line2><gtr:postCode>15001</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2D53F5AB-1256-4813-BF74-4AFDE1870B96"><gtr:id>2D53F5AB-1256-4813-BF74-4AFDE1870B96</gtr:id><gtr:firstName>Adam</gtr:firstName><gtr:otherNames>Murdin</gtr:otherNames><gtr:surname>Sillito</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/9146EF2B-B6AF-49DA-A6C1-36EEB68F077B"><gtr:id>9146EF2B-B6AF-49DA-A6C1-36EEB68F077B</gtr:id><gtr:firstName>Stewart</gtr:firstName><gtr:otherNames>David</gtr:otherNames><gtr:surname>Shipp</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FG022305%2F1"><gtr:id>66301977-92D8-413D-B732-00EEC50F5DCA</gtr:id><gtr:title>Top-down and bottom-up selective mechanisms in attention: subcortical convergence in visual thalamus?</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/G022305/1</gtr:grantReference><gtr:abstractText>If a lime gets amongst the lemons at a supermarket fruit stall, it's easily spotted. But a rogue satsuma nestling amidst the clementines is less easily detected, and a novice stock-keeper might need it to be physically pointed out, before he can see it. These are simple examples of two converse ways in which we select an item deserving of attention, referred to by psychologists as 'bottom-up and 'top-down', respectively. In the first example the conspicuous quality of the misplaced lime is termed 'salience'. No property (e.g. 'green' or 'oval shaped') is inherently salient , it all depends on context. In Piccadilly Circus, where everything is designed to be salient, nothing really dominates - giving the sensation of being visually overwhelmed, and not knowing where to look first. In this situation, a 'top-down' instruction - a pointing cue, or a verbal command, can be rather helpful. Redirecting gaze is the typical expression of visual attention, but is not automatic. The focus of attention - the mind's eye - may rove about whilst gaze is frozen (as in social groupings, to avoid eye contact). Attention thus precedes an eye movement, and our aim is to study exactly what happens in the brain at this formative stage. We propose to do this by recording neural activity in the thalamus, a brainstem organ generally responsible for regulating the traffic of sensory information amongst different areas of the cerebral cortex (the brain's top level of information processing). As a strategy, this could be likened to studying the operation of a TV broadcast controlroom, as it covers, say, a Formula 1 Grand Prix. The controlroom receives multiple feeds from all over the racecourse, and the TV-director selects the most dramatic action for transmission to the viewing public. In the terms of this analogy, the thalamus (and in particular a component known as the 'pulvinar') assesses feeds from multiple areas of cerebral cortex - some describing events as they occur, others predicting such events. However, the pulvinar's 'viewing public' is nothing other than the set of cortical areas that provide its input. In other words, the pulvinar is in two-way communication with the cerebral cortex, and acts as a device enabling cortical areas to vote amongst themselves which visible item is the most attention-worthy. Attention is absent under anaesthesia, so we plan to record thalamic activity from an alert, nonhuman primate (NHP). The animal is confronted with an array of items and trained to select the salient item, or a non-descript one that has been pointed out by a suitable visual cue. A neuron in the thalamus, like other visual centres, has a restricted 'receptive field' (RF) - it scrutinises a certain window in the field of view. We locate the RF of a neuron under study, and arrange that it contains the salient, or cued item. Next trial, the target item may be elsewhere. We seek to find neural activity that corresponds to the behavioural significance of the item within the RF, independent of its particular visual features. The timing of activity may vary between the experimentally arranged bottom-up and top-down circumstances and especially, also, between thalamic subdivisions that are differentially connected to bottom-up and top-down cortical pathways. There is another twist to the strategy. We adjust the level of difficulty of the task and monitor how well the NHP performs. It may take longer to reach a decision, or begin to make mistakes. Changes in activity are calibrated against accuracy of performance, to index the dependency of behaviour on specific neural activity. Finally, we can also apply artificial pharmacological stimulation or inhibition to the test site to see if we can influence the selection of the item in its RF - will these artificial manipulations change behavior in line with predictions furnished by neural recordings?</gtr:abstractText><gtr:technicalSummary>The LGN may differentially amplify selective features of the visual image. In the pulvinar, a 2nd-order thalamic nucleus, cortical inputs replace retinal ones. A signature characteristic - the 'replication principle' - is that reciprocally linked pairs of cortical areas are also enabled to connect indirectly via the pulvinar. If direct intercortical links are adept at feature information transfer, the pulvinar may act to regulate transcortical traffic. Neural models of attention posit a competitive process between rival visible items. Since each item is represented across multiple areas of cortex, a mechanism is inferred to ensure that the dominant activation in each area does not derive from different items - to avert a fragmented, rather than focused state of attention. The project asks if the pulvinar and LGN together are instrumental in so coordinating cortical activity. Automatic bottom-up mechanisms of spatial selection will be contrasted with top-down selection mediated by a symbolic cue. NHPs will be trained to select a salient item, or a cued item from an array of distractors, and we shall look for a neuro-behavioural correlate between psychophysical task performance over a range of difficulty, and concurrently recorded thalamic activity. We shall also apply pharmacologically mediated stimulation and inhibition to the test site, to test the predicted effects upon task performance. We also aim to distinguish the functions of the dorsal and ventral pulvinar subdivisions (DP and VP). DP is directly linked to a fronto-parietal attention control network, VP to the ventral pathway for object analysis - associating DP and VP with cued or salience driven mechanisms respectively. DP and VP do not communicate directly, but indirect circuits exist to transfer salience and cue information between them. The nature of the circuitry thus predicts the relative timing of top-down and bottom-up attentional mechanisms within DP and VP, and between pulvinar and LGN.</gtr:technicalSummary><gtr:fund><gtr:end>2014-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2010-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>1333486</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of A Coru?a</gtr:collaboratingOrganisation><gtr:country>Spain, Kingdom of</gtr:country><gtr:description>Cudeiro BBSRC</gtr:description><gtr:id>EFF1E8CC-12EE-4621-BC28-BB432387FBFB</gtr:id><gtr:impact>New Software - Opticka
Manuscripts currently under review and in preparation.</gtr:impact><gtr:outcomeId>542705a2815e71.17730802-1</gtr:outcomeId><gtr:partnerContribution>Team members have visited their laboratory to acquire complementary expertise necessary for this project and have participated in experiments there as well.</gtr:partnerContribution><gtr:piContribution>Our laboratories have complementary expertise and research programmes - we have developed a new visual display/acquisition program to enable us to gather data for the project and the programming for this has been made available to them. The results from the work carried out here have also driven a new project in Spain, where they have access to certain techniques that we do not.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>This work has contributed in an original way to the understanding of the processes of vision by probing higher order visual processes standing in the interface between cortex and thalamus. By adding to knowledge of how the brain musters finite resources to tackle very complex problems, the results are highly relevant in guiding strategies driving computational approaches to vision and the development of artificial visual systems for computational, industrial and medical systems. The work has also advanced knowledge of a key brain mechanism with relevance to health and disease.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>7FF2196D-3CF8-481F-B9A1-64D6C4FDA0D9</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>542069b70150f8.39188044</gtr:outcomeId><gtr:sector>Healthcare,Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The global objective of our work was to advance our understanding of the way the central visual system reconstructs the visual world from the retinal input with particular emphasis on the role of the looped feedback circuits involving the lateral geniculate (LGN) and pulvinar thalamic components of the visual system, and their role in attentional mechanisms. 

Perceptually, our visual system reconstructs objects from the diverse components of early distributed processing by grouping image elements and segregating them from the background as a figure. Detection of a salient target is a standard means of investigating bottom-up attentional mechanisms and our primary task was based on the use of a figure ground pop-out paradigm. 

Figure-ground discrimination refers to the perception of an object, the figure, against a nondescript background. Neural mechanisms of figure-ground detection are commonly linked to feedback interactions between higher centers and primary visual cortex, and held to index the impact of global analysis upon local feature encoding. In the current work, in recordings from visual thalamus of alert primates, we demonstrated a robust enhancement of neuronal firing when the figure, as opposed to the ground, component of a motion-defined figure-ground stimulus was located over the receptive field. Stochastically, visual stimulation of the receptive field and its near environs was identical across both conditions, suggesting that the response enhancement reflects higher integrative mechanisms. It thus appears that cortical activity generating the higher order percept of the figure is simultaneously re-entered into the lowest level that is anatomically possible - the thalamus - so to govern the dynamics of the evolving featural representations in the cortex. This suggests that the signature of a higher order percept is fed back into the thalamus in a re-entrant manner, thus changing the information relayed to the cortex. It argues for a re-evaluation of some of the iterative neural mechanisms that represent and extract salient features of the visual world.

Overall, this work has provided a significant advance in our understanding of the contribution of thalamic processes to the mechanisms of visual perception and attention. The surprising complexity of the responses in the LGN added an extra dimension to the way we originally conceived the work and the results have delivered new insight into the way the LGN is linked into these brain mechanisms.</gtr:description><gtr:exploitationPathways>Our data have contributed in an original way to the understanding of the processes of vision by probing higher order visual processes standing in the interface between cortex and thalamus. As the thalamo-cortico-thalamic circuitry is broadly common to all mammalian sensory systems, the recognition of what happens in the visual system should generalize across other modalities. By adding to knowledge of how the brain musters finite resources to tackle very complex problems the results may also guide strategies driving computational approaches to vision and contribute to ways of optimising system performance with finite resources in the development of artificial visual systems for computational, industrial and medical systems. The work has also advanced knowledge of a key brain mechanism with relevance to health and disease. Our data suggest that the visual input from the thalamus to the cortex is constantly rephrased in terms of the priors reflecting the interpretation extracted by higher levels and the attentional focus. This may have major consequences for our understanding of filling in mechanisms operating in retinal disease and the way in which cortical feedback projections may generate hallucinations in AMD patients with denervated thalamus and in schizophrenia.</gtr:exploitationPathways><gtr:id>52B8AC0B-7F77-4BA3-B3B3-222611F1E805</gtr:id><gtr:outcomeId>54206a246b1de9.15702106</gtr:outcomeId><gtr:sectors><gtr:sector>Healthcare,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Opticka Stimulus Generator is an object oriented framework with optional GUI for the Psychophysics toolbox (PTB), allowing randomised interleaved presentation of complex stimuli. It is designed to work on OS X, Windows (currently no digital I/O) or Linux, and interfaces via strobed words (using either a DataPixx [15bit] or a LabJack [11bit]) and ethernet with a Plexon Omniplex for recording neurophysiological data. Behavioural control uses the Eyelink eye tracker and a full behavioural repertoire is available by using a state-machine logic. Opticka uses the ethernet interface to the Eyelink thus affording much better control and reliability over using the analog voltages alone. The various classes can be used without the need to run the GUI and stimuli provide a unified interface (setup, animate, draw, update, reset) to integrate into standard PTB routines. The various object methods take care of all the background geometry and normalization, meaning stimuli are much easier to use than &amp;quot;raw&amp;quot; PTB. Analysis routines are also present for taking the raw Plexon files (.PLX or .PL2) and Eyelink files (.EDF) and parsing them into a consistent trials and variable structure, for analysis in matlab, or interfacing directly with Fieldtrip for further spike and LFP analysis.</gtr:description><gtr:id>2C53B6F2-9C47-4DA9-A155-7C3811095DB2</gtr:id><gtr:impact>This visual display and experimental control software has underpinned our ability to generate the necessary visual stimuli and control paradigms to gather the experimental data in our acute and behaving primate work. The software is now also being used by one of our collaborators on the project.</gtr:impact><gtr:outcomeId>5427043bc21e67.94157205</gtr:outcomeId><gtr:title>Opticka visual stimulation presentation and experimental control and analysis software</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/iandol/opticka/tree/v1.004</gtr:url><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>641135F9-F509-4B70-B63A-149490D4E080</gtr:id><gtr:title>Focal Gain Control of Thalamic Visual Receptive Fields by Layer 6 Corticothalamic Feedback.</gtr:title><gtr:parentPublicationTitle>Cerebral cortex (New York, N.Y. : 1991)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fbc349d2fc465d67b54b7c17905208d7"><gtr:id>fbc349d2fc465d67b54b7c17905208d7</gtr:id><gtr:otherNames>Wang W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2018-01-01</gtr:date><gtr:issn>1047-3211</gtr:issn><gtr:outcomeId>58bc904793aeb2.62035133</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>44FD934D-3839-45CC-A5D4-BB7612E81399</gtr:id><gtr:title>Figure-ground modulation in awake primate thalamus.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93ea4f380bdda00b56e830cfa03018a1"><gtr:id>93ea4f380bdda00b56e830cfa03018a1</gtr:id><gtr:otherNames>Jones HE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn><gtr:outcomeId>5675e300dcd2e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>869E16C7-6939-4FD3-BC0C-B709B4953176</gtr:id><gtr:title>Spike stochastics during figure-ground discrimination in primate LGN</gtr:title><gtr:parentPublicationTitle>Neuroscience Meeting Planner. San Diego, CA: Society for Neuroscience, 2013. Online</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/61e769de86a60c3e3b45ecf3f8caf7eb"><gtr:id>61e769de86a60c3e3b45ecf3f8caf7eb</gtr:id><gtr:otherNames>Andolina, I.M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>542700143d5145.61303426</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A1B1B439-97B8-4C96-9A69-1D6D55DEA8FB</gtr:id><gtr:title>Figure-ground modulation in primate LGN</gtr:title><gtr:parentPublicationTitle>Neuroscience Meeting Planner. San Diego, CA: Society for Neuroscience, 2013. Online</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f6704fa39ed5a348a780cd4e5c64182c"><gtr:id>f6704fa39ed5a348a780cd4e5c64182c</gtr:id><gtr:otherNames>Jones, H.E.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5426ffaaa77479.10796022</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/G022305/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>