<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/C6BE156F-9B9E-4CB2-B699-F05BD793F5B9"><gtr:id>C6BE156F-9B9E-4CB2-B699-F05BD793F5B9</gtr:id><gtr:name>Stroke Association</gtr:name><gtr:address><gtr:line1>Stroke Association House</gtr:line1><gtr:line2>240 City Road</gtr:line2><gtr:postCode>EC1V 2PR</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:department>Centre for HCI Design</gtr:department><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C6BE156F-9B9E-4CB2-B699-F05BD793F5B9"><gtr:id>C6BE156F-9B9E-4CB2-B699-F05BD793F5B9</gtr:id><gtr:name>Stroke Association</gtr:name><gtr:address><gtr:line1>Stroke Association House</gtr:line1><gtr:line2>240 City Road</gtr:line2><gtr:postCode>EC1V 2PR</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/7167774E-5158-4FA2-AF9C-6D34140A863B"><gtr:id>7167774E-5158-4FA2-AF9C-6D34140A863B</gtr:id><gtr:name>The Stroke Association</gtr:name><gtr:address><gtr:line1>Mitchell House</gtr:line1><gtr:line2>433 Chiswick High Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>W4 4AU</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8A8A6CA6-5ECA-45A9-BF7A-E131DBB82E3C"><gtr:id>8A8A6CA6-5ECA-45A9-BF7A-E131DBB82E3C</gtr:id><gtr:firstName>Tim</gtr:firstName><gtr:surname>Pring</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/8585A06D-A4E9-4B0F-9FD8-83B753B973E2"><gtr:id>8585A06D-A4E9-4B0F-9FD8-83B753B973E2</gtr:id><gtr:firstName>Naomi</gtr:firstName><gtr:surname>Cocks</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5C69B7CD-C70B-4FA0-9846-5CEE030880E6"><gtr:id>5C69B7CD-C70B-4FA0-9846-5CEE030880E6</gtr:id><gtr:firstName>Jane</gtr:firstName><gtr:surname>Marshall</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/6333DA1B-AA36-4542-B0AC-8E7C23016863"><gtr:id>6333DA1B-AA36-4542-B0AC-8E7C23016863</gtr:id><gtr:firstName>Stephanie</gtr:firstName><gtr:surname>Wilson</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/AAA7DC97-99DD-4D22-AF37-DEDB73E5AE4B"><gtr:id>AAA7DC97-99DD-4D22-AF37-DEDB73E5AE4B</gtr:id><gtr:firstName>Julia</gtr:firstName><gtr:otherNames>Rose</gtr:otherNames><gtr:surname>Galliers</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FI001824%2F1"><gtr:id>48D7DDF9-79F9-4989-9773-44290BFD648C</gtr:id><gtr:title>Gesture Recognition in Aphasia Therapy</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/I001824/1</gtr:grantReference><gtr:abstractText>Aphasia is a language disorder, usually caused by stroke. It affects a substantial number of people; there are about 250,000 people living with aphasia in the UK and approximately 45,000 new cases each year. People with aphasia have difficulty with all aspects of communication: speaking, reading and writing. The negative effects of aphasia can be immense and are not confined to the affected person but are also felt by the immediate family and social circle.One approach advocated by therapists is for the aphasic person to communicate using gestures, but this also poses challenges as the ability to produce and understand gestures may be impaired. In recent research we have investigated whether gesture production can be enhanced by therapy and the initial evidence from face-to-face therapy is encouraging. However gesture therapy is resource-intensive and this has motivated our proposal.Our goal is to develop and pilot an innovative gesture training tool to be used in aphasia therapy at home. This will build on our existing work on non-computer based therapy and there is no previous published research in this area. Our approach to achieving this goal will be to refine and adapt existing gesture recognition technology, incorporating it within a training package that we will develop. In so doing, we will refine and exploit existing research into gesture recognition and gesture-based interaction, utilising mainstream interaction devices such as the Nintendo Wii remote and open source software. We will investigate appropriate forms of gesture recognition and feedback for this user community.The development of the tool will address several fundamental issues: it needs to recognise a substantial set of gestures that are relevant to the aphasic user and can be trained by the therapist; it must not be over-sensitive as gesture production is likely to be variable and inaccurate; we need to understand and incorporate appropriate forms of training and feedback in the tool.Research in the wild is integral to this proposal. Close engagement with the user community will be facilitated by our project partner, the Stroke Association. Aphasic people will be employed as consultants in exploring and evaluating gesture recognition technologies as the design and development of the therapy tool progresses. In the later stages of the project, a pilot study will be conducted with 10 people who have severe aphasia to investigate the therapeutic efficacy of the tool as well as its broader acceptability.The potential transformational impact of using gesture-recognition technology in therapy is significant. Given the numbers of people affected by aphasia, the provision of a therapeutically effective, low-cost, gesture training tool would be of substantial benefit.</gtr:abstractText><gtr:potentialImpactText>Who will benefit from this research? The main beneficiaries will be people with aphasia. Aphasia affects about 250,000 people in the UK and profoundly impairs quality of life. Secondary beneficiaries will be caregivers of people with aphasia, a group at risk of negative health outcomes [1], and rehabilitation staff and services, particularly speech and language therapists. Other disabled groups, e.g. people with intellectual disorders, may benefit from similar creative uses of interaction technologies. HCI and LCS researchers will benefit from exposure of ideas to the user community. IT companies may benefit from commercial development and exploitation of the tool. How will they benefit? Aphasic people will benefit by acquiring a new therapeutic tool that will help them learn a vocabulary of gestures and hence communicate with family members and friends. Wii applications with other disabled groups suggest that there may be further benefits for mood and wellbeing [2]. Family members will also benefit from the communicative gains. We will select gestures that relate to caregiving (e.g. 'drink' and 'toilet') to help alleviate carers' burden. Rehabilitation staff will acquire a new therapeutic tool to use with their aphasic clients, based on cheap and widely available technology. As the tool is self administered it should be highly cost effective. This is important, given the scarcity of face-to-face therapy: many clinical settings offer only minimal provision [3]. Timescales: The gesture training tool will be available 12 months into the project, when it will be piloted with 10 aphasic people. If the results are positive, we will make the tool widely available to the stroke and clinical communities. Thus there will be immediate benefits. We will also seek funding for a large follow up trial with at least 50 users. This will provide class 1 evidence about the efficacy of the tool. The current and follow up study will be informative for rehabilitation staff working with other client groups, and may promote further adaptations. Such subsidiary benefits are long term (3-8 years). What will be done to ensure that they have the opportunity to benefit? Engagement with aphasic people is integral to this research. Aphasic consultants will advise on the development of the technology, and different pilot participants will test its learning potential and acceptability. We will consult and inform participants' main carers. Results will be disseminated through the 30 London stroke groups affiliated to the Stroke Association and a travelling road show will give group members taster opportunities with the technology. Results of the study will be published in outlets designed for people with aphasia, such as 'Aphasia Now' (website). Additional activities will engage clinical staff. We will stage a CPD training event, to report on the project findings and give clinicians access to the technology. Practising therapists will be invited to trial the therapy tool with their clients, and give feedback. We will target both clinical and academic audiences when writing for publication and making conference presentations. Any Intellectual Property arising from the project will be protected through patent applications by the University's dedicated Research and Enterprise (CREU) team. We anticipate further development of the tool following feedback from the pilot and will work with CREU to achieve this through technology transfer opportunities. The project team is very experienced in engaging user communities and carrying out high impact research, e.g. exploring computer applications in healthcare (HCID) and outcomes from novel therapies (LCS). Thus the team offers an ideal synergy of skills for this project. 1. Bakas, T. et al (2006) Rehabilitation Nursing, 31 (1) 33 - 42 2. Science Daily (2009) Nintendo Wii may enhance Parkinson's Treatment. 3. Enderby, P. et al (2002) Clinical Rehabilitation, 16, 604-608.</gtr:potentialImpactText><gtr:fund><gtr:end>2012-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2010-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>297280</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Stroke Association</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Project Collaborator</gtr:description><gtr:id>C125AE18-44DB-4402-B276-A254AE39F68F</gtr:id><gtr:impact>All project outputs.</gtr:impact><gtr:outcomeId>58c8f9b8ca91e7.70534570-1</gtr:outcomeId><gtr:partnerContribution>Participated in advisory meetings, provided us with access to stroke groups for recruitment and dissemination, supported dissemination activities.</gtr:partnerContribution><gtr:piContribution>Co-design of the GeST therapy tool, implementation of GeST, field study with people who have aphasia, dissemination activities including road shows at stroke groups.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Research Presentation at 15th International Aphasia Rehabilitation Conference.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>37A908A7-797E-41BB-AA0C-6B9A715EBDFE</gtr:id><gtr:impact>Discussion and dissemination.

Increased international profile.</gtr:impact><gtr:outcomeId>54628ae6db51c2.71456776</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research Presentation at RAatE 2012 Conference</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>2BD7F19C-0000-457C-B5AD-DC102E6F84C0</gtr:id><gtr:impact>Dissemination and contacts.

Raised profile.</gtr:impact><gtr:outcomeId>54628c638c6c26.33483078</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited Research Presentation at UK Stroke Forum 2013</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>75972A15-FAFF-41B1-AB99-5DDF3647A05D</gtr:id><gtr:impact>Shared information. Sparked interest and discussion.

Raised profile and interest in our work.</gtr:impact><gtr:outcomeId>54628db39af661.33857616</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Video of GeST, a software tool for gesture therapy</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>14D737C7-8FF2-4AFD-A6D5-224720AA3A84</gtr:id><gtr:impact>http://vimeo.com/40089296.

International contacts.</gtr:impact><gtr:outcomeId>r-247716587.267552140c0ac2fc</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://vimeo.com/40089296</gtr:url><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Press release</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>A4BE2C7B-BC9E-46B6-9445-219EBF4A481C</gtr:id><gtr:impact>Press release.

n/a</gtr:impact><gtr:outcomeId>r-5709498865.2593450bcfed4e</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>GeST Road Shows</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>7BBFC543-DFAE-4DF8-AF23-255C09972AF7</gtr:id><gtr:impact>A series of events where GeST was demonstrated at Stroke Clubs. Resulted in discussion and the recruitment of research participants.

New research participants and contacts with Stroke Group co-ordinators.</gtr:impact><gtr:outcomeId>r-7910876654.0054940bfac3a2</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research Seminar: Fun and Consistency: Engaging Interaction Design for People with Aphasia</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>BD6490C0-5F53-4A8B-BCDB-6B9C79E2E0AE</gtr:id><gtr:impact>Research seminar at UCL, November 2011.

n/a</gtr:impact><gtr:outcomeId>r-1920806292.37071250bc657c0</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>GReAT Project Video</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>B585DFE5-411A-4631-B926-03E4A6607584</gtr:id><gtr:impact>Video introducing the context within which the research was undertaken and main achievements of the project.

http://vimeo.com/40081415.

International contacts.</gtr:impact><gtr:outcomeId>r-3889938140.1854920c0ac1c6</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://vimeo.com/40081415</gtr:url><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research Seminar: Engaging and Accessible Interaction Design for People with Aphasia</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>083BD2EF-FB70-46BC-9FAD-E3D12BD632BA</gtr:id><gtr:impact>Research seminar at Brunel University.

n/a</gtr:impact><gtr:outcomeId>r-2015158275.15642930bfa5598</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research Presentation to Frenchay Computers in Therapy SIG. GeST: Computer Delivered Gesture Therapy for People with Aphasia</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>267E66D2-0D58-45F3-B2B0-6F23D621261D</gtr:id><gtr:impact>Research and practice presentation. 
Presentation to Frenchay Computers in Therapy SIG.
Talk sparked questions and discussion.

Talk sparked questions and discussion.</gtr:impact><gtr:outcomeId>r-344783775.82950870bfa5160</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Video: Demonstration of the GeST tool</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>1C430106-F942-49F1-AE93-2FBF13F4AE52</gtr:id><gtr:impact>Video demonstrating the first prototype of GeST.

Contacts.</gtr:impact><gtr:outcomeId>r-8496432219.1629860bcfcd32</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://vimeo.com/37727969</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Research Presentation at British Aphasiology Society Therapy Symposium, Sept 2012</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>0562521F-04B6-468F-8E40-B832281844C0</gtr:id><gtr:impact>Questions and discussion.

n/a</gtr:impact><gtr:outcomeId>54628b9e12f947.82013481</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Presentation at Centre for HCI Design Open Day 2012</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>A0B7F0E2-374B-4A54-BA88-C81020A18B1D</gtr:id><gtr:impact>Talk sparked discussion.

New contacts.</gtr:impact><gtr:outcomeId>r-2609901859.06170130bfa528c</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2012</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Gesture-Based Interaction In The Rehabilitation of Stroke Survivors</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>F5E7481A-4121-4246-9527-C120328B84C5</gtr:id><gtr:impact>Research presentation.

n/a</gtr:impact><gtr:outcomeId>r-1211434594.55243730bc58b56</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>1000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>City University Alumni Fund</gtr:description><gtr:end>2012-12-02</gtr:end><gtr:fundingOrg>City, University of London</gtr:fundingOrg><gtr:id>B74B94D7-E969-47CF-A32F-D6BE58A49580</gtr:id><gtr:outcomeId>5ed43b7e5ed43b92</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2011-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>50000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>City University London Doctoral Studentship</gtr:description><gtr:end>2015-03-02</gtr:end><gtr:fundingOrg>City, University of London</gtr:fundingOrg><gtr:id>B63749A1-9D47-404F-A36C-721E31B28CEA</gtr:id><gtr:outcomeId>54629766dc9ac6.86649531</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-04-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>5000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:department>Research Pump-Priming Fund</gtr:department><gtr:description>Exploring the Accessibility of Second Life for People with Aphasia (EASE)</gtr:description><gtr:end>2012-10-02</gtr:end><gtr:fundingOrg>City, University of London</gtr:fundingOrg><gtr:id>367D7B9F-57AA-4C84-9119-BB59A945BDF3</gtr:id><gtr:outcomeId>5ed43fa25ed43fb6</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-04-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>204898</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Evaluating the effects of a virtual communication environment for people with aphasia</gtr:description><gtr:end>2015-08-02</gtr:end><gtr:fundingOrg>Stroke Association</gtr:fundingOrg><gtr:id>2EB04EB4-B698-4F9E-A07C-4CEFE5CCB39C</gtr:id><gtr:outcomeId>5ec386125ec38626</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2012-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>53263</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Research grant. Remote Aphasia Therapy: A Feasibility Study</gtr:description><gtr:end>2013-09-02</gtr:end><gtr:fundingOrg>The Tavistock Trust for Aphasia</gtr:fundingOrg><gtr:id>E7542104-1D07-428C-8176-630B08E54A46</gtr:id><gtr:outcomeId>5463daa2e30643.65503485</gtr:outcomeId><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2012-10-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings have:
- Inspired further research into technologies, including therapeutic technologies, for people with aphasia.
- Been taken forward into a doctoral research project that is using the GeST software in further trials.
- Been disseminated directly to practitioners and user groups, contributing to a heightened awareness of the therapeutic potential of technology for people with aphasia. 
- Contributed to an increasing body of knowledge on how to design technology that is accessible to people with aphasia. E.g. a presentation on UX design for people with language impairments to the UXPA UK in Feb 2016.
Opportunities for making the software available to practitioners are being explored.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>3704E73B-A7CE-4AA9-BBAD-5FD7080B8D48</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:outcomeId>546294e490ce28.30860925</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Aphasia is a communication disorder that sometimes occurs after a stroke and can affect all aspects of a person's use of language: speaking, reading, writing and comprehension. One possibility for people with aphasia is to use non-verbal communication strategies such as gestures instead but their ability to produce gestures may also be impaired. Therapy to enhance the production of gestures is usually delivered by speech and language therapists; the GReAT project aimed to provide a novel, computer-based alternative.

The overall objective of GReAT was to investigate, prototype and trial a gesture therapy tool for use at home by people with aphasia. The key findings from the research lay in three areas:

1. Interaction design for people with aphasia
Current guidelines for designing accessible interactive technologies provide little advice on designing for aphasia; the first of our key findings was a contribution to this area. We ran a series of participatory design workshops with 5 people who have aphasia who were employed as consultants on the project. The workshops explored how people with aphasia interact with technologies, where they are successful and where they face challenges. The results were reported as a set of initial design principles (Galliers et al, 2011) and as techniques and lessons learned for facilitating participation of people with aphasia in design (Galliers et al, 2012).

2. GeST: a gesture therapy tool for people with aphasia
We designed and implemented GeST, a prototype gesture therapy tool to help people with aphasia improve their gesturing (Marshall et al, 2013) (Wilson et al, 2015). GeST works by demonstrating communicative gestures (such as phone, umbrella, glasses) to the user, detecting the user's attempts to produce the gestures and providing motivational feedback. It incorporates computer vision-based gesture recognition technology and a 3D world to provide an engaging interactive experience. GeST is novel both as a mechanism for providing gesture therapy and in its use of a 3D virtual world in a therapy tool for people with aphasia.

3. Therapy study
An eight-month, home-based study was undertaken to investigate the therapeutic efficacy of GeST (Marshall et al, 2013). The study involved 10 participants with severe aphasia; 9 successfully completed the therapy. The primary aim was to determine whether GeST improved gesture production; secondary aims were to investigate whether GeST improved production of spoken words, its acceptability and its usability.
Results showed that gestures practised with GeST improved significantly after therapy and the gain was maintained. The gains only occurred on items that were practised with GeST and therapist support. There was no generalisation to unpractised gestures and no effect on spoken words. Usability results were positive: results showed that GeST provoked interest, motivation and a sense of fun.</gtr:description><gtr:exploitationPathways>1. The principles for accessible design can be applied by practitioners involved in the design and implementation of a broad range of interactive technologies for people with communication impairments. These principles are being developed further in a subsequent research project (EVA).

2. The GeST prototype could be developed into a robust software package that could be made widely available to therapists and people with aphasia. We are exploring options for follow-on funding for this purpose.

3. A PhD student has undertaken a further, more substantial, empirical study of the GeST tool involving 20 people with aphasia. This work will be reported in late 2016.

4. The research has, and will continue to, raise awareness of the potential role of digital technology in aphasia therapy. It has demonstrated a novel approach to utilising technology which has attracted significant interest from both academic researchers and practitioners.</gtr:exploitationPathways><gtr:id>4BC193F3-0283-4195-894B-9C4336E047B2</gtr:id><gtr:outcomeId>r-5569025860.6979867d659426</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>C1D25F76-6661-4979-B537-AB7268705A63</gtr:id><gtr:title>Computer delivery of gesture therapy for people with severe aphasia</gtr:title><gtr:parentPublicationTitle>Aphasiology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/39b67e551d367c42fa1ba3570c32e0df"><gtr:id>39b67e551d367c42fa1ba3570c32e0df</gtr:id><gtr:otherNames>Marshall J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53d03c03c46108cb</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8D27AA06-C174-48D4-89ED-F787497E3D33</gtr:id><gtr:title>An exploratory study into the accessibility of a multi-user virtual world for young people with aphasia</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9451b7bd3fe1e5ed6c8d8532d543ffcc"><gtr:id>9451b7bd3fe1e5ed6c8d8532d543ffcc</gtr:id><gtr:otherNames>Galliers J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>56afde3fd8be87.44902447</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FC409C25-6842-4A62-A89F-8ADD3EA63CD7</gtr:id><gtr:title>Codesign for people with aphasia through tangible design languages</gtr:title><gtr:parentPublicationTitle>CoDesign</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7fa67ef462f1c2f32c599b852900c665"><gtr:id>7fa67ef462f1c2f32c599b852900c665</gtr:id><gtr:otherNames>Wilson S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56afda69eceb40.31250297</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/I001824/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>40</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>FD25826C-8B50-43A3-8871-3FF08D051906</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Biomechanics &amp; Rehabilitation</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0AD041FC-DCB2-46BB-B9CC-ADDFF2FA5E17</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Human-Computer Interactions</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E48C802F-8897-4353-910A-09D09331BB82</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Medical science &amp; disease</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>10</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>