<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/8319F78A-DCBD-49F6-BE00-78E1CD75CDA9"><gtr:id>8319F78A-DCBD-49F6-BE00-78E1CD75CDA9</gtr:id><gtr:name>University of York</gtr:name><gtr:address><gtr:line1>Heslington</gtr:line1><gtr:line4>York</gtr:line4><gtr:line5>North Yorkshire</gtr:line5><gtr:postCode>YO10 5DD</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/B83892A3-8FDF-47C1-A48C-043BCF174A0B"><gtr:id>B83892A3-8FDF-47C1-A48C-043BCF174A0B</gtr:id><gtr:firstName>William</gtr:firstName><gtr:otherNames>Alfred</gtr:otherNames><gtr:surname>Smith</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FF036949%2F1"><gtr:id>2EA17DE6-8367-4632-ABD1-B365913B8813</gtr:id><gtr:title>Combining Model- and Irradiance-based Constraints for Improved Face Shape Recovery and Recognition From Single Images</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F036949/1</gtr:grantReference><gtr:abstractText>The problem of estimating 3-dimensional face shape from single images has attracted considerable attention in recent years. One of the reasons for this is that 3D shape information provides a pose and illumination invariant description of a face, which can either be used for recognition directly, or to produce illumination and pose normalised images for input to a 2D recognition system. Recent work which has performed recognition using 3D face shape information acquired through non-standard sensing modalities has demonstrated the potential benefits of 3D over 2D intensity images. The most important of these are improved robustness to changes in pose, illumination and expression. However, the benefits of using the face over other biometrics are lost in these systems since they require the participation and knowledge of a subject. On the other hand, systems which require only a single intensity image as input may be deployed in any scenario where existing equipment captures image data, for example CCTV cameras. Crucially, such a system could be used to recognise subjects for whom only a single training image exists. It is therefore clear that some of the most alluring applications of face recognition technology are made possible by robust methods for face shape recovery from single images. Recent advances in this area have followed two distinct avenues of research. The first uses a morphable model of facial appearance while the second uses classical shape-from-shading techniques. The body of work which uses morphable models offers globally accurate and robust shape recovery from real images, but fitting the model to an image is computationally expensive and the recovered shape lacks local detail and only weakly satisfies image irradiance constraints (and hence photorealism). Recent results in shape-from-shading have shown that fine local surface detail can be recovered from face images but that the estimated global 3D shape is of inferior quality to that recovered using a morphable model. The primary aim of this proposal is to research new methods which will lie between these currently divergent strands of research. In doing so, the hope is to combine the strengths of both approaches while tackling the weaknesses described above. We also intend to explore avenues of research relating to statistical modelling of cast shadow formation and revisiting the process of morphable model construction. Finally we will apply these enhanced techniques to challenging face recognition tasks.</gtr:abstractText><gtr:fund><gtr:end>2012-02-03</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-08-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>127309</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>In a follow-on project, I obtained funding from DSTL through their Centre for Defence Enterprise programme. This led to development of a system for reconstructing high quality face images from one or more low resolution/low quality images. The system was demonstrated to commercial customers at a week-long field trial showcase at Porton Down. Subsequently, commercial partners have expressed interest in the approach and our final report has been shared with them to enable exploitation.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>A3136F7A-ED07-485A-A4AB-47FA35E25894</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>56ddc332d3b910.15597658</gtr:outcomeId><gtr:sector>Aerospace, Defence and Marine,Security and Diplomacy</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The aim of this research was to advance the state-of-the-art in reconstructing 3D models from single images of faces. This process provides a route to pose and illumination insensitive face recognition given only a single training image of a face. There are also many applications in graphics and animation where estimating 3D models from images or editing illumination or texture properties is useful.

The project succeeded in advancing the state-of-the-art in a number of ways:

1. A major problem with statistical-model-based approaches is &amp;quot;model dominance&amp;quot;. The result is that reconstructed models are too close to the average face and lack identifying features. We proposed using shading cues to overcome this limitation and suggested new statistical constraints that encourage solutions further from the mean.
2. Previous methods were limited to either overly simplistic models of illumination or overly simplistic models of skin reflectance. We developed the first method that can handle both arbitrarily complex illumination and non-Lambertian reflectance. Moreover, our method can be solved using convex methods and, hence, always obtains the best possible result.
3. The process of constructing a morphable model has not been studied in depth before. We made advances in the statistical modelling and computational geometry involved in the groupwise processing of a set of face meshes.</gtr:description><gtr:exploitationPathways>The two most likely areas for commercial exploitation of the results of this project are: 1. security (biometrics and face recognition), 2. entertainment (visual effects and gaming). The project succeeded in enabling high detail 3D face models to be estimated from single images. In security, this potentially allows difficult face recognition input to be handled through illumination or pose normalisation. So, for example, forensic face imaging scenarios where only a single image exists which is in a difficult pose or illumination condition could be processed using our methods. In entertainment, our methods allow high quality 3D models to be acquired from images. So, for example, if you wished to re-animate a deceased actor or import a player's face into a 3D game, this is possible from only images of the face.</gtr:exploitationPathways><gtr:id>C4D2B20D-941C-44FF-BD40-051D7B49DA3D</gtr:id><gtr:outcomeId>56ddc259b958a3.82570321</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B6F5C52A-8E32-4ACB-B02A-6CCBC44AD001</gtr:id><gtr:title>Simplification of 3D morphable models</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d87383292ff314baabba8e48b3e9fc3a"><gtr:id>d87383292ff314baabba8e48b3e9fc3a</gtr:id><gtr:otherNames>Patel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>r_1125744033cac78352</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EF0103FC-0A38-4939-BA02-58C8E3777E38</gtr:id><gtr:title>Inverse rendering of faces with a 3D morphable model.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on pattern analysis and machine intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cfa953dd4a8b8e3518a5ce5c0551c3ce"><gtr:id>cfa953dd4a8b8e3518a5ce5c0551c3ce</gtr:id><gtr:otherNames>Aldrian O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0098-5589</gtr:issn><gtr:outcomeId>56ddbf2f78b9b2.47574043</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F68DE208-15C9-473B-8489-EC2BF499A9F3</gtr:id><gtr:title>Learning the nature of generalisation errors in a 3D morphable model</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cfa953dd4a8b8e3518a5ce5c0551c3ce"><gtr:id>cfa953dd4a8b8e3518a5ce5c0551c3ce</gtr:id><gtr:otherNames>Aldrian O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:isbn>978-1-4244-7992-4</gtr:isbn><gtr:outcomeId>56ddbf30829f66.18933018</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>13950CB7-4319-44AD-AF25-3C1610ED9E30</gtr:id><gtr:title>Automated construction of low-resolution, texture-mapped, class-optimal meshes.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d87383292ff314baabba8e48b3e9fc3a"><gtr:id>d87383292ff314baabba8e48b3e9fc3a</gtr:id><gtr:otherNames>Patel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>m_45885503461369e840</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AAC9F55C-71A2-4CE5-8547-744D2F596A1B</gtr:id><gtr:title>Driving 3D Morphable Models Using Shading Cues</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d9c48271f4c711bc3a79eab305ac2c91"><gtr:id>d9c48271f4c711bc3a79eab305ac2c91</gtr:id><gtr:otherNames>William Alfred Peter Smith (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>m_15241061121392d69c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>585F2366-9ACD-4D47-99A3-5E11A0744E0A</gtr:id><gtr:title>Manifold-based constraints for operations in face space</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d87383292ff314baabba8e48b3e9fc3a"><gtr:id>d87383292ff314baabba8e48b3e9fc3a</gtr:id><gtr:otherNames>Patel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>56ddbf2f504383.55136534</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>097E8ED5-733B-4E74-9541-7054423644F5</gtr:id><gtr:title>Driving 3D morphable models using shading cues</gtr:title><gtr:parentPublicationTitle>Pattern Recognition</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d87383292ff314baabba8e48b3e9fc3a"><gtr:id>d87383292ff314baabba8e48b3e9fc3a</gtr:id><gtr:otherNames>Patel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>56ddbf2fa20a44.36518471</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>97B02345-3588-49A8-8A3B-1D5B2BC538E6</gtr:id><gtr:title>3D morphable face models revisited</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d87383292ff314baabba8e48b3e9fc3a"><gtr:id>d87383292ff314baabba8e48b3e9fc3a</gtr:id><gtr:otherNames>Patel A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_878350140764277ad2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DA49D3A2-A115-47C5-9197-FFCD7BDCD7EE</gtr:id><gtr:title>Inverse rendering in SUV space with a linear texture model</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cfa953dd4a8b8e3518a5ce5c0551c3ce"><gtr:id>cfa953dd4a8b8e3518a5ce5c0551c3ce</gtr:id><gtr:otherNames>Aldrian O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-1-4673-0062-9</gtr:isbn><gtr:outcomeId>56ddbf303b3826.40042791</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F036949/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>