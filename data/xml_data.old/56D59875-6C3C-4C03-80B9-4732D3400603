<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:department>Sch of Life and Health Sciences</gtr:department><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A"><gtr:id>5BFB9036-9D16-4AB9-A9EF-097BB6FBD69A</gtr:id><gtr:name>Aston University</gtr:name><gtr:address><gtr:line1>Aston Triangle</gtr:line1><gtr:line4>Birmingham</gtr:line4><gtr:postCode>B4 7ET</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/61571307-9F25-4F84-B4D5-C8ABCC05066B"><gtr:id>61571307-9F25-4F84-B4D5-C8ABCC05066B</gtr:id><gtr:firstName>Mark</gtr:firstName><gtr:otherNames>Andrew</gtr:otherNames><gtr:surname>Georgeson</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/5B5C20B9-4E9D-44A6-87F9-45E09593090A"><gtr:id>5B5C20B9-4E9D-44A6-87F9-45E09593090A</gtr:id><gtr:firstName>Tim</gtr:firstName><gtr:surname>Meese</gtr:surname><gtr:orcidId>0000-0003-3744-4679</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FH00159X%2F1"><gtr:id>56D59875-6C3C-4C03-80B9-4732D3400603</gtr:id><gtr:title>A multi-scale model of binocular fusion in the human visual system</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/H00159X/1</gtr:grantReference><gtr:abstractText>We have two eyes but see one world. Although this might seem obvious (there is only one world), there are conditions where we do see double. For example, hold your index finger up a few inches in front of your nose, then fix your gaze on a more distant object straight ahead; your finger will be clearly seen as two, side-by-side. Then, as you switch your gaze to the finger, the two will become one. This is binocular fusion, or 'single-vision', and it is achieved by the brain (the visual cortex, containing thousands of millions of nerve cells) piecing together the information from both eyes. As a result, your ability to detect very faint things, or to see fine details, is better with two eyes than one. Our research aims to study single-vision and double-vision in carefully controlled experiments, and to build a general explanation in the form of a computer model that identifies both the main mechanisms and how they serve to identify basic visual features such as lines and edges that may be the building blocks of perception. How is the binocular combination organized ? Does the visual system use only the combined (left+right eye) information, or does it also make use of separate responses from the left eye and right eye ? Or might it even use the difference between left and right views, as well as the sum ? Our experiments will get at these questions by looking at how well we can detect images that are, in some sense, opposite in the two eyes. This could be a pattern of light and dark stripes, where the light stripes in one eye are superimposed on the dark stripes of the other eye, or the stripes might increase in contrast for one eye while they decrease in contrast for the other. If the brain only had left+right information available, such opposites should cancel. Previous findings suggest that they don't cancel, and so other information must also be used. New experiments will test this further and clarify what the extra information may be. Whether we see things as single or double depends on how far apart the left and right eye's views are and, importantly, on how blurred or sharp they are. Our second set of experiments will carefully measure these effects using images (blurred edges) that have not been used before, but should give cleaner, more general results than previous studies. Vision in one eye can be dramatically suppressed or inhibited by events in the other eye, especially when images in the two eyes are very different. Bright, flashed images in one eye particularly tend to suppress weak, steady images in the other eye. Present evidence, however, suggests that such competition between the eyes is also part of the normal process of binocular combination. We aim to study several aspects of binocular fusion (the perceived position, contrast and blur of edges and lines), and to do so when the left and right images themselves differ in position, contrast, or blur. With these data, assisted by our computer model, we shall work out how the mutual suppression between the eyes, taking place in the brain, shapes the binocular fusion and appearance of visual features. This work will be of direct benefit to other scientists researching in various fields that are concerned with binocular vision: neuroscientists studying the cellular responses of the visual brain; vision scientists and psychologists studying sensation &amp;amp; perception and brain-imaging; computer scientists interested in machine vision and robotics, especially 3-D vision; and optometrists concerned with vision correction and treatment of sight disorders. In optometry, our work may shed new light on 'monovision', where older patients (40+) are often successfully given different contact lenses in the two eyes - one for far, and one for near. By explaining how images with different blurs in the two eyes are combined by the brain, our research could lead to better understanding of monovision and to improvements in diagnosis and prescription.</gtr:abstractText><gtr:technicalSummary>The visual cortex combines signals from the two eyes resulting in fusion or diplopia, with or without stereo vision, but fusion and its neural basis remain poorly understood. The goal of this project is a more complete functional account of binocular fusion through psychophysical experiments and computational modelling. Modelling: A key objective is to unify our models of multi-scale feature analysis (JoV 2007) and binocular signal processing (JoV 2006), to implement multi-scale spatial vision in the context of binocular combination and interocular suppression. We need to know (i) how multi-scale filtering is organized across monocular &amp;amp; binocular stages of processing, (ii) how responses are combined across the eyes, (iii) how interocular suppression modifies each eye's response &amp;amp; how it is distributed across space &amp;amp; scale, (iv) how decisions about the identity of features are made. Experiments: (1) to address the functional architecture and performance of the binocular system, by finding whether * cancellation is ever possible between opposite images in the two eyes, * observers can distinguish between monocular and binocular inputs, * observers can tell that fused left and right images are different in contrast. (2) to quantify the disparity that separates fusion from diplopia for blurred test edges, over a range of blurs &amp;amp; contrasts. (3) to study the fused appearance of edges or bars that have different positions, contrasts or blurs in the two eyes, so as to shed light on the summation and interocular suppression that shape the appearance of binocular features. These data and model will answer some key questions about: * the necessary conditions for fusion * the cause of double vision at larger disparities * why the disparity range of single-vision is scale-dependent * what entities are combined between the eyes * the inter-play of feature detection and binocular fusion * the role of monocular and binocular mechanisms in fusion and diplopia.</gtr:technicalSummary><gtr:fund><gtr:end>2012-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2009-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>354219</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Seeing with two eyes is generally better than one, but not always. Visual signals sent along the optic nerves from the left and right eyes are combined in the visual cortex of the brain. In binocular vision, different images in the two eyes can be 'fused' in perception, but little is known about the nature of fusion or how it is achieved. We studied fusion, and the failure of fusion (double vision), in carefully controlled psychophysical experiments using blurred edges. If fusion added or averaged the signals from each eye, we should expect binocularly fused edges to look increasingly blurred when they are shown in slightly different positions in the two eyes. We found that this was true when the two edges were physically added in the same eye, but not when one edge was shown to each eye. Binocular combination is not like addition, but more like multiplication. Neural systems can carry out mathematical computations.

We developed a new, quantitative, theory of binocular fusion and double vision that accounts for these results. The visual system first computes the gradients of luminance in each eye, then combines them (by a form of multiplication) across the eyes. These operations, in that order, are crucial to the success of the combination process. If the combined response is strong enough, we experience a single 'fused' image and the fused image correctly preserves the sharpness or blur of features from each eye. 

But the fused (binocular) response is not the only game in town. The two eyes also assert themselves separately, and responses drawn from the left &amp;amp; right eyes are in a 3-way competition with the fused response. If the images in the two eyes are different - in their position or blur - then the fused response gets weaker. Eventually it loses the 3-way competition and becomes strongly suppressed. Instead of fusion, we get double vision. This suppression of the binocular response is intimately linked to the classic phenomenon of binocular rivalry where left and right eye responses compete with each other. Our results and modelling suggest that underlying the dynamic complexity of rivalry - when fusion fails - there is a simple rule: at each location in visual space, the eye that has the steeper luminance gradient wins the competition - 'the winner takes all'. 

Our findings offer some insight and application in Optometry. As an alternative to bifocal glasses, optometrists may offer a prescription called monovision. This gives you a contact lens for far vision in one eye, and one for near vision in the other eye. The idea is that the brain may select and use the sharper parts of the two images. Our results show how this can work, and work more simply than one might think. In a blurred image the light is smeared out, and luminance gradients become shallower. At an early stage in the visual cortex, the brain can sense the steeper gradient, and suppress the other one. It may do this automatically, and simultaneously at all locations. It then assembles these fragments, some drawn from one eye, some from the other, into a coherent whole. Only the steeper gradients have been selected, and the scene is apparently sharp everywhere. 
 
How do we know the brain is selecting the steeper gradients, rather than the sharper image content? This is shown by experiments where a sharper image is in one eye, with a blurred image in the other. The sharper image dominates. But luminance gradients increase with contrast, and so if we increase the blurred image contrast there comes a point at which the blurred image has the steeper gradients. We find that vision then switches to seeing the blurred image and suppressing the sharper one. This proves that gradients, not sharpness, control the competitive selection process. Nevertheless, in monovision, the sharper image also has the steeper gradients, so the gradient competition that we have uncovered does in fact select the sharper image content in this situation.</gtr:description><gtr:exploitationPathways>Our findings offer some insight and application in Optometry, as described more fully above</gtr:exploitationPathways><gtr:id>53BACF85-E8BE-47F0-BA0C-3651D3CA4171</gtr:id><gtr:outcomeId>54621975d40323.10651894</gtr:outcomeId><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>B6BF4105-2C6D-47CC-9036-E25CA3B6A98F</gtr:id><gtr:title>The effect of interocular phase difference on perceived contrast.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn><gtr:outcomeId>doi_53d081081512731e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D28CA372-720F-46B4-83EE-7A0BB4614E3A</gtr:id><gtr:title>The slope of the psychometric function and non-stationarity of thresholds in spatiotemporal contrast vision.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b6e14f0bc8cf77a6720b4428a55e298"><gtr:id>3b6e14f0bc8cf77a6720b4428a55e298</gtr:id><gtr:otherNames>Wallis SA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_55f94b94beb8e9f9</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B8963B74-5E79-4E6A-A34F-0FBFBF7C8B15</gtr:id><gtr:title>Mach bands and multiscale models of spatial vision: the role of first, second, and third derivative operators in encoding bars and edges.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3b6e14f0bc8cf77a6720b4428a55e298"><gtr:id>3b6e14f0bc8cf77a6720b4428a55e298</gtr:id><gtr:otherNames>Wallis SA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_55f94b94bed6e6cd</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BC241AF6-AA99-4097-91F7-42143A0F08C3</gtr:id><gtr:title>Response normalization and blur adaptation: data and multi-scale model.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a0cc912e9629fc06e6e65ee41fe5a9cb"><gtr:id>a0cc912e9629fc06e6e65ee41fe5a9cb</gtr:id><gtr:otherNames>Elliott SL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>r_2092510232034ea4da</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6F89EDA1-19C6-40D7-90CE-A8516D7AF04A</gtr:id><gtr:title>Contrast summation across eyes and space is revealed along the entire dipper function by a &amp;quot;Swiss cheese&amp;quot; stimulus.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4b5e5156f6f4d927c3f5e20ee119e8d9"><gtr:id>4b5e5156f6f4d927c3f5e20ee119e8d9</gtr:id><gtr:otherNames>Meese TS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>56758e9f15ca5</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7F2EBBDC-5E71-4017-871D-612DE918155F</gtr:id><gtr:title>Linear binocular combination of responses to contrast modulation: contrast-weighted summation in first- and second-order vision.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/4db6155b7727bc65964379121650f2f6"><gtr:id>4db6155b7727bc65964379121650f2f6</gtr:id><gtr:otherNames>Zhou J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>546212f4717459.83975400</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B81CB617-B7CD-4CB2-9FA4-6790EA34829A</gtr:id><gtr:title>Nonlinearities in the binocular combination of luminance and contrast.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>doi_53d00f00f0b7aa3f</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>6AC64BFF-7B1A-45D8-94D2-59EF4AE7F37E</gtr:id><gtr:title>Binocular fusion, suppression and diplopia for blurred edges.</gtr:title><gtr:parentPublicationTitle>Ophthalmic &amp; physiological optics : the journal of the British College of Ophthalmic Opticians (Optometrists)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d14311e8f34322798b7a9de3e84289fb"><gtr:id>d14311e8f34322798b7a9de3e84289fb</gtr:id><gtr:otherNames>Georgeson MA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0275-5408</gtr:issn><gtr:outcomeId>54203eff36e9a5.42164929</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>76D1FF0A-D9AE-4930-A401-E0B6ECB27359</gtr:id><gtr:title>Paradoxical psychometric functions ('swan functions') are explained by dilution masking in four stimulus dimensions.</gtr:title><gtr:parentPublicationTitle>iPerception</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/25af8048956d0f5f37927db4c9485cac"><gtr:id>25af8048956d0f5f37927db4c9485cac</gtr:id><gtr:otherNames>Baker DH</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>54621224293357.49415279</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D74B9CB8-7B47-46AC-8714-2B761F48AD96</gtr:id><gtr:title>Contrast and lustre: A model that accounts for eleven different forms of contrast discrimination in binocular vision.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d14311e8f34322798b7a9de3e84289fb"><gtr:id>d14311e8f34322798b7a9de3e84289fb</gtr:id><gtr:otherNames>Georgeson MA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>58bebfe12dacd9.85348101</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7B168773-3E4D-49EE-B710-D21A47976B58</gtr:id><gtr:title>Direction discrimination thresholds in binocular, monocular, and dichoptic viewing: Motion opponency and contrast gain control.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bf15443b52ab6e67856f4a00b7b414ba"><gtr:id>bf15443b52ab6e67856f4a00b7b414ba</gtr:id><gtr:otherNames>Maehara G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>58bec1fa0994c2.85581950</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1E7E59BC-8CD0-46A1-B1BE-696522A03A84</gtr:id><gtr:title>Binocular functional architecture for detection of contrast-modulated gratings.</gtr:title><gtr:parentPublicationTitle>Vision research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d14311e8f34322798b7a9de3e84289fb"><gtr:id>d14311e8f34322798b7a9de3e84289fb</gtr:id><gtr:otherNames>Georgeson MA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0042-6989</gtr:issn><gtr:outcomeId>58bec19f288810.20295098</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/H00159X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>