<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Centre for Speech Technology Research</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/6E9EAE62-9ADC-4E84-B950-56966D646A8F"><gtr:id>6E9EAE62-9ADC-4E84-B950-56966D646A8F</gtr:id><gtr:firstName>Simon</gtr:firstName><gtr:surname>King</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/67120D29-60E5-40C8-98E7-F04842E29D84"><gtr:id>67120D29-60E5-40C8-98E7-F04842E29D84</gtr:id><gtr:firstName>Robert</gtr:firstName><gtr:surname>Clark</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/39AA7330-3F74-4507-B17F-D40DD393F5C0"><gtr:id>39AA7330-3F74-4507-B17F-D40DD393F5C0</gtr:id><gtr:firstName>Volker</gtr:firstName><gtr:otherNames>Franz</gtr:otherNames><gtr:surname>Strom</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER_COI</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE031447%2F1"><gtr:id>B2E21596-C3E2-4B83-AEBB-9569C4A9A3D0</gtr:id><gtr:title>Automatic target cost and database design for unit-selection speech synthesis</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E031447/1</gtr:grantReference><gtr:abstractText>We propose to replace three components of a typical concatenativespeech synthesiser: the text selection algorithm (what to record forthe database), the target cost function (which units to select fromthe database) and the backoff strategy (what to do when the databasedoes not contain the desired unit).These components are currently designed independently using humanintuition. This is very hard, can only be done by experts, and meansthat each component is unlikely to be optimised with respect to theothers. We propose to base these three components on a singleunderlying model. The model will learn, from data, which speech unitsare perceptually interchangeable. This information will then be usedby the target cost function / backoff strategy, and when selecting thetext to be recorded. The proposed techniques will be implemented inthe Festival 2 speech synthesis system and evaluated using formallistening tests.We break down the research programme into three phases. In Phase 1, wewill gain a deeper understanding of current techniques. In Phase 2, wewill examine techniques for learning just the target cost/backoffstrategy, given an existing voice, then for learning thetext-selection algorithm for a given target cost/backoffstrategy. Finally, in Phase 3, we will devise a method for jointlylearning both together.</gtr:abstractText><gtr:fund><gtr:end>2010-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>280478</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Invited public lecture: A survey of speech technology</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>87647622-59C4-426B-817D-F839A48611EE</gtr:id><gtr:impact>Discussions with the audience


Follow up emails from members of the audience</gtr:impact><gtr:outcomeId>545f6e82a15719.69114559</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2009</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>The future of Languages - more than just words</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>77CF6A03-CEC8-4FFB-A5E9-BB5C65F74AA7</gtr:id><gtr:impact>A public lecture at the Public Library in Amsterdam, followed by a debate with an audience.

Interactions with the audience.</gtr:impact><gtr:outcomeId>545f6dbf8a2f28.04664057</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.clubofamsterdam.com/event.asp?contentid=854</gtr:url><gtr:year>2012</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>1904C869-CCA2-4C04-927D-36BBA18CDDD3</gtr:id><gtr:title>Investigating Festival's target cost function using perceptual experiments</gtr:title><gtr:parentPublicationTitle>Proceedings Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8e6b8329991faadc2e1cee47a2738cbc"><gtr:id>8e6b8329991faadc2e1cee47a2738cbc</gtr:id><gtr:otherNames>Strom, V and King, S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>543fca35e8abe6.51644739</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F0491657-D42A-4463-8ABD-2783D75C70F0</gtr:id><gtr:title>The Blizzard Challenge 2008</gtr:title><gtr:parentPublicationTitle>The Blizzard Challenge 2008</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ee79ca208d19b566298a2b323b3c9119"><gtr:id>ee79ca208d19b566298a2b323b3c9119</gtr:id><gtr:otherNames>Karaiskos,  V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_983459920114091244</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>A7708B9C-F1A2-4A3A-B3CC-0F0B69B16FE1</gtr:id><gtr:title>A classifier-based target cost for unit selection speech synthesis trained on perceptual data</gtr:title><gtr:parentPublicationTitle>Proceedings of Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/bcb3d1787510afdd4d703cc13c79ec30"><gtr:id>bcb3d1787510afdd4d703cc13c79ec30</gtr:id><gtr:otherNames> Strom, V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_849887379114092d06</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>913E80AB-482A-444A-93AC-0FB6852844CF</gtr:id><gtr:title>Festival Multisyn Voices for the 2007 Blizzard Challenge</gtr:title><gtr:parentPublicationTitle>Proc. Blizzard Challenge Workshop (in Proc. SSW6)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6e99b0e94792dddd242811946a1f13c4"><gtr:id>6e99b0e94792dddd242811946a1f13c4</gtr:id><gtr:otherNames>Richmond, K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>5432671d120582.82880808</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AF221765-5333-46F1-94C0-3CFB205D5068</gtr:id><gtr:title>Including Pitch Accent Optionality in Unit Selection Text-to-Speech Synthesis</gtr:title><gtr:parentPublicationTitle>Proc. Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6d2ddccc22fb4a16fc34928d33f68af4"><gtr:id>6d2ddccc22fb4a16fc34928d33f68af4</gtr:id><gtr:otherNames>Badino, L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>543266dd17fc17.45197773</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D98D6F85-F185-44E8-87F8-45CD22FBFB42</gtr:id><gtr:title>The Blizzard Challenge 2009</gtr:title><gtr:parentPublicationTitle>The Blizzard Challenge 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/589ffcf041bbe48a53acf08a2cbd7346"><gtr:id>589ffcf041bbe48a53acf08a2cbd7346</gtr:id><gtr:otherNames>King, S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_56748190231404f07e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>233243C0-5E1A-4866-BA7B-48FF30F7F02B</gtr:id><gtr:title>Speech Synthesis Without a Phone Inventory</gtr:title><gtr:parentPublicationTitle>Interspeech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/5408f0cfbda4d97e12bad46673fea0e8"><gtr:id>5408f0cfbda4d97e12bad46673fea0e8</gtr:id><gtr:otherNames> M Aylett</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_103537480213edb832</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E031447/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>41593421-CFAC-411D-94A7-E144022B0E6D</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Artificial Intelligence</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>0A982A4A-12CF-4734-AFCA-A5DC61F667F3</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Information &amp; Knowledge Mgmt</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>