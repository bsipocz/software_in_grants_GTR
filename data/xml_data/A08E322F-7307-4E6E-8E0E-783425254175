<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/2B07D609-46B2-43F9-BD52-DF09C354CF71"><gtr:id>2B07D609-46B2-43F9-BD52-DF09C354CF71</gtr:id><gtr:firstName>Tim</gtr:firstName><gtr:otherNames>Johannes</gtr:otherNames><gtr:surname>Muller</gtr:surname><gtr:orcidId>0000-0003-1263-4230</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FR01034X%2F1"><gtr:id>A08E322F-7307-4E6E-8E0E-783425254175</gtr:id><gtr:title>Provably Secure Decisions Based on Potentially Malicious Trust Ratings</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/R01034X/1</gtr:grantReference><gtr:abstractText>Anyone who uses the internet will be aware of ratings and reviews, for example when booking a hotel. How much trust can we place in reviews we read online? Perhaps internet trolls bombarded a site with negative ratings, or perhaps a company's PR person wrote something glowingly positive for their client? Most people have a degree of skepticism. Ratings can also be used behind the screens, for example when flagging possible malware. Can we automate decisions based on ratings? Is there a formulaic way of using the ratings without being deceived? Our research proposes a foundation to enable secure decisions based on ratings.

Ratings are especially important in open networks, which play a large role in the internet of things. In open networks, participants are potentially malicious (attackers), yet we may rely on information that they provide. In current analysis of networks that use potentially unfair ratings, assumptions are made about the attackers. For example, that they maximise their profit, or want to perform specific actions. In reality, however, we cannot know what the attackers want or will do. This is the crucial challenge in our approach: we provide solutions with a proven risk-bound, regardless of the behaviour of the attackers.

Using information theory, digital networks are able to reconstruct signals despite noise. By modelling correct decisions as a signal, and attacks as noise, we have proven in previous work that typically, information is carried in ratings. With techniques similar to those applied in digital networks, we can reconstruct the correct decision. So, we propose a framework of methods to use information to come to correct decisions despite attacks.

Our framework consists of general techniques regarding transforming ratings to correct decisions, and of decision schemes based on these techniques. There are two major applications: a centralised system making a decision, and a decentralised system where individuals make decisions. Centralised examples are YouTube deleting content on the basis of copyright claims, Facebook censoring obscene material and finding fraudulent merchants on an e-commerce system. Decentralised example are ad-hoc networks, where distant nodes are selected to route sensitive information, peer to peer networks, with malicious peers breaking protocol, and peer assessment, where students have to grade their peers. We deliver both a centralised and a decentralised system that makes provably correct decisions under all attacks.

A major component of the framework is the theoretical foundation for ratings. We define three desirable properties: robustness, optimality and stability. A decision scheme is called epsilon-robust if it provides the wrong decision with a probability under epsilon. With sufficient ratings from sources that are sufficiently probably honest, this is easy to obtain. Optimality is about reducing the cost (amount and complexity of ratings) to the minimum. Stability means that if the degree of honesty is lower than expected, the decision scheme cannot be improved without raising costs. We investigate in which contexts robustness, optimality and stability can combine, and at which cost this occurs.

The most interesting context is dynamic: where users can determine (with a probability of false positives/negatives) the veracity of previous ratings. This dynamic context is both theoretically and practically interesting. The theoretical interest is that more advanced information theoretic techniques are required, and there may be deep links to other fields, such as adversarial machine learning. The practical interest is that in many systems, sources are being used more than once, and decision makers do have a vague idea about the quality of older ratings. Provably effective use of this dynamic information has not been achieved, and will improve the security of rating systems.

The result of this research will be to provide more secure rating systems.</gtr:abstractText><gtr:potentialImpactText>There are multiple ways in which our research can have a positive impact. There are commercial applications of our research, via two routes:
1. There is a direct route to commercialisation, via the systems that we deliver in case-studies (centralised and decentralised).
2. And there is an indirect route, where our results and proofs are used by other parties to improve their systems.
Finally, there are non-commercial routes to impact. We discuss these three cases below:

We construct a centralised system, which accumulates reports from users, and makes decisions based upon these. An example is YouTube's copyright claim system. It is currently under criticism, since YouTube cannot manually check all complaints. Therefore, some copyrighted content stays online too long whereas other legal content is unjustifiably removed. Both are unacceptable, and may cause legal issues for Google (YouTube's owner). Provably keeping the false decisions below a threshold epsilon also helps Google defend against litigation. YouTube is far from the only system that relies on reports from users, and since we do not use any of the domain specific properties (i.e. video's), our approach can applied to other systems (e-market places, malware detection on software distributors, malicious website detection in a browser).

We also construct a decentralised robust decision maker. Here, individuals can adopt a piece of software to ensure their own decisions are correct with bounded risk, rather than monolithic systems-wide decision making.
An example is vehicular ad-hoc networks, where moving vehicles communicate with eachother. The purpose of communication could be to relay traffic information, to warn nearby vehicles to brake, or even to (partially) automate driving.
The challenge here is that the amount of sources available is more sparse in this environment. Fortunately, domain-specific elements can be used to mitigate this problem, such as traffic information via radio or visual cues from brake lights from other vehicles.

In order to build systems that make robust decisions, we need to develop novel techniques with provable results. These results can be used outside the specific systems that we deliver. Therefore, we believe we push forward all domains that involve (secure use of) information from potentially malicious sources. Specifically, we can apply some of our results to crowdsourcing, trust management systems, trust and reputation systems, adversarial machine learning, secure routing protocols, decision making, information fusion, and the risk of using trusted third parties in security protocols. Our results enable the development of provably secure rating systems.

Part of the research performed in this research will be taught in the context of the security track of the Software Engineering Programme at the University of Oxford. The SEP is a programme for professional master students. The material will be taught to students with a career in computer security.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-12-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2018-01-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>92901</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/R01034X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0A982A4A-12CF-4734-AFCA-A5DC61F667F3</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Information &amp; Knowledge Mgmt</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E05CFE0B-163D-412D-A3C2-28E89B2CA336</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Software Engineering</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>