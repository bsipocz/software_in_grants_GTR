<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:department>Informatics</gtr:department><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/13D19C0B-467F-48A5-8F34-9E73D9BA5C65"><gtr:id>13D19C0B-467F-48A5-8F34-9E73D9BA5C65</gtr:id><gtr:name>Ericsson UK</gtr:name><gtr:address><gtr:line1>Ansty Park</gtr:line1><gtr:line2>Ansty</gtr:line2><gtr:postCode>CV2 2TF</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/F0A4B8FD-FF0C-4D00-95BA-99CE62631F54"><gtr:id>F0A4B8FD-FF0C-4D00-95BA-99CE62631F54</gtr:id><gtr:name>MediaTek</gtr:name><gtr:address><gtr:line1>Building 2030</gtr:line1><gtr:line2>Cambourne Business Park</gtr:line2><gtr:line3>Cambourne</gtr:line3><gtr:postCode>CB23 6DW</gtr:postCode><gtr:region>East of England</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/27812A1D-D032-4A2A-8CC1-4EEE59C345C4"><gtr:id>27812A1D-D032-4A2A-8CC1-4EEE59C345C4</gtr:id><gtr:name>Thales Research and Technology UK Ltd</gtr:name><gtr:address><gtr:line1>Worton Drive</gtr:line1><gtr:line2>Worton Grange Business Park</gtr:line2><gtr:line4>Reading</gtr:line4><gtr:line5>Berkshire</gtr:line5><gtr:postCode>RG2 0SB</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/655C6837-F593-4799-8D1A-C91B859A7EF7"><gtr:id>655C6837-F593-4799-8D1A-C91B859A7EF7</gtr:id><gtr:name>Samsung Electronics Research Institute</gtr:name><gtr:address><gtr:line1>Communications House</gtr:line1><gtr:line2>South Street</gtr:line2><gtr:line4>Staines</gtr:line4><gtr:postCode>TW18 4QE</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/A89F7E56-4599-4BB3-B4F5-6F71A367E980"><gtr:id>A89F7E56-4599-4BB3-B4F5-6F71A367E980</gtr:id><gtr:name>iniLabs Ltd</gtr:name><gtr:address><gtr:line1>Laternengasse 4</gtr:line1><gtr:postCode>8001</gtr:postCode><gtr:region>Outside UK</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1FCC355F-510E-4265-8F32-F8B68EE2A2BE"><gtr:id>1FCC355F-510E-4265-8F32-F8B68EE2A2BE</gtr:id><gtr:name>Keysight Technologies UK Ltd</gtr:name><gtr:address><gtr:line1>5 Lochside Avenue</gtr:line1><gtr:postCode>EH12 9DJ</gtr:postCode><gtr:region>Scotland</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/8BE63B84-352E-4077-B928-CBD8A888ECE1"><gtr:id>8BE63B84-352E-4077-B928-CBD8A888ECE1</gtr:id><gtr:firstName>Mohammad</gtr:firstName><gtr:surname>Shikh-Bahaei</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/A35C6D64-9544-4DCB-8A16-2226CDE83D3A"><gtr:id>A35C6D64-9544-4DCB-8A16-2226CDE83D3A</gtr:id><gtr:firstName>Mischa</gtr:firstName><gtr:surname>Dohler</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/CDABC457-5520-453F-A655-8B7C5DC3A5C1"><gtr:id>CDABC457-5520-453F-A655-8B7C5DC3A5C1</gtr:id><gtr:firstName>Hamid</gtr:firstName><gtr:surname>Aghvami</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/DF50928B-3F06-4A1E-BBA2-FE0DB138821D"><gtr:id>DF50928B-3F06-4A1E-BBA2-FE0DB138821D</gtr:id><gtr:firstName>Nishanth</gtr:firstName><gtr:otherNames>Ramakrishna</gtr:otherNames><gtr:surname>Sastry</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FP022723%2F1"><gtr:id>745F1BED-DBE9-48C7-863F-FB1894A1863E</gtr:id><gtr:title>The Internet of Silicon Retinas (IoSiRe): Machine to machine communications for neuromorphic vision sensing data</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/P022723/1</gtr:grantReference><gtr:abstractText>This proposal starts with the notion that, when considering future visual sensing technologies for next-generation Internet-of-Things surveillance, drone technology, and robotics, it is quickly becoming evident that sampling and processing raw pixels is going to be extremely inefficient in terms of energy consumption and reaction times. After all, the most efficient visual computing systems we know, i.e., biological vision and perception in mammals, do not use pixels and frame-based sampling. Therefore, IOSIRE argues that we need to explore the feasibility of advanced machine-to-machine (M2M) communications systems that directly capture, compress and transmit neuromorphically-sampled visual information to cloud computing services in order to produce content classification or retrieval results with extremely low power and low latency.

IOSIRE aims to build on recently-devised hardware for neuromorphic sensing, a.k.a. dynamic vision sensors (DVS) or silicon retinas. Unlike conventional global-shutter (frame) based sensors, DVS cameras capture the on/off triggering corresponding to changes of reflectance in the observed scene. Remarkably, DVS cameras achieve this with (i) 10-fold reduction in power consumption (10-20 mW of power consumption instead of hundreds of milliwatts) and (ii) 100-fold increase in speed (e.g., when the events are rendered as video frames, 700-2000 frames per second can be achieved). 

In more detail, the IOSIRE project proposes a fundamentally new paradigm where the DVS sensing and processing produces a layered representation that can be used locally to derive actionable responses via edge processing, but select parts can also be transmitted to a server in the cloud in order to derive advanced analytics and services. The classes of services considered by IOSIRE require a scalable and hierarchical representation for multipurpose usage of DVS data, rather than a fixed representation suitable for an individual application (such as motion analysis or object detection). Indeed, this is the radical difference of IOSIRE from existing DVS approaches: instead of constraining applications to on-board processing, we propose layered data representations and adaptive M2M transmission frameworks for DVS data representations, which are mapped to each application's quality metrics, response times, and energy consumption limits, and will enable a wide range of services by selectively offloading the data to the cloud. The targeted breakthrough by IOSIRE is to provide a framework with extreme scalability: in comparison to conventional designs for visual data processing and transmission over M2M networks, and under comparable reconstruction, recognition or retrieval accuracy in applications, up to 100-fold decrease in energy consumption (and associated delay in transmission/reaction time) will be pursued. Such ground-breaking boosting of performance will be pursued via proof-of-concept designs and will influence the design of future commercial systems.</gtr:abstractText><gtr:potentialImpactText>Given the significant savings in bandwidth, energy consumption and network latencies expected through the adoption of IOSIRE based technology in video over M2M networks, the general public will benefit from the results of this research via the development of advanced classification, retrieval and video frame rate upscaling services that are impossible to achieve with conventional frame-based video systems. The project outcomes will enable a wide range of IoT-related applications for machine-to-machine networks of the future, thus helping to meet public expectations for the future of the Internet-of-Things paradigm. The role of industry, and in particular our industrial partners, will be paramount here, especially in view of the significance of international standards in the widespread adoption of our new media processing and M2M communication techniques in vertical sectors. The dissemination of our research outputs to standardisation bodies (such as 3GPP, IEEE and the ITU) as well as industry fora (Cambridge Wireless, MWC, etc.) will facilitate this impact.

Our industrial partners are well positioned to exploit the research outcomes within their products and services and the planned interactions with them will substantially facilitate this. As detailed in the Impact document, this potentially encompasses sensor/transceiver chip set development, M2M network architecture and management, and consumer products with enhanced video-over-wireless connectivity.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>560633</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>E5EC2FE1-604F-43FE-8F7E-BD2077E8C2F2</gtr:id><gtr:title>FD device-to-device communication for wireless video distribution</gtr:title><gtr:parentPublicationTitle>IET Communications</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/34fefbc4773d5b6d61765690b9693af7"><gtr:id>34fefbc4773d5b6d61765690b9693af7</gtr:id><gtr:otherNames>Naslcheraghi M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a995ea84a9929.80709045</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2652A9CE-47C0-4F1E-93F1-B1AEFD0C3D0C</gtr:id><gtr:title>Survey on peer-assisted content delivery networks</gtr:title><gtr:parentPublicationTitle>Computer Networks</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/57e9cdd86334e050209b18e059cb29cd"><gtr:id>57e9cdd86334e050209b18e059cb29cd</gtr:id><gtr:otherNames>Anjum N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a9846b98a83d0.47470487</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F950E2FC-BEDE-4F11-9221-EFC0B5E5244C</gtr:id><gtr:title>Full-duplex Device-to-Device collaboration for low-latency wireless video distribution</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/34fefbc4773d5b6d61765690b9693af7"><gtr:id>34fefbc4773d5b6d61765690b9693af7</gtr:id><gtr:otherNames>Naslcheraghi M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:outcomeId>5a995f4a18ecc6.78137768</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/P022723/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>0F8B7B13-F2F5-42B3-95C6-EF12D7877319</gtr:id><gtr:percentage>15</gtr:percentage><gtr:text>Multimedia</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>34B6BDD6-DA02-4CA0-A969-29D50394A953</gtr:id><gtr:percentage>85</gtr:percentage><gtr:text>Networks &amp; Distributed Systems</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>