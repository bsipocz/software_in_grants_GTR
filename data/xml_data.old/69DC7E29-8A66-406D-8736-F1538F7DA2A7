<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7"><gtr:id>88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7</gtr:id><gtr:name>University of East Anglia</gtr:name><gtr:address><gtr:line1>Earlham Road</gtr:line1><gtr:line4>Norwich</gtr:line4><gtr:line5>Norfolk</gtr:line5><gtr:postCode>NR4 7TJ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7"><gtr:id>88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7</gtr:id><gtr:name>University of East Anglia</gtr:name><gtr:department>Computing Sciences</gtr:department><gtr:address><gtr:line1>Earlham Road</gtr:line1><gtr:line4>Norwich</gtr:line4><gtr:line5>Norfolk</gtr:line5><gtr:postCode>NR4 7TJ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7"><gtr:id>88C5F7F9-8DCC-41C9-BC4F-F37DA01075C7</gtr:id><gtr:name>University of East Anglia</gtr:name><gtr:address><gtr:line1>Earlham Road</gtr:line1><gtr:line4>Norwich</gtr:line4><gtr:line5>Norfolk</gtr:line5><gtr:postCode>NR4 7TJ</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/D4F37595-15E3-42D8-B157-072942EBF226"><gtr:id>D4F37595-15E3-42D8-B157-072942EBF226</gtr:id><gtr:firstName>A</gtr:firstName><gtr:surname>Day</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE035639%2F1"><gtr:id>69DC7E29-8A66-406D-8736-F1538F7DA2A7</gtr:id><gtr:title>Real-time rendering of crowds consisting of high quality and distinct people</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E035639/1</gtr:grantReference><gtr:abstractText>Computer generated virtual models of cities alone are often empty and lifeless, the presence of a crowd helps bring them to life . Currently real-time virtual models have only been able to show a small variety in the crowd, for example they often all walk the same way, even though the crowd itself is very large (thus containing many clones of each human). For example the realistic simulation and display of how people walk on uneven ground, step onto or off the curb without a foot floating in the air or disappearing into the ground has not been satisfactorily solved. The computer animation research community has not yet achieved this with sufficiently small computation cost to facilitate real-time crowd rendering. For example the different gaits people possess and the different ways that old, young, men, women and disabled people move is as yet uncharted in the virtual world of real-time crowd simulation. Our proposed work focuses on crowds of unique humans, in terms of how they look, how they move and how they interact with the world around them.The challenges of our proposed research are split into three areas: firstly the behaviour engine for each crowd member has to work out what the individual's goal is and how it will be achieved. Once this is accomplished, the behaviour engine directs the animation engine to perform the required action. The human models are then deformed to fit the animation and implemented within the urban model using the rendering engine. The decisions cannot be pre-processed and must be based on the current situation at any point in time i.e. in real time.Each area will bring features previously unseen in the crowd rendering field. The animation engines to date have a very limited number of actions they can perform, usually just playing an existing motion on loop. The real-time adaptation of existing animations (or generation of them if a suitable animation is not within the animation cache) will allow each crowd member to appear to perform unique movements, with the end goal of providing an extensive range of animations. This is a significant task and will require the development of algorithms capable of extreme scalability, from high precision and high cost close to the viewer, to low precision and low cost for the distant crowd (with many levels in-between).Obviously if the animation engine is capable of constructing new and unique poses, the rendering engine must be able to represent these. A pre-selected number of positions, as is currently used, will not be sufficient. The rendering engine must be fully dynamic, abandoning traditionally static levels of detail, instead using, for example, animation caching, dynamic impostors and dynamic mesh simplification to achieve the desired speed without forfeiting the power of the system. With the rendering and animation engines providing this flexibility, it is clear the behaviour engine must be extended beyond those currently used in crowds in order to provide the information for the other parts to reach their full potential.</gtr:abstractText><gtr:fund><gtr:end>2010-06-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>275989</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of East Anglia</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Virtual Past, School of History UEA</gtr:description><gtr:id>BC2E8E87-1025-4DAB-8F76-88D354DA6E57</gtr:id><gtr:impact>Several 3D modelling contracts</gtr:impact><gtr:outcomeId>54608bd4bb1a97.27772785-1</gtr:outcomeId><gtr:partnerContribution>History expertise</gtr:partnerContribution><gtr:piContribution>Computer science historic reconstruction and modelling expertise</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2008-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Talk at cultural heritage event</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3F91150E-D509-4B9C-B07C-81464F4BD077</gtr:id><gtr:impact>Discussion and increased communication with other relevant organisations

Initation to bid for other 3D modelling work.</gtr:impact><gtr:outcomeId>54609249aace45.70803756</gtr:outcomeId><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2010</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The main project findings are:



1) New ways of drawing a crowd of animated characters in real-time. Previous work has focused almost exclusively on how to visualize ever larger crowd scenes and the current state-of-the- art can display tens of thousands of virtual humans with ease. The associated trade-off, however, is that crowd members can do little more than play a set of scripted motion clips. It follows that designating individuals to be members of a crowd instantly limits the techniq</gtr:description><gtr:exploitationPathways>Incorporation into games engine software.
Simulation of crowd behaviour in cities</gtr:exploitationPathways><gtr:id>AC31CEB1-8A20-4A48-9F3A-E4A649214017</gtr:id><gtr:outcomeId>r-7495174414.9394097798240e</gtr:outcomeId><gtr:sectors><gtr:sector>Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections,Transport</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>AA7E6065-3DE1-4498-BCD1-13D6B3A3A48E</gtr:id><gtr:title>SIMULATING REAL TIME CLOTH WITH ADAPTIVE EDGE BASED MESHES</gtr:title><gtr:parentPublicationTitle>JOURNAL OF WSCG</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/cf7dff9265df211f96c0ff53ac676d7d"><gtr:id>cf7dff9265df211f96c0ff53ac676d7d</gtr:id><gtr:otherNames> T SIMNETT</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>m_874733453713865c64</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8E7EB2C3-E3B4-415B-A694-16FB94CED821</gtr:id><gtr:title>A DYNAMIC CACHING SYSTEM FOR RENDERING AN ANIMATED CROWD IN REAL TIME</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9e9bd110caa33aeac5bdfe797432a86d"><gtr:id>9e9bd110caa33aeac5bdfe797432a86d</gtr:id><gtr:otherNames> W LISTER</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_14185509011409a678</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>45BB534B-9223-4224-A8F3-E35BB1B9FF3E</gtr:id><gtr:title>Dynamically populating large urban environments with ambient virtual humans</gtr:title><gtr:parentPublicationTitle>Computer Animation and Virtual Worlds</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecec5c995adacbb64399d609ef050d04"><gtr:id>ecec5c995adacbb64399d609ef050d04</gtr:id><gtr:otherNames>Haciomeroglu M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53cfc2fc26876655</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CFC49581-780F-4E03-9B21-D737D3134FF0</gtr:id><gtr:title>Automatic spatial analysis and pedestrian flow control for&amp;nbsp;real-time crowd simulation in an urban environment</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/ecec5c995adacbb64399d609ef050d04"><gtr:id>ecec5c995adacbb64399d609ef050d04</gtr:id><gtr:otherNames>Haciomeroglu M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>doi_53cfd5fd58e46840</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>50731247-122A-4C3B-847D-3F5D877C7E96</gtr:id><gtr:title>A Key-Pose Caching System for Rendering an Animated Crowd in Real-Time</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7544d52d3bb72ea70ce219b4d1bad0b5"><gtr:id>7544d52d3bb72ea70ce219b4d1bad0b5</gtr:id><gtr:otherNames>Lister W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d067067713b1b2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DD24A153-F6A2-4D41-AC64-1DC3E3C2389B</gtr:id><gtr:title>Stream-based animation of real-time crowd scenes</gtr:title><gtr:parentPublicationTitle>Computers &amp; Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7544d52d3bb72ea70ce219b4d1bad0b5"><gtr:id>7544d52d3bb72ea70ce219b4d1bad0b5</gtr:id><gtr:otherNames>Lister W</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_55f976976c3571a3</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E035639/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>