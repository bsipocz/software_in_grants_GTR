<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/D7FD7E3A-6001-47C8-8411-7B7D70555F93"><gtr:id>D7FD7E3A-6001-47C8-8411-7B7D70555F93</gtr:id><gtr:name>Harman Becker Automotive Systems</gtr:name><gtr:address><gtr:line1>Bennett Street</gtr:line1><gtr:line2>Bridgend Industrial Estate</gtr:line2><gtr:line4>Bridgend</gtr:line4><gtr:line5>Mid Glamorgan</gtr:line5><gtr:postCode>CF31 3SH</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:department>Sound Recording</gtr:department><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/67B34D05-3A52-4A09-8FF9-F2398D60E246"><gtr:id>67B34D05-3A52-4A09-8FF9-F2398D60E246</gtr:id><gtr:name>University of Surrey</gtr:name><gtr:address><gtr:line1>Registry</gtr:line1><gtr:line2>Stag Hill</gtr:line2><gtr:line4>Guildford</gtr:line4><gtr:line5>Surrey</gtr:line5><gtr:postCode>GU2 7XH</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/D7FD7E3A-6001-47C8-8411-7B7D70555F93"><gtr:id>D7FD7E3A-6001-47C8-8411-7B7D70555F93</gtr:id><gtr:name>Harman Becker Automotive Systems</gtr:name><gtr:address><gtr:line1>Bennett Street</gtr:line1><gtr:line2>Bridgend Industrial Estate</gtr:line2><gtr:line4>Bridgend</gtr:line4><gtr:line5>Mid Glamorgan</gtr:line5><gtr:postCode>CF31 3SH</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/CAF908AB-A1A1-4BFD-9848-22BC53CDC3DA"><gtr:id>CAF908AB-A1A1-4BFD-9848-22BC53CDC3DA</gtr:id><gtr:firstName>Russell</gtr:firstName><gtr:surname>Mason</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FD049253%2F1"><gtr:id>F3CDE099-F459-41ED-98DE-14345343BCA0</gtr:id><gtr:title>The role of head movement in the analysis of spatial impression</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D049253/1</gtr:grantReference><gtr:abstractText>Recent research carried out at Surrey's Institute of Sound Recording has developed software that can predict the perceived room width and the location and width of sound sources from audio recordings made using microphones positioned in the ears of a listener or a dummy head. This software is useful in the development of sound reproduction systems such as home cinema systems, because it is cheaper, quicker and more accurate than asking a large number of listeners to judge the sound. However, we now need to investigate the best way to apply this software to making measurements of these sound reproduction systems.Humans make great use of head movement to work out where sounds are coming from. This helps to sort out a number of issues, including whether the sound source is in front or behind, and whether the sound source is above or below. Taking this into account, if our measurements are to accurately predict what we hear when we listen to a surround sound system, we need to find out: what type of head movements we make; how best to capture the signals at the ears to take into account these head movements; and what it sounds like when various physical parameters change as we move our heads. By finding answers to all these questions, we can develop a measurement technique that captures the ear signals in a manner that is relevant to the way in which we usually listen, and we can properly interpret the results from the software.</gtr:abstractText><gtr:fund><gtr:end>2009-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>113577</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Harman Becker Automotive Systems</gtr:collaboratingOrganisation><gtr:country>Germany, Federal Republic of</gtr:country><gtr:description>Harman Becker Automotive Systems</gtr:description><gtr:id>2C6FD640-696B-453A-956A-61E443176911</gtr:id><gtr:outcomeId>b9b49966b9b4997a-1</gtr:outcomeId><gtr:sector>Private</gtr:sector><gtr:start>2006-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Humans are not usually stationary when listening, but use head movement to explore a sound field and resolve potentially confusing cues. We therefore need to take these movements into account if we wish to make measurements that accurately predict what listeners hear. For this, we need to find out: what type of head movement listeners make; how to capture the signals at the ears to take these into account; and what it sounds like when physical parameters change as we move our heads. By finding t</gtr:description><gtr:exploitationPathways>The outcomes of this research can be used in any area in which a perceptually-motivated measurement of audio is required. Increasingly, there is a need for rapid and inexpensive evaluation of audio systems (be they audio processing algorithms, acoustic designs, audio reproduction systems, etc). This research helps to make these measurements more relevant and more similar to human listening, incorporating the fact that human listeners are not stationary when listening. The result of this research</gtr:exploitationPathways><gtr:id>4A5EA6D0-D1E9-4CAC-8889-57A5D24AB736</gtr:id><gtr:outcomeId>r-3268466883.58901777607c20</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Electronics</gtr:sector></gtr:sectors><gtr:url>http://www.surrey.ac.uk/msr/people/ryan_chungeun_kim/index.htm</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>67C354F7-2928-4EBB-8958-7B8DBF16A29E</gtr:id><gtr:title>An investigation into head movements made when evaluating various attributes of sound</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0756d77974c480f811410c2779332012"><gtr:id>0756d77974c480f811410c2779332012</gtr:id><gtr:otherNames> C Kim</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_797378980513da5292</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>646ECE7B-5578-4D5F-97B7-5678FF15C2DB</gtr:id><gtr:title>Initial investigation of signal capture techniques for objective measurement of spatial impression considering head movement</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0756d77974c480f811410c2779332012"><gtr:id>0756d77974c480f811410c2779332012</gtr:id><gtr:otherNames> C Kim</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_370869460413da5404</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>08ABDAF0-F0E1-4E86-B2BA-7B5D2179DA29</gtr:id><gtr:title>Perception of head-position-dependent variations in interaural cross-correlation coefficient</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e0fe35cbac5d5a5b0e31efa1670b12c6"><gtr:id>e0fe35cbac5d5a5b0e31efa1670b12c6</gtr:id><gtr:otherNames> R Mason</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>m_2396023717140275b0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>FF1D5479-E918-480C-A5C1-D10D05B363E2</gtr:id><gtr:title>Head movements made by listeners in experimental and real-life listening activities</gtr:title><gtr:parentPublicationTitle>AES: Journal of the Audio Engineering Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2420d925947f87e623e06b9276c57714"><gtr:id>2420d925947f87e623e06b9276c57714</gtr:id><gtr:otherNames>Kim C.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>15494950</gtr:issn><gtr:outcomeId>54628caa615e66.89733159</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E522B0E8-9516-48DA-879F-7724E831D77B</gtr:id><gtr:title>Taking head movements into account in measurement of spatial attributes</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e0fe35cbac5d5a5b0e31efa1670b12c6"><gtr:id>e0fe35cbac5d5a5b0e31efa1670b12c6</gtr:id><gtr:otherNames> R Mason</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_8293294672140276d2</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>533D7263-0352-4CE1-AD6E-F4268E8F34A0</gtr:id><gtr:title>Characteristics of head movements in subjective evaluation of spatial impression and improvements on spherical binaural capture model towards its obje</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/0756d77974c480f811410c2779332012"><gtr:id>0756d77974c480f811410c2779332012</gtr:id><gtr:otherNames> C Kim</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_552601284313da533c</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D049253/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>