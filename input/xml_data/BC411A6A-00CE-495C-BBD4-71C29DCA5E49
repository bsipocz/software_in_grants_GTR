<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:department>Experimental Psychology</gtr:department><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/4A348A76-B2D0-4DDD-804A-CE735A6D3798"><gtr:id>4A348A76-B2D0-4DDD-804A-CE735A6D3798</gtr:id><gtr:name>University of Bristol</gtr:name><gtr:address><gtr:line1>Senate House</gtr:line1><gtr:line4>Bristol</gtr:line4><gtr:line5>Avon</gtr:line5><gtr:postCode>BS8 1TH</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/3F5FF400-3C1E-434C-A2E6-73F6536F2ECA"><gtr:id>3F5FF400-3C1E-434C-A2E6-73F6536F2ECA</gtr:id><gtr:firstName>Iain</gtr:firstName><gtr:otherNames>Donald</gtr:otherNames><gtr:surname>Gilchrist</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.ukri.org:80/person/1B1F2323-F669-465D-A55F-643C58962339"><gtr:id>1B1F2323-F669-465D-A55F-643C58962339</gtr:id><gtr:firstName>Casimir</gtr:firstName><gtr:surname>Ludwig</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE003044%2F1"><gtr:id>BC411A6A-00CE-495C-BBD4-71C29DCA5E49</gtr:id><gtr:title>The salience of luminance transients to the saccadic eye movement system</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E003044/1</gtr:grantReference><gtr:abstractText>The human visual system is limited in its ability to resolve fine detail. In fact, only in the one or two degrees of central vision (an area of approximately the width of two thumbs at an arm's length) are we able to see with high acuity. Therefore, in order to explore the visual environment humans move their eyes very frequently. These eye movements are called saccades, and we make up to ~10000 of these movements every hour of our waking lives.These eye movements are critical for our ability to see, and therefore for the successful interaction with the world around us. Eye movement researchers are interested in the properties of saccades, and the visual signals that are effective in triggering these movements. To date their approach has been to present human observers with very sparse displays, often only containing one or two items. From these kinds of studies it is clear that the saccadic eye movement system is extremely sensitive to sudden changes in luminance (such as the appearance of a bright spot on a dark background). However, our everyday visual environment is much more stable than the visual displays used to examine saccadic eye movements. For instance, objects typically do not appear or disappear abruptly, but move in or out of sight due to motion in the environment or motion of the observer him/herself. In addition, luminance changes are extremely common- they can results from changes in lighting conditions and, again, motion in the environment or of the observer. It would be best is some of these changes were ignored by the visual system.Ideally one would want the saccadic eye movement system to be sensitive to those luminance changes that really matter. Changes in overall illumination are probably less important that the appearance of a new object. In the proposed project we will examine whether the saccadic system is more sensitive to certain types of luminance changes than to others. In these studies, we present human observers with a number of patches on a computer screen. At the same time, we record their eye movements using an eye tracker. This is a machine that uses cameras to record where people are looking at any particular point in time. After some time, the contrast of one of the patches will be increased and the observer's task is to look at this item. That appears like, and actually is, a very easy task. However, at the time of the contrast increase a change in luminance will occur elsewhere in the display. This change may be brought about by a simulated change in overall lighting conditions (meaning that everything in the display will become brighter), by the sudden appearance of a new object or disappearance of an existing object, and by object motion. If the saccadic eye movement system is sensitive to these kinds of changes it should become more difficult to correctly select the one item that increased in contrast. The extent to which the task becomes more difficult reveals important information about the what kind of luminance changes are particularly important for the saccadic system.Such information is important in a variety of settings in which people are required to quickly respond to rapidly changing visual information. Here you can think about a pilot flying an aircraft or the staff in the airtraffic control room. Our results will inform engineers who design these types of human-computer or human-machine interfaces. The proposed work addresses the fundamental question of what constitutes a salient event for the saccadic eye movement system. Our methodology allows for a more specific answer than simply saying that the system is sensitive to luminance transients.</gtr:abstractText><gtr:fund><gtr:end>2007-10-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>99710</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>4F46A1F0-B1BA-4224-A8BB-891704927CA7</gtr:id><gtr:title>Comparison of the effect of dynamic visual events on saccade target selection</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/96df32260031b60bc06cd5176a7ed9e8"><gtr:id>96df32260031b60bc06cd5176a7ed9e8</gtr:id><gtr:otherNames>C Ludwig</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_340006934813da66c4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F6215D4F-4FBE-47E4-9665-E96195120F35</gtr:id><gtr:title>Limited temporal integration for saccade generation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/96df32260031b60bc06cd5176a7ed9e8"><gtr:id>96df32260031b60bc06cd5176a7ed9e8</gtr:id><gtr:otherNames>C Ludwig</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_942673823513da67fa</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>71D8C419-8B70-4A28-87BF-11215EB971E9</gtr:id><gtr:title>Oculomotor capture by transient events: a comparison of abrupt onsets, offsets, motion, and flicker.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/afd52801c4872da74045af1148c522ee"><gtr:id>afd52801c4872da74045af1148c522ee</gtr:id><gtr:otherNames>Ludwig CJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn><gtr:outcomeId>doi_53d07707756732d6</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E003044/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>30</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>70</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>