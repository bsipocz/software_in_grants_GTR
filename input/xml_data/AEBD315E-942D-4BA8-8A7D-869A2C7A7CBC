<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.ukri.org:80/organisation/B314D8BF-8FAA-491B-BDAB-B0B1C5CEB1EB"><gtr:id>B314D8BF-8FAA-491B-BDAB-B0B1C5CEB1EB</gtr:id><gtr:name>Xerox Research Center Webster; Xerox Corporation</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:department>Sch of Life Sciences</gtr:department><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F"><gtr:id>0838B2E1-D5E2-4ACD-AA27-D2B1BFDC124F</gtr:id><gtr:name>University of Bradford</gtr:name><gtr:address><gtr:line1>Richmond Road</gtr:line1><gtr:line4>Bradford</gtr:line4><gtr:line5>West Yorkshire</gtr:line5><gtr:postCode>BD7 1DP</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/B314D8BF-8FAA-491B-BDAB-B0B1C5CEB1EB"><gtr:id>B314D8BF-8FAA-491B-BDAB-B0B1C5CEB1EB</gtr:id><gtr:name>Xerox Research Center Webster; Xerox Corporation</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948"><gtr:id>58E3A7F8-5B1E-48D2-BDC5-0E835B3FA948</gtr:id><gtr:name>Xerox Corporation</gtr:name><gtr:address><gtr:line1>800 Phillips Road</gtr:line1><gtr:line2>Webster</gtr:line2><gtr:line4>New York 14580</gtr:line4><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/113AB417-F607-4F2F-9367-870B6E7E1A05"><gtr:id>113AB417-F607-4F2F-9367-870B6E7E1A05</gtr:id><gtr:firstName>Marina</gtr:firstName><gtr:surname>Bloj</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FE012159%2F1"><gtr:id>AEBD315E-942D-4BA8-8A7D-869A2C7A7CBC</gtr:id><gtr:title>Colour to grey scale and related transforms</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/E012159/1</gtr:grantReference><gtr:abstractText>Every year, millions of poor grey scale reproductions of colour images are made. Through our research we aim to make millions more good grey scale prints.It is now increasingly common to capture images using colour digital cameras and display them on colour monitors or using colour inkjet printers. However, there are still many occasions when colour images are reproduced in grey scale. The use of black and white printers, photocopiers and fax machines is still an every day occurrence. Unfortunately, the conversion of colour images to their grey scale equivalent, either by these devices, or through other means, often results in a poor reproduction of the images. The aim of our research is to develop a method to derive the best possible grey scale reproduction of a colour image, by a careful consideration of the limitations of our own visual system, and by exploiting the underlying physics of colour image formation. Usually, the colour at a given image point is coded by three numbers, and in the grey scale transformation these three numbers are reduced to just one grey value. More generally, colour information might be coded using N (where N&amp;gt;3) numbers, and in this case it is useful to be able to derive methods to reduce these N numbers to 3, or fewer, so that the N-dimensional information recorded can be displayed on conventional imaging technology. We will extend our research to also consider such cases. Our research will lead to the improved reproduction of images on grey scale devices (e.g. improved photocopying and faxing) as well as providing us with the ability to better visualise the information contained in, for example, satellite images. We also expect that it will be possible to exploit the technology we develop to make colour images that can be viewed without error or confusion, by colour-blind observers. In addition, the work will lead to improvements in existing image-processing algorithms, and to a better understanding of how our own visual system perceives colour and brightness information.</gtr:abstractText><gtr:fund><gtr:end>2010-01-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>34768</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Xerox Research Center Webster; Xerox Corporation</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>Xerox Corporation</gtr:description><gtr:id>5B963C04-7C6C-4BE3-8D66-9B1A94A63549</gtr:id><gtr:impact>No specific outcomes are related to this collaboration. 
The collaboration was not multidisciplinary, but the partners offered a commercial perspective on our research, and applicability in real-life situations.</gtr:impact><gtr:outcomeId>b9c4c2dcb9c4c2f0-1</gtr:outcomeId><gtr:partnerContribution>Guidance and advice throughout the project through regular phone meetings.
Facilities to perform a psychophysical experiment.</gtr:partnerContribution><gtr:piContribution>Regular phone meetings to inform the partner of progress and new developments. 
We visited the research partner for 1 week, giving a talk and performing a psychophysical experiment at their facilities.</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2006-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>63742</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>SpectralEdge Image Visualisation</gtr:description><gtr:end>2011-08-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/I028455/1</gtr:fundingRef><gtr:id>26D1E7B1-ABD9-4C11-ABA7-075FB7ACB8A2</gtr:id><gtr:outcomeId>5eda668e5eda66a2</gtr:outcomeId><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-12-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs><gtr:intellectualPropertyOutput><gtr:description>The technology encompasses a method and system for producing a scalar image from a derivative field. A function class c is selected, where all members of the class c are functions which map each vector of the vector image to a unique scalar value. A function f is selected from the class c which maps the vector image to a scalar image, the derivative of which is closest to the derivative field. The scalar image is generated from the vector image by using f to calculate each scalar value in the scalar image from a corresponding vector in the vector image.</gtr:description><gtr:grantRef>EP/E012159/1</gtr:grantRef><gtr:id>B39CC553-BB58-483F-84AF-2FBCFF015B26</gtr:id><gtr:impact>N/A</gtr:impact><gtr:licensed>Commercial In Confidence</gtr:licensed><gtr:outcomeId>m-7543755562.5510927667247a</gtr:outcomeId><gtr:patentId>GB0914603</gtr:patentId><gtr:protection>Patent application published</gtr:protection><gtr:title>Image reconstruction method</gtr:title></gtr:intellectualPropertyOutput><gtr:intellectualPropertyOutput><gtr:description>The technology prescribes a method and system for producing accented image data for an accented image. The method includes decomposing each of a first and a second image into a gradient representation which comprises spectral and edge components. The first image comprises more spectral dimensions than the second image. The edge component from the first image is combined with the spectral component from the second image to form a combined gradient representation. Accented image data for the accented image is then generated from data including the combined gradient representation.</gtr:description><gtr:grantRef>EP/E012159/1</gtr:grantRef><gtr:id>C9C4ABC9-AEF0-40E9-9D71-05813840378D</gtr:id><gtr:impact>N/A</gtr:impact><gtr:licensed>Commercial In Confidence</gtr:licensed><gtr:outcomeId>m-5000068475.4923627667270e</gtr:outcomeId><gtr:patentId>US12870056</gtr:patentId><gtr:protection>Patent granted</gtr:protection><gtr:title>Method and apparatus for generating accented image data</gtr:title></gtr:intellectualPropertyOutput></gtr:intellectualPropertyOutputs><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>Spectral Edge Ltd</gtr:companyName><gtr:description>Formed in February 2011, Spectral Edge is a spin-out company of the Colour and Vision Group of the School of Computing Sciences at the University of East Anglia in Norwich (United Kingdom).

The Group is active in a range of different research areas such as Computational Colour Constancy, Physics based vision, Image Reproduction, Colour Graphics, Image Indexing, Colour scanning, Colour Science, and Computer Vision.

Spectral Edge was formed to exploit exciting research into image fusion and colour perception.

This technology is provided as embedded software (matlab reference code, production C code, production OpenGL shader code, ...). Our aim is to enable our customers to differentiate their products by enabling the highest possible visual quality.</gtr:description><gtr:id>CE015519-4654-46CA-A6E1-AA491A84B8BD</gtr:id><gtr:impact>July 18th 2014, Visual Clarity for All : Spectral Edge Announces Seed Investment Round Led by the Rainbow Seed Fund and ICENI.</gtr:impact><gtr:outcomeId>54624a6be2a0c1.58789909</gtr:outcomeId><gtr:url>http://www.spectraledge.co.uk</gtr:url><gtr:yearCompanyFormed>2011</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication><gtr:id>F88F9287-7F08-4576-AFA9-2615058F88FF</gtr:id><gtr:title>Seeing Beyond Luminance: A Psychophysical Comparison of Techniques for Converting Colour Images to Greyscale</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f1f6f750f82b3f2b78418e1681169baa"><gtr:id>f1f6f750f82b3f2b78418e1681169baa</gtr:id><gtr:otherNames>Connah D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:outcomeId>m_586665560613dc1cbc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>35CD7D33-F947-47F7-8076-074638355BFC</gtr:id><gtr:title>Preferred greyscale versions of coloured images: Human vs machine</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d07707763dbde6</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F7703C13-17B0-4C0F-8112-2AA44E261FCB</gtr:id><gtr:title>Reducing integrability error of color tensor gradients for image fusion.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_53d05e05e4183b25</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>CCBC3D2B-C63E-411A-B969-2B5344A5E879</gtr:id><gtr:title>Histogram compression and image retrieval through Padua points interpolation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/690fe49e5246c0e9cc2f0f4623cc40db"><gtr:id>690fe49e5246c0e9cc2f0f4623cc40db</gtr:id><gtr:otherNames>Montagna R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_90318753966427b916</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>602462CB-854F-461A-81A0-D8CC21E90CD4</gtr:id><gtr:title>Optimal interpolation and Lp norm minimisation in colour indexing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c6490cc9ec5c2bd9fddd930ed505e3fc"><gtr:id>c6490cc9ec5c2bd9fddd930ed505e3fc</gtr:id><gtr:otherNames> Finlayson G. D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_76813251036427bf10</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>56225937-2890-4B27-B05D-64937E96D977</gtr:id><gtr:title>Path-based computations in colour image processing</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/7d2af2357ad530f42e006146ed02d7ce"><gtr:id>7d2af2357ad530f42e006146ed02d7ce</gtr:id><gtr:otherNames>Montagna Roberto</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:outcomeId>r_198012169663eaa832</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>400A3C7F-68A5-4BD8-A550-AB626E5BCA58</gtr:id><gtr:title>Constrained pseudo-Brownian motion and its application to image enhancement.</gtr:title><gtr:parentPublicationTitle>Journal of the Optical Society of America. A, Optics, image science, and vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1084-7529</gtr:issn><gtr:outcomeId>doi_53d07e07e9025fb4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>105C205B-B86D-4FF0-B7E1-BBF93A6A11D9</gtr:id><gtr:title>A Unified Approach to Colour2Grey and Image Enhancement Through Gradient Field Integration</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2e489e0111355dc6ce6ccc399d41260c"><gtr:id>2e489e0111355dc6ce6ccc399d41260c</gtr:id><gtr:otherNames>Finlayson G. D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>r_95539016656427ba4c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>52587F5E-C76E-40A2-9F82-3DB4FA5C549A</gtr:id><gtr:title>Consistent grey-level ordering for iso-luminant and iso-saturated colours</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/93a4f7642466af9bc199e6952e10d554"><gtr:id>93a4f7642466af9bc199e6952e10d554</gtr:id><gtr:otherNames>Bloj M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>r_37832614576430ecc0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ACAB249A-1782-4CDF-9343-4F0CA137C864</gtr:id><gtr:title>A novel approach to hue ordering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f1f6f750f82b3f2b78418e1681169baa"><gtr:id>f1f6f750f82b3f2b78418e1681169baa</gtr:id><gtr:otherNames>Connah D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_429885799213dc1d66</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>14688851-CF6E-4CBF-AF0B-3CF3BCD8AEB5</gtr:id><gtr:title>Human Assignment of Grey Levels Depends on Scene Complexity</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f1f6f750f82b3f2b78418e1681169baa"><gtr:id>f1f6f750f82b3f2b78418e1681169baa</gtr:id><gtr:otherNames>Connah D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>r_14013289156427b79a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BFEA8EAB-EAB2-4566-A7DF-89C053683C07</gtr:id><gtr:title>What do we know about how humans choose grey levels for images?</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d7e19aef2209102c9305d15d4cdad672"><gtr:id>d7e19aef2209102c9305d15d4cdad672</gtr:id><gtr:otherNames>Bloj M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d077077392b08b</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>E22AC47B-1D4C-4A87-9251-18F98B8A1BB8</gtr:id><gtr:title>Improved colour to greyscale via integrability correction</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2cacdc99d24acf09aef11e8bea3e98f3"><gtr:id>2cacdc99d24acf09aef11e8bea3e98f3</gtr:id><gtr:otherNames>Drew M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:outcomeId>doi_53d06d06d949b61a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>253296DF-29DC-41BB-98C9-7D16435C76CC</gtr:id><gtr:title>Padua point interpolation and Lp-norm minimisation in colour-based image indexing and retrieval</gtr:title><gtr:parentPublicationTitle>IET Image Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:outcomeId>doi_53d03103192eb01e</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>F0DD12A7-D5EA-4E71-AE43-CCCA97E1F07F</gtr:id><gtr:title>Constrained Pseudo-Brownian Motion for Image Enhancement</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/690fe49e5246c0e9cc2f0f4623cc40db"><gtr:id>690fe49e5246c0e9cc2f0f4623cc40db</gtr:id><gtr:otherNames>Montagna R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>r_55404553216427c03c</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>20A5DFA4-ACAB-4F74-BF33-5C3722F6F2FB</gtr:id><gtr:title>Visual sensitivity to achromatic gradients with different luminance profiles</gtr:title><gtr:parentPublicationTitle>Journal of Vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/c13e117b06aca330858c5b689b139c35"><gtr:id>c13e117b06aca330858c5b689b139c35</gtr:id><gtr:otherNames>Garcia-Suarez L</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:outcomeId>doi_53d0770775c9bddc</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>D38E3593-E706-4C4B-836C-C5B6EA9C494C</gtr:id><gtr:title>An investigation into perceptual hue-ordering</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/f1f6f750f82b3f2b78418e1681169baa"><gtr:id>f1f6f750f82b3f2b78418e1681169baa</gtr:id><gtr:otherNames>Connah D.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:outcomeId>m_621149002113dc1bf4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>EC719752-D5DA-488D-BBFF-BC628730131E</gtr:id><gtr:title>Reducing integrability artefacts for data fusion through colour space manipulation</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/3d157d26d45cf4016791144dd77e1330"><gtr:id>3d157d26d45cf4016791144dd77e1330</gtr:id><gtr:otherNames>Montagna R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:isbn>978-1-4244-4442-7</gtr:isbn><gtr:outcomeId>doi_53d0580586d0dd7a</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2E89A847-2378-40E1-9E11-692A9BBB8B7D</gtr:id><gtr:title>Lookup-table-based gradient field reconstruction.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/6a93a01532ef14b3aa1a1b901c40810e"><gtr:id>6a93a01532ef14b3aa1a1b901c40810e</gtr:id><gtr:otherNames>Finlayson GD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_53d05e05e3d7f337</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/E012159/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>80</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>