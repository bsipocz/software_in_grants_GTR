<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/1AB05DA1-4DD6-4843-B416-D7D9441EBFFB"><gtr:id>1AB05DA1-4DD6-4843-B416-D7D9441EBFFB</gtr:id><gtr:name>Royal Veterinary College</gtr:name><gtr:department>Comparative Biomedical Sciences CBS</gtr:department><gtr:address><gtr:line1>Royal College Street</gtr:line1><gtr:line2>Camden Town</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>NW1 0TU</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/1AB05DA1-4DD6-4843-B416-D7D9441EBFFB"><gtr:id>1AB05DA1-4DD6-4843-B416-D7D9441EBFFB</gtr:id><gtr:name>Royal Veterinary College</gtr:name><gtr:address><gtr:line1>Royal College Street</gtr:line1><gtr:line2>Camden Town</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>NW1 0TU</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E50BFB7B-D2A9-4939-B759-001C41FF20F7"><gtr:id>E50BFB7B-D2A9-4939-B759-001C41FF20F7</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:otherNames>James</gtr:otherNames><gtr:surname>Bomphrey</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=BB%2FR002657%2F1"><gtr:id>05AB34A7-5668-4F90-BA53-1D0D613883B0</gtr:id><gtr:title>Fly-by-Feel: the neural representation of aeroelasticity.</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/R002657/1</gtr:grantReference><gtr:abstractText>Mechanosensation is the fastest sensory modality in animals, and insects exploit this fully in flight control. In particular, the insect wings are adorned with hundreds of mechanosensors distributed in a well-organized manner. These sensors perform multiple tasks, but many are used to encode the unsteady aerodynamics of flight. Several lines of evidence to date suggest that wing sensors provide essential sensory feedback to modulate the motor pattern, gate other sensory signals, implement aerial reflexes and possibly contribute to motor-learning. In contrast, human approaches to evaluating unsteady, or time-dependent, aerodynamic phenomena often require heavy instrumentation and expensive computational power to simulate or measure the fluid flows. How do insects, with acutely limited computational resources, extract relevant information using smart sensor distribution, sensor tuning and signal encoding? What is the neural representation of the sensation of fluid? These are key questions that have implications for our understanding of mechanosensation in general; the results will be directly applicable to aviation and adaptive motion control for modern robotics.

The principal goal of this proposed research is to unite cutting edge neurophysiology with state-of-art computational fluid and structural dynamics to reveal how fluid sensing is realized in insect wings. We will first catalog the wing sensor distribution and types in selected species of dragonflies, hawkmoths, and locusts. Second, we will characterize the output signals of representative sensors individually and as populations. With the recently developed ultra-light neural recording device, we will monitor selected wing sensors while the insects are in-flight. Simultaneous we will digitize the detailed wing deformation in order to reconstruct the mechanical stimuli the wing sensors register and the aerodynamic features associated with the wing deformation. Finally, we will combine all the data and link aerodynamics to wing deformation, and to mechanosensory signals.

Both dragonflies and hawkmoths are excellent fliers that rely on flight to intercept flying prey or to feed from a flower. They are great systems for studying the neural encoding of fluid sensing because they have exposed sensors, relatively simple nervous system and sufficient payload to carry wireless neural devices while performing flight maneuvers. Our work will provide fundamental understanding of how fluid sensing is achieved with only a few sensors and insights to how complex mechanics can be represented in a nervous system. Sensor robustness, cost, and the associated computational power requirements are major issues of concern for modern aviation. The next generation of manned and unmanned air vehicles will require fundamentally redesigned control architectures based on biological designs. Our findings will illuminate the evolution of fluid sensing in animals and also inform the design of future aircraft. 

The use of mechanosensors in locomotor control is fundamental to most animals at some stage in their lives. Therefore, this work will answer fundamental questions of locomotion relevant to all animal taxa. Ultimately, this project will thoroughly change the way biologists see how neural encoding links sensory cues from self-motion and the environment to behavioral commands.</gtr:abstractText><gtr:technicalSummary>Mechanosensation is ubiquitous and central to adaptive motion control. However, there is currently only a poor understanding of the sensory input signals elicited by complex forces (e.g. friction, acoustics, and fluid forces). During flight, insects are masters of monitoring the instantaneous loads on their wings, exemplifying the encoding of dynamic complexity in a tractable system. In this work, we will uncover how insects extract relevant aerodynamic features via an intricately organized suite of mechanosensors on the wings.

Our work is made possible by three recent technical breakthroughs. First, by miniaturizing neural amplifiers and developing neural implants for large insects, we are now able to record from sensory neurons in free-flying animals. This allows us to eavesdrop on the mechanosensory signals from the wings during flight. Second, we have developed a high-precision motion-capture protocol to digitize flying insect kinematics in real-time, allowing us to trigger high-speed cameras that capture wing motion and deformation. Third, we can use coupled computational fluid dynamics and structural dynamics models. This tool enables us to reconstruct and predict the aerodynamic and mechanical stimuli the wing sensors measure (via fluid-solid coupling). Combining these three technologies, we can reveal the neural representation of aeroelasticity for the first time.

Recording neural activities in freely moving animals offers direct answers to how neural networks compute sensory information to generate actions. Neural telemetry systems enable this approach, yet recording from a moving subject and reconstructing sensory stimuli during free behaviors remains a formidable task. In this work, we will demonstrate how to record wirelessly from a fast moving appendage on a moving subject, and reconstruct complex sensory stimuli with computational models. This breaks new ground and will advance substantially the field of wireless neurophysiology.</gtr:technicalSummary><gtr:potentialImpactText>Fluid sensing is the least understood of all mechanosensations, yet nature achieves this with robustness and finesse. Engineered systems from wind turbines to cardiovascular implants are designed based on pre-calculated (or pre-calibrated) steady-state conditions the system typically experiences but there is no easy way to extrapolate to unsteady fluid states to maintain effective, optimal function. Even with modern computational tools, it takes much time and effort to simulate and understand complex fluid dynamics. This project aims to understand how highly dynamic flying insects sense and encode aeroelasticity in flight. The result will reveal how a relatively simple nervous system extracts relevant aerodynamic features through a small yet strategically patterned sensor array. Our findings will have direct impact on engineering designs and control systems for any application involving fluid manipulation.

With the development of smart cameras from the late 80's, vision research in neuroscience and computational biology flourished, revealing how animals perceive the world. Today, we have sophisticated machine vision systems driving a revolution in artificial intelligence (AI) and automated industries (eg automobile, food processing, farming, pharmaceutical). Similarly, mechanosensation is poised to provide similar insights for systems neuroscience and bio-inspired engineering in the next few decades. While AI robotic systems can provide timely and relevant information, they are limited in physical performance due to the challenge of adaptive motion control. Optical systems are relatively slow and computationally costly. To advance beyond this barrier, AI systems must be able not only to see, but also to feel. With the rapid emergence of civilian drones, self-driving cars and medical robots, that sense of touch might be all we need to make things safe and reliable. In 2016 the Ministry of Defence announced &amp;pound;800m for the Defence Innovation Initiative, including a fous on bio-inspired innovation to tackle current security challenges. The expected outputs from this research project are crucial to delivering impact in this sector.

Our outputs will have immediate impact in the field of aerial robotics. Our findings will promote the development of bio-inspired sensing mechanisms on the wings, body, or rotors of next generation aerial systems, where aeroelastic information will become the principal input for flight controllers. Instantaneous loading information will help aerial systems achieve greater control, more agile flight maneuvers, and to harvest energy from the atmosphere for improved economy. Similarly, incorporating aeroelastic sensory feedback will allow manned aircraft to respond more rapidly to turbulence or the onset of stall. Beyond aviation, effective fluid sensing can improve the design and control of wind-turbines, hydroelectric turbines, and even combustion engines. In biomedical applications, cardiovascular implants and endoscopy would benefit from enhanced state information. Our work will show how to capture unsteady aeroelastic information in real-time which is a new discovery in biological mechanosensing, and will underpin a new domain for technological innovations. Large-scale stakeholder sectors include (but are not limited to) medical instrumentation, aerial robotics, soft robotics, and renewable energy (e.g. wind and tidal turbines), each of which contribute to human health and well-being. Success in these fields will have a positive economic impact and maintain the UK at the forefront of technology innovation.</gtr:potentialImpactText><gtr:fund><gtr:end>2020-09-30</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2017-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>352623</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">BB/R002657/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>772CD758-53CD-407F-9B2C-F2B861E86155</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Mechanical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>ED6338AE-3457-45D6-90CA-B994C3CF422B</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Aerodynamics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>CF888A60-6892-4111-A23F-E8A95D103915</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Musculoskeletal system</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>