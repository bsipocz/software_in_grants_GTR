<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/9C10D78F-6430-4CA7-9528-B96B0762A4C6"><gtr:id>9C10D78F-6430-4CA7-9528-B96B0762A4C6</gtr:id><gtr:name>Cardiff University</gtr:name><gtr:address><gtr:line1>Research &amp; Consultancy</gtr:line1><gtr:line2>PO Box 923</gtr:line2><gtr:line4>Cardiff</gtr:line4><gtr:line5>South Glamorgan</gtr:line5><gtr:postCode>CF10 3TE</gtr:postCode><gtr:region>Wales</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/FA571F54-6F0E-48EA-87B8-B07A83E6004B"><gtr:id>FA571F54-6F0E-48EA-87B8-B07A83E6004B</gtr:id><gtr:name>Tsinghua University</gtr:name><gtr:address><gtr:line1>Tsinghua</gtr:line1><gtr:line4>Hai Dian District</gtr:line4><gtr:line5>Beijing</gtr:line5><gtr:postCode>100084</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>China</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/CCFA3B48-16D1-482A-A2A0-368E4528C384"><gtr:id>CCFA3B48-16D1-482A-A2A0-368E4528C384</gtr:id><gtr:firstName>Ralph</gtr:firstName><gtr:otherNames>Robert</gtr:otherNames><gtr:surname>Martin</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=EP%2FJ009830%2F1"><gtr:id>C720EEE5-1AE0-449D-86FE-62B76D025EBB</gtr:id><gtr:title>Structural analysis and interactive composition of visual media</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J009830/1</gtr:grantReference><gtr:abstractText>This project represents joint work between 12 leading Chinese Universities, and several other invited key partners in the UK and US. 

The Internet, and other large-scale databases, form a significant resource of what may be termed &amp;quot;visual media&amp;quot;: images, videos, 3D shape models, and so on. Internet text searches usually produce useful results. However, it can be much more difficult to find visual media, e.g. videos with specific content, or images similar to a picture in one's mind's eye. This is partly due to the fact that most image search is based on text inputs, and partly due to the difficulty of classifying pictures. It is easy for humans to &amp;quot;know&amp;quot; what an image contains, but image understanding by computer requires many tricky tasks - splitting an image into separate objects, and analysing their colour, their shape, and many other attributes. Better solutions to search of visual media would enable many applications in addition to search itself, and we will also look at one of them - the re-use of existing visual media when creating new visual media. 

This project has four main goals. 

The first is to investigate new approaches to structural analysis of visual media. This will include devising methods to find salient information (for example, what is the main object? what is irrelevant background? how is this object composed of parts?), and methods which process the information on different scales (small details may be just as important as overall shape, for example). The aim is to come up with hierarchical descriptions of the important information in visual media. 

The second is to find efficient new approaches to comparing, classifying and searching visual media, based on the above hierarchical descriptions. We will also look at how sketches can be used as a much more powerful means than text of allowing users to describe what they want to find when searching.

The third area to be considered is editing and resynthesis of visual media. Structural analysis will provide more meaningful ways to select parts of an image than just, for example, all parts of the scene with a certain colour. In turn, this will simplify the process of editing visual media. Users will be able to apply consistent editing to scene elements with similar meaning (e.g. the user controls bending of one finger, and the computer applies a similar bend to the rest of the fingers of a hand, despite minor shape differences). More powerful search will also allow elements to be rapidly retrieved from visual media databases or the Internet to be combined into new scenes, or to be included within existing images, with suitable adjustment for different lighting, etc. When video is processed, further considerations will be needed to ensure results are consistent over time, and smoothly vary as time progresses; the vast amounts of data involved in video processing make this a challenging problem.

The final area of work concerns the use of machine learning techniques to assist with all of the previous goals. The aim here is to automatically learn to recognize complex patterns, permitting software to make intelligent decisions based on visual data. Ultimately, a careful balance must be struck in which the user is firmly in control of the creative process, but the computer makes it easy for the user to produce the desired results.</gtr:abstractText><gtr:potentialImpactText>The ultimate beneficiaries of this research will be multiple, and wide ranging. 
Improved search of visual media, e.g. for images or video on the Internet, could clearly benefit the public at large. Improved content analysis has potential applications in many areas such as security (where have I seen this person before? what are they doing?), summarisation (e.g. producing edited highlights of a sports match or movie), digital rights protection (finding unauthorised copies of digital media), and so on. 
Interactive composition of digital media has many potential applications in computer aided design, digital entertainment, broadcasting, games, advertising, and other areas. 
For example, incorporation of existing geometric mesh data has the potential to allow rapid design and re-use of complex shapes, helping CAD to go beyond its traditional remit of mechanical design to applications in artistic design. 
The ability to synthesise video content from a mix of geometric models and existing video, and to edit video content in novel ways, promises large savings in the cost of movie production. 

Apart from these established application areas, other areas are rapidly developing - current mobile phones already include graphics processors, and some are starting to employ 3D cameras and displays. The techniques devised during this project will help to provide an underpinning for a new generation of mobile applications.

Historically, the UK has been at the forefront of CAD software and digital entertainment software, and participation in internationally leading collaborations is essential to retain that position.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-04-21</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2012-01-15</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>95804</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Various algorithms are in use by Chinese companies such as Tencent.
A new journal, Computational Visual Media, has been set up by the UK and Chinese partners in on this grant, as a new outlet for this expanding area.</gtr:description><gtr:firstYearOfImpact>2012</gtr:firstYearOfImpact><gtr:id>49FF1ECD-33B7-4146-82FE-57847EBEE371</gtr:id><gtr:impactTypes><gtr:impactType>Societal,Economic</gtr:impactType></gtr:impactTypes><gtr:outcomeId>5440daee36eaa2.49473560</gtr:outcomeId><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Mnay algorithms for processing visual media: images and video. For example, extrapolating an image to make a larger one using data from online images, and changing the times at which things happen in a video.</gtr:description><gtr:exploitationPathways>Implementation in commercial software, Further research.</gtr:exploitationPathways><gtr:id>584635BE-E39E-4B43-9985-1A37BF386082</gtr:id><gtr:outcomeId>5440dbc42235e4.01354945</gtr:outcomeId><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Leisure Activities, including Sports, Recreation and Tourism,Culture, Heritage, Museums and Collections,Other</gtr:sector></gtr:sectors><gtr:url>http://ralph.cs.cf.ac.uk/publications.html</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>462C8AC4-1959-4C81-BD17-8C10C935A0AC</gtr:id><gtr:title>Panorama completion for street views</gtr:title><gtr:parentPublicationTitle>Computational Visual Media</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c0c432d0afd5a378dfedf7d936619a8"><gtr:id>2c0c432d0afd5a378dfedf7d936619a8</gtr:id><gtr:otherNames>Zhu Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>55e94d7bd535b1.01526528</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>C2D93701-8E38-4256-AE87-337F40875808</gtr:id><gtr:title>Simultaneous Camera Path Optimization and Distraction Removal for Improving Amateur Video.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/628d35a1720db833836a7bf008a2e7bc"><gtr:id>628d35a1720db833836a7bf008a2e7bc</gtr:id><gtr:otherNames>Zhang FL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>571dd889c95eb5.66551249</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>0C15BE86-CCC9-42E6-90F4-B89D22FB5D6C</gtr:id><gtr:title>PatchNet</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c28afab156b866005fe5f0f689561a1"><gtr:id>2c28afab156b866005fe5f0f689561a1</gtr:id><gtr:otherNames>Hu S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>doi_53d075075d655904</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>470E524D-623C-43A8-8356-5BAA7A2BC504</gtr:id><gtr:title>Internet visual media processing: a survey with graphics and vision applications</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c28afab156b866005fe5f0f689561a1"><gtr:id>2c28afab156b866005fe5f0f689561a1</gtr:id><gtr:otherNames>Hu S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:outcomeId>5440d4ea131f18.17053588</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>BDED04FB-B720-42BC-A7B4-DA77014166B5</gtr:id><gtr:title>Automatic semantic modeling of indoor scenes from low-quality RGB-D data using contextual information</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2d598d492808bcc18f3f0976a1aedc8f"><gtr:id>2d598d492808bcc18f3f0976a1aedc8f</gtr:id><gtr:otherNames>Chen K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5486eec626b657.61893431</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B378C978-12A9-4C0F-B08F-B67C2CF5EE83</gtr:id><gtr:title>Semiregular solid texturing from 2D image exemplars.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1221d2049391aa9f08fbe283cd6eef89"><gtr:id>1221d2049391aa9f08fbe283cd6eef89</gtr:id><gtr:otherNames>Du SP</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_53d05f05fe5cf258</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>1D77D33F-0EA4-4F11-839E-ACEB209F8E46</gtr:id><gtr:title>BiggerPicture</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/737ffe0e530a693d7c0da01892f1528d"><gtr:id>737ffe0e530a693d7c0da01892f1528d</gtr:id><gtr:otherNames>Wang M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>5486eec65217d3.66311320</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>5EE39D97-0146-4340-BA4A-7563BAE66850</gtr:id><gtr:title>Timeline editing of objects in video.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1595f4fec3d527d94f6038db1b337c1c"><gtr:id>1595f4fec3d527d94f6038db1b337c1c</gtr:id><gtr:otherNames>Lu SP</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_53d05f05fe667347</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>505138DC-2F60-472B-91CA-10FACBE06909</gtr:id><gtr:title>Learning Natural Colors for Image Recoloring</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/e94754791b4be0de589dc01808c98d92"><gtr:id>e94754791b4be0de589dc01808c98d92</gtr:id><gtr:otherNames>Huang H</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546f3cc330df74.05235408</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>DABDBECC-8344-450D-B077-E543B8AD6C7F</gtr:id><gtr:title>New advances in visual computing for intelligent processing of visual media and augmented reality</gtr:title><gtr:parentPublicationTitle>Science China Technological Sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/8db5e45b76ddc3e40438e2c04b30cb1a"><gtr:id>8db5e45b76ddc3e40438e2c04b30cb1a</gtr:id><gtr:otherNames>Wang J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:outcomeId>56a91222546313.68877556</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>23265DDE-A507-4D07-905F-9F1FCAF015DA</gtr:id><gtr:title>Multiphase SPH simulation for interactive fluids and solids</gtr:title><gtr:parentPublicationTitle>ACM Transactions on Graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1d7922a4a78edbd9d9df91afc6382995"><gtr:id>1d7922a4a78edbd9d9df91afc6382995</gtr:id><gtr:otherNames>Yan X</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>579f15bb4e19e5.24092403</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>AC94AD7D-D58C-4ED7-9ABA-7D5BAC31DC8F</gtr:id><gtr:title>Structure Aware Visual Cryptography</gtr:title><gtr:parentPublicationTitle>Computer Graphics Forum</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a4377ed4861af442d6d8939bfb897ce6"><gtr:id>a4377ed4861af442d6d8939bfb897ce6</gtr:id><gtr:otherNames>Liu B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>546f3cc2b437a1.24753660</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>30ECE313-74E8-4B9B-B745-B1990AD02891</gtr:id><gtr:title>Versatile Interactions at Interfaces for SPH-Based Simulations</gtr:title><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/a99850b69fb4b76b223930633610ac61"><gtr:id>a99850b69fb4b76b223930633610ac61</gtr:id><gtr:otherNames>Yang, T.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>578659d317aac9.45847688</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>2E706CE4-7044-4B3F-BE09-CB6D9E543FEA</gtr:id><gtr:title>Changing perspective in stereoscopic images.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/1221d2049391aa9f08fbe283cd6eef89"><gtr:id>1221d2049391aa9f08fbe283cd6eef89</gtr:id><gtr:otherNames>Du SP</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_53d05f05feb47cca</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7D9726F8-4C0C-4BEC-B8F9-2593B54169E2</gtr:id><gtr:title>Fisheye video correction.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on visualization and computer graphics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/55b6926a204b256a6c5e49c80d04d792"><gtr:id>55b6926a204b256a6c5e49c80d04d792</gtr:id><gtr:otherNames>Wei J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1077-2626</gtr:issn><gtr:outcomeId>doi_53d05f05fe3d4749</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>7CB833F0-E1FF-400C-B904-179956332EF5</gtr:id><gtr:title>Mixed-domain edge-aware image manipulation.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/d02ba7e8619540be14955b5bffe007af"><gtr:id>d02ba7e8619540be14955b5bffe007af</gtr:id><gtr:otherNames>Li XY</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>doi_53d05e05e40e54f0</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ED6C4303-23BA-410E-B427-9AEEF2B9FD59</gtr:id><gtr:title>3D modeling and motion parallax for improved videoconferencing</gtr:title><gtr:parentPublicationTitle>Computational Visual Media</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/2c0c432d0afd5a378dfedf7d936619a8"><gtr:id>2c0c432d0afd5a378dfedf7d936619a8</gtr:id><gtr:otherNames>Zhu Z</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:outcomeId>575ec609677647.64544184</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>ADAEC9E6-AF6B-4059-977D-5B0B0B970FDD</gtr:id><gtr:title>Efficient, Edge-Aware, Combined Color Quantization and Dithering.</gtr:title><gtr:parentPublicationTitle>IEEE transactions on image processing : a publication of the IEEE Signal Processing Society</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/95751be6b85264ed7d8b7a9e5a9e7ff1"><gtr:id>95751be6b85264ed7d8b7a9e5a9e7ff1</gtr:id><gtr:otherNames>Huang HZ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1057-7149</gtr:issn><gtr:outcomeId>56a91300326632.90517070</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>049E2884-73C5-4060-8589-C2C7351A1043</gtr:id><gtr:title>A response time model for abrupt changes in binocular disparity</gtr:title><gtr:parentPublicationTitle>The Visual Computer</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/9c6a03da30e18c4e9be91d585407f66d"><gtr:id>9c6a03da30e18c4e9be91d585407f66d</gtr:id><gtr:otherNames>Mu T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:outcomeId>56a9110420b7f1.03109824</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J009830/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>A704B681-6133-41A6-8D93-905FFEC6353B</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Computer Graphics &amp; Visual.</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>