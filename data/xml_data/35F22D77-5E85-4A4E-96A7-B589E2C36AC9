<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.ukri.org/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.ukri.org:80/organisation/C4145C68-58B8-441E-86DD-A4079B65B478"><gtr:id>C4145C68-58B8-441E-86DD-A4079B65B478</gtr:id><gtr:name>MRC Institute of Hearing Research</gtr:name><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.ukri.org:80/organisation/C4145C68-58B8-441E-86DD-A4079B65B478"><gtr:id>C4145C68-58B8-441E-86DD-A4079B65B478</gtr:id><gtr:name>MRC Institute of Hearing Research</gtr:name><gtr:address><gtr:line1>University Park</gtr:line1><gtr:line4>Nottingham</gtr:line4><gtr:postCode>NG7 2RD</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.ukri.org:80/person/E7CF1C00-6496-4E6F-A64E-CD46D9C74470"><gtr:id>E7CF1C00-6496-4E6F-A64E-CD46D9C74470</gtr:id><gtr:firstName>Deb</gtr:firstName><gtr:otherNames>Ann</gtr:otherNames><gtr:surname>Hall</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.ukri.org:80/projects?ref=MC_U135079243"><gtr:id>35F22D77-5E85-4A4E-96A7-B589E2C36AC9</gtr:id><gtr:title>Human auditory attention measured using behavioural and neuroimaging techniques</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Intramural</gtr:grantCategory><gtr:grantReference>MC_U135079243</gtr:grantReference><gtr:abstractText>Imagine being at a party. Your auditory environment contains a rich array of sounds from which you must select the person who is speaking to you, whilst suppressing the rest of the background chatter. Attention is the term that refers to this ability to select information in order to guide perception and action. Overwhelmingly so far, research has focused on visual attention. One of the key questions we address concerns the extent to which the mechanisms of auditory attention are the same as those reported for visual attention. Impaired attention can have radical consequences for everyday functioning, even when the peripheral senses (eyes and ears) are working normally. At one extreme, a deficit in auditory attention caused by stroke impairs the ability to make simple comparisons between a pair of sounds. More subtle difficulties may however compromise listening abilities in many other groups, such as the elderly hearing-impaired and children with auditory processing disorders, especially in situations containing a lot of background noise. Mostly, our research questions can be answered by recruiting normally-hearing listeners to participate in a range of specially-designed listening tests. However, an additional project has been tailored to investigate attention-related performance in clinical groups.</gtr:abstractText><gtr:technicalSummary>This research aims to anchor hearing in an appropriate behavioural context. Attention is one of the principal influences on listening performance. Attention has many different definitions, but this project concerns the ability to select information from the environment to guide perception and action and requires the appropriate allocation of limited processing capacities. Attention is measured by studying the effect of different 'attentional' conditions on people?s ability to discriminate a range of stimuli. Such manipulations have primarily been made in the visual domain and have identified a taxonomy of attention processes. One of the dominant frameworks considers attention processes as a general set of supramodal primitives (i.e. they operate in the same way across the senses). In a series of projects we are evaluating how well these existing models of visual attention describe attention in the auditory domain. One of the primary objectives therefore is to seek empirical support for the functional and anatomical correspondences between visual and auditory attention systems using behavioural, neuroimaging measures and cognitive neuropsychological techniques.

A number of clinical tests of attention work on the assumption that the modality of presentation has no material effect on performance. While we have shown that this is true for some types of attention (such as control processing), it is not necessarily the case for other types of attention (such as spatial orienting). In a series of behavioural experiments, we have fully explored a key aspect of this modality difference; the size of the advantage for non-spatial judgements gained by spatially orienting to the correct target location. The weak effect in audition indicates that attention effects are not equivalent across vision and audition. Our results suggests that the benefit of orienting attention in audition is partly determined by the way in which the attended stimulus feature is encoded by the brain, as well as by the spatial coordinate frame of the stimulus (determined by presenting a sound in freefield or over headphones). We have also used an approach that is complementary to the behavioural tests in normal hearing listeners. This includes a cognitive neuropsychological approach which examines attentional problems in patients who have suffered stroke or head injury. The performance of patients with attentional deficits on carefully-matched visual and auditory tasks also support the same conclusion. We have shown that patients who have impaired spatial awareness of their visual environment do not always have corresponding difficulties in perceiving the auditory world around them.

The outcome of this work will feed into other IHR programmes by providing a guide to the design of an appropriate selective attention test for use in awake-behaving ferrets, as well as a background for the ERP studies of attention and the more applied work with elderly listeners.</gtr:technicalSummary><gtr:fund><gtr:end>2009-03-31</gtr:end><gtr:funder url="http://gtr.ukri.org:80/organisation/C008C651-F5B0-4859-A334-5F574AB6B57C"><gtr:id>C008C651-F5B0-4859-A334-5F574AB6B57C</gtr:id><gtr:name>MRC</gtr:name></gtr:funder><gtr:start>2004-04-01</gtr:start><gtr:type>EXPENDITURE_ACTUAL</gtr:type><gtr:valuePounds>523390</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Audiologists professional development</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:id>1A9248B6-7E13-44F6-AECD-971D895ED778</gtr:id><gtr:impact>Invited faculty member at the European Tinnitus course: 2010, 2009, 2004, 2002, 2001 held annually in cambridge. Attended by about 200 audiologists from all over the world

None known</gtr:impact><gtr:outcomeId>7142F0BE762</gtr:outcomeId><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Health professionals</gtr:primaryAudience><gtr:year>2009</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication><gtr:id>028E2A86-EF00-4E41-8A8E-383C5D5A4027</gtr:id><gtr:title>Covert auditory spatial orienting: an evaluation of the spatial relevance hypothesis.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/35c34ed729fbda00ed41955e94795c37"><gtr:id>35c34ed729fbda00ed41955e94795c37</gtr:id><gtr:otherNames>Roberts KL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn><gtr:outcomeId>1B2A9D1BA55</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>86045DF0-E060-47A5-BBF4-0B391F10DE14</gtr:id><gtr:title>Auditory processing disorders: acquisition and treatment.</gtr:title><gtr:parentPublicationTitle>Journal of communication disorders</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/760090565cb4f49c4dbc3a2438be4a16"><gtr:id>760090565cb4f49c4dbc3a2438be4a16</gtr:id><gtr:otherNames>Moore DR</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0021-9924</gtr:issn><gtr:outcomeId>5224192A3E4</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>B6DF6ABE-96DC-4F27-A19A-F1CB2F6D25C0</gtr:id><gtr:title>Attention in neglect and extinction: assessing the degree of correspondence between visual and auditory impairments using matched tasks.</gtr:title><gtr:parentPublicationTitle>Journal of clinical and experimental neuropsychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/030c670ba7ba7f979dd79ebd5bf0c85d"><gtr:id>030c670ba7ba7f979dd79ebd5bf0c85d</gtr:id><gtr:otherNames>Barrett DJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date><gtr:issn>1380-3395</gtr:issn><gtr:outcomeId>83B514CAF57</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>79797A0D-772B-41E8-8BBA-8A7B4EF12CB5</gtr:id><gtr:title>Presentation modality influences behavioral measures of alerting, orienting, and executive control.</gtr:title><gtr:parentPublicationTitle>Journal of the International Neuropsychological Society : JINS</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/35c34ed729fbda00ed41955e94795c37"><gtr:id>35c34ed729fbda00ed41955e94795c37</gtr:id><gtr:otherNames>Roberts KL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2006-01-01</gtr:date><gtr:issn>1355-6177</gtr:issn><gtr:outcomeId>293FB7CF802</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>63B4C5F3-E458-4EDB-BB80-D7ACFC6E9700</gtr:id><gtr:title>Examining the role of frequency specificity in the enhancement and suppression of human cortical activity by auditory selective attention.</gtr:title><gtr:parentPublicationTitle>Hearing research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/442c0f9898536fabbec3851d1b9362ec"><gtr:id>442c0f9898536fabbec3851d1b9362ec</gtr:id><gtr:otherNames>Paltoglou AE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>0378-5955</gtr:issn><gtr:outcomeId>056798CA719</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>8D949E5E-5544-4263-86C9-602CE8549E18</gtr:id><gtr:title>Examining a supramodal network for conflict processing: a systematic review and novel functional magnetic resonance imaging data for related visual and auditory stroop tasks.</gtr:title><gtr:parentPublicationTitle>Journal of cognitive neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/35c34ed729fbda00ed41955e94795c37"><gtr:id>35c34ed729fbda00ed41955e94795c37</gtr:id><gtr:otherNames>Roberts KL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>0898-929X</gtr:issn><gtr:outcomeId>BD010EB20EE</gtr:outcomeId></gtr:publication><gtr:publication><gtr:id>4FCAF908-6F4A-4B6B-BDB5-0D757A06D7B0</gtr:id><gtr:title>Auditory Cortex 2006: the listening brain.</gtr:title><gtr:parentPublicationTitle>Hearing research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.ukri.org:80/person/fd3be258471e0c0e3dd79d3406359b5f"><gtr:id>fd3be258471e0c0e3dd79d3406359b5f</gtr:id><gtr:otherNames>Moore D</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2007-01-01</gtr:date><gtr:issn>0378-5955</gtr:issn><gtr:outcomeId>3D1F7DE4193</gtr:outcomeId></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">MC_U135079243</gtr:identifier></gtr:identifiers><gtr:healthCategories><gtr:healthCategory><gtr:id>3C193D18-12BD-4B15-8347-037BA623E0FF</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Mental Health</gtr:text></gtr:healthCategory></gtr:healthCategories><gtr:researchActivities><gtr:researchActivity><gtr:id>878A242A-6B84-462E-BEA5-346583F6CA54</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>1.2  Psychological and socioeconomic processes</gtr:text></gtr:researchActivity></gtr:researchActivities><gtr:researchSubjects/><gtr:researchTopics/><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>